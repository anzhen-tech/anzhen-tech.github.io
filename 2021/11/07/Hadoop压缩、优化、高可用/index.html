<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
        
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title>Hadoop压缩、优化、高可用 |  anzhen.tech</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/favicon.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css"
      />
      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
      <meta name="baidu-site-verification" content="code-BgeZtJHZzY" />
      <meta name="google-site-verification" content="wNOxVwDPcgD6IwrCt_pD_Xtq-E86p8USRXPN73jLu0A" />
    <link rel="alternate" href="/atom.xml" title="anzhen.tech" type="application/atom+xml">
</head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      <section class="outer">
  <article
  id="post-Hadoop压缩、优化、高可用"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  Hadoop压缩、优化、高可用
</h1>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/11/07/Hadoop%E5%8E%8B%E7%BC%A9%E3%80%81%E4%BC%98%E5%8C%96%E3%80%81%E9%AB%98%E5%8F%AF%E7%94%A8/" class="article-date">
  <time datetime="2021-11-07T00:10:55.000Z" itemprop="datePublished">2021-11-07</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hadoop/">Hadoop</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">10.9k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">45 分钟</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Hadoop压缩、优化、高可用"><a href="#Hadoop压缩、优化、高可用" class="headerlink" title="Hadoop压缩、优化、高可用"></a>Hadoop压缩、优化、高可用</h1><h1 id="一、Hadoop数据压缩"><a href="#一、Hadoop数据压缩" class="headerlink" title="一、Hadoop数据压缩"></a>一、Hadoop数据压缩</h1><h2 id="1-1-概述"><a href="#1-1-概述" class="headerlink" title="1.1 概述"></a>1.1 概述</h2><h3 id="1-1-1-压缩概述"><a href="#1-1-1-压缩概述" class="headerlink" title="1.1.1 压缩概述"></a>1.1.1 压缩概述</h3><ul>
<li>压缩技术能够有效减少底层存储系统（HDFS）读写字节数。压缩提高了网络带宽和磁盘空间的效率。在运行MR程序时，I/O操作、网络数据传输、 Shuffle和Merge要花大量的时间，尤其是数据规模很大和工作负载密集的情况下，因此，使用数据压缩显得非常重要。</li>
<li>鉴于磁盘I/O和网络带宽是Hadoop的宝贵资源，数据压缩对于节省资源、最小化磁盘I/O和网络传输非常有帮助。可以在任意MapReduce阶段启用压缩。不过，尽管压缩与解压操作的CPU开销不高，其性能的提升和资源的节省并非没有代价。<h2 id="1-1-2-压缩策略和原则"><a href="#1-1-2-压缩策略和原则" class="headerlink" title="1.1.2 压缩策略和原则"></a>1.1.2 压缩策略和原则</h2></li>
<li>压缩是提高Hadoop运行效率的一种优化策略</li>
<li>通过对Mapper、Reducer运行过程的数据进行压缩，以减少磁盘IO，提高MR程序运行速度</li>
<li>注意：采用压缩技术减少了磁盘IO，但同时增加了CPU运算负担。所以，压缩特性运用得当能提高性能，但运用不当也可能降低性能</li>
<li>压缩基本原则<ul>
<li>运算密集型的job，少用压缩</li>
<li>IO密集型的job，多用压缩</li>
</ul>
</li>
</ul>
<hr>
<h2 id="1-2-MR支持的压缩编码"><a href="#1-2-MR支持的压缩编码" class="headerlink" title="1.2 MR支持的压缩编码"></a>1.2 MR支持的压缩编码</h2><ul>
<li>支持的压缩编码<table>
<thead>
<tr>
<th>压缩格式</th>
<th>hadoop自带？</th>
<th>算法</th>
<th>文件扩展名</th>
<th>是否可切分</th>
<th>换成压缩格式后，原来的程序是否需要修改</th>
</tr>
</thead>
<tbody><tr>
<td>DEFLATE</td>
<td>是，直接使用</td>
<td>DEFLATE</td>
<td>.deflate</td>
<td>否</td>
<td>和文本处理一样，不需要修改</td>
</tr>
<tr>
<td>Gzip</td>
<td>是，直接使用</td>
<td>DEFLATE</td>
<td>.gz</td>
<td>否</td>
<td>和文本处理一样，不需要修改</td>
</tr>
<tr>
<td>bzip2</td>
<td>是，直接使用</td>
<td>bzip2</td>
<td>.bz2</td>
<td>是</td>
<td>和文本处理一样，不需要修改</td>
</tr>
<tr>
<td>LZO</td>
<td>否，需要安装</td>
<td>LZO</td>
<td>.lzo</td>
<td>是</td>
<td>需要建索引，还需要指定输入格式</td>
</tr>
<tr>
<td>Snappy</td>
<td>是，直接使用</td>
<td>Snappy</td>
<td>.snappy</td>
<td>否</td>
<td>和文本处理一样，不需要修改</td>
</tr>
</tbody></table>
</li>
<li>为了支持多种压缩/解压缩算法，Hadoop引入了编码/解码器，如下表所示。<table>
<thead>
<tr>
<th>压缩格式</th>
<th>对应的编码/解码器</th>
</tr>
</thead>
<tbody><tr>
<td>DEFLATE</td>
<td>org.apache.hadoop.io.compress.DefaultCodec</td>
</tr>
<tr>
<td>gzip</td>
<td>org.apache.hadoop.io.compress.GzipCodec</td>
</tr>
<tr>
<td>bzip2</td>
<td>org.apache.hadoop.io.compress.BZip2Codec</td>
</tr>
<tr>
<td>LZO</td>
<td>com.hadoop.compression.lzo.LzopCodec</td>
</tr>
<tr>
<td>Snappy</td>
<td>org.apache.hadoop.io.compress.SnappyCodec</td>
</tr>
</tbody></table>
</li>
<li>压缩性能的比较<table>
<thead>
<tr>
<th>压缩算法</th>
<th>原始文件大小</th>
<th>压缩文件大小</th>
<th>压缩速度</th>
<th>解压速度</th>
</tr>
</thead>
<tbody><tr>
<td>gzip</td>
<td>8.3GB</td>
<td>1.8GB</td>
<td>17.5MB/s</td>
<td>58MB/s</td>
</tr>
<tr>
<td>bzip2</td>
<td>8.3GB</td>
<td>1.1GB</td>
<td>2.4MB/s</td>
<td>9.5MB/s</td>
</tr>
<tr>
<td>LZO</td>
<td>8.3GB</td>
<td>2.9GB</td>
<td>49.3MB/s</td>
<td>74.6MB/s</td>
</tr>
</tbody></table>
</li>
</ul>
<hr>
<h2 id="1-3-压缩方式选择"><a href="#1-3-压缩方式选择" class="headerlink" title="1.3 压缩方式选择"></a>1.3 压缩方式选择</h2><h3 id="1-3-1-Gzip"><a href="#1-3-1-Gzip" class="headerlink" title="1.3.1 Gzip"></a>1.3.1 Gzip</h3><ul>
<li>优点：压缩率比较高，而且压缩/解压速度也比较快；Hadoop本身支持，在应用中处理Gzip格式的文件就和直接处理文本一样；大部分Linux系统都自带Gzip命令，使用方便。</li>
<li>缺点：不支持Split。</li>
<li>应用场景：当每个文件压缩之后在130M以内的（1个块大小内），都可以考虑用Gzip压缩格式。例如说一天或者一个小时的日志压缩成一个Gzip文件。</li>
</ul>
<h3 id="1-3-2-Bzip2"><a href="#1-3-2-Bzip2" class="headerlink" title="1.3.2 Bzip2"></a>1.3.2 Bzip2</h3><ul>
<li>优点：支持Split；具有很高的压缩率，比Gzip压缩率都高；Hadoop本身自带，使用方便</li>
<li>缺点：压缩/解压速度慢</li>
<li>应用场景：适合对速度要求不高，但需要较高的压缩率的时候；或者输出之后的数据比较大，处理之后的数据需要压缩存档减少磁盘空间并且以后数据用得比较少的情况；或者对单个很大的文本文件想压缩减少存储空间，同时又需要支持Split，而且兼容之前的应用程序的情况</li>
</ul>
<h3 id="1-3-3-Lzo压缩"><a href="#1-3-3-Lzo压缩" class="headerlink" title="1.3.3 Lzo压缩"></a>1.3.3 Lzo压缩</h3><ul>
<li>优点：压缩/解压速度也比较快，合理的压缩率；支持Split，是Hadoop中最流行的压缩格式；可以在Linux系统下安装lzop命令，使用方便</li>
<li>缺点：压缩率比Gzip要低一些；Hadoop本身不支持，需要安装；在应用中对Lzo格式的文件需要做一些特殊处理（为了支持Split需要建索引，还需要指定InputFormat为Lzo格式）</li>
<li>应用场景：一个很大的文本文件，压缩之后还大于200M以上的可以考虑，而且单个文件越大，Lzo优点越越明显</li>
</ul>
<h3 id="1-3-4-Snappy压缩"><a href="#1-3-4-Snappy压缩" class="headerlink" title="1.3.4 Snappy压缩"></a>1.3.4 Snappy压缩</h3><ul>
<li>优点：高速压缩速度和合理的压缩率</li>
<li>缺点：不支持Split；压缩率比Gzip要低；Hadoop本身不支持，需要安装</li>
<li>应用场景：当MapReduce作业的Map输出的数据比较大的时候，作为Map到Reduce的中间数据的压缩格式；或者作为一个MapReduce作业的输出和另外一个MapReduce作业的输入</li>
</ul>
<hr>
<h2 id="1-4-压缩位置选择"><a href="#1-4-压缩位置选择" class="headerlink" title="1.4 压缩位置选择"></a>1.4 压缩位置选择</h2><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16345428872480.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<hr>
<h2 id="1-5-压缩参数配置"><a href="#1-5-压缩参数配置" class="headerlink" title="1.5 压缩参数配置"></a>1.5 压缩参数配置</h2><p>要在Hadoop中启用压缩，可以配置如下参数：<br>|参数    |默认值    |阶段    |建议|<br>|——|——|——|—-|<br>|io.compression.codecs（在core-site.xml中配置）    |无，这个需要在命令行输入hadoop checknative查看    |输入压缩    |Hadoop使用文件扩展名判断是否支持某种编解码器|<br>|mapreduce.map.output.compress（在mapred-site.xml中配置）    |false    |mapper输出    |这个参数设为true启用压缩|<br>|mapreduce.map.output.compress.codec（在mapred-site.xml中配置）    |org.apache.hadoop.io.compress.DefaultCodec    |mapper输出    |企业多使用LZO或Snappy编解码器在此阶段压缩数据|<br>|mapreduce.output.fileoutputformat.compress（在mapred-site.xml中配置）    |false    |reducer输出    |这个参数设为true启用压缩|<br>|mapreduce.output.fileoutputformat.compress.codec（在mapred-site.xml中配置）    |org.apache.hadoop.io.compress.DefaultCodec    |reducer输出    |使用标准工具或者编解码器，如gzip和bzip2|<br>|mapreduce.output.fileoutputformat.compress.type（在mapred-site.xml中配置）    |RECORD    |reducer输出    |SequenceFile输出使用的压缩类型：NONE和BLOCK|</p>
<hr>
<h2 id="1-6-压缩实操案例"><a href="#1-6-压缩实操案例" class="headerlink" title="1.6 压缩实操案例"></a>1.6 压缩实操案例</h2><h3 id="1-6-1-数据流的压缩和解压缩"><a href="#1-6-1-数据流的压缩和解压缩" class="headerlink" title="1.6.1 数据流的压缩和解压缩"></a>1.6.1 数据流的压缩和解压缩</h3><ul>
<li>使用createOutputStream(OutputStreamout)方法创建一个CompressionOutputStream，将其以压缩格式写入底层的流</li>
<li>调用createInputStream(InputStreamin)函数，获得一个CompressionInputStream，从底层的流读取未压缩的数据</li>
</ul>
<h3 id="1-6-2-Map输出端压缩"><a href="#1-6-2-Map输出端压缩" class="headerlink" title="1.6.2 Map输出端压缩"></a>1.6.2 Map输出端压缩</h3><ul>
<li>即使MapReduce的输入输出文件都是未压缩的文件，仍然可以对Map任务的中间结果输出做压缩，因为它要写在硬盘并且通过网络传输到Reduce节点，对其压缩可以提高很多性能，这些工作只要设置两个属性即可。  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 开启map端输出压缩</span></span><br><span class="line">conf.setBoolean(<span class="string">&quot;mapreduce.map.output.compress&quot;</span>, <span class="keyword">true</span>);</span><br><span class="line"><span class="comment">// 设置map端输出压缩方式</span></span><br><span class="line">conf.setClass(<span class="string">&quot;mapreduce.map.output.compress.codec&quot;</span>, BZip2Codec.class,CompressionCodec.class);</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="1-6-3-Reduce输出端压缩"><a href="#1-6-3-Reduce输出端压缩" class="headerlink" title="1.6.3 Reduce输出端压缩"></a>1.6.3 Reduce输出端压缩</h3><pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置reduce端输出压缩开启</span></span><br><span class="line">FileOutputFormat.setCompressOutput(job, <span class="keyword">true</span>);</span><br><span class="line"><span class="comment">// 设置压缩的方式</span></span><br><span class="line">FileOutputFormat.setOutputCompressorClass(job, BZip2Codec.class); </span><br></pre></td></tr></table></figure>
</code></pre>
<h1 id="二、Hadoop性能优化"><a href="#二、Hadoop性能优化" class="headerlink" title="二、Hadoop性能优化"></a>二、Hadoop性能优化</h1><h2 id="2-1-MapReduce跑得慢的原因"><a href="#2-1-MapReduce跑得慢的原因" class="headerlink" title="2.1 MapReduce跑得慢的原因"></a>2.1 MapReduce跑得慢的原因</h2><ol>
<li>计算机性能<ul>
<li>CPU，内存，磁盘，网络···</li>
</ul>
</li>
<li>I/O操作优化<ol>
<li>数据倾斜</li>
<li>Map和Reduce数设置不合理</li>
<li>Map运行时间太长，导致Reduce等待过久</li>
<li>小文件过多</li>
<li>大量不可切片的超大压缩文件</li>
<li>Spill次数过多</li>
<li>Merge次数过多</li>
</ol>
</li>
</ol>
<h2 id="2-2-MapReduce优化"><a href="#2-2-MapReduce优化" class="headerlink" title="2.2 MapReduce优化"></a>2.2 MapReduce优化</h2><ul>
<li>MapReduce优化方法主要从六个方面考虑：数据输入、Map阶段、Reduce阶段、IO传输、数据倾斜问题、常用的调优参数</li>
</ul>
<h3 id="2-2-1-数据输入"><a href="#2-2-1-数据输入" class="headerlink" title="2.2.1 数据输入"></a>2.2.1 数据输入</h3><ol>
<li>合并小文件：执行MR任务前将小文件合并，大量小文件会产生大量Map任务，增大Map任务装载次数，而任务的装载比较耗时，从而导致MR运行较慢</li>
<li>采用CombineTextInputFormat来作为输入，解决输入端大量小文件场景</li>
</ol>
<h3 id="2-2-2-Map阶段"><a href="#2-2-2-Map阶段" class="headerlink" title="2.2.2 Map阶段"></a>2.2.2 Map阶段</h3><ol>
<li>减少溢写（Spill）次数：通过调整mapreduce.task.io.sort.mb及mapreduce.map.sort.spill.percent参数值，增大触发Spill的内存上限，减少Spill次数，从而减少磁盘IO</li>
<li>减少合并（Merge）次数：通过调整mapreduce.task.io.sort.factor参数，增大Merge的文件数目，减少Merge的次数，从而缩短MR处理时间</li>
<li>在Map之后，不影响业务逻辑前提下，先进行Combine处理，减少 I/O</li>
</ol>
<h3 id="2-2-3-Reduce阶段"><a href="#2-2-3-Reduce阶段" class="headerlink" title="2.2.3 Reduce阶段"></a>2.2.3 Reduce阶段</h3><ol>
<li>合理设置Map和Reduce数：两个都不能设置太少，也不能设置太多。太少，会导致Task等待，延长处理时间；太多，会导致Map、Reduce任务间竞争资源，造成处理超时等错误</li>
<li>设置Map、Reduce共存：调整mapreduce.job.reduce.slowstart.completedmaps参数，使Map运行到一定程度后，Reduce也开始运行，减少Reduce的等待时间</li>
<li>规避使用Reduce：因为Reduce在用于连接数据集的时候将会产生大量的网络消耗</li>
<li>合理设置Reduce端的Buffer：默认情况下，数据达到一个阈值的时候，Buffer中的数据就会写入磁盘，然后Reduce会从磁盘中获得所有的数据。也就是说，Buffer和Reduce是没有直接关联的，中间多次写磁盘-&gt;读磁盘的过程，既然有这个弊端，那么就可以通过参数来配置，使得Buffer中的一部分数据可以直接输送到Reduce，从而减少IO开销：<font color ='red' >mapreduce.reduce.input.buffer.percent，默认为0.0。当值大于0的时候，会保留指定比例的内存读Buffer中的数据直接拿给Reduce使用。这样一来，设置Buffer需要内存，读取数据需要内存，Reduce计算也要内存，所以要根据作业的运行情况进行调整</font></li>
</ol>
<h3 id="2-2-4-I-O传输"><a href="#2-2-4-I-O传输" class="headerlink" title="2.2.4 I/O传输"></a>2.2.4 I/O传输</h3><ol>
<li>采用数据压缩的方式，减少网络I/O传输的数据量，从而减少I/O传输时间，安装Snappy和LZO压缩编码器。</li>
<li>使用SequenceFile二进制文件</li>
</ol>
<h3 id="2-2-5-数据倾斜问题"><a href="#2-2-5-数据倾斜问题" class="headerlink" title="2.2.5 数据倾斜问题"></a>2.2.5 数据倾斜问题</h3><ol>
<li>数据倾斜现象<ul>
<li>数据频率倾斜——某一个区域的数据量要远远大于其他区域</li>
<li>数据大小倾斜——部分记录的大小远远大于平均值</li>
</ul>
</li>
<li>减少数据倾斜的方法<ul>
<li>方法1：抽样和范围分区<ol>
<li>可以通过对原始数据进行抽样得到的结果集来预设分区边界值</li>
</ol>
</li>
<li>方法2：自定义分区<ol>
<li>基于输出键的背景知识进行自定义分区。例如，如果Map输出键的单词来源于一本书。且其中某几个专业词汇较多。那么就可以自定义分区将这这些专业词汇发送给固定的一部分Reduce实例。而将其他的都发送给剩余的Reduce实例</li>
</ol>
</li>
<li>方法3：Combiner<ol>
<li>使用Combiner可以大量地减小数据倾斜。在可能的情况下，Combine的目的就是聚合并精简数据</li>
</ol>
</li>
<li>方法4：采用Map Join，尽量避免Reduce Join</li>
</ul>
</li>
</ol>
<h2 id="2-3常用的调优参数"><a href="#2-3常用的调优参数" class="headerlink" title="2.3常用的调优参数"></a>2.3常用的调优参数</h2><ol>
<li><p>资源相关参数：<br> 在MR应用程序中配置就可以生效（mapred-default.xml）</p>
<table>
<thead>
<tr>
<th>配置参数</th>
<th>参数说明</th>
</tr>
</thead>
<tbody><tr>
<td>mapreduce.map.memory.mb</td>
<td>一个MapTask可使用的资源上限（单位:MB），默认为1024。如果MapTask实际使用的资源量超过该值，则会被强制杀死。</td>
</tr>
<tr>
<td>mapreduce.reduce.memory.mb</td>
<td>一个ReduceTask可使用的资源上限（单位:MB），默认为1024。如果ReduceTask实际使用的资源量超过该值，则会被强制杀死。</td>
</tr>
<tr>
<td>mapreduce.map.cpu.vcores</td>
<td>每个MapTask可使用的最多cpu core数目，默认值: 1</td>
</tr>
<tr>
<td>mapreduce.reduce.cpu.vcores</td>
<td>每个ReduceTask可使用的最多cpu core数目，默认值: 1</td>
</tr>
<tr>
<td>mapreduce.reduce.shuffle.parallelcopies</td>
<td>每个Reduce去Map中取数据的并行数。默认值是5</td>
</tr>
<tr>
<td>mapreduce.reduce.shuffle.merge.percent</td>
<td>Buffer中的数据达到多少比例开始写入磁盘。默认值0.66</td>
</tr>
<tr>
<td>mapreduce.reduce.shuffle.input.buffer.percent</td>
<td>Buffer大小占Reduce可用内存的比例。默认值0.7</td>
</tr>
<tr>
<td>mapreduce.reduce.input.buffer.percent</td>
<td>指定多少比例的内存用来存放Buffer中的数据，默认值是0.0</td>
</tr>
</tbody></table>
</li>
<li><p>在YARN启动之前就配置在服务器的配置文件中才能生效（yarn-default.xml）</p>
<table>
<thead>
<tr>
<th>配置参数</th>
<th>参数说明</th>
</tr>
</thead>
<tbody><tr>
<td>yarn.scheduler.minimum-allocation-mb</td>
<td>给应用程序Container分配的最小内存，默认值：1024</td>
</tr>
<tr>
<td>yarn.scheduler.maximum-allocation-mb</td>
<td>给应用程序Container分配的最大内存，默认值：8192</td>
</tr>
<tr>
<td>yarn.scheduler.minimum-allocation-vcores</td>
<td>每个Container申请的最小CPU核数，默认值：1</td>
</tr>
<tr>
<td>yarn.scheduler.maximum-allocation-vcores</td>
<td>每个Container申请的最大CPU核数，默认值：32</td>
</tr>
<tr>
<td>yarn.nodemanager.resource.memory-mb</td>
<td>给Containers分配的最大物理内存，默认值：8192</td>
</tr>
</tbody></table>
</li>
<li><p>Shuffle性能优化的关键参数，应在YARN启动之前就配置好（mapred-default.xml）</p>
<table>
<thead>
<tr>
<th>配置参数</th>
<th>参数说明</th>
</tr>
</thead>
<tbody><tr>
<td>mapreduce.task.io.sort.mb</td>
<td>Shuffle的环形缓冲区大小，默认100m</td>
</tr>
<tr>
<td>mapreduce.map.sort.spill.percent</td>
<td>环形缓冲区溢出的阈值，默认80%</td>
</tr>
</tbody></table>
</li>
<li><p>容错相关参数（MapReduce性能优化）</p>
<table>
<thead>
<tr>
<th>配置参数</th>
<th>参数说明</th>
</tr>
</thead>
<tbody><tr>
<td>mapreduce.map.maxattempts</td>
<td>每个Map Task最大重试次数，一旦重试次数超过该值，则认为Map Task运行失败，默认值：4。</td>
</tr>
<tr>
<td>mapreduce.reduce.maxattempts</td>
<td>每个Reduce Task最大重试次数，一旦重试次数超过该值，则认为Map Task运行失败，默认值：4。</td>
</tr>
<tr>
<td>mapreduce.task.timeout</td>
<td>Task超时时间，经常需要设置的一个参数，该参数表达的意思为：如果一个Task在一定时间内没有任何进入，即不会读取新的数据，也没有输出数据，则认为该Task处于Block状态，可能是卡住了，也许永远会卡住，为了防止因为用户程序永远Block住不退出，则强制设置了一个该超时时间（单位毫秒），默认是600000（10分钟）。如果你的程序对每条输入数据的处理时间过长（比如会访问数据库，通过网络拉取数据等），建议将该参数调大，该参数过小常出现的错误提示是：“AttemptID:attempt_14267829456721_123456_m_000224_0 Timed out after 300 secsContainer killed by the ApplicationMaster.”。</td>
</tr>
</tbody></table>
</li>
</ol>
<h2 id="2-4-Hadoop小文件优化方法"><a href="#2-4-Hadoop小文件优化方法" class="headerlink" title="2.4 Hadoop小文件优化方法"></a>2.4 Hadoop小文件优化方法</h2><h3 id="2-4-1-Hadoop小文件弊端"><a href="#2-4-1-Hadoop小文件弊端" class="headerlink" title="2.4.1 Hadoop小文件弊端"></a>2.4.1 Hadoop小文件弊端</h3><ul>
<li>HDFS上每个文件都要在NameNode上创建对应的元数据，这个元数据的大小约为150byte，这样当小文件比较多的时候，就会产生很多的元数据文件，一方面会大量占用NameNode的内存空间，另一方面就是元数据文件过多，使得寻址索引速度变慢。</li>
<li>小文件过多，在进行MR计算时，会生成过多切片，需要启动过多的MapTask。每个MapTask处理的数据量小，导致MapTask的处理时间比启动时间还小，白白消耗资源。<h3 id="2-4-2-Hadoop小文件解决方案"><a href="#2-4-2-Hadoop小文件解决方案" class="headerlink" title="2.4.2 Hadoop小文件解决方案"></a>2.4.2 Hadoop小文件解决方案</h3></li>
</ul>
<ol>
<li>小文件优化的方向：<ul>
<li>（1）在数据采集的时候，就将小文件或小批数据合成大文件再上传HDFS。</li>
<li>（2）在业务处理之前，在HDFS上使用MapReduce程序对小文件进行合并。</li>
<li>（3）在MapReduce处理时，可采用CombineTextInputFormat提高效率。</li>
<li>（4）开启uber模式，实现jvm重用</li>
</ul>
</li>
<li>Hadoop Archive<ul>
<li>是一个高效的将小文件放入HDFS块中的文件存档工具，能够将多个小文件打包成一个HAR文件，从而达到减少NameNode的内存使用</li>
</ul>
</li>
<li>SequenceFile<ul>
<li>SequenceFile是由一系列的二进制k/v组成，如果为key为文件名，value为文件内容，可将大批小文件合并成一个大文件</li>
</ul>
</li>
<li>CombineTextInputFormat<ul>
<li>CombineTextInputFormat用于将多个小文件在切片过程中生成一个单独的切片或者少量的切片。 </li>
</ul>
</li>
<li>开启uber模式，实现jvm重用。默认情况下，每个Task任务都需要启动一个jvm来运行，如果Task任务计算的数据量很小，我们可以让同一个Job的多个Task运行在一个Jvm中，不必为每个Task都开启一个Jvm. <ul>
<li>开启uber模式，在mapred-site.xml中添加如下配置  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!--  开启uber模式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.ubertask.enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- uber模式中最大的mapTask数量，可向下修改  --&gt;</span> </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.ubertask.maxmaps<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>9<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- uber模式中最大的reduce数量，可向下修改 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.ubertask.maxreduces<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- uber模式中最大的输入数据量，默认使用dfs.blocksize 的值，可向下修改 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.ubertask.maxbytes<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span><span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h1 id="三、Hadoop新特性"><a href="#三、Hadoop新特性" class="headerlink" title="三、Hadoop新特性"></a>三、Hadoop新特性</h1><h2 id="3-1-Hadoop2-x新特性"><a href="#3-1-Hadoop2-x新特性" class="headerlink" title="3.1 Hadoop2.x新特性"></a>3.1 Hadoop2.x新特性</h2><h3 id="3-1-1-集群间数据拷贝"><a href="#3-1-1-集群间数据拷贝" class="headerlink" title="3.1.1 集群间数据拷贝"></a>3.1.1 集群间数据拷贝</h3><ul>
<li>采用distcp命令实现两个Hadoop集群之间的递归数据复制<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 ~]$ hadoop distcp hdfs://hadoop002:9820/WeCom_3.1.18.90318.dmg hdfs://hadoop002:9820/testDistct</span><br><span class="line">···</span><br><span class="line">···</span><br><span class="line">2021-10-19 17:56:03,705 INFO mapreduce.Job: Job job_1634633871057_0003 completed successfully</span><br><span class="line">2021-10-19 17:56:03,754 INFO mapreduce.Job: Counters: 36</span><br><span class="line">	File System Counters</span><br><span class="line">		FILE: Number of bytes <span class="built_in">read</span>=0</span><br><span class="line">		FILE: Number of bytes written=227128</span><br><span class="line">		FILE: Number of <span class="built_in">read</span> operations=0</span><br><span class="line">		FILE: Number of large <span class="built_in">read</span> operations=0</span><br><span class="line">		FILE: Number of write operations=0</span><br><span class="line">		HDFS: Number of bytes <span class="built_in">read</span>=325449295</span><br><span class="line">		HDFS: Number of bytes written=325448910</span><br><span class="line">		HDFS: Number of <span class="built_in">read</span> operations=19</span><br><span class="line">		HDFS: Number of large <span class="built_in">read</span> operations=0</span><br><span class="line">		HDFS: Number of write operations=5</span><br><span class="line">	Job Counters</span><br><span class="line">		Launched map tasks=1</span><br><span class="line">		Other <span class="built_in">local</span> map tasks=1</span><br><span class="line">		Total time spent by all maps <span class="keyword">in</span> occupied slots (ms)=5517</span><br><span class="line">		Total time spent by all reduces <span class="keyword">in</span> occupied slots (ms)=0</span><br><span class="line">		Total time spent by all map tasks (ms)=5517</span><br><span class="line">		Total vcore-milliseconds taken by all map tasks=5517</span><br><span class="line">		Total megabyte-milliseconds taken by all map tasks=5649408</span><br><span class="line">	Map-Reduce Framework</span><br><span class="line">		Map input records=1</span><br><span class="line">		Map output records=0</span><br><span class="line">		Input split bytes=136</span><br><span class="line">		Spilled Records=0</span><br><span class="line">		Failed Shuffles=0</span><br><span class="line">		Merged Map outputs=0</span><br><span class="line">		GC time elapsed (ms)=52</span><br><span class="line">		CPU time spent (ms)=1730</span><br><span class="line">		Physical memory (bytes) snapshot=270876672</span><br><span class="line">		Virtual memory (bytes) snapshot=2578894848</span><br><span class="line">		Total committed heap usage (bytes)=217055232</span><br><span class="line">		Peak Map Physical memory (bytes)=270876672</span><br><span class="line">		Peak Map Virtual memory (bytes)=2578894848</span><br><span class="line">	File Input Format Counters</span><br><span class="line">		Bytes Read=249</span><br><span class="line">	File Output Format Counters</span><br><span class="line">		Bytes Written=0</span><br><span class="line">	DistCp Counters</span><br><span class="line">		Bandwidth <span class="keyword">in</span> Btyes=81362227</span><br><span class="line">		Bytes Copied=325448910</span><br><span class="line">		Bytes Expected=325448910</span><br><span class="line">		Files Copied=1</span><br><span class="line">[atguigu@hadoop001 ~]$</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="3-1-2-小文件存档"><a href="#3-1-2-小文件存档" class="headerlink" title="3.1.2 小文件存档"></a>3.1.2 小文件存档</h3><ol>
<li>HDFS存储小文件弊端<ul>
<li>每个文件均按块存储，每个块的元数据存储在NameNode的内存中，因此HDFS存储小文件会非常低效。因为大量的小文件会耗尽NameNode中的大部分内存。但注意，存储小文件所需要的磁盘容量和数据块的大小无关。例如，一个1MB的文件设置为128MB的块存储，实际使用的是1MB的磁盘空间，而不是128MB</li>
</ul>
</li>
<li>解决存储小文件办法之一<ul>
<li>HDFS存档文件或HAR文件，是一个更高效的文件存档工具，它将文件存入HDFS块，在减少NameNode内存使用的同时，允许对文件进行透明的访问。具体说来，HDFS存档文件对内还是一个一个独立文件，对NameNode而言却是一个整体，减少了NameNode的内存<br><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16346376074095.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
</ul>
</li>
<li>案例实操<ul>
<li>归档文件:把/user/atguigu/input目录里面的所有文件归档成一个叫input.har的归档文件，并把归档后文件存储到/user/atguigu/output路径下。  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop archive -archiveName input.har -p  /user/atguigu/input   /user/atguigu/output</span><br></pre></td></tr></table></figure></li>
<li>查看归档  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -ls /user/atguigu/output/input.har</span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -ls har:///user/atguigu/output/input.har</span><br></pre></td></tr></table></figure></li>
<li>解归档文件  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -cp har:/// user/atguigu/output/input.har/*    /user/atguigu</span><br></pre></td></tr></table></figure>
<h3 id="3-1-2-回收站"><a href="#3-1-2-回收站" class="headerlink" title="3.1.2 回收站"></a>3.1.2 回收站</h3></li>
</ul>
</li>
</ol>
<ul>
<li>开启回收站功能，可以将删除的文件在不超时的情况下，恢复原数据，起到防止误删除、备份等作用</li>
<li>开启回收站功能参数说明<ol>
<li>默认值fs.trash.interval=0，0表示禁用回收站;其他值表示设置文件的存活时间</li>
<li>默认值fs.trash.checkpoint.interval=0，检查回收站的间隔时间。如果该值为0，则该值设置和fs.trash.interval的参数值相等</li>
<li>要求fs.trash.checkpoint.interval&lt;=fs.trash.interval</li>
</ol>
</li>
<li>回收站工作机制<br>  <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16346388522940.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>回收站使用<ol>
<li>启用回收站：修改core-site.xml，配置垃圾回收时间为1分钟。 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.checkpoint.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>查看回收站 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#回收站目录在hdfs集群中的路径：</span></span><br><span class="line">/user/atguigu/.Trash/</span><br></pre></td></tr></table></figure></li>
<li>通过程序删除的文件不会经过回收站，需要调用moveToTrash()才进入回收站 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Trash trash = <span class="function">New <span class="title">Trash</span><span class="params">(conf)</span></span>;</span><br><span class="line">trash.moveToTrash(path);</span><br></pre></td></tr></table></figure></li>
<li>通过网页上直接删除的文件也不会走回收站。</li>
<li>只有在命令行利用hadoop fs -rm命令删除的文件才会走回收站。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -rm -r /user/atguigu/input</span><br><span class="line">2020-07-14 16:13:42,643 INFO fs.TrashPolicyDefault: Moved: <span class="string">&#x27;hdfs://hadoop102:9820/user/atguigu/input&#x27;</span> to trash at: hdfs://hadoop102:9820/user/atguigu/.Trash/Current/user/atguigu/input</span><br></pre></td></tr></table></figure></li>
<li>恢复回收站数据 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -mv /user/atguigu/.Trash/Current/user/atguigu/input    /user/atguigu/input</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ul>
<h2 id="3-2-Hadoop3-x新特性"><a href="#3-2-Hadoop3-x新特性" class="headerlink" title="3.2 Hadoop3.x新特性"></a>3.2 Hadoop3.x新特性</h2><h3 id="3-2-1-多NN的HA架构"><a href="#3-2-1-多NN的HA架构" class="headerlink" title="3.2.1 多NN的HA架构"></a>3.2.1 多NN的HA架构</h3><ul>
<li>HDFS NameNode高可用性的初始实现为单个活动NameNode和单个备用NameNode，将edits复制到三个JournalNode。该体系结构能够容忍系统中一个NN或一个JN的故障。但是，某些部署需要更高程度的容错能力。</li>
<li>Hadoop3.x允许用户运行多个备用NameNode。例如，通过配置三个NameNode和五个JournalNode，群集能够容忍两个节点而不是一个节点的故障。<h3 id="3-2-2-纠删码"><a href="#3-2-2-纠删码" class="headerlink" title="3.2.2 纠删码"></a>3.2.2 纠删码</h3></li>
<li>HDFS中的默认3副本方案在存储空间和其他资源（例如，网络带宽）中具有200％的开销。但是，对于I / O活动相对较低暖和冷数据集，在正常操作期间很少访问其他块副本，但仍会消耗与第一个副本相同的资源量。</li>
<li>纠删码（Erasure Coding）能够在不到50% 的数据冗余情况下提供和3副本相同的容错能力，因此，使用纠删码作为副本机制的改进是自然而然的。</li>
<li>查看集群支持的纠删码策略：hdfs ec -listPolicies</li>
</ul>
<p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16346151537039.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<h1 id="四、HadoopHA高可用"><a href="#四、HadoopHA高可用" class="headerlink" title="四、HadoopHA高可用"></a>四、HadoopHA高可用</h1><h2 id="4-1-现有集群存在哪些问题？"><a href="#4-1-现有集群存在哪些问题？" class="headerlink" title="4.1 现有集群存在哪些问题？"></a>4.1 现有集群存在哪些问题？</h2><ol>
<li>HDFS集群 单个NN场景下NN如果故障了，整个HDFS集群就不可用（中心化集群） <ul>
<li>解决方案：配置多个NN !!!</li>
</ul>
</li>
<li>多个NN的场景下由哪一台对外进行服务？<ul>
<li>当HDFS实现多NN的高可用后，但是只有一台 NN 对外提供服务(Active)，其他的NN都是替补（Standby），当正在提供服务的NN宕机故障，其他的NN自动切换成Active状态</li>
</ul>
</li>
<li>HA实现后，元数据的管理策略是否发生改变？<ul>
<li>不改变，但是在HA的HDFS中合并 fsimage和edits编辑日志的合并工作交给Standby状态的NN去完成！</li>
</ul>
</li>
<li>2NN 在高可用的集群中还要不要？<ul>
<li>不要了！2NN的工作有Standby状态的NN完成！</li>
</ul>
</li>
<li>为了保证整个集群中的所有NN 能够共享元数据信息，会新增一个 JournalNode 服务，在集群中我们会启动多个JournalNode服务 形成一个集群，每个JournalNode服务对应一个NN。进行数共享！</li>
<li>JournalNode如何实现元数据的共享？<ul>
<li>在集群状态下，当一个请求对元数据进行更改的时候，此时Active状态的NN会处理请求，会往磁盘上的编辑日志edits文件追加记录，并且会通过当前机器的JournalNode服务同步edits日志文件。接下来请求也会被转发到Standby状态的NN上，Standby状态的NN接收到请求后，只去读取自己的JournalNode服务中保存的最新的编辑日志信息，加载内存中形成最新的元数据映像，保证一旦Active状态的NN宕机，Standby自己马上顶上后能够展示最新的元数据。  </li>
<li>到达checkPoint之后，Standby都会尝试进行合并Edit和Fsimage，以接收到的第一个为准</li>
</ul>
</li>
<li>当一台NN故障后，其他NN如何争抢上位？<ul>
<li>采用高可用集群中的自动故障转移机制来完成切换。</li>
</ul>
</li>
<li>自动故障转移的机制如何实现？</li>
</ol>
<h2 id="4-2-HDFS-HA工作机制"><a href="#4-2-HDFS-HA工作机制" class="headerlink" title="4.2 HDFS-HA工作机制"></a>4.2 HDFS-HA工作机制</h2><ul>
<li>通过多个NameNode消除单点故障<h3 id="4-2-1-HDFS-HA工作要点"><a href="#4-2-1-HDFS-HA工作要点" class="headerlink" title="4.2.1 HDFS-HA工作要点"></a>4.2.1 HDFS-HA工作要点</h3></li>
</ul>
<ol>
<li>元数据管理方式需要改变<ul>
<li>内存中各自保存一份元数据；</li>
<li>Edits日志只有Active状态的NameNode节点可以做写操作；</li>
<li>所有的NameNode都可以读取Edits；</li>
<li>共享的Edits放在一个共享存储中管理（qjournal和NFS两个主流实现）；</li>
</ul>
</li>
<li>需要一个状态管理功能模块<ul>
<li>实现了一个zkfailover，常驻在每一个namenode所在的节点，每一个zkfailover负责监控自己所在NameNode节点，利用zk进行状态标识，当需要进行状态切换时，由zkfailover来负责切换，切换时需要防止brain split现象的发生。</li>
</ul>
</li>
<li>必须保证两个NameNode之间能够ssh无密码登录</li>
<li>隔离（Fence），即同一时刻仅仅有一个NameNode对外提供服务</li>
</ol>
<h3 id="4-2-2-HDFS-HA自动故障转移工作机制"><a href="#4-2-2-HDFS-HA自动故障转移工作机制" class="headerlink" title="4.2.2 HDFS-HA自动故障转移工作机制"></a>4.2.2 HDFS-HA自动故障转移工作机制</h3><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16346403266012.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ul>
<li>自动故障转移为HDFS部署增加了两个新组件：ZooKeeper和ZKFailoverController（ZKFC）进程。</li>
<li>ZooKeeper是维护少量协调数据，通知客户端这些数据的改变和监视客户端故障的高可用服务。</li>
<li>HA的自动故障转移依赖于ZooKeeper的以下功能：<ol>
<li>故障检测<ul>
<li>集群中的每个NameNode在ZooKeeper中维护了一个会话，如果机器崩溃，ZooKeeper中的会话将终止，ZooKeeper通知另一个NameNode需要触发故障转移。</li>
</ul>
</li>
<li>现役NameNode选择<ul>
<li>ZooKeeper提供了一个简单的机制用于唯一的选择一个节点为active状态。如果目前现役NameNode崩溃，另一个节点可能从ZooKeeper获得特殊的排外锁以表明它应该成为现役NameNode。</li>
</ul>
</li>
</ol>
</li>
<li>ZKFC是自动故障转移中的另一个新组件，是ZooKeeper的客户端，也监视和管理NameNode的状态。每个运行NameNode的主机也运行了一个ZKFC进程，ZKFC负责：<ol>
<li>健康监测<ul>
<li>ZKFC使用一个健康检查命令定期地ping与之在相同主机的NameNode，只要该NameNode及时地回复健康状态，ZKFC认为该节点是健康的。如果该节点崩溃，冻结或进入不健康状态，健康监测器标识该节点为非健康的。</li>
</ul>
</li>
<li>ZooKeeper会话管理<ul>
<li>当本地NameNode是健康的，ZKFC保持一个在ZooKeeper中打开的会话。如果本地NameNode处于active状态，ZKFC也保持一个特殊的znode锁，该锁使用了ZooKeeper对短暂节点的支持，如果会话终止，锁节点将自动删除。</li>
</ul>
</li>
<li>基于ZooKeeper的选择<ul>
<li>如果本地NameNode是健康的，且ZKFC发现没有其它的节点当前持有znode锁，它将为自己获取该锁。如果成功，则它已经赢得了选择，并负责运行故障转移进程以使它的本地NameNode为Active。</li>
</ul>
</li>
</ol>
</li>
</ul>
<h2 id="4-3-HDFS-HA集群配置"><a href="#4-3-HDFS-HA集群配置" class="headerlink" title="4.3 HDFS-HA集群配置"></a>4.3 HDFS-HA集群配置</h2><h3 id="4-3-1-环境准备"><a href="#4-3-1-环境准备" class="headerlink" title="4.3.1 环境准备"></a>4.3.1 环境准备</h3><ul>
<li>准备三台服务器</li>
<li>JDK,Hadoop安装包</li>
<li>干净的集群</li>
<li>环境变量<h3 id="4-3-2-规划集群"><a href="#4-3-2-规划集群" class="headerlink" title="4.3.2 规划集群"></a>4.3.2 规划集群</h3><table>
<thead>
<tr>
<th>hadoop102</th>
<th>hadoop103</th>
<th>hadoop104</th>
</tr>
</thead>
<tbody><tr>
<td>NameNode</td>
<td>NameNode</td>
<td>NameNode</td>
</tr>
<tr>
<td>ZKFC</td>
<td>ZKFC</td>
<td>ZKFC</td>
</tr>
<tr>
<td>JournalNode</td>
<td>JournalNode</td>
<td>JournalNode</td>
</tr>
<tr>
<td>DataNode</td>
<td>DataNode</td>
<td>DataNode</td>
</tr>
<tr>
<td>ZK</td>
<td>ZK</td>
<td>ZK</td>
</tr>
<tr>
<td>-</td>
<td>ResourceManager</td>
<td>-</td>
</tr>
<tr>
<td>NodeManager</td>
<td>NodeManager</td>
<td>NodeManager</td>
</tr>
</tbody></table>
</li>
</ul>
<h3 id="4-3-3-配置HA集群"><a href="#4-3-3-配置HA集群" class="headerlink" title="4.3.3 配置HA集群"></a>4.3.3 配置HA集群</h3><ol>
<li>修改配置文件 core-site.xml  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 把多个NameNode的地址组装成一个集群mycluster --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	  <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">&lt;!-- 指定hadoop数据的存储目录 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/ha/hadoop-3.1.3/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">&lt;!-- 配置HDFS网页登录使用的静态用户为atguigu --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>atguigu<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">&lt;!-- 配置该atguigu(superUser)允许通过代理访问的主机节点 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.atguigu.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 配置该atguigu(superUser)允许通过代理用户所属组 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.atguigu.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 配置该atguigu(superUser)允许通过代理的用户--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.atguigu.users<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>修改配置文件 hdfs-site.xml    <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- NameNode数据存储目录 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>file://$&#123;hadoop.tmp.dir&#125;/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- DataNode数据存储目录 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>file://$&#123;hadoop.tmp.dir&#125;/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- JournalNode数据存储目录 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;hadoop.tmp.dir&#125;/jn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 完全分布式HDFS集群名称 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 集群中NameNode节点都有哪些 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>nn1,nn2,nn3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- NameNode的RPC通信地址 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:9820<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103:9820<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.nn3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:9820<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- NameNode的Web通信地址 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.nn3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 指定NameNode元数据在JournalNode上的存放位置 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://hadoop102:8485;hadoop103:8485;hadoop104:8485/mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 访问代理类：client用于确定哪个NameNode为Active --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 --&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>sshfence<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 使用隔离机制时需要ssh秘钥登录--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">		<span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/atguigu/.ssh/id_rsa<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	</span><br><span class="line">  <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>修改每一台机器的HADOOP_HOME 的环境变量打开 /etc/profile.d/set_evn.sh 修改如下： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HADOOP_HOME=/opt/module/ha/hadoop-3.1.3</span><br></pre></td></tr></table></figure></li>
<li>将/opt/ha/hadoop-3.1.3 分发到103 和 104 并且修改103和104的 HADOOP_HOME=/opt/module/ha/hadoop-3.1.3<ul>
<li>注意：修改完环境变量后一定要重新加载 profile 文件</li>
</ul>
</li>
<li>在102、103、104 各个JournalNode节点上，输入以下命令启动journalnode服务 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs --daemon start journalnode</span><br></pre></td></tr></table></figure></li>
<li>在 hadoop102的 nn1 上，对其进行格式化，并启动 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br><span class="line">hdfs --daemon start namenode</span><br></pre></td></tr></table></figure></li>
<li>分别在 hadoop103的nn2 和 hadoop104的nn3上，同步nn1的元数据信息 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -bootstrapStandby</span><br></pre></td></tr></table></figure></li>
<li>分别在 hadoop103上启动nn2 和 hadoop104上启动nn3 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs --daemon start namenode</span><br></pre></td></tr></table></figure></li>
<li>通过web地址访问nn1 nn2 nn3    <ul>
<li>nn1:<a target="_blank" rel="noopener" href="http://hadoop102:9870/">http://hadoop102:9870</a></li>
<li>nn2:<a target="_blank" rel="noopener" href="http://hadoop103:9870/">http://hadoop103:9870</a></li>
<li>nn3:<a target="_blank" rel="noopener" href="http://hadoop104:9870/">http://hadoop104:9870</a></li>
</ul>
</li>
<li>在每台机器上启动DN <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">    hdfs --daemon start datanode</span><br><span class="line">    ```   </span><br><span class="line">9. 将其中的一个nn切换成Active状态</span><br><span class="line">    ```bash</span><br><span class="line">    hdfs haadmin -transitionToActive nn1</span><br></pre></td></tr></table></figure></li>
<li>查看是否Active<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs haadmin -getServiceState nn1</span><br></pre></td></tr></table></figure>
<h3 id="4-3-4-实现HA的故障自动转移"><a href="#4-3-4-实现HA的故障自动转移" class="headerlink" title="4.3.4 实现HA的故障自动转移"></a>4.3.4 实现HA的故障自动转移</h3></li>
<li>在core-site.xml文件中增加 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定zkfc要连接的zkServer地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:2181,hadoop103:2181,hadoop104:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>在hdfs-site.xml中增加 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 启用nn故障自动转移 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>修改后分发配置文件<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">   xsync /opt/module/ha/hadoop-3.1.3/etc/hadoop </span><br><span class="line">   ```   </span><br><span class="line">4. 关闭HDFS集群</span><br><span class="line">   ```bash</span><br><span class="line">   stop-dfs.sh</span><br></pre></td></tr></table></figure></li>
<li>启动Zookeeper集群<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zk.sh start</span><br></pre></td></tr></table></figure></li>
<li>初始化HA在Zookeeper中状态<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs zkfc -formatZK</span><br></pre></td></tr></table></figure></li>
<li>启动HDFS服务<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure></li>
<li>可以去zkCli.sh客户端查看Namenode选举锁节点内容 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">get /hadoop-ha/mycluster/ActiveStandbyElectorLock</span><br></pre></td></tr></table></figure></li>
<li>测试故障自动转移<ul>
<li>将当前状态为Active的namenode 杀死</li>
<li>刷新另外两台namenode的web端，关注状态</li>
<li>最后可以到zk中验证锁内容的名称</li>
</ul>
</li>
</ol>
<h2 id="4-4-YARN-HA配置"><a href="#4-4-YARN-HA配置" class="headerlink" title="4.4 YARN-HA配置"></a>4.4 YARN-HA配置</h2><p>YARN HA 集群搭建步骤</p>
<ol>
<li>修改yarn-site.xml <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 启用resourcemanager ha --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 声明三台resourcemanager的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>cluster-yarn1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--指定resourcemanager的逻辑列表--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1,rm2,rm3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- ========== rm1的配置 ========== --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定rm1的主机名 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定rm1的web端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定rm1的 RPC 通信地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定AM向rm1申请资源的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定供NM连接的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- ========== rm2的配置 ========== --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定rm2的主机名 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- ========== rm3的配置 ========== --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定rm3的主机名 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address.rm3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address.rm3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address.rm3<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:8031<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定zookeeper集群的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:2181,hadoop103:2181,hadoop104:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 启用自动恢复,启用自动故障转移 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.recovery.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 指定resourcemanager的状态信息存储在zookeeper集群 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.store.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>将yarn-site.xml文件进行分发<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsync /opt/module/ha/hadoop-3.1.3/etc/hadoop/yarn-site.xml</span><br></pre></td></tr></table></figure></li>
<li>在任意的机器上启动yarn <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure></li>
<li>通过访问web地址验证<br> <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16346426629749.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"> </li>
<li>测试Yarn故障自动转移<ul>
<li>kill 当前active节点，会有另一个standby节点自动升级成active</li>
</ul>
</li>
</ol>
<h2 id="4-5-HDFS-Federation架构设计"><a href="#4-5-HDFS-Federation架构设计" class="headerlink" title="4.5 HDFS Federation架构设计"></a>4.5 HDFS Federation架构设计</h2><h3 id="4-5-1-NameNode架构的局限性"><a href="#4-5-1-NameNode架构的局限性" class="headerlink" title="4.5.1 NameNode架构的局限性"></a>4.5.1 NameNode架构的局限性</h3><ol>
<li>Namespace（命名空间）的限制<ul>
<li>由于NameNode在内存中存储所有的元数据（metadata），因此单个NameNode所能存储的对象（文件+块）数目受到NameNode所在JVM的heap size的限制。50G的heap能够存储20亿（200million）个对象，这20亿个对象支持4000个DataNode，12PB的存储（假设文件平均大小为40MB）。随着数据的飞速增长，存储的需求也随之增长。单个DataNode从4T增长到36T，集群的尺寸增长到8000个DataNode。存储的需求从12PB增长到大于100PB。</li>
</ul>
</li>
<li>隔离问题<ul>
<li>由于HDFS仅有一个NameNode，无法隔离各个程序，因此HDFS上的一个实验程序就很有可能影响整个HDFS上运行的程序。</li>
</ul>
</li>
<li>性能的瓶颈<ul>
<li>由于是单个NameNode的HDFS架构，因此整个HDFS文件系统的吞吐量受限于单个NameNode的吞吐量。</li>
</ul>
</li>
</ol>
<h3 id="4-5-2-HDFS-Federation架构设计"><a href="#4-5-2-HDFS-Federation架构设计" class="headerlink" title="4.5.2 HDFS Federation架构设计"></a>4.5.2 HDFS Federation架构设计</h3><p>多个NameNode集群管理不同业务线的元数据<br>| NameNode | NameNode | NameNode          |<br>| ——– | ——– | —————– |<br>| 元数据   | 元数据   | 元数据            |<br>| Log      | machine  | 电商数据/话单数据 |</p>
<p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16346432680052.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<h3 id="4-5-3-HDFS-Federation应用思考"><a href="#4-5-3-HDFS-Federation应用思考" class="headerlink" title="4.5.3 HDFS Federation应用思考"></a>4.5.3 HDFS Federation应用思考</h3><p>不同应用可以使用不同NameNode进行数据管理图片业务、爬虫业务、日志审计业务。Hadoop生态系统中，不同的框架使用不同的NameNode进行管理NameSpace。（隔离性）<br><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16346433814694.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<h3 id="4-5-4-联邦机制原理："><a href="#4-5-4-联邦机制原理：" class="headerlink" title="4.5.4 联邦机制原理："></a>4.5.4 联邦机制原理：</h3><ol>
<li>将NameNode划分成不同的命名空间并进行编号。不同的命名空间之间相互隔离互不干扰。</li>
<li>在DataNode中创建目录，此目录对应命名空间的编号。</li>
<li>由此，编号相同的数据由对应的命名空间进行管理</li>
<li>适用场景分析 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">128G(内存空间大小) * 1024(M) * 1024(KB) * 1024(bety) / 150 = xxx（元数据的数量）</span><br><span class="line">xxx * 256M（每一个文件大小） = yyy</span><br><span class="line">yyy / 1024(G) / 1024(TB) / 1024(PB) = 200 左右PB的数据</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="问答"><a href="#问答" class="headerlink" title="问答"></a>问答</h1><h3 id="一、Hadoop中的压缩作为一种常用的优化手段，经常被用在什么场景下？"><a href="#一、Hadoop中的压缩作为一种常用的优化手段，经常被用在什么场景下？" class="headerlink" title="一、Hadoop中的压缩作为一种常用的优化手段，经常被用在什么场景下？"></a>一、Hadoop中的压缩作为一种常用的优化手段，经常被用在什么场景下？</h3><ol>
<li>降低磁盘占用</li>
<li>减少网络IO</li>
</ol>
<h3 id="二、如果想要使用压缩，Hadoop如何对某一种压缩编码格式进行取舍？"><a href="#二、如果想要使用压缩，Hadoop如何对某一种压缩编码格式进行取舍？" class="headerlink" title="二、如果想要使用压缩，Hadoop如何对某一种压缩编码格式进行取舍？"></a>二、如果想要使用压缩，Hadoop如何对某一种压缩编码格式进行取舍？</h3><ol>
<li>压缩/解压的速度，资源占用</li>
<li>压缩率</li>
<li>压缩后是否支持切片</li>
</ol>
<h3 id="三、你们公司常用的压缩方式有哪些？"><a href="#三、你们公司常用的压缩方式有哪些？" class="headerlink" title="三、你们公司常用的压缩方式有哪些？"></a>三、你们公司常用的压缩方式有哪些？</h3><ol>
<li>单文件压缩后再130M以内使用gzip，如每天的日志文件，可以支持并行处理</li>
<li>单文件压缩后大于400M考虑支持切片的lzo 或者bzip</li>
</ol>
<h3 id="四、从哪些方面定位MR执行的效率（如何分析MR执行慢的原因）"><a href="#四、从哪些方面定位MR执行的效率（如何分析MR执行慢的原因）" class="headerlink" title="四、从哪些方面定位MR执行的效率（如何分析MR执行慢的原因）"></a>四、从哪些方面定位MR执行的效率（如何分析MR执行慢的原因）</h3><ol>
<li>计算机性能<ul>
<li>cpu，内存，磁盘，网络</li>
</ul>
</li>
<li>I/O操作优化<ol>
<li>数据倾斜</li>
<li>Map和Reduce数量设置不合理</li>
<li>Map运行时间过长，导致Reduce等待过久</li>
<li>小文件过多</li>
<li>大量不可切片的超大压缩文件</li>
<li>Spill次数过多</li>
<li>Merge次数过多</li>
</ol>
</li>
</ol>
<h3 id="五、如果想对MR程序进行优化，应该从哪些方面入手以及可能用到的优化手段？"><a href="#五、如果想对MR程序进行优化，应该从哪些方面入手以及可能用到的优化手段？" class="headerlink" title="五、如果想对MR程序进行优化，应该从哪些方面入手以及可能用到的优化手段？"></a>五、如果想对MR程序进行优化，应该从哪些方面入手以及可能用到的优化手段？</h3><ol>
<li>数据输入<ol>
<li>合并小文件</li>
<li>使用CombineTextInputFormat作为输入解决小文件场景</li>
</ol>
</li>
<li>Map阶段<ol>
<li>减少Spill溢写次数，调整环形缓冲区大小和触发溢写的内存上限，减少磁盘IO</li>
<li>减少Merge合并次数：调整一次merge合并的Spill溢写文件数量，减少Merge次数</li>
<li>Map之后合理使用Combine，减少网络IO</li>
</ol>
</li>
<li>Reduce阶段<ol>
<li>合理设置Map和Reduce数量</li>
<li>设置Map和Reduce并行处理，减少Reduce等待时间</li>
<li>规避使用Reduce，减少连接数据集产生的网络IO</li>
<li>合理设置Reduce端的Buffer</li>
</ol>
</li>
<li>IO传输<ol>
<li>选择合适的压缩算法，减少网络I\O传输的数据量</li>
<li>使用sequenceFile二进制文件</li>
</ol>
</li>
<li>数据倾斜<ol>
<li>对原始数据进行抽样得到结果集来预设分区边界值</li>
<li>根据业务分析自定义分区</li>
<li>使用combiner减少数据倾斜</li>
<li>尽量使用MapJoin，避免ReduceJoin</li>
</ol>
</li>
<li>参数调优<ol>
<li>MR源相关配置：MapTask和ReduceTask使用的内存，cpu</li>
<li>Yarn资源配置：Container使用的内存，cpu</li>
<li>Shuffer配置：环形缓冲区的大小，触发溢写的内存比例</li>
<li>容错配置：任务重试次数，超时时间</li>
</ol>
</li>
</ol>
<h3 id="六、在Hadoop针对小文件的处理方案有哪些？"><a href="#六、在Hadoop针对小文件的处理方案有哪些？" class="headerlink" title="六、在Hadoop针对小文件的处理方案有哪些？"></a>六、在Hadoop针对小文件的处理方案有哪些？</h3><ol>
<li>数据采集的时候，将小文件或小批数据合并成大文件在上传HDFS，从源头上避免小文件产生</li>
<li>业务处理之前，使用MapReduce程序对HDFS上的小文件进行合并</li>
<li>使用CombineTextInputFormat处理小文件的输入</li>
<li>开启uber模式，实现jvm重用</li>
</ol>
<h3 id="七、如何解决MR中Reduce的数据倾斜问题？"><a href="#七、如何解决MR中Reduce的数据倾斜问题？" class="headerlink" title="七、如何解决MR中Reduce的数据倾斜问题？"></a>七、如何解决MR中Reduce的数据倾斜问题？</h3><ol>
<li>对原始数据进行抽样得到结果集来预设分区边界值</li>
<li>根据业务分析自定义分区</li>
<li>使用combiner减少数据倾斜</li>
<li>尽量使用MapJoin，避免ReduceJoin</li>
</ol>
<h3 id="八、大概简述一下-Hadoop每一代版本的新特性？"><a href="#八、大概简述一下-Hadoop每一代版本的新特性？" class="headerlink" title="八、大概简述一下 Hadoop每一代版本的新特性？"></a>八、大概简述一下 Hadoop每一代版本的新特性？</h3><ol>
<li>Hadoop 2.x<ul>
<li>distcp命令实现两个Hadoop集群之间的递归数据复制</li>
<li>小文件存档</li>
<li>回收站</li>
</ul>
</li>
<li>Hadoop 3.x<ul>
<li>多NN的HA架构：提高集群的可用性</li>
<li>纠删码：降低磁盘占用</li>
</ul>
</li>
</ol>
<h3 id="九、什么是Hadoop的HA"><a href="#九、什么是Hadoop的HA" class="headerlink" title="九、什么是Hadoop的HA?"></a>九、什么是Hadoop的HA?</h3><ol>
<li>集群可实现7*24小时不中断服务</li>
<li>不存在单点故障</li>
<li>可以实现故障自动转移</li>
</ol>
<h3 id="十、描述一下HDFS-HA的工作机制？"><a href="#十、描述一下HDFS-HA的工作机制？" class="headerlink" title="十、描述一下HDFS-HA的工作机制？"></a>十、描述一下HDFS-HA的工作机制？</h3><ol>
<li>多NN消除单点故障</li>
<li>由Active状态的NN负责写操作，JournalNode负责同步Edits，Standby状态的NN读取自己的Edit，加载到内存形成完整元数据</li>
<li>Standby状态的NN负责合并Edit和FsImage</li>
<li>依赖Zookeeper实现故障自动转移</li>
</ol>
<h3 id="十一、如何实现HA的集群搭建-用话术描述即可！！！"><a href="#十一、如何实现HA的集群搭建-用话术描述即可！！！" class="headerlink" title="十一、如何实现HA的集群搭建?(用话术描述即可！！！)"></a>十一、如何实现HA的集群搭建?(用话术描述即可！！！)</h3><ol>
<li>配置集群名称</li>
<li>配置集群节点</li>
<li>配置JournalNode</li>
<li>配置zookeeper连接地址</li>
</ol>
<h3 id="十二、HDFS如何实现自动故障转移？"><a href="#十二、HDFS如何实现自动故障转移？" class="headerlink" title="十二、HDFS如何实现自动故障转移？"></a>十二、HDFS如何实现自动故障转移？</h3><ol>
<li>HDFS故障自动转移依赖zookeeper和zkfc进程</li>
<li>zookeeper实现功能<ol>
<li>故障检测：集群中的每个NameNode在ZooKeeper中维护了一个会话，如果机器崩溃，ZooKeeper中的会话将终止，ZooKeeper通知另一个NameNode触发故障转移</li>
<li>现役NameNode选择：ZooKeeper提供了一个简单的机制用于唯一的选择一个节点为active状态。如果目前现役NameNode崩溃，另一个节点可能从ZooKeeper获得特殊的排外锁以表明它应该成为现役NameNode</li>
</ol>
</li>
<li>zkfc进程是ZooKeeper的客户端，也监视和管理NameNode的状态。每个运行NameNode的主机也运行了一个ZKFC进程，ZKFC负责：<ol>
<li>健康监测<ul>
<li>ZKFC使用一个健康检查命令定期地ping与之在相同主机的NameNode，只要该NameNode及时地回复健康状态，ZKFC认为该节点是健康的。如果该节点崩溃，冻结或进入不健康状态，健康监测器标识该节点为非健康的。</li>
</ul>
</li>
<li>ZooKeeper会话管理<ul>
<li>当本地NameNode是健康的，ZKFC保持一个在ZooKeeper中打开的会话。如果本地NameNode处于active状态，ZKFC也保持一个特殊的znode锁，该锁使用了ZooKeeper对短暂节点的支持，如果会话终止，锁节点将自动删除。</li>
</ul>
</li>
<li>基于ZooKeeper的选择<ul>
<li>如果本地NameNode是健康的，且ZKFC发现没有其它的节点当前持有znode锁，它将为自己获取该锁。如果成功，则它已经赢得了选择，并负责运行故障转移进程以使它的本地NameNode为Active。</li>
</ul>
</li>
</ol>
</li>
</ol>
<h3 id="十三、什么是脑裂问题？HDFS-HA中如何解决的脑裂问题？"><a href="#十三、什么是脑裂问题？HDFS-HA中如何解决的脑裂问题？" class="headerlink" title="十三、什么是脑裂问题？HDFS-HA中如何解决的脑裂问题？"></a>十三、什么是脑裂问题？HDFS-HA中如何解决的脑裂问题？</h3><ol>
<li>active节点的zkfc进程检测到namenode异常，会通知另一台NameNode的zkfc</li>
<li>接收通知的zkf会通过ssh在异常namenode上执行kill命令，确保异常NameNode死透</li>
<li>避免了出现两个active节点，解决了脑裂问题</li>
</ol>
<h3 id="十四、YARN-HA-实现高可用的思路"><a href="#十四、YARN-HA-实现高可用的思路" class="headerlink" title="十四、YARN-HA 实现高可用的思路"></a>十四、YARN-HA 实现高可用的思路</h3><ol>
<li>ResourceManager启动时候会向ZK的/rmstore目录写lock文件，写成功就为active，否则standby.</li>
<li>ResourceManager节点zkfc会一直监控这个lock文件是否存在，假如不存在，就为active，否则为standby.</li>
<li>zookeeper存储RMStateStore。选举active RM。</li>
<li>RMStateStore: 存储在zk的/rmstore目录下。</li>
<li>activeRM会向这个目录写APP信息</li>
<li>当activeRM挂了，另外一个standby RM通过ZKFC选举成功为active，会从/rmstore读取相应的作业信息。重新构建作业的内存信息，启动内部的服务，开始接收NM的心跳，构建集群的资源信息，并且接收客户端的作业提交请求。</li>
</ol>
<h3 id="十五、简单说一下-联邦架构-HDFS-Federation-架构设计思想。-了解"><a href="#十五、简单说一下-联邦架构-HDFS-Federation-架构设计思想。-了解" class="headerlink" title="十五、简单说一下 联邦架构(HDFS Federation) 架构设计思想。(了解)"></a>十五、简单说一下 联邦架构(HDFS Federation) 架构设计思想。(了解)</h3><ol>
<li>解决Namespace（命名空间）的限制</li>
<li>解决隔离问题</li>
<li>解决性能的瓶颈</li>
<li>将NameNode划分成不同的命名空间并进行编号。不同的命名空间之间相互隔离互不干扰。</li>
<li>在DataNode中创建目录，此目录对应命名空间的编号。</li>
<li>由此，编号相同的数据由对应的命名空间进行管理</li>
</ol>
<p>空间进行管理</p>
 
      <!-- reward -->
      
      <div id="reword-out">
        <div id="reward-btn">
          打赏
        </div>
      </div>
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>版权声明： </strong>
          
          本博客所有文章除特别声明外，著作权归作者所有。转载请注明出处！
          
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://anzhen-tech.github.io/2021/11/07/Hadoop%E5%8E%8B%E7%BC%A9%E3%80%81%E4%BC%98%E5%8C%96%E3%80%81%E9%AB%98%E5%8F%AF%E7%94%A8/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/" rel="tag">Hadoop</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/2021/11/07/Hive%E8%BF%9B%E9%98%B6/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            Hive进阶
          
        </div>
      </a>
    
    
      <a href="/2021/11/07/Zookeeper/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">Zookeeper</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "XCKHv09pYxF5EmF2ezNgFfLS-gzGzoHsz",
    app_key: "gyCHBp787fNNfXDiHGIcj7Am",
    path: window.location.pathname,
    avatar: "monsterid",
    placeholder: "给我的文章加点评论吧~",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
   
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2019-2021
        <i class="ri-heart-fill heart_icon"></i> Anzhen
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src=''></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="anzhen.tech"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/HDFS">HDFS</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Yarn">Yarn</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/MR">MR</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Hive">Hive</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86">数据采集</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/HBase">HBase</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Kafka">Kafka</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Spark">Spark</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Flink">Flink</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/MySQL">MySQL</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Java">Java</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/interview">面试宝典</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/2019/11/07/about-me">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.png">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.png">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->
 
<script src="/js/tocbot.min.js"></script>

<script>
  tocbot.init({
    tocSelector: ".tocbot",
    contentSelector: ".article-entry",
    headingSelector: "h1, h2, h3, h4, h5, h6",
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: "main",
    positionFixedSelector: ".tocbot",
    positionFixedClass: "is-position-fixed",
    fixedSidebarOffset: "auto",
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->
 <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  var ayerConfig = {
    mathjax: true,
  };
</script>

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    <div id="music">
    
    
    
    <iframe frameborder="no" border="1" marginwidth="0" marginheight="0" width="200" height="52"
        src="//music.163.com/outchain/player?type=2&id=318916815&auto=1&height=32"></iframe>
</div>

<style>
    #music {
        position: fixed;
        right: 15px;
        bottom: 0;
        z-index: 998;
    }
</style>
    
    

  </div>
</body>

</html>
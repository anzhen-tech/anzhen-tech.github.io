<!DOCTYPE html>


<html lang="zh-CN">
  

    <head>
      <meta charset="utf-8" />
        
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title> anzhen.tech</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/favicon.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css"
      />
      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
      <meta name="baidu-site-verification" content="code-BgeZtJHZzY" />
      <meta name="google-site-verification" content="wNOxVwDPcgD6IwrCt_pD_Xtq-E86p8USRXPN73jLu0A" />
    <link rel="alternate" href="/atom.xml" title="anzhen.tech" type="application/atom+xml">
</head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      
<section class="cover">
    
      
      <a class="forkMe" href="https://github.com/anzhen-tech"
        target="_blank"><img width="149" height="149" src="/images/forkme.png"
          class="attachment-full size-full" alt="Fork me on GitHub" data-recalc-dims="1"></a>
    
  <div class="cover-frame">
    <div class="bg-box">
      <img src="/images/cover1.jpg" alt="image frame" />
    </div>
    <div class="cover-inner text-center text-white">
      <h1><a href="/">anzhen.tech</a></h1>
      <div id="subtitle-box">
        
        <span id="subtitle"></span>
        
      </div>
      <div>
        
        <img
          src="/images/ayer.svg"
          class="cover-logo"
          alt="anzhen.tech"
        />
        
      </div>
    </div>
  </div>
  <div class="cover-learn-more">
    <a href="javascript:void(0)" class="anchor"><i class="ri-arrow-down-line"></i></a>
  </div>
</section>



<script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js"></script>


<!-- Subtitle -->

  <script>
    try {
      var typed = new Typed("#subtitle", {
        strings: ['越努力，越美好', '愿你一生努力，一生被爱', '想要的都拥有，得不到的都释怀'],
        startDelay: 0,
        typeSpeed: 200,
        loop: true,
        backSpeed: 100,
        showCursor: true
      });
    } catch (err) {
      console.log(err)
    }
  </script>
  
<div id="main">
  <section class="outer">
  
  <ul class="ads">
    
        <li>
            <a target="_blank" rel="noopener" href="https://www.aliyun.com/minisite/goods?userCode=e6rdw2zn&amp;share_source=copy_link">
                <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/WX20211107-102324@2x.png?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10" width="300" alt="阿里云服务器">
            </a>
        </li>
    
</ul>
  
  
  

<div class="notice" style="margin-top:50px">
    <i class="ri-heart-fill"></i>
    <div class="notice-content" id="broad"></div>
</div>
<script type="text/javascript">
    fetch('https://v1.hitokoto.cn')
        .then(response => response.json())
        .then(data => {
            document.getElementById("broad").innerHTML = data.hitokoto;
        })
        .catch(console.error)
</script>

<style>
    .notice {
        padding: 20px;
        border: 1px dashed #e6e6e6;
        color: #969696;
        position: relative;
        display: inline-block;
        width: 100%;
        background: #fbfbfb50;
        border-radius: 10px;
    }

    .notice i {
        float: left;
        color: #999;
        font-size: 16px;
        padding-right: 10px;
        vertical-align: middle;
        margin-top: -2px;
    }

    .notice-content {
        display: initial;
        vertical-align: middle;
    }
</style>
  
  <article class="articles">
    
    
    
    
    <article
  id="post-Hive"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/11/07/Hive/"
    >Hive</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/11/07/Hive/" class="article-date">
  <time datetime="2021-11-07T00:08:35.000Z" itemprop="datePublished">2021-11-07</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Hive/">Hive</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h1><h1 id="一、Hive基本概念"><a href="#一、Hive基本概念" class="headerlink" title="一、Hive基本概念"></a>一、Hive基本概念</h1><h2 id="1-1-什么是Hive"><a href="#1-1-什么是Hive" class="headerlink" title="1.1 什么是Hive"></a>1.1 什么是Hive</h2><p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/1456786">通俗易懂理解hive是什么</a></p>
<ol>
<li>Hive简介<ul>
<li>Hive：由Facebook开源用于解决海量结构化日志的数据统计工具。</li>
<li>Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类SQL查询功能。</li>
</ul>
</li>
<li>Hive本质：将HQL转化成MapReduce程序<ol>
<li>Hive处理的数据存储在HDFS</li>
<li>Hive分析数据底层的实现是MapReduce</li>
<li>执行程序运行在Yarn上<br><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16346965217937.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
</ol>
</li>
</ol>
<h2 id="1-2Hive的优缺点"><a href="#1-2Hive的优缺点" class="headerlink" title="1.2Hive的优缺点"></a>1.2Hive的优缺点</h2><h3 id="1-2-1-优点"><a href="#1-2-1-优点" class="headerlink" title="1.2.1 优点"></a>1.2.1 优点</h3><ol>
<li>操作接口采用类SQL语法，提供快速开发的能力（简单、容易上手）。</li>
<li>避免了去写MapReduce，减少开发人员的学习成本。</li>
<li>Hive的执行延迟比较高，因此Hive常用于数据分析，对实时性要求不高的场合。</li>
<li>Hive优势在于处理大数据，对于处理小数据没有优势，因为Hive的执行延迟比较高。</li>
<li>Hive支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。<h3 id="1-2-2-缺点"><a href="#1-2-2-缺点" class="headerlink" title="1.2.2 缺点"></a>1.2.2 缺点</h3></li>
<li>Hive的HQL表达能力有限<ol>
<li>迭代式算法无法表达</li>
<li>数据挖掘方面不擅长，由于MapReduce数据处理流程的限制，效率更高的算法却无法实现。</li>
</ol>
</li>
<li>Hive的效率比较低<ol>
<li>Hive自动生成的MapReduce作业，通常情况下不够智能化</li>
<li>Hive调优比较困难，粒度较粗</li>
</ol>
</li>
</ol>
<h2 id="1-3-Hive架构原理"><a href="#1-3-Hive架构原理" class="headerlink" title="1.3 Hive架构原理"></a>1.3 Hive架构原理</h2><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16346968536473.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ol>
<li>用户接口：Client<ul>
<li>CLI（command-line interface）、JDBC/ODBC(jdbc访问hive)、WEBUI（浏览器访问hive）</li>
</ul>
</li>
<li>元数据：Metastore<ul>
<li>元数据包括：表名、表所属的数据库（默认是default）、表的拥有者、列/分区字段、表的类型（是否是外部表）、表的数据所在目录等；</li>
<li>默认存储在自带的derby数据库中，推荐使用MySQL存储Metastore</li>
</ul>
</li>
<li>Hadoop<ul>
<li>使用HDFS进行存储，使用MapReduce进行计算。</li>
</ul>
</li>
<li>驱动器：Driver<ul>
<li>解析器（SQL Parser）：将SQL字符串转换成抽象语法树AST，这一步一般都用第三方工具库完成，比如antlr；对AST进行语法分析，比如表是否存在、字段是否存在、SQL语义是否有误。</li>
<li>编译器（Physical Plan）：将AST编译生成逻辑执行计划。</li>
<li>优化器（Query Optimizer）：对逻辑执行计划进行优化。</li>
<li>执行器（Execution）：把逻辑执行计划转换成可以运行的物理计划。对于Hive来说，就是MR/Spark。</li>
</ul>
</li>
</ol>
<h2 id="1-4-Hive和-数据库比较"><a href="#1-4-Hive和-数据库比较" class="headerlink" title="1.4 Hive和 数据库比较"></a>1.4 Hive和 数据库比较</h2><ul>
<li>由于 Hive 采用了类似SQL 的查询语言 HQL(Hive Query Language)，因此很容易将 Hive 理解为数据库。其实从结构上来看，Hive 和数据库除了拥有类似的查询语言，再无类似之处。本文将从多个方面来阐述 Hive 和数据库的差异。数据库可以用在 Online 的应用中，但是Hive 是为数据仓库而设计的，清楚这一点，有助于从应用角度理解 Hive 的特性。<h3 id="1-4-1-查询语言"><a href="#1-4-1-查询语言" class="headerlink" title="1.4.1 查询语言"></a>1.4.1 查询语言</h3></li>
<li>由于SQL被广泛的应用在数据仓库中，因此，专门针对Hive的特性设计了类SQL的查询语言HQL。熟悉SQL开发的开发者可以很方便的使用Hive进行开发。<h3 id="1-4-2-数据更新"><a href="#1-4-2-数据更新" class="headerlink" title="1.4.2 数据更新"></a>1.4.2 数据更新</h3></li>
<li>由于Hive是针对数据仓库应用设计的，而数据仓库的内容是读多写少的。因此，Hive中不建议对数据的改写，所有的数据都是在加载的时候确定好的。而数据库中的数据通常是需要经常进行修改的，因此可以使用 INSERT INTO …  VALUES 添加数据，使用 UPDATE … SET修改数据。<h3 id="1-4-3-执行延迟"><a href="#1-4-3-执行延迟" class="headerlink" title="1.4.3 执行延迟"></a>1.4.3 执行延迟</h3></li>
<li>Hive 在查询数据的时候，由于没有索引，需要扫描整个表，因此延迟较高。另外一个导致 Hive 执行延迟高的因素是 MapReduce框架。由于MapReduce 本身具有较高的延迟，因此在利用MapReduce 执行Hive查询时，也会有较高的延迟。相对的，数据库的执行延迟较低。当然，这个低是有条件的，即数据规模较小，当数据规模大到超过数据库的处理能力的时候，Hive的并行计算显然能体现出优势。<h3 id="1-4-4-数据规模"><a href="#1-4-4-数据规模" class="headerlink" title="1.4.4 数据规模"></a>1.4.4 数据规模</h3></li>
<li>由于Hive建立在集群上并可以利用MapReduce进行并行计算，因此可以支持很大规模的数据；对应的，数据库可以支持的数据规模较小。</li>
</ul>
<h1 id="二、Hive安装"><a href="#二、Hive安装" class="headerlink" title="二、Hive安装"></a>二、Hive安装</h1><h2 id="2-1-Hive安装地址"><a href="#2-1-Hive安装地址" class="headerlink" title="2.1 Hive安装地址"></a>2.1 Hive安装地址</h2><ol>
<li>Hive官网地址<ul>
<li><a target="_blank" rel="noopener" href="http://hive.apache.org/">http://hive.apache.org/</a></li>
</ul>
</li>
<li>文档查看地址<ul>
<li><a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/GettingStarted">https://cwiki.apache.org/confluence/display/Hive/GettingStarted</a></li>
</ul>
</li>
<li>下载地址<ul>
<li><a target="_blank" rel="noopener" href="http://archive.apache.org/dist/hive/">http://archive.apache.org/dist/hive/</a></li>
</ul>
</li>
<li>github地址<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/apache/hive">https://github.com/apache/hive</a></li>
</ul>
</li>
</ol>
<h2 id="2-2-MySql安装"><a href="#2-2-MySql安装" class="headerlink" title="2.2 MySql安装"></a>2.2 MySql安装</h2><ul>
<li>参考<a href="mweblib://16347028415943">Mysql安装</a></li>
</ul>
<h2 id="2-3-Hive安装部署"><a href="#2-3-Hive安装部署" class="headerlink" title="2.3 Hive安装部署"></a>2.3 Hive安装部署</h2><ol>
<li>把apache-hive-3.1.2-bin.tar.gz上传到linux的/opt/software目录下  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 software]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/software</span><br><span class="line">[atguigu@hadoop001 software]$ ll</span><br><span class="line">total 835216</span><br><span class="line">-rw-r--r--. 1 atguigu atguigu 312850286 Apr 20  2020 apache-hive-3.1.2-bin.tar.gz</span><br><span class="line">-rw-r--r--. 1 atguigu atguigu   9311744 Apr 20  2020 apache-zookeeper-3.5.7-bin.tar.gz</span><br><span class="line">-rw-r--r--. 1 atguigu atguigu 338075860 Oct  9 12:59 hadoop-3.1.3.tar.gz</span><br><span class="line">-rw-r--r--. 1 atguigu atguigu 195013152 Oct  9 12:59 jdk-8u212-linux-x64.tar.gz</span><br><span class="line">[atguigu@hadoop001 software]$</span><br></pre></td></tr></table></figure></li>
<li>解压apache-hive-3.1.2-bin.tar.gz到/opt/module/目录下面 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 software]$ tar -zxvf /opt/software/apache-hive-3.1.2-bin.tar.gz -C /opt/module/</span><br><span class="line">···</span><br><span class="line">[atguigu@hadoop001 module]$ ll</span><br><span class="line">total 0</span><br><span class="line">drwxrwxr-x.  9 atguigu atguigu 153 Oct 20 13:55 apache-hive-3.1.2-bin</span><br><span class="line">drwxr-xr-x.  9 atguigu atguigu 149 Oct 19 14:29 hadoop-3.1.3</span><br><span class="line">drwxr-xr-x. 11 atguigu atguigu 173 Oct 19 14:45 ha-hadoop-3.1.3</span><br><span class="line">drwxr-xr-x.  7 atguigu atguigu 245 Apr  2  2019 jdk1.8.0_212</span><br><span class="line">drwxrwxr-x.  8 atguigu atguigu 160 Oct 18 13:44 zookeeper-3.5.7</span><br><span class="line">[atguigu@hadoop001 module]$</span><br></pre></td></tr></table></figure></li>
<li>修改apache-hive-3.1.2-bin.tar.gz的名称为hive<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 module]$ mv apache-hive-3.1.2-bin hive-3.1.2</span><br><span class="line">[atguigu@hadoop001 module]$ ll</span><br><span class="line">total 0</span><br><span class="line">drwxr-xr-x.  9 atguigu atguigu 149 Oct 19 14:29 hadoop-3.1.3</span><br><span class="line">drwxr-xr-x. 11 atguigu atguigu 173 Oct 19 14:45 ha-hadoop-3.1.3</span><br><span class="line">drwxrwxr-x.  9 atguigu atguigu 153 Oct 20 13:55 hive-3.1.2</span><br><span class="line">drwxr-xr-x.  7 atguigu atguigu 245 Apr  2  2019 jdk1.8.0_212</span><br><span class="line">drwxrwxr-x.  8 atguigu atguigu 160 Oct 18 13:44 zookeeper-3.5.7</span><br><span class="line">[atguigu@hadoop001 module]$</span><br></pre></td></tr></table></figure></li>
<li>修改/etc/profile.d/set_env.sh，添加环境变量 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 module]$ cat /etc/profile.d/set_env.sh</span><br><span class="line"><span class="comment">#JAVA_HOME</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_212</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br><span class="line"></span><br><span class="line"><span class="comment">#HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/opt/module/ha-hadoop-3.1.3</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/sbin</span><br><span class="line"></span><br><span class="line"><span class="comment">#HIVE_HOME</span></span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/opt/module/hive-3.1.2</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HIVE_HOME</span>/bin</span><br><span class="line">[atguigu@hadoop001 module]$</span><br></pre></td></tr></table></figure></li>
<li>解决日志Jar包冲突 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 ~]$ ll <span class="variable">$HIVE_HOME</span>/lib/log4j-slf4j-impl-2.10.0.jar</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu 24173 Apr 15  2020 /opt/module/hive-3.1.2/lib/log4j-slf4j-impl-2.10.0.jar</span><br><span class="line">[atguigu@hadoop001 ~]$ mv <span class="variable">$HIVE_HOME</span>/lib/log4j-slf4j-impl-2.10.0.jar <span class="variable">$HIVE_HOME</span>/lib/log4j-slf4j-impl-2.10.0.jar_bak</span><br><span class="line">[atguigu@hadoop001 ~]$ ll <span class="variable">$HIVE_HOME</span>/lib/log4j-slf4j-impl-2.10.0.jar_bak</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu 24173 Apr 15  2020 /opt/module/hive-3.1.2/lib/log4j-slf4j-impl-2.10.0.jar_bak</span><br><span class="line">[atguigu@hadoop001 ~]$</span><br></pre></td></tr></table></figure>
<h2 id="2-4-Hive元数据配置到MySql"><a href="#2-4-Hive元数据配置到MySql" class="headerlink" title="2.4 Hive元数据配置到MySql"></a>2.4 Hive元数据配置到MySql</h2><h3 id="2-4-1-拷贝驱动"><a href="#2-4-1-拷贝驱动" class="headerlink" title="2.4.1 拷贝驱动"></a>2.4.1 拷贝驱动</h3></li>
<li>将MySQL的JDBC驱动拷贝到Hive的lib目录下 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 software]$ cp /opt/software/mysql-connector-java-8.0.25.jar <span class="variable">$HIVE_HOME</span>/lib</span><br><span class="line">[atguigu@hadoop001 software]$ ll <span class="variable">$HIVE_HOME</span>/lib/mysql-connector-java-8.0.25.jar</span><br><span class="line">-rw-r--r--. 1 atguigu atguigu 2428320 Oct 20 14:14 /opt/module/hive-3.1.2/lib/mysql-connector-java-8.0.25.jar</span><br><span class="line">[atguigu@hadoop001 software]$</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="2-4-2-配置Metastore到MySql"><a href="#2-4-2-配置Metastore到MySql" class="headerlink" title="2.4.2 配置Metastore到MySql"></a>2.4.2 配置Metastore到MySql</h3><ol>
<li>在$HIVE_HOME/conf目录下新建hive-site.xml文件添加如下内容 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- jdbc连接的URL --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://hadoop102:3306/metastore?useSSL=false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- jdbc连接的Driver--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- jdbc连接的username--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- jdbc连接的password --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- Hive默认在HDFS的工作目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- Hive元数据存储的验证 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.schema.verification<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 元数据存储授权  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.event.db.notification.api.auth<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="2-5-启动Hive"><a href="#2-5-启动Hive" class="headerlink" title="2.5 启动Hive"></a>2.5 启动Hive</h2><h3 id="2-5-1-初始化元数据库"><a href="#2-5-1-初始化元数据库" class="headerlink" title="2.5.1 初始化元数据库"></a>2.5.1 初始化元数据库</h3><ol>
<li>登陆MySQL创建Hive元数据库 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> databases;</span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------+</span></span><br><span class="line"><span class="operator">|</span> Database           <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------+</span></span><br><span class="line"><span class="operator">|</span> information_schema <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> mysql              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> performance_schema <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> sys                <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------+</span></span><br><span class="line"><span class="number">4</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">create</span> database metastore;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">show</span> databases;</span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------+</span></span><br><span class="line"><span class="operator">|</span> Database           <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------+</span></span><br><span class="line"><span class="operator">|</span> information_schema <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> metastore          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> mysql              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> performance_schema <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> sys                <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------+</span></span><br><span class="line"><span class="number">5</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>初始化Hive元数据库 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 conf]$ schematool -initSchema -dbType mysql -verbose</span><br><span class="line">Metastore connection URL:	 jdbc:mysql://mysql:3306/metastore?useSSL=<span class="literal">false</span></span><br><span class="line">Metastore Connection Driver :	 com.mysql.jdbc.Driver</span><br><span class="line">Metastore connection User:	 root</span><br><span class="line">Loading class `com.mysql.jdbc.Driver<span class="string">&#x27;. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver&#x27;</span>. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.</span><br><span class="line">Starting metastore schema initialization to 3.1.0</span><br><span class="line">Initialization script hive-schema-3.1.0.mysql.sql</span><br><span class="line">Connecting to jdbc:mysql://mysql:3306/metastore?useSSL=<span class="literal">false</span></span><br><span class="line">Connected to: MySQL (version 8.0.25)</span><br><span class="line">Driver: MySQL Connector/J (version mysql-connector-java-8.0.25 (Revision: 08be9e9b4cba6aa115f9b27b215887af40b159e0))</span><br><span class="line">Transaction isolation: TRANSACTION_READ_COMMITTED</span><br><span class="line">0: jdbc:mysql://mysql:3306/metastore&gt; !autocommit on</span><br><span class="line">Autocommit status: <span class="literal">true</span></span><br><span class="line">···</span><br><span class="line">···</span><br><span class="line">Closing: 0: jdbc:mysql://mysql:3306/metastore?useSSL=<span class="literal">false</span></span><br><span class="line">beeline&gt;</span><br><span class="line">beeline&gt; Initialization script completed</span><br><span class="line">schemaTool completed</span><br><span class="line">[atguigu@hadoop001 conf]$</span><br></pre></td></tr></table></figure></li>
<li>元数据相关表 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">desc</span> dbs;</span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------+---------------+------+-----+---------+-------+</span></span><br><span class="line"><span class="operator">|</span> Field           <span class="operator">|</span> Type          <span class="operator">|</span> <span class="keyword">Null</span> <span class="operator">|</span> Key <span class="operator">|</span> <span class="keyword">Default</span> <span class="operator">|</span> Extra <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------+---------------+------+-----+---------+-------+</span></span><br><span class="line"><span class="operator">|</span> DB_ID           <span class="operator">|</span> <span class="type">bigint</span>        <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span> PRI <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">DESC</span>            <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">4000</span>) <span class="operator">|</span> YES  <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> DB_LOCATION_URI <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">4000</span>) <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> NAME            <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">128</span>)  <span class="operator">|</span> YES  <span class="operator">|</span> MUL <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> OWNER_NAME      <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">128</span>)  <span class="operator">|</span> YES  <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> OWNER_TYPE      <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">10</span>)   <span class="operator">|</span> YES  <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> CTLG_NAME       <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">256</span>)  <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span> MUL <span class="operator">|</span> hive    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------+---------------+------+-----+---------+-------+</span></span><br><span class="line"><span class="number">7</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">desc</span> tbls;</span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------+--------------+------+-----+---------+-------+</span></span><br><span class="line"><span class="operator">|</span> Field              <span class="operator">|</span> Type         <span class="operator">|</span> <span class="keyword">Null</span> <span class="operator">|</span> Key <span class="operator">|</span> <span class="keyword">Default</span> <span class="operator">|</span> Extra <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------+--------------+------+-----+---------+-------+</span></span><br><span class="line"><span class="operator">|</span> TBL_ID             <span class="operator">|</span> <span class="type">bigint</span>       <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span> PRI <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> CREATE_TIME        <span class="operator">|</span> <span class="type">int</span>          <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> DB_ID              <span class="operator">|</span> <span class="type">bigint</span>       <span class="operator">|</span> YES  <span class="operator">|</span> MUL <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> LAST_ACCESS_TIME   <span class="operator">|</span> <span class="type">int</span>          <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> OWNER              <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">767</span>) <span class="operator">|</span> YES  <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> OWNER_TYPE         <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">10</span>)  <span class="operator">|</span> YES  <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> RETENTION          <span class="operator">|</span> <span class="type">int</span>          <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> SD_ID              <span class="operator">|</span> <span class="type">bigint</span>       <span class="operator">|</span> YES  <span class="operator">|</span> MUL <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> TBL_NAME           <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">256</span>) <span class="operator">|</span> YES  <span class="operator">|</span> MUL <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> TBL_TYPE           <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">128</span>) <span class="operator">|</span> YES  <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> VIEW_EXPANDED_TEXT <span class="operator">|</span> mediumtext   <span class="operator">|</span> YES  <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> VIEW_ORIGINAL_TEXT <span class="operator">|</span> mediumtext   <span class="operator">|</span> YES  <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> IS_REWRITE_ENABLED <span class="operator">|</span> bit(<span class="number">1</span>)       <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> b<span class="string">&#x27;0&#x27;</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------+--------------+------+-----+---------+-------+</span></span><br><span class="line"><span class="number">13</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">desc</span> sds;</span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------+---------------+------+-----+---------+-------+</span></span><br><span class="line"><span class="operator">|</span> Field                     <span class="operator">|</span> Type          <span class="operator">|</span> <span class="keyword">Null</span> <span class="operator">|</span> Key <span class="operator">|</span> <span class="keyword">Default</span> <span class="operator">|</span> Extra <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------+---------------+------+-----+---------+-------+</span></span><br><span class="line"><span class="operator">|</span> SD_ID                     <span class="operator">|</span> <span class="type">bigint</span>        <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span> PRI <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> CD_ID                     <span class="operator">|</span> <span class="type">bigint</span>        <span class="operator">|</span> YES  <span class="operator">|</span> MUL <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> INPUT_FORMAT              <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">4000</span>) <span class="operator">|</span> YES  <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> IS_COMPRESSED             <span class="operator">|</span> bit(<span class="number">1</span>)        <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> IS_STOREDASSUBDIRECTORIES <span class="operator">|</span> bit(<span class="number">1</span>)        <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> LOCATION                  <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">4000</span>) <span class="operator">|</span> YES  <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> NUM_BUCKETS               <span class="operator">|</span> <span class="type">int</span>           <span class="operator">|</span> <span class="keyword">NO</span>   <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> OUTPUT_FORMAT             <span class="operator">|</span> <span class="type">varchar</span>(<span class="number">4000</span>) <span class="operator">|</span> YES  <span class="operator">|</span>     <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> SERDE_ID                  <span class="operator">|</span> <span class="type">bigint</span>        <span class="operator">|</span> YES  <span class="operator">|</span> MUL <span class="operator">|</span> <span class="keyword">NULL</span>    <span class="operator">|</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------+---------------+------+-----+---------+-------+</span></span><br><span class="line"><span class="number">9</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="2-5-2-启动Hive"><a href="#2-5-2-启动Hive" class="headerlink" title="2.5.2 启动Hive"></a>2.5.2 启动Hive</h3></li>
<li>先启动hadoop集群</li>
<li>启动Hive <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 conf]$ hive</span><br><span class="line"><span class="built_in">which</span>: no hbase <span class="keyword">in</span> (/usr/<span class="built_in">local</span>/bin:/usr/bin:/usr/<span class="built_in">local</span>/sbin:/usr/sbin:/opt/module/jdk1.8.0_212/bin:/opt/module/ha-hadoop-3.1.3/bin:/opt/module/ha-hadoop-3.1.3/sbin:/opt/module/hive-3.1.2/bin:/home/atguigu/.<span class="built_in">local</span>/bin:/home/atguigu/bin)</span><br><span class="line">Hive Session ID = 6e003b50-4b21-418c-9983-d13aea1037a4</span><br><span class="line"></span><br><span class="line">Logging initialized using configuration <span class="keyword">in</span> jar:file:/opt/module/hive-3.1.2/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: <span class="literal">true</span></span><br><span class="line">Loading class `com.mysql.jdbc.Driver<span class="string">&#x27;. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver&#x27;</span>. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.</span><br><span class="line">Hive-on-MR is deprecated <span class="keyword">in</span> Hive 2 and may not be available <span class="keyword">in</span> the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span><br><span class="line">Hive Session ID = 19720043-aa70-4ba3-8eb9-7ff94beb4379</span><br><span class="line">hive&gt; </span><br></pre></td></tr></table></figure></li>
<li>使用Hive <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">show</span> databases;</span><br><span class="line">OK</span><br><span class="line"><span class="keyword">default</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.58</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">show</span> tables;</span><br><span class="line">OK</span><br><span class="line">test</span><br><span class="line">test_2</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.029</span> seconds, Fetched: <span class="number">2</span> <span class="type">row</span>(s)</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">table</span> test_3 (id <span class="type">int</span>,name string,age <span class="type">int</span>);</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.346</span> seconds</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">show</span> tables;</span><br><span class="line">OK</span><br><span class="line">test</span><br><span class="line">test_2</span><br><span class="line">test_3</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.034</span> seconds, Fetched: <span class="number">3</span> <span class="type">row</span>(s)</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">insert</span> <span class="keyword">into</span> test_3 <span class="keyword">values</span> (<span class="number">123</span>,<span class="string">&#x27;zhangsan&#x27;</span>,<span class="number">18</span>);</span><br><span class="line">Query ID <span class="operator">=</span> atguigu_20211020154850_d4a395ef<span class="operator">-</span>b85d<span class="number">-466</span>a<span class="number">-852</span>f<span class="operator">-</span>b6707a260960</span><br><span class="line">Total jobs <span class="operator">=</span> <span class="number">3</span></span><br><span class="line">Launching Job <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">3</span></span><br><span class="line">Number <span class="keyword">of</span> reduce tasks determined <span class="keyword">at</span> compile <span class="type">time</span>: <span class="number">1</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> change the average load <span class="keyword">for</span> a reducer (<span class="keyword">in</span> bytes):</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.bytes.per.reducer<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> limit the maximum number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> hive.exec.reducers.max<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line"><span class="keyword">In</span> <span class="keyword">order</span> <span class="keyword">to</span> <span class="keyword">set</span> a constant number <span class="keyword">of</span> reducers:</span><br><span class="line">  <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="operator">&lt;</span>number<span class="operator">&gt;</span></span><br><span class="line">Starting Job <span class="operator">=</span> job_1634689350447_0003, Tracking URL <span class="operator">=</span> http:<span class="operator">/</span><span class="operator">/</span>hadoop003:<span class="number">8088</span><span class="operator">/</span>proxy<span class="operator">/</span>application_1634689350447_0003<span class="operator">/</span></span><br><span class="line">Kill Command <span class="operator">=</span> <span class="operator">/</span>opt<span class="operator">/</span><span class="keyword">module</span><span class="operator">/</span>ha<span class="operator">-</span>hadoop<span class="number">-3.1</span><span class="number">.3</span><span class="operator">/</span>bin<span class="operator">/</span>mapred job  <span class="operator">-</span>kill job_1634689350447_0003</span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">1</span></span><br><span class="line"><span class="number">2021</span><span class="number">-10</span><span class="number">-20</span> <span class="number">15</span>:<span class="number">50</span>:<span class="number">00</span>,<span class="number">166</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span></span><br><span class="line"><span class="number">2021</span><span class="number">-10</span><span class="number">-20</span> <span class="number">15</span>:<span class="number">50</span>:<span class="number">05</span>,<span class="number">319</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">0</span><span class="operator">%</span>, Cumulative CPU <span class="number">1.37</span> sec</span><br><span class="line"><span class="number">2021</span><span class="number">-10</span><span class="number">-20</span> <span class="number">15</span>:<span class="number">50</span>:<span class="number">10</span>,<span class="number">425</span> Stage<span class="number">-1</span> map <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>,  reduce <span class="operator">=</span> <span class="number">100</span><span class="operator">%</span>, Cumulative CPU <span class="number">2.49</span> sec</span><br><span class="line">MapReduce Total cumulative CPU <span class="type">time</span>: <span class="number">2</span> seconds <span class="number">490</span> msec</span><br><span class="line">Ended Job <span class="operator">=</span> job_1634689350447_0003</span><br><span class="line">Stage<span class="number">-4</span> <span class="keyword">is</span> selected <span class="keyword">by</span> <span class="keyword">condition</span> resolver.</span><br><span class="line">Stage<span class="number">-3</span> <span class="keyword">is</span> filtered <span class="keyword">out</span> <span class="keyword">by</span> <span class="keyword">condition</span> resolver.</span><br><span class="line">Stage<span class="number">-5</span> <span class="keyword">is</span> filtered <span class="keyword">out</span> <span class="keyword">by</span> <span class="keyword">condition</span> resolver.</span><br><span class="line">Moving data <span class="keyword">to</span> directory hdfs:<span class="operator">/</span><span class="operator">/</span>mycluster<span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>test_3<span class="operator">/</span>.hive<span class="operator">-</span>staging_hive_2021<span class="number">-10</span><span class="number">-20</span>_15<span class="number">-48</span><span class="number">-50</span>_976_8532078537182566570<span class="number">-1</span><span class="operator">/</span><span class="operator">-</span>ext<span class="number">-10000</span></span><br><span class="line">Loading data <span class="keyword">to</span> <span class="keyword">table</span> default.test_3</span><br><span class="line">MapReduce Jobs Launched:</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">1</span>   Cumulative CPU: <span class="number">2.49</span> sec   HDFS Read: <span class="number">16281</span> HDFS Write: <span class="number">285</span> SUCCESS</span><br><span class="line">Total MapReduce CPU <span class="type">Time</span> Spent: <span class="number">2</span> seconds <span class="number">490</span> msec</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">80.881</span> seconds</span><br><span class="line">hive<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> test_3;</span><br><span class="line">OK</span><br><span class="line"><span class="number">123</span>	zhangsan	<span class="number">18</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.109</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">hive<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="2-5-3-使用独立的元数据服务的方式访问Hive"><a href="#2-5-3-使用独立的元数据服务的方式访问Hive" class="headerlink" title="2.5.3 使用独立的元数据服务的方式访问Hive"></a>2.5.3 使用独立的元数据服务的方式访问Hive</h3><ol>
<li>在hive-site.xml文件中添加如下配置信息 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定存储元数据要连接的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://hadoop102:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>启动metastore <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 conf]$ hive --service metastore</span><br><span class="line">2021-10-20 16:19:53: Starting Hive Metastore Server</span><br><span class="line">Loading class `com.mysql.jdbc.Driver<span class="string">&#x27;. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver&#x27;</span>. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.</span><br></pre></td></tr></table></figure>
 注意: 启动后窗口不能再操作，需打开一个新的shell窗口做别的操作</li>
<li>启动 hive <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 ~]$ hive</span><br><span class="line"><span class="built_in">which</span>: no hbase <span class="keyword">in</span> (/usr/<span class="built_in">local</span>/bin:/usr/bin:/usr/<span class="built_in">local</span>/sbin:/usr/sbin:/opt/module/jdk1.8.0_212/bin:/opt/module/ha-hadoop-3.1.3/bin:/opt/module/ha-hadoop-3.1.3/sbin:/opt/module/hive-3.1.2/bin:/home/atguigu/.<span class="built_in">local</span>/bin:/home/atguigu/bin)</span><br><span class="line">Hive Session ID = cc81e23a-657b-47e7-b211-bc4364e64fc2</span><br><span class="line"></span><br><span class="line">Logging initialized using configuration <span class="keyword">in</span> jar:file:/opt/module/hive-3.1.2/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: <span class="literal">true</span></span><br><span class="line">Hive-on-MR is deprecated <span class="keyword">in</span> Hive 2 and may not be available <span class="keyword">in</span> the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.</span><br><span class="line">Hive Session ID = 60aa1b01-a2b8-4766-b9fc-4246f8c5fee6</span><br><span class="line">hive&gt;</span><br></pre></td></tr></table></figure>
<h3 id="2-5-4-使用JDBC方式访问Hive"><a href="#2-5-4-使用JDBC方式访问Hive" class="headerlink" title="2.5.4 使用JDBC方式访问Hive"></a>2.5.4 使用JDBC方式访问Hive</h3></li>
<li>在hive-site.xml文件中添加如下配置信息 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">    <span class="comment">&lt;!-- 指定hiveserver2连接的host --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.bind.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- 指定hiveserver2连接的端口号 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    ```    </span><br><span class="line">2. 启动hiveserver2</span><br><span class="line">    ```bash</span><br><span class="line">    [atguigu@hadoop001 ~]$ hive --service hiveserver2</span><br><span class="line">    which: no hbase in (/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/module/jdk1.8.0_212/bin:/opt/module/ha-hadoop-3.1.3/bin:/opt/module/ha-hadoop-3.1.3/sbin:/opt/module/hive-3.1.2/bin:/home/atguigu/.local/bin:/home/atguigu/bin)</span><br><span class="line">    2021-10-20 16:23:25: Starting HiveServer2</span><br><span class="line">    Hive Session ID = 9191577f-34bc-478c-a4ae-8b0f2d20f945</span><br><span class="line">    Hive Session ID = 769ddf72-053a-4f0b-aa48-5723090f513b</span><br></pre></td></tr></table></figure></li>
<li>启动beeline客户端（需要多等待一会） <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 ~]$ beeline -u jdbc:hive2://hadoop001:10000 -n atguigu</span><br><span class="line">Connecting to jdbc:hive2://hadoop001:10000</span><br><span class="line">Connected to: Apache Hive (version 3.1.2)</span><br><span class="line">Driver: Hive JDBC (version 3.1.2)</span><br><span class="line">Transaction isolation: TRANSACTION_REPEATABLE_READ</span><br><span class="line">Beeline version 3.1.2 by Apache Hive</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt;</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt;</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt;</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt; show databases;</span><br><span class="line">INFO  : Compiling <span class="built_in">command</span>(queryId=atguigu_20211020162645_fd2a8faf-9209-4bec-b36d-ec4c63bd8149): show databases</span><br><span class="line">INFO  : Concurrency mode is disabled, not creating a lock manager</span><br><span class="line">INFO  : Semantic Analysis Completed (retrial = <span class="literal">false</span>)</span><br><span class="line">INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:database_name, <span class="built_in">type</span>:string, comment:from deserializer)], properties:null)</span><br><span class="line">INFO  : Completed compiling <span class="built_in">command</span>(queryId=atguigu_20211020162645_fd2a8faf-9209-4bec-b36d-ec4c63bd8149); Time taken: 0.589 seconds</span><br><span class="line">INFO  : Concurrency mode is disabled, not creating a lock manager</span><br><span class="line">INFO  : Executing <span class="built_in">command</span>(queryId=atguigu_20211020162645_fd2a8faf-9209-4bec-b36d-ec4c63bd8149): show databases</span><br><span class="line">INFO  : Starting task [Stage-0:DDL] <span class="keyword">in</span> serial mode</span><br><span class="line">INFO  : Completed executing <span class="built_in">command</span>(queryId=atguigu_20211020162645_fd2a8faf-9209-4bec-b36d-ec4c63bd8149); Time taken: 0.016 seconds</span><br><span class="line">INFO  : OK</span><br><span class="line">INFO  : Concurrency mode is disabled, not creating a lock manager</span><br><span class="line">+----------------+</span><br><span class="line">| database_name  |</span><br><span class="line">+----------------+</span><br><span class="line">| default        |</span><br><span class="line">+----------------+</span><br><span class="line">1 row selected (0.84 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="2-5-5-编写启动metastore和hiveserver2脚本"><a href="#2-5-5-编写启动metastore和hiveserver2脚本" class="headerlink" title="2.5.5 编写启动metastore和hiveserver2脚本"></a>2.5.5 编写启动metastore和hiveserver2脚本</h3><ol>
<li><p>前台启动的方式导致需要打开多个shell窗口，可以使用如下方式后台方式启动</p>
<ul>
<li>nohup: 放在命令开头，表示不挂起,也就是关闭终端进程也继续保持运行状态<ul>
<li>0:标准输入</li>
<li>1:标准输出</li>
<li>2:错误输出</li>
<li>2&gt;&amp;1 : 表示将错误重定向到标准输出上</li>
<li>&amp;: 放在命令结尾,表示后台运行</li>
<li>一般会组合使用: nohup  [xxx命令操作]&gt; file  2&gt;&amp;1 &amp;  ， 表示将xxx命令运行的<br>结果输出到file中，并保持命令启动的进程在后台运行。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 ~]$ nohup hive --service metastore 2&gt;&amp;1 &amp;</span><br><span class="line">[1] 19488</span><br><span class="line">[atguigu@hadoop001 ~]$ nohup: ignoring input and appending output to ‘nohup.out’</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop001 ~]$</span><br><span class="line">[atguigu@hadoop001 ~]$ nohup hive --service hiveserver2 2&gt;&amp;1 &amp;</span><br><span class="line">[2] 19603</span><br><span class="line">[atguigu@hadoop001 ~]$ nohup: ignoring input and appending output to ‘nohup.out’</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop001 ~]$</span><br><span class="line">[atguigu@hadoop001 ~]$ tail -f nohup.out</span><br><span class="line">2021-10-20 16:46:00: Starting Hive Metastore Server</span><br><span class="line">Loading class `com.mysql.jdbc.Driver<span class="string">&#x27;. This is deprecated. The new driver class is `com.mysql.cj.jdbc.Driver&#x27;</span>. The driver is automatically registered via the SPI and manual loading of the driver class is generally unnecessary.</span><br><span class="line"><span class="built_in">which</span>: no hbase <span class="keyword">in</span> (/usr/<span class="built_in">local</span>/bin:/usr/bin:/usr/<span class="built_in">local</span>/sbin:/usr/sbin:/opt/module/jdk1.8.0_212/bin:/opt/module/ha-hadoop-3.1.3/bin:/opt/module/ha-hadoop-3.1.3/sbin:/opt/module/hive-3.1.2/bin:/home/atguigu/.<span class="built_in">local</span>/bin:/home/atguigu/bin)</span><br><span class="line">2021-10-20 16:46:07: Starting HiveServer2</span><br><span class="line">Hive Session ID = e305ccdf-dd51-48e1-a740-fbc309de0a31</span><br><span class="line">Hive Session ID = b9a65f04-071e-493d-b89e-774daf7cac0f</span><br><span class="line">Hive Session ID = 985ef9a9-6d00-47f6-a0e4-178eed45c7f8</span><br><span class="line">Hive Session ID = dae41fea-63a9-4bda-84e6-c4e171fc0ecc</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
<li><p>编写脚本hiveservices.sh</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">HIVE_LOG_DIR=<span class="variable">$HIVE_HOME</span>/logs</span><br><span class="line"><span class="keyword">if</span> [ ! -d <span class="variable">$HIVE_LOG_DIR</span> ]; <span class="keyword">then</span></span><br><span class="line">    mkdir -p <span class="variable">$HIVE_LOG_DIR</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="comment">#检查进程是否运行正常，参数1为进程名，参数2为进程端口</span></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">check_process</span></span>() &#123;</span><br><span class="line">    pid=$(ps -ef 2&gt;/dev/null | grep -v grep | grep -i <span class="variable">$1</span> | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span>)</span><br><span class="line">    ppid=$(netstat -nltp 2&gt;/dev/null | grep <span class="variable">$2</span> | awk <span class="string">&#x27;&#123;print $7&#125;&#x27;</span> | cut -d <span class="string">&#x27;/&#x27;</span> -f 1)</span><br><span class="line">    <span class="built_in">echo</span> <span class="variable">$pid</span></span><br><span class="line">    [[ <span class="string">&quot;<span class="variable">$pid</span>&quot;</span> =~ <span class="string">&quot;<span class="variable">$ppid</span>&quot;</span> ]] &amp;&amp; [ <span class="string">&quot;<span class="variable">$ppid</span>&quot;</span> ] &amp;&amp; <span class="built_in">return</span> 0 || <span class="built_in">return</span> 1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">hive_start</span></span>() &#123;</span><br><span class="line">    metapid=$(check_process HiveMetastore 9083)</span><br><span class="line">    cmd=<span class="string">&quot;nohup hive --service metastore &gt;<span class="variable">$HIVE_LOG_DIR</span>/metastore.log 2&gt;&amp;1 &amp;&quot;</span></span><br><span class="line">    cmd=<span class="variable">$cmd</span><span class="string">&quot; sleep 4; hdfs dfsadmin -safemode wait &gt;/dev/null 2&gt;&amp;1&quot;</span></span><br><span class="line">    [ -z <span class="string">&quot;<span class="variable">$metapid</span>&quot;</span> ] &amp;&amp; <span class="built_in">eval</span> <span class="variable">$cmd</span> || <span class="built_in">echo</span> <span class="string">&quot;Metastroe服务已启动&quot;</span></span><br><span class="line">    server2pid=$(check_process HiveServer2 10000)</span><br><span class="line">    cmd=<span class="string">&quot;nohup hive --service hiveserver2 &gt;<span class="variable">$HIVE_LOG_DIR</span>/hiveServer2.log 2&gt;&amp;1 &amp;&quot;</span></span><br><span class="line">    [ -z <span class="string">&quot;<span class="variable">$server2pid</span>&quot;</span> ] &amp;&amp; <span class="built_in">eval</span> <span class="variable">$cmd</span> || <span class="built_in">echo</span> <span class="string">&quot;HiveServer2服务已启动&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">hive_stop</span></span>() &#123;</span><br><span class="line">    metapid=$(check_process HiveMetastore 9083)</span><br><span class="line">    [ <span class="string">&quot;<span class="variable">$metapid</span>&quot;</span> ] &amp;&amp; <span class="built_in">kill</span> <span class="variable">$metapid</span> || <span class="built_in">echo</span> <span class="string">&quot;Metastore服务未启动&quot;</span></span><br><span class="line">    server2pid=$(check_process HiveServer2 10000)</span><br><span class="line">    [ <span class="string">&quot;<span class="variable">$server2pid</span>&quot;</span> ] &amp;&amp; <span class="built_in">kill</span> <span class="variable">$server2pid</span> || <span class="built_in">echo</span> <span class="string">&quot;HiveServer2服务未启动&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line"><span class="string">&quot;start&quot;</span>)</span><br><span class="line">    hive_start</span><br><span class="line">    ;;</span><br><span class="line"><span class="string">&quot;stop&quot;</span>)</span><br><span class="line">    hive_stop</span><br><span class="line">    ;;</span><br><span class="line"><span class="string">&quot;restart&quot;</span>)</span><br><span class="line">    hive_stop</span><br><span class="line">    sleep 2</span><br><span class="line">    hive_start</span><br><span class="line">    ;;</span><br><span class="line"><span class="string">&quot;status&quot;</span>)</span><br><span class="line">    check_process HiveMetastore 9083 &gt;/dev/null &amp;&amp; <span class="built_in">echo</span> <span class="string">&quot;Metastore服务运行正常&quot;</span> || <span class="built_in">echo</span> <span class="string">&quot;Metastore服务运行异常&quot;</span></span><br><span class="line">    check_process HiveServer2 10000 &gt;/dev/null &amp;&amp; <span class="built_in">echo</span> <span class="string">&quot;HiveServer2服务运行正常&quot;</span> || <span class="built_in">echo</span> <span class="string">&quot;HiveServer2服务运行异常&quot;</span></span><br><span class="line">    ;;</span><br><span class="line">*)</span><br><span class="line">    <span class="built_in">echo</span> Invalid Args!</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&#x27;Usage: &#x27;</span>$(basename <span class="variable">$0</span>)<span class="string">&#x27; start|stop|restart|status&#x27;</span></span><br><span class="line">    ;;</span><br><span class="line"><span class="keyword">esac</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>添加执行权限</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 bin]$ ll</span><br><span class="line">total 20</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu 1723 Oct 20 17:02 hive_server.sh</span><br><span class="line">[atguigu@hadoop001 bin]$ chmod a+x hive_server.sh</span><br><span class="line">[atguigu@hadoop001 bin]$ ll</span><br><span class="line">total 20</span><br><span class="line">-rwxrwxr-x. 1 atguigu atguigu 1723 Oct 20 17:02 hive_server.sh</span><br><span class="line">[atguigu@hadoop001 bin]$</span><br></pre></td></tr></table></figure></li>
<li><p>启动Hive后台服务</p>
 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 bin]$ hive_server.sh start</span><br><span class="line">[atguigu@hadoop001 bin]$ hive_server.sh status</span><br><span class="line">Metastore服务运行正常</span><br><span class="line">HiveServer2服务运行正常</span><br><span class="line">[atguigu@hadoop001 bin]$</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="2-6-Hive常用交互命令"><a href="#2-6-Hive常用交互命令" class="headerlink" title="2.6 Hive常用交互命令"></a>2.6 Hive常用交互命令</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 hive]$ hive -<span class="built_in">help</span></span><br><span class="line"><span class="built_in">which</span>: no hbase <span class="keyword">in</span> (/usr/<span class="built_in">local</span>/bin:/usr/bin:/usr/<span class="built_in">local</span>/sbin:/usr/sbin:/opt/module/jdk1.8.0_212/bin:/opt/module/ha-hadoop-3.1.3/bin:/opt/module/ha-hadoop-3.1.3/sbin:/opt/module/hive-3.1.2/bin:/home/atguigu/.<span class="built_in">local</span>/bin:/home/atguigu/bin)</span><br><span class="line">Hive Session ID = ccd1a72b-c24a-4b49-9583-1601fa1f7a34</span><br><span class="line">usage: hive</span><br><span class="line"> -d,--define &lt;key=value&gt;          Variable substitution to apply to Hive</span><br><span class="line">                                  commands. e.g. -d A=B or --define A=B</span><br><span class="line">    --database &lt;databasename&gt;     Specify the database to use</span><br><span class="line"> -e &lt;quoted-query-string&gt;         SQL from <span class="built_in">command</span> line</span><br><span class="line"> -f &lt;filename&gt;                    SQL from files</span><br><span class="line"> -H,--<span class="built_in">help</span>                        Print <span class="built_in">help</span> information</span><br><span class="line">    --hiveconf &lt;property=value&gt;   Use value <span class="keyword">for</span> given property</span><br><span class="line">    --hivevar &lt;key=value&gt;         Variable substitution to apply to Hive</span><br><span class="line">                                  commands. e.g. --hivevar A=B</span><br><span class="line"> -i &lt;filename&gt;                    Initialization SQL file</span><br><span class="line"> -S,--silent                      Silent mode <span class="keyword">in</span> interactive shell</span><br><span class="line"> -v,--verbose                     Verbose mode (<span class="built_in">echo</span> executed SQL to the</span><br><span class="line">                                  console)</span><br><span class="line">[atguigu@hadoop001 hive]$</span><br></pre></td></tr></table></figure>
<ol>
<li>“-e”不进入hive的交互窗口执行sql语句 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 hive]$ hive -e <span class="string">&#x27;select count(1) from test_3&#x27;</span></span><br><span class="line"><span class="built_in">which</span>: no hbase <span class="keyword">in</span> (/usr/<span class="built_in">local</span>/bin:/usr/bin:/usr/<span class="built_in">local</span>/sbin:/usr/sbin:/opt/module/jdk1.8.0_212/bin:/opt/module/ha-hadoop-3.1.3/bin:/opt/module/ha-hadoop-3.1.3/sbin:/opt/module/hive-3.1.2/bin:/home/atguigu/.<span class="built_in">local</span>/bin:/home/atguigu/bin)</span><br><span class="line">Hive Session ID = 8eeed838-5d5e-4ed4-a252-29f85e7f15f3</span><br><span class="line"></span><br><span class="line">Logging initialized using configuration <span class="keyword">in</span> jar:file:/opt/module/hive-3.1.2/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: <span class="literal">true</span></span><br><span class="line">Hive Session ID = c1c58f1c-71c4-4869-9f5e-8dc2a4ac52f4</span><br><span class="line">OK</span><br><span class="line">32</span><br><span class="line">Time taken: 1.972 seconds, Fetched: 1 row(s)</span><br><span class="line">[atguigu@hadoop001 hive]$</span><br></pre></td></tr></table></figure></li>
<li>-f”执行脚本中sql语句 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 hive]$ ls</span><br><span class="line">selectall.sql</span><br><span class="line"><span class="comment"># 编写sql脚本</span></span><br><span class="line">[atguigu@hadoop001 hive]$ cat selectall.sql</span><br><span class="line">select count(1) from test_3</span><br><span class="line"><span class="comment"># 使用-f执行脚本</span></span><br><span class="line">[atguigu@hadoop001 hive]$ hive -f selectall.sql</span><br><span class="line"><span class="built_in">which</span>: no hbase <span class="keyword">in</span> (/usr/<span class="built_in">local</span>/bin:/usr/bin:/usr/<span class="built_in">local</span>/sbin:/usr/sbin:/opt/module/jdk1.8.0_212/bin:/opt/module/ha-hadoop-3.1.3/bin:/opt/module/ha-hadoop-3.1.3/sbin:/opt/module/hive-3.1.2/bin:/home/atguigu/.<span class="built_in">local</span>/bin:/home/atguigu/bin)</span><br><span class="line">Hive Session ID = 2b43ecf4-1fd8-4bd1-be10-60adaad0ffa4</span><br><span class="line"></span><br><span class="line">Logging initialized using configuration <span class="keyword">in</span> jar:file:/opt/module/hive-3.1.2/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: <span class="literal">true</span></span><br><span class="line">Hive Session ID = a07efeea-d038-4ca8-b342-7b001f1493d7</span><br><span class="line">OK</span><br><span class="line">32</span><br><span class="line">Time taken: 1.954 seconds, Fetched: 1 row(s)</span><br><span class="line">[atguigu@hadoop001 hive]$</span><br><span class="line"><span class="comment"># 执行并导出文件</span></span><br><span class="line">[atguigu@hadoop001 hive]$ hive -f selectall.sql &gt; selectall.txt</span><br><span class="line"><span class="built_in">which</span>: no hbase <span class="keyword">in</span> (/usr/<span class="built_in">local</span>/bin:/usr/bin:/usr/<span class="built_in">local</span>/sbin:/usr/sbin:/opt/module/jdk1.8.0_212/bin:/opt/module/ha-hadoop-3.1.3/bin:/opt/module/ha-hadoop-3.1.3/sbin:/opt/module/hive-3.1.2/bin:/home/atguigu/.<span class="built_in">local</span>/bin:/home/atguigu/bin)</span><br><span class="line">Hive Session ID = 13cd6a52-4af8-4234-86bf-70841d565b98</span><br><span class="line"></span><br><span class="line">Logging initialized using configuration <span class="keyword">in</span> jar:file:/opt/module/hive-3.1.2/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: <span class="literal">true</span></span><br><span class="line">Hive Session ID = 9279ee4e-997c-4a92-b258-11ac8c0beaa6</span><br><span class="line">OK</span><br><span class="line">Time taken: 1.953 seconds, Fetched: 1 row(s)</span><br><span class="line">[atguigu@hadoop001 hive]$ cat selectall.txt</span><br><span class="line">32</span><br><span class="line">[atguigu@hadoop001 hive]$</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="2-7-Hive其他命令操作"><a href="#2-7-Hive其他命令操作" class="headerlink" title="2.7 Hive其他命令操作"></a>2.7 Hive其他命令操作</h2><ol>
<li>退出hive窗口： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive(default)&gt;<span class="built_in">exit</span>;</span><br><span class="line">hive(default)&gt;quit;</span><br></pre></td></tr></table></figure>
<ul>
<li>在新版的hive中没区别了，在以前的版本是有的：</li>
<li>exit:先隐性提交数据，再退出；</li>
<li>quit:不提交数据，退出；</li>
</ul>
</li>
<li>在hive cli命令窗口中如何查看hdfs文件系统 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; dfs -ls /user;</span><br><span class="line">Found 1 items</span><br><span class="line">drwxr-xr-x   - atguigu supergroup          0 2021-10-20 14:52 /user/hive</span><br><span class="line">hive&gt; dfs -ls /user/hive;</span><br><span class="line">Found 1 items</span><br><span class="line">drwxr-xr-x   - atguigu supergroup          0 2021-10-20 15:48 /user/hive/warehouse</span><br><span class="line">hive&gt; dfs -ls /user/hive/warehouse;</span><br><span class="line">Found 3 items</span><br><span class="line">drwxr-xr-x   - atguigu supergroup          0 2021-10-20 15:40 /user/hive/warehouse/<span class="built_in">test</span></span><br><span class="line">drwxr-xr-x   - atguigu supergroup          0 2021-10-20 15:43 /user/hive/warehouse/test_2</span><br><span class="line">drwxr-xr-x   - atguigu supergroup          0 2021-10-22 15:06 /user/hive/warehouse/test_3</span><br><span class="line">hive&gt;</span><br></pre></td></tr></table></figure></li>
<li>查看在hive中输入的所有历史命令,用户home目录下.hivehistory文件,~/.hivehistory <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 ~]$ head -n 10 ~/.hivehistory</span><br><span class="line">show databases;</span><br><span class="line">create table <span class="built_in">test</span> (id int);</span><br><span class="line">show database;</span><br><span class="line">show databases;</span><br><span class="line">ls</span><br><span class="line">show databases;</span><br><span class="line">quit;</span><br><span class="line">show databases;</span><br><span class="line">quit</span><br><span class="line">;</span><br><span class="line">[atguigu@hadoop001 ~]$</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="2-8-Hive常见属性配置"><a href="#2-8-Hive常见属性配置" class="headerlink" title="2.8 Hive常见属性配置"></a>2.8 Hive常见属性配置</h2><h3 id="2-8-1-hive窗口打印默认库和表头"><a href="#2-8-1-hive窗口打印默认库和表头" class="headerlink" title="2.8.1 hive窗口打印默认库和表头"></a>2.8.1 hive窗口打印默认库和表头</h3><ol>
<li>打印 当前库 和 表头 hive-site.xml中加入如下两个配置:  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.header<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.current.db<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> test_2;</span><br><span class="line">OK</span><br><span class="line">test_2.id	test_2.name</span><br><span class="line"><span class="number">123</span>	zhangsan</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.106</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="2-8-2-Hive运行日志信息配置"><a href="#2-8-2-Hive运行日志信息配置" class="headerlink" title="2.8.2 Hive运行日志信息配置"></a>2.8.2 Hive运行日志信息配置</h3></li>
<li>Hive的log默认存放在/tmp/atguigu/hive.log目录下（当前用户名下）</li>
<li>修改hive的log存放日志到/opt/module/hive-3.1.2/logs<ol>
<li>修改/opt/module/hive/conf/hive-log4j2.properties.template文件名称为hive-log4j2.properties <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 conf]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hive/conf</span><br><span class="line">[atguigu@hadoop102 conf]$ mv hive-log4j2.properties.template hive-log4j2.properties</span><br></pre></td></tr></table></figure></li>
<li>在hive-log4j.properties文件中修改log存放位置 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">property.hive.log.dir=/opt/module/hive/logs</span><br></pre></td></tr></table></figure>
<h3 id="2-8-2-参数配置方式"><a href="#2-8-2-参数配置方式" class="headerlink" title="2.8.2 参数配置方式"></a>2.8.2 参数配置方式</h3></li>
</ol>
</li>
<li>查看当前所有的配置信息 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive<span class="operator">&gt;</span><span class="keyword">set</span>;</span><br></pre></td></tr></table></figure></li>
<li>参数的配置三种方式<ol>
<li>配置文件方式<ul>
<li>默认配置文件：hive-default.xml </li>
<li>用户自定义配置文件：hive-site.xml</li>
<li>注意：用户自定义配置会覆盖默认配置。另外，Hive也会读入Hadoop的配置，因为Hive是作为Hadoop的客户端启动的，Hive的配置会覆盖Hadoop的配置。配置文件的设定对本机启动的所有Hive进程都有效。</li>
</ul>
</li>
<li>命令行参数方式<ul>
<li>启动Hive时，可以在命令行添加-hiveconf param=value来设定参数。</li>
<li>例如：  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop103 hive]$ bin/hive -hiveconf mapred.reduce.tasks=10;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>注意：仅对本次hive启动有效。查看参数设置：  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">set</span> mapred.reduce.tasks;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>参数声明方式<ul>
<li>可以在HQL中使用SET关键字设定参数</li>
<li>例如：  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">set</span> mapred.reduce.tasks<span class="operator">=</span><span class="number">100</span>;</span><br></pre></td></tr></table></figure></li>
<li>注意：仅对本次hive启动有效。查看参数设置  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">set</span> mapred.reduce.tasks;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>上述三种设定方式的优先级依次递增。即default配置文件&lt;hive-site.x配置文件&lt;命令行参数&lt;参数声明。注意某些系统级的参数，例如log4j相关的设定，必须用前两种方式设定，因为那些参数的读取在会话建立以前已经完成了。</li>
</ol>
</li>
</ol>
<h1 id="三、Hive数据类型"><a href="#三、Hive数据类型" class="headerlink" title="三、Hive数据类型"></a>三、Hive数据类型</h1><h2 id="3-1-基本数据类型"><a href="#3-1-基本数据类型" class="headerlink" title="3.1 基本数据类型"></a>3.1 基本数据类型</h2><table>
<thead>
<tr>
<th>Hive数据类型</th>
<th>Java数据类型</th>
<th>长度</th>
</tr>
</thead>
<tbody><tr>
<td>TINYINT</td>
<td>byte</td>
<td>1byte有符号整数</td>
</tr>
<tr>
<td>SMALINT</td>
<td>short</td>
<td>2byte有符号整数</td>
</tr>
<tr>
<td>INT</td>
<td>int</td>
<td>4byte有符号整数</td>
</tr>
<tr>
<td>BIGINT</td>
<td>long</td>
<td>8byte有符号整数</td>
</tr>
<tr>
<td>BOOLEAN</td>
<td>boolean</td>
<td>布尔类型</td>
</tr>
<tr>
<td>FLOAT</td>
<td>float</td>
<td>单精度浮点数</td>
</tr>
<tr>
<td>DOUBLE</td>
<td>double</td>
<td>双精度浮点数</td>
</tr>
<tr>
<td>STRING</td>
<td>string</td>
<td>字符系列。可以指定字符集。使用单引号或者双引号</td>
</tr>
<tr>
<td>TIMESTAMP</td>
<td>Dat</td>
<td>时间类型</td>
</tr>
<tr>
<td>BINARY</td>
<td></td>
<td>字节数组</td>
</tr>
</tbody></table>
<ul>
<li>对于Hive的String类型相当于数据库的varchar类型，该类型是一个可变的字符串，不过它不能声明其中最多能存储多少个字符，理论上它可以存储2GB的字符数</li>
</ul>
<h2 id="3-2-集合数据类型"><a href="#3-2-集合数据类型" class="headerlink" title="3.2 集合数据类型"></a>3.2 集合数据类型</h2><table>
<thead>
<tr>
<th>数据类型</th>
<th>描述</th>
<th>语法示例</th>
</tr>
</thead>
<tbody><tr>
<td>STRUCT</td>
<td>和c语言中的struct类似，都可以通过“点”符号访问元素内容。例如，如果某个列的数据类型是STRUCT{first STRING, last STRING},那么第1个元素可以通过字段.first来引用。</td>
<td>struct()<br> 例如struct&lt;street:string, city:string&gt;</td>
</tr>
<tr>
<td>MAP</td>
<td>MAP是一组键-值对元组集合，使用数组表示法可以访问数据。例如，如果某个列的数据类型是MAP，其中键-&gt;值对是’first’-&gt;’John’和’last’-&gt;’Doe’，那么可以通过字段名[‘last’]获取最后一个元素</td>
<td>map()<br>例如map&lt;string, int&gt;</td>
</tr>
<tr>
<td>ARRAY</td>
<td>数组是一组具有相同类型和名称的变量的集合。这些变量称为数组的元素，每个数组元素都有一个编号，编号从零开始。例如，数组值为[‘John’, ‘Doe’]，那么第2个元素可以通过数组名[1]进行引用。</td>
<td>Array()<br>例如array<string></td>
</tr>
</tbody></table>
<ul>
<li>Hive有三种复杂数据类型ARRAY、MAP 和 STRUCT。ARRAY和MAP与Java中的Array和Map类似，而STRUCT与C语言中的Struct类似，它封装了一个命名字段集合，复杂数据类型允许任意层次的嵌套</li>
</ul>
<ol>
<li>数据类型实操<ol>
<li>数据示例 <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;songsong&quot;</span>,</span><br><span class="line">    </span><br><span class="line">    <span class="attr">&quot;friends&quot;</span>: [</span><br><span class="line">        <span class="string">&quot;bingbing&quot;</span>,</span><br><span class="line">        <span class="string">&quot;lili&quot;</span></span><br><span class="line">    ], </span><br><span class="line">    <span class="attr">&quot;children&quot;</span>: &#123; </span><br><span class="line">        <span class="attr">&quot;xiao song&quot;</span>: <span class="number">19</span>,</span><br><span class="line">        <span class="attr">&quot;xiaoxiao song&quot;</span>: <span class="number">18</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">&quot;address&quot;</span>: &#123; </span><br><span class="line">        <span class="attr">&quot;street&quot;</span>: <span class="string">&quot;hui long guan&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;city&quot;</span>: <span class="string">&quot;beijing&quot;</span>,</span><br><span class="line">        <span class="attr">&quot;zip&quot;</span>: <span class="number">1000001</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>基于上述数据结构，在Hive里创建对应的表，并导入数据 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">test.txt</span><br><span class="line">songsong,bingbing_lili,xiao song:18_xiaoxiao song:19,hui long guan_beijing_1000001</span><br><span class="line">yangyang,caicai_susu,xiao yang:18_xiaoxiao yang:19,chao yang_beijing_1000001</span><br></pre></td></tr></table></figure>
<ul>
<li>注意：MAP，STRUCT和ARRAY里的元素间关系都可以用同一个字符表示，这里用“_”。</li>
</ul>
</li>
<li>Hive上创建测试表user <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> person_info (</span><br><span class="line">    name     string,</span><br><span class="line">    friends  <span class="keyword">array</span><span class="operator">&lt;</span>string<span class="operator">&gt;</span>,</span><br><span class="line">    children map<span class="operator">&lt;</span>string, <span class="type">int</span><span class="operator">&gt;</span>,</span><br><span class="line">    address  struct<span class="operator">&lt;</span>street:string, city:string, zip:<span class="type">int</span><span class="operator">&gt;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">-- 列分隔符</span></span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;,&#x27;</span></span><br><span class="line"><span class="comment">-- MAP STRUCT 和 ARRAY 的分隔符(数据分割符号)</span></span><br><span class="line">collection items terminated <span class="keyword">by</span> <span class="string">&#x27;_&#x27;</span></span><br><span class="line"><span class="comment">-- MAP中的key与value的分隔符</span></span><br><span class="line">map keys terminated <span class="keyword">by</span> <span class="string">&#x27;:&#x27;</span></span><br><span class="line"><span class="comment">-- 行分隔符</span></span><br><span class="line">lines terminated <span class="keyword">by</span> <span class="string">&#x27;\n&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li>导入数据 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/home/atguigu/hive/user.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> person_info;</span><br><span class="line">Loading data <span class="keyword">to</span> <span class="keyword">table</span> default.user_test</span><br><span class="line">OK</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">0.873</span> seconds</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>查看数据 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> person_info <span class="keyword">where</span> friends[<span class="number">1</span>]<span class="operator">=</span><span class="string">&#x27;lili&#x27;</span> <span class="keyword">and</span> address.city<span class="operator">=</span><span class="string">&#x27;beijing&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+----------------------+--------------------------------------+----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> person_info.name  <span class="operator">|</span> person_info.friends  <span class="operator">|</span>         person_info.children         <span class="operator">|</span>                person_info.address                 <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+----------------------+--------------------------------------+----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> songsong          <span class="operator">|</span> [&quot;bingbing&quot;,&quot;lili&quot;]  <span class="operator">|</span> &#123;&quot;xiao song&quot;:<span class="number">18</span>,&quot;xiaoxiao song&quot;:<span class="number">19</span>&#125;  <span class="operator">|</span> &#123;&quot;street&quot;:&quot;hui long guan&quot;,&quot;city&quot;:&quot;beijing&quot;,&quot;zip&quot;:<span class="number">1000001</span>&#125; <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+----------------------+--------------------------------------+----------------------------------------------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> selected (<span class="number">0.076</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h2 id="3-3-类型转化"><a href="#3-3-类型转化" class="headerlink" title="3.3 类型转化"></a>3.3 类型转化</h2><p>Hive的原生数据类型是可以进行隐式转换的，类似于Java的类型转换，例如某表达式使用INT类型，TINYINT会自动转换为INT类型，但是Hive不会进行反向转化，例如，某表达式使用TINYINT类型，INT不会自动转换为TINYINT类型，它会返回错误，除非使用CAST操作。</p>
<ol>
<li>隐式类型转换规则如下<ul>
<li>任何整数类型都可以隐式地转换为一个范围更广的类型，如TINYINT可以转换成INT，INT可以转换成BIGINT。</li>
<li>所有整数类型、FLOAT和STRING类型都可以隐式地转换成DOUBLE。</li>
<li>TINYINT、SMALLINT、INT都可以转换为FLOAT。</li>
<li>BOOLEAN类型不可以转换为任何其它的类型。</li>
</ul>
</li>
<li>可以使用CAST操作显示进行数据类型转换<ul>
<li>例如CAST(‘1’ AS INT)将把字符串’1’ 转换成整数1；如果强制类型转换失败，如执行CAST(‘X’ AS INT)，表达式返回空值 NULL。  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="number">1</span><span class="operator">+</span><span class="string">&#x27;1&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">------+</span></span><br><span class="line"><span class="operator">|</span> _c0  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2.0</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> selected (<span class="number">0.098</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="number">1</span><span class="operator">+</span><span class="built_in">cast</span>(<span class="string">&#x27;1&#x27;</span> <span class="keyword">as</span> <span class="type">int</span>);</span><br><span class="line"><span class="operator">+</span><span class="comment">------+</span></span><br><span class="line"><span class="operator">|</span> _c0  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2</span>    <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> selected (<span class="number">0.087</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="number">1</span><span class="operator">+</span><span class="built_in">cast</span>(<span class="string">&#x27;x&#x27;</span> <span class="keyword">as</span> <span class="type">int</span>);</span><br><span class="line"><span class="operator">+</span><span class="comment">-------+</span></span><br><span class="line"><span class="operator">|</span>  _c0  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> selected (<span class="number">0.096</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h1 id="四、DDL数据库定义操作"><a href="#四、DDL数据库定义操作" class="headerlink" title="四、DDL数据库定义操作"></a>四、DDL数据库定义操作</h1><h2 id="4-1-创建数据库"><a href="#4-1-创建数据库" class="headerlink" title="4.1 创建数据库"></a>4.1 创建数据库</h2><ul>
<li>格式  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> DATABASE [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] database_name</span><br><span class="line">[COMMENT database_comment]</span><br><span class="line">[LOCATION hdfs_path]</span><br><span class="line">[<span class="keyword">WITH</span> DBPROPERTIES (property_name<span class="operator">=</span>property_value, ...)];</span><br></pre></td></tr></table></figure></li>
</ul>
<ol>
<li>创建一个数据库，数据库在HDFS上的默认存储路径是/user/hive/warehouse/*.db。 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">create</span> database hive_id;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.108</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> databases;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="operator">|</span> database_name  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">default</span>        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> hive_id        <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> selected (<span class="number">0.044</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>避免要创建的数据库已经存在错误，增加if not exists判断。（标准写法） <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> databases;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="operator">|</span> database_name  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">default</span>        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> hive_id        <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> selected (<span class="number">0.044</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">create</span> database hive_id;</span><br><span class="line">Error: Error while processing statement: FAILED: Execution Error, <span class="keyword">return</span> code <span class="number">1</span> <span class="keyword">from</span> org.apache.hadoop.hive.ql.exec.DDLTask. Database hive_id already <span class="keyword">exists</span> (state<span class="operator">=</span><span class="number">42000</span>,code<span class="operator">=</span><span class="number">1</span>)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">create</span> database if <span class="keyword">not</span> <span class="keyword">exists</span> hive_id;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.031</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> databases;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="operator">|</span> database_name  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">default</span>        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> hive_id        <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> selected (<span class="number">0.03</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>创建一个数据库，指定数据库在HDFS上存放的位置 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">create</span> database if <span class="keyword">not</span> <span class="keyword">exists</span> database_test location <span class="string">&#x27;/hive/db/test/location/location_test_db.db&#x27;</span> <span class="keyword">with</span> dbproperties (<span class="string">&#x27;author&#x27;</span><span class="operator">=</span><span class="string">&#x27;anzhen&#x27;</span>, <span class="string">&#x27;create_time&#x27;</span><span class="operator">=</span><span class="string">&#x27;2021/10/25&#x27;</span>);</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.057</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> databases;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+</span></span><br><span class="line"><span class="operator">|</span>   database_name   <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">default</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> hive_id           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> location_test_db  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+</span></span><br><span class="line"><span class="number">3</span> <span class="keyword">rows</span> selected (<span class="number">0.027</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> dfs <span class="operator">-</span>ls <span class="operator">/</span>hive<span class="operator">/</span>db<span class="operator">/</span>test<span class="operator">/</span>location<span class="operator">/</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span>                     DFS Output                     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> Found <span class="number">1</span> items                                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> drwxr<span class="operator">-</span>xr<span class="operator">-</span>x   <span class="operator">-</span> atguigu supergroup          <span class="number">0</span> <span class="number">2021</span><span class="number">-10</span><span class="number">-22</span> <span class="number">17</span>:<span class="number">11</span> <span class="operator">/</span>hive<span class="operator">/</span>db<span class="operator">/</span>test<span class="operator">/</span>location<span class="operator">/</span>location_test_db.db <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> selected (<span class="number">0.011</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="4-2-查询数据库"><a href="#4-2-查询数据库" class="headerlink" title="4.2 查询数据库"></a>4.2 查询数据库</h2></li>
<li>2.1 显示数据库</li>
<li>显示数据库 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> databases;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+</span></span><br><span class="line"><span class="operator">|</span>   database_name   <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">default</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> hive_id           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> location_test_db  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+</span></span><br><span class="line"><span class="number">3</span> <span class="keyword">rows</span> selected (<span class="number">0.096</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>过滤显示查询的数据库 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> databases <span class="keyword">like</span> <span class="string">&#x27;l*&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+</span></span><br><span class="line"><span class="operator">|</span>   database_name   <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+</span></span><br><span class="line"><span class="operator">|</span> location_test_db  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> selected (<span class="number">0.025</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="4-2-2-查看数据库详情"><a href="#4-2-2-查看数据库详情" class="headerlink" title="4.2.2 查看数据库详情"></a>4.2.2 查看数据库详情</h3></li>
<li>显示数据库信息 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">desc</span> database location_test_db;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+----------+----------------------------------------------------+-------------+-------------+-------------+</span></span><br><span class="line"><span class="operator">|</span>      db_name      <span class="operator">|</span> comment  <span class="operator">|</span>                      location                      <span class="operator">|</span> owner_name  <span class="operator">|</span> owner_type  <span class="operator">|</span> parameters  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+----------+----------------------------------------------------+-------------+-------------+-------------+</span></span><br><span class="line"><span class="operator">|</span> location_test_db  <span class="operator">|</span>          <span class="operator">|</span> hdfs:<span class="operator">/</span><span class="operator">/</span>mycluster<span class="operator">/</span>hive<span class="operator">/</span>db<span class="operator">/</span>test<span class="operator">/</span>location<span class="operator">/</span>location_test_db.db <span class="operator">|</span> atguigu     <span class="operator">|</span> <span class="keyword">USER</span>        <span class="operator">|</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+----------+----------------------------------------------------+-------------+-------------+-------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> selected (<span class="number">0.037</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>显示数据库详细信息，extended <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">desc</span> database EXTENDED database_test;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+----------+----------------------------------------------------+-------------+-------------+------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span>    db_name     <span class="operator">|</span> comment  <span class="operator">|</span>                      location                      <span class="operator">|</span> owner_name  <span class="operator">|</span> owner_type  <span class="operator">|</span>                parameters                <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+----------+----------------------------------------------------+-------------+-------------+------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> database_test  <span class="operator">|</span>          <span class="operator">|</span> hdfs:<span class="operator">/</span><span class="operator">/</span>mycluster<span class="operator">/</span>hive<span class="operator">/</span>db<span class="operator">/</span>test<span class="operator">/</span>location<span class="operator">/</span>location_test_db.db <span class="operator">|</span> atguigu     <span class="operator">|</span> <span class="keyword">USER</span>        <span class="operator">|</span> &#123;create_time<span class="operator">=</span><span class="number">2021</span><span class="operator">/</span><span class="number">10</span><span class="operator">/</span><span class="number">25</span>, author<span class="operator">=</span>anzhen&#125;  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+----------+----------------------------------------------------+-------------+-------------+------------------------------------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> selected (<span class="number">0.019</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="4-2-3-切换当前数据库"><a href="#4-2-3-切换当前数据库" class="headerlink" title="4.2.3 切换当前数据库"></a>4.2.3 切换当前数据库</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> use location_test_db;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.026</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> use hive_id;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.022</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="4-3-修改数据库"><a href="#4-3-修改数据库" class="headerlink" title="4.3 修改数据库"></a>4.3 修改数据库</h2></li>
<li>用户可以使用ALTER DATABASE命令为某个数据库的DBPROPERTIES设置键-值对属性值，来描述这个数据库的属性信息。 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">alter</span> database location_test_db <span class="keyword">set</span> dbproperties(<span class="string">&#x27;createtile&#x27;</span><span class="operator">=</span><span class="string">&#x27;20211022&#x27;</span>);</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.069</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">desc</span> database extended location_test_db;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+----------+----------------------------------------------------+-------------+-------------+------------------------+</span></span><br><span class="line"><span class="operator">|</span>      db_name      <span class="operator">|</span> comment  <span class="operator">|</span>                      location                      <span class="operator">|</span> owner_name  <span class="operator">|</span> owner_type  <span class="operator">|</span>       parameters       <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+----------+----------------------------------------------------+-------------+-------------+------------------------+</span></span><br><span class="line"><span class="operator">|</span> location_test_db  <span class="operator">|</span>          <span class="operator">|</span> hdfs:<span class="operator">/</span><span class="operator">/</span>mycluster<span class="operator">/</span>hive<span class="operator">/</span>db<span class="operator">/</span>test<span class="operator">/</span>location<span class="operator">/</span>location_test_db.db <span class="operator">|</span> atguigu     <span class="operator">|</span> <span class="keyword">USER</span>        <span class="operator">|</span> &#123;createtile<span class="operator">=</span><span class="number">20211022</span>&#125;  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+----------+----------------------------------------------------+-------------+-------------+------------------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> selected (<span class="number">0.023</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="4-4-删除数据库"><a href="#4-4-删除数据库" class="headerlink" title="4.4 删除数据库"></a>4.4 删除数据库</h2><ol>
<li>删除空数据库 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> databases;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+</span></span><br><span class="line"><span class="operator">|</span>   database_name   <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">default</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> hive_id           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> location_test_db  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+</span></span><br><span class="line"><span class="number">3</span> <span class="keyword">rows</span> selected (<span class="number">0.026</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">drop</span> database location_test_db;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.12</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> databases;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="operator">|</span> database_name  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">default</span>        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> hive_id        <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> selected (<span class="number">0.022</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>如果删除的数据库不存在，最好采用 if exists判断数据库是否存在 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> databases;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="operator">|</span> database_name  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">default</span>        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> hive_id        <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> selected (<span class="number">0.022</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">drop</span> database location_test_db;</span><br><span class="line">Error: Error while compiling statement: FAILED: SemanticException [Error <span class="number">10072</span>]: Database does <span class="keyword">not</span> exist: location_test_db (state<span class="operator">=</span><span class="number">42000</span>,code<span class="operator">=</span><span class="number">10072</span>)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">drop</span> database if <span class="keyword">exists</span> location_test_db;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.011</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> databases;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="operator">|</span> database_name  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">default</span>        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> hive_id        <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> selected (<span class="number">0.02</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>如果数据库不为空，可以采用cascade命令，强制删除 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> databases;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="operator">|</span> database_name  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">default</span>        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> hive_id        <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> selected (<span class="number">0.02</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">create</span> database location_test_db;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.051</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> use location_test_db;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.02</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">table</span> test(id <span class="type">int</span>,name string);</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.053</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">drop</span> database location_test_db;</span><br><span class="line">Error: Error while processing statement: FAILED: Execution Error, <span class="keyword">return</span> code <span class="number">1</span> <span class="keyword">from</span> org.apache.hadoop.hive.ql.exec.DDLTask. InvalidOperationException(message:Database location_test_db <span class="keyword">is</span> <span class="keyword">not</span> empty. <span class="keyword">One</span> <span class="keyword">or</span> more tables exist.) (state<span class="operator">=</span><span class="number">08</span>S01,code<span class="operator">=</span><span class="number">1</span>)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">drop</span> database location_test_db cascade;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.31</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> databases;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="operator">|</span> database_name  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">default</span>        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> hive_id        <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> selected (<span class="number">0.02</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="4-5-创建表"><a href="#4-5-创建表" class="headerlink" title="4.5 创建表"></a>4.5 创建表</h2><ol>
<li>建表语法 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> [<span class="keyword">EXTERNAL</span>] <span class="keyword">TABLE</span> [IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] table_name </span><br><span class="line">[(col_name data_type [COMMENT col_comment], ...)] </span><br><span class="line">[COMMENT table_comment] </span><br><span class="line">[PARTITIONED <span class="keyword">BY</span> (col_name data_type [COMMENT col_comment], ...)] </span><br><span class="line">[CLUSTERED <span class="keyword">BY</span> (col_name, col_name, ...) </span><br><span class="line">[SORTED <span class="keyword">BY</span> (col_name [<span class="keyword">ASC</span><span class="operator">|</span><span class="keyword">DESC</span>], ...)] <span class="keyword">INTO</span> num_buckets BUCKETS] </span><br><span class="line">[<span class="type">ROW</span> FORMAT row_format] </span><br><span class="line">[STORED <span class="keyword">AS</span> file_format] </span><br><span class="line">[LOCATION hdfs_path]</span><br><span class="line">[TBLPROPERTIES (property_name<span class="operator">=</span>property_value, ...)]</span><br><span class="line">[<span class="keyword">AS</span> select_statement]</span><br></pre></td></tr></table></figure></li>
<li>字段解释说明 <ol>
<li><code>CREATE TABLE</code>: 创建一个指定名字的表。如果相同名字的表已经存在，则抛出异常；用户可以用<code>IF NOT EXISTS</code>选项来忽略这个异常。</li>
<li><code>EXTERNAL</code>: 关键字可以让用户创建一个外部表，在建表的同时可以指定一个指向实际数据的路径（<code>LOCATION</code>），<font color ='red' >在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据</font>。</li>
<li><code>COMMENT</code>: 为表和列添加注释。</li>
<li><code>PARTITIONED BY</code>: 指定分区表的规范</li>
<li><code>CLUSTERED BY</code>: 指定分桶表的规范</li>
<li><code>SORTED BY</code>: 指定单签表默认排序规则及粪桶数量</li>
<li><code>ROW FORMAT DELIMITED</code>: 定义每一行中字段之间的分隔符</li>
<li><code>collection items terminated by</code>: 集合数据类型，元素之间的分隔符</li>
<li><code>map keys terminated by</code>: map数据类型key-value分隔符</li>
<li><code>lines terminated by</code>: 每一行的分隔符</li>
<li><code>STORED AS</code>: 指定存储文件类型<ul>
<li>常用的存储文件类型：SEQUENCEFILE（二进制序列文件）、TEXTFILE（文本）、RCFILE（列式存储格式文件）</li>
<li>如果文件数据是纯文本，可以使用STORED AS TEXTFILE。如果数据需要压缩，使用 STORED AS SEQUENCEFILE。</li>
</ul>
</li>
<li><code>LOCATION</code>: 指定表在HDFS上的存储位置。</li>
<li><code>AS select_statement</code>: 后跟查询语句，根据查询结果创建表。</li>
<li><code>LIKE</code>: 允许用户复制现有的表结构，但是不复制数据。</li>
</ol>
</li>
</ol>
<h3 id="4-5-1-管理表-内部表"><a href="#4-5-1-管理表-内部表" class="headerlink" title="4.5.1 管理表(内部表)"></a>4.5.1 管理表(内部表)</h3><ol>
<li>理论<ul>
<li>默认创建的表都是所谓的管理表，有时也被称为内部表。因为这种表，Hive会（或多或少地）控制着数据的生命周期。Hive默认情况下会将这些表的数据存储在由配置项hive.metastore.warehouse.dir(例如，/user/hive/warehouse)所定义的目录的子目录下。当我们<font color ='red' >删除一个管理表时，Hive也会删除这个表中数据。管理表不适合和其他工具共享数据</font>。</li>
</ul>
</li>
<li>案例实操<ol>
<li>原始数据 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">1001	ss1</span><br><span class="line">1002	ss2</span><br><span class="line">1003	ss3</span><br><span class="line">1004	ss4</span><br><span class="line">1005	ss5</span><br><span class="line">1006	ss6</span><br><span class="line">1007	ss7</span><br><span class="line">1008	ss8</span><br><span class="line">1009	ss9</span><br><span class="line">1010	ss10</span><br><span class="line">1011	ss11</span><br><span class="line">1012	ss12</span><br><span class="line">1013	ss13</span><br><span class="line">1014	ss14</span><br><span class="line">1015	ss15</span><br><span class="line">1016	ss16</span><br></pre></td></tr></table></figure></li>
<li>普通创建表 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> student (</span><br><span class="line">    id   <span class="type">int</span>,</span><br><span class="line">    name string</span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">stored <span class="keyword">as</span> textfile</span><br><span class="line">location <span class="string">&#x27;/user/hive/warehouse/student&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li>导入数据 </li>
<li>根据查询结果创建表（查询的结果会添加到新创建的表中） <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> student_copy <span class="keyword">as</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student;</span><br></pre></td></tr></table></figure></li>
<li>根据已经存在的表结构创建表 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> student_copy_like <span class="keyword">like</span> student;</span><br></pre></td></tr></table></figure></li>
<li>查询表的类型 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">desc</span> student;</span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+------------+----------+</span></span><br><span class="line"><span class="operator">|</span> col_name  <span class="operator">|</span> data_type  <span class="operator">|</span> comment  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+------------+----------+</span></span><br><span class="line"><span class="operator">|</span> id        <span class="operator">|</span> <span class="type">int</span>        <span class="operator">|</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> name      <span class="operator">|</span> string     <span class="operator">|</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+------------+----------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> selected (<span class="number">0.101</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="4-5-2-外部表"><a href="#4-5-2-外部表" class="headerlink" title="4.5.2 外部表"></a>4.5.2 外部表</h3></li>
</ol>
</li>
<li>理论<ul>
<li>因为表是外部表，所以Hive并非认为其完全拥有这份数据。<font color ='red' >删除该表并不会删除掉这份数据，不过描述表的元数据信息会被删除掉</font>。</li>
</ul>
</li>
<li>管理表和外部表的使用场景<ul>
<li>每天将收集到的网站日志定期流入HDFS文本文件。在外部表（原始日志表）的基础上做大量的统计分析，用到的中间表、结果表使用内部表存储，数据通过SELECT+INSERT进入内部表。</li>
</ul>
</li>
<li>案例实操<ul>
<li>分别创建部门和员工外部表，并向表中导入数据。</li>
</ul>
<ol>
<li>原始数据<ul>
<li>dept:  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">10	ACCOUNTING	1700</span><br><span class="line">20	RESEARCH	1800</span><br><span class="line">30	SALES	1900</span><br><span class="line">40	OPERATIONS	1700</span><br></pre></td></tr></table></figure></li>
<li>emp：  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">7369	SMITH	CLERK	7902	1980-12-17	800.00		20</span><br><span class="line">7499	ALLEN	SALESMAN	7698	1981-2-20	1600.00	300.00	30</span><br><span class="line">7521	WARD	SALESMAN	7698	1981-2-22	1250.00	500.00	30</span><br><span class="line">7566	JONES	MANAGER	7839	1981-4-2	2975.00		20</span><br><span class="line">7654	MARTIN	SALESMAN	7698	1981-9-28	1250.00	1400.00	30</span><br><span class="line">7698	BLAKE	MANAGER	7839	1981-5-1	2850.00		30</span><br><span class="line">7782	CLARK	MANAGER	7839	1981-6-9	2450.00		10</span><br><span class="line">7788	SCOTT	ANALYST	7566	1987-4-19	3000.00		20</span><br><span class="line">7839	KING	PRESIDENT		1981-11-17	5000.00		10</span><br><span class="line">7844	TURNER	SALESMAN	7698	1981-9-8	1500.00	0.00	30</span><br><span class="line">7876	ADAMS	CLERK	7788	1987-5-23	1100.00		20</span><br><span class="line">7900	JAMES	CLERK	7698	1981-12-3	950.00		30</span><br><span class="line">7902	FORD	ANALYST	7566	1981-12-3	3000.00		20</span><br><span class="line">7934	MILLER	CLERK	7782	1982-1-23	1300.00		10</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>上传数据到HDFS <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 hive]$ hadoop fs -put dep.txt /hive/source_data/</span><br><span class="line">[atguigu@hadoop001 hive]$ hadoop fs -put emp.txt /hive/source_data/</span><br><span class="line">[atguigu@hadoop001 hive]$ hadoop fs -ls /hive/source_data</span><br><span class="line">Found 2 items</span><br><span class="line">-rw-r--r--   3 atguigu supergroup         69 2021-10-25 13:15 /hive/source_data/dep.txt</span><br><span class="line">-rw-r--r--   3 atguigu supergroup        657 2021-10-25 13:15 /hive/source_data/emp.txt</span><br><span class="line">[atguigu@hadoop001 hive]$</span><br></pre></td></tr></table></figure></li>
<li>建表语句，创建外部表<ul>
<li>创建部门表  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> dept (</span><br><span class="line">    dept_no <span class="type">int</span>,</span><br><span class="line">    dept_name  string,</span><br><span class="line">    loc    <span class="type">int</span></span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li>创建员工表  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> emp (</span><br><span class="line">    emp_no    <span class="type">int</span>,</span><br><span class="line">    emp_name  string,</span><br><span class="line">    job       string,</span><br><span class="line">    mgr       <span class="type">int</span>,</span><br><span class="line">    hire_date string,</span><br><span class="line">    sal       <span class="keyword">double</span>,</span><br><span class="line">    comm      <span class="keyword">double</span>,</span><br><span class="line">    dept_no   <span class="type">int</span></span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li>查看表格式化数据  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">0: jdbc:hive2://hadoop001:10000&gt; desc formatted dept;</span><br><span class="line">+---------------+------------------+--------+</span><br><span class="line">| col_name      | data_type        | comment|</span><br><span class="line">+---------------+------------------+--------+</span><br><span class="line">···</span><br><span class="line">···</span><br><span class="line">| Table Type:   | EXTERNAL_TABLE   | NULL   |</span><br><span class="line">···</span><br><span class="line">···</span><br><span class="line">+---------------+------------------+--------+</span><br><span class="line">35 rows selected (0.054 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>导入数据 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">0: jdbc:hive2://hadoop001:10000&gt; load data inpath <span class="string">&#x27;/hive/source_data/dep.txt&#x27;</span> into table mock_data.dept;</span><br><span class="line">No rows affected (0.132 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt; load data inpath <span class="string">&#x27;/hive/source_data/emp.txt&#x27;</span> into table mock_data.emp;</span><br><span class="line">No rows affected (0.095 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt; select count(1) from mock_data.emp;</span><br><span class="line">+------+</span><br><span class="line">| _c0  |</span><br><span class="line">+------+</span><br><span class="line">| 14   |</span><br><span class="line">+------+</span><br><span class="line">1 row selected (14.939 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt; select count(1) from mock_data.dept;</span><br><span class="line">+------+</span><br><span class="line">| _c0  |</span><br><span class="line">+------+</span><br><span class="line">| 4    |</span><br><span class="line">+------+</span><br><span class="line">1 row selected (13.836 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt;</span><br></pre></td></tr></table></figure></li>
<li>删除外部表后，hdfs中的数据还在，但是metadata中dept的元数据已被删除 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">drop</span> <span class="keyword">table</span> mock_data.dept;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.097</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> tables;</span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------+</span></span><br><span class="line"><span class="operator">|</span>      tab_name      <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------+</span></span><br><span class="line"><span class="operator">|</span> emp                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> person             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> person_info        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> student            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> student_copy_as    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> student_copy_like  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------+</span></span><br><span class="line"><span class="number">6</span> <span class="keyword">rows</span> selected (<span class="number">0.02</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> dfs <span class="operator">-</span>ls <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>mock_data.db<span class="operator">/</span>dept;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span>                     DFS Output                     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> Found <span class="number">1</span> items                                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="operator">-</span>rw<span class="operator">-</span>r<span class="comment">--r--   3 atguigu supergroup         69 2021-10-25 13:15 /user/hive/warehouse/mock_data.db/dept/dep.txt |</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> selected (<span class="number">0.042</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>重建表，再次查询 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> dept (</span><br><span class="line">     dept_no <span class="type">int</span>,</span><br><span class="line">     dept_name  string,</span><br><span class="line">     loc    <span class="type">int</span></span><br><span class="line"> )</span><br><span class="line"> <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.039</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> tables ;</span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------+</span></span><br><span class="line"><span class="operator">|</span>      tab_name      <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------+</span></span><br><span class="line"><span class="operator">|</span> dept               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> emp                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> person             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> person_info        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> student            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> student_copy_as    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> student_copy_like  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------+</span></span><br><span class="line"><span class="number">7</span> <span class="keyword">rows</span> selected (<span class="number">0.021</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dept;</span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+-----------------+-----------+</span></span><br><span class="line"><span class="operator">|</span> dept.dept_no  <span class="operator">|</span> dept.dept_name  <span class="operator">|</span> dept.loc  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+-----------------+-----------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">10</span>            <span class="operator">|</span> ACCOUNTING      <span class="operator">|</span> <span class="number">1700</span>      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">20</span>            <span class="operator">|</span> RESEARCH        <span class="operator">|</span> <span class="number">1800</span>      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">30</span>            <span class="operator">|</span> SALES           <span class="operator">|</span> <span class="number">1900</span>      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">40</span>            <span class="operator">|</span> OPERATIONS      <span class="operator">|</span> <span class="number">1700</span>      <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+-----------------+-----------+</span></span><br><span class="line"><span class="number">4</span> <span class="keyword">rows</span> selected (<span class="number">0.059</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h3 id="4-5-3-管理表-内部表-与外部表的互相转换"><a href="#4-5-3-管理表-内部表-与外部表的互相转换" class="headerlink" title="4.5.3 管理表(内部表)与外部表的互相转换"></a>4.5.3 管理表(内部表)与外部表的互相转换</h3><ol>
<li>查询表的类型 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 hive]$ hive -e <span class="string">&#x27;desc formatted mock_data.student;&#x27;</span>| grep <span class="string">&#x27;Table Type&#x27;</span></span><br><span class="line"><span class="built_in">which</span>: no hbase <span class="keyword">in</span> (/usr/<span class="built_in">local</span>/bin:/usr/bin:/usr/<span class="built_in">local</span>/sbin:/usr/sbin:/opt/module/jdk1.8.0_212/bin:/opt/module/ha-hadoop-3.1.3/bin:/opt/module/ha-hadoop-3.1.3/sbin:/opt/module/hive-3.1.2/bin:/home/atguigu/.<span class="built_in">local</span>/bin:/home/atguigu/bin)</span><br><span class="line">Hive Session ID = 8eb096f9-31db-49d1-b22b-5eb6e458c0c4</span><br><span class="line"></span><br><span class="line">Logging initialized using configuration <span class="keyword">in</span> file:/opt/module/hive-3.1.2/conf/hive-log4j2.properties Async: <span class="literal">true</span></span><br><span class="line">Hive Session ID = a1d905c5-6885-493a-bd5e-db945af0b3ac</span><br><span class="line">OK</span><br><span class="line">Table Type:         	MANAGED_TABLE</span><br><span class="line">Time taken: 0.679 seconds, Fetched: 32 row(s)</span><br><span class="line">[atguigu@hadoop001 hive]$</span><br></pre></td></tr></table></figure></li>
<li>内部表外部表转换 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 外部表</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">alter</span> <span class="keyword">table</span> student <span class="keyword">set</span> tblproperties(<span class="string">&#x27;EXTERNAL&#x27;</span><span class="operator">=</span><span class="string">&#x27;TRUE&#x27;</span>);</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.048</span> seconds)</span><br><span class="line"># 内部表</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">alter</span> <span class="keyword">table</span> student <span class="keyword">set</span> tblproperties(<span class="string">&#x27;EXTERNAL&#x27;</span><span class="operator">=</span><span class="string">&#x27;FALSE&#x27;</span>);</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.053</span> seconds)</span><br></pre></td></tr></table></figure>
<ul>
<li>注意：(‘EXTERNAL’=’TRUE’)和(‘EXTERNAL’=’FALSE’)为固定写法，区分大小写！</li>
</ul>
</li>
</ol>
<h3 id="4-5-3-内部表外部表使用场景"><a href="#4-5-3-内部表外部表使用场景" class="headerlink" title="4.5.3 内部表外部表使用场景"></a>4.5.3 内部表外部表使用场景</h3><ul>
<li>内部表：不常用，通常一些中间表(运算过程产生)会使用内部表</li>
<li>外部表：常用，主要考虑HDFS源数据安全性，数据分析一般采用外部表</li>
</ul>
<h2 id="4-6-修改表"><a href="#4-6-修改表" class="headerlink" title="4.6 修改表"></a>4.6 修改表</h2><h3 id="4-6-1-重命名表"><a href="#4-6-1-重命名表" class="headerlink" title="4.6.1 重命名表"></a>4.6.1 重命名表</h3><ol>
<li>语法 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name RENAME <span class="keyword">TO</span> new_table_name</span><br></pre></td></tr></table></figure></li>
<li>实操案例 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> tables;</span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------+</span></span><br><span class="line"><span class="operator">|</span>      tab_name      <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------+</span></span><br><span class="line"><span class="operator">|</span> dept               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> emp                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> person             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> person_info        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> student            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> student_copy_as    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> student_copy_like  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------+</span></span><br><span class="line"><span class="number">7</span> <span class="keyword">rows</span> selected (<span class="number">0.035</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">alter</span> <span class="keyword">table</span> student_copy_as rename <span class="keyword">to</span> student_copy_as_rename;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.069</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> tables;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+</span></span><br><span class="line"><span class="operator">|</span>        tab_name         <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+</span></span><br><span class="line"><span class="operator">|</span> dept                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> emp                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> person                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> person_info             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> student                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> student_copy_as_rename  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> student_copy_like       <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------+</span></span><br><span class="line"><span class="number">7</span> <span class="keyword">rows</span> selected (<span class="number">0.019</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="4-6-2-增加、修改和删除表分区"><a href="#4-6-2-增加、修改和删除表分区" class="headerlink" title="4.6.2 增加、修改和删除表分区"></a>4.6.2 增加、修改和删除表分区</h3> 详见7.1章分区表基本操作。</li>
</ol>
<h3 id="4-6-3-增加-修改-替换列信息"><a href="#4-6-3-增加-修改-替换列信息" class="headerlink" title="4.6.3 增加/修改/替换列信息"></a>4.6.3 增加/修改/替换列信息</h3><ol>
<li>语法<ul>
<li>更新列  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name CHANGE [<span class="keyword">COLUMN</span>] col_old_name col_new_name column_type [COMMENT col_comment] [<span class="keyword">FIRST</span><span class="operator">|</span>AFTER column_name]</span><br></pre></td></tr></table></figure></li>
<li>增加和替换列  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">ADD</span><span class="operator">|</span>REPLACE COLUMNS (col_name data_type [COMMENT col_comment], ...) </span><br></pre></td></tr></table></figure>
<ul>
<li>注：ADD是代表新增一字段，字段位置在所有列后面(partition列前)，REPLACE则是表示替换表中所有字段。</li>
</ul>
</li>
</ul>
</li>
<li>实操案例<ul>
<li>查询表结构  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">desc</span> student;</span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+------------+----------+</span></span><br><span class="line"><span class="operator">|</span> col_name  <span class="operator">|</span> data_type  <span class="operator">|</span> comment  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+------------+----------+</span></span><br><span class="line"><span class="operator">|</span> id        <span class="operator">|</span> <span class="type">int</span>        <span class="operator">|</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> name      <span class="operator">|</span> string     <span class="operator">|</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+------------+----------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> selected (<span class="number">0.027</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>添加列  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">alter</span> <span class="keyword">table</span> dept <span class="keyword">add</span> columns(dept_desc string, dept_create_time string);</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.058</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">desc</span> dept;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+------------+----------+</span></span><br><span class="line"><span class="operator">|</span>     col_name      <span class="operator">|</span> data_type  <span class="operator">|</span> comment  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+------------+----------+</span></span><br><span class="line"><span class="operator">|</span> dept_no           <span class="operator">|</span> <span class="type">int</span>        <span class="operator">|</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> dept_name         <span class="operator">|</span> string     <span class="operator">|</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> loc               <span class="operator">|</span> <span class="type">int</span>        <span class="operator">|</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> dept_desc         <span class="operator">|</span> string     <span class="operator">|</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> dept_create_time  <span class="operator">|</span> string     <span class="operator">|</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------+------------+----------+</span></span><br><span class="line"><span class="number">5</span> <span class="keyword">rows</span> selected (<span class="number">0.026</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>更新列  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">0: jdbc:hive2://hadoop001:10000&gt; alter table dept change column dept_desc desc string;</span><br><span class="line">No rows affected (0.055 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt; desc dept;</span><br><span class="line">+-------------------+------------+----------+</span><br><span class="line">|     col_name      | data_type  | comment  |</span><br><span class="line">+-------------------+------------+----------+</span><br><span class="line">| dept_no           | int        |          |</span><br><span class="line">| dept_name         | string     |          |</span><br><span class="line">| loc               | int        |          |</span><br><span class="line">| desc              | string     |          |</span><br><span class="line">| dept_create_time  | string     |          |</span><br><span class="line">+-------------------+------------+----------+</span><br><span class="line">5 rows selected (0.026 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt;</span><br></pre></td></tr></table></figure></li>
<li>替换列  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">alter</span> <span class="keyword">table</span> dept replace columns(deptno string, dname string, loc string);</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.083</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">desc</span> dept;</span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+------------+----------+</span></span><br><span class="line"><span class="operator">|</span> col_name  <span class="operator">|</span> data_type  <span class="operator">|</span> comment  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+------------+----------+</span></span><br><span class="line"><span class="operator">|</span> deptno    <span class="operator">|</span> string     <span class="operator">|</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> dname     <span class="operator">|</span> string     <span class="operator">|</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> loc       <span class="operator">|</span> string     <span class="operator">|</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+------------+----------+</span></span><br><span class="line"><span class="number">3</span> <span class="keyword">rows</span> selected (<span class="number">0.027</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h1 id="五、DML数据库操作"><a href="#五、DML数据库操作" class="headerlink" title="五、DML数据库操作"></a>五、DML数据库操作</h1><h2 id="5-1-数据导入"><a href="#5-1-数据导入" class="headerlink" title="5.1 数据导入"></a>5.1 数据导入</h2><h3 id="5-1-1-向表中装载数据（Load）"><a href="#5-1-1-向表中装载数据（Load）" class="headerlink" title="5.1.1 向表中装载数据（Load）"></a>5.1.1 向表中装载数据（Load）</h3><ol>
<li>语法 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data [<span class="built_in">local</span>] inpath <span class="string">&#x27;数据的path&#x27;</span> [overwrite] into table student [partition (partcol1=val1,…)];</span><br></pre></td></tr></table></figure>
<ul>
<li>load data:表示加载数据</li>
<li>local:表示从本地加载数据到hive表；否则从HDFS加载数据到hive表</li>
<li>inpath:表示加载数据的路径</li>
<li>overwrite:表示覆盖表中已有数据，否则表示追加</li>
<li>into table:表示加载到哪张表</li>
<li>student:表示具体的表</li>
<li>partition:表示上传到指定分区</li>
</ul>
</li>
<li>实操案例<ul>
<li>加载本地文件到hive  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/home/atguigu/hive/student.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> mock_data.student;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.148</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>加载HDFS文件到hive中  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> dfs <span class="operator">-</span>ls <span class="operator">/</span>hive<span class="operator">/</span>source_data;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span>                     DFS Output                     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> Found <span class="number">1</span> items                                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="operator">-</span>rw<span class="operator">-</span>r<span class="comment">--r--   3 atguigu supergroup        150 2021-10-25 15:22 /hive/source_data/student.txt |</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> selected (<span class="number">0.055</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> load data inpath <span class="string">&#x27;/hive/source_data/student.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> mock_data.student;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.121</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>加载数据覆盖表中已有的数据  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">0: jdbc:hive2://hadoop001:10000&gt; select count(*) from mock_data.student;</span><br><span class="line">+------+</span><br><span class="line">| _c0  |</span><br><span class="line">+------+</span><br><span class="line">| 48   |</span><br><span class="line">+------+</span><br><span class="line">1 row selected (16.219 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt; load data <span class="built_in">local</span> inpath <span class="string">&#x27;/home/atguigu/hive/student.txt&#x27;</span> overwrite into table mock_data.student;</span><br><span class="line">No rows affected (0.104 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt; select count(*) from mock_data.student;</span><br><span class="line">+------+</span><br><span class="line">| _c0  |</span><br><span class="line">+------+</span><br><span class="line">| 16   |</span><br><span class="line">+------+</span><br><span class="line">1 row selected (14.727 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>导入顺序<ul>
<li>追加导入数据根据文件名字典序排序</li>
</ul>
</li>
</ol>
<h3 id="5-1-2-通过查询语句向表中插入数据（Insert）"><a href="#5-1-2-通过查询语句向表中插入数据（Insert）" class="headerlink" title="5.1.2 通过查询语句向表中插入数据（Insert）"></a>5.1.2 通过查询语句向表中插入数据（Insert）</h3><ol>
<li>根据单张表查询结果插入 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> student_from_select <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student;</span><br></pre></td></tr></table></figure>
<ul>
<li>insert into：以追加数据的方式插入到表或分区，原有数据不会删除</li>
<li>insert overwrite：会覆盖表中已存在的数据</li>
<li>注意：insert不支持插入部分字段</li>
</ul>
</li>
<li>多表（多分区）插入模式（根据多张表查询结果） <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> student</span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> student_from_select</span><br><span class="line"><span class="keyword">select</span> id, name <span class="keyword">where</span> id<span class="operator">=</span><span class="number">1001</span></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> student_copy_like</span><br><span class="line"><span class="keyword">select</span> id, name <span class="keyword">where</span> id<span class="operator">=</span><span class="number">1009</span></span><br></pre></td></tr></table></figure>
<h3 id="5-1-3-查询语句中创建表并加载数据（As-Select）"><a href="#5-1-3-查询语句中创建表并加载数据（As-Select）" class="headerlink" title="5.1.3 查询语句中创建表并加载数据（As Select）"></a>5.1.3 查询语句中创建表并加载数据（As Select）</h3></li>
<li>根据查询结果创建表（查询的结果会添加到新创建的表中） <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> student3 <span class="keyword">as</span> <span class="keyword">select</span> id, name <span class="keyword">from</span> student; </span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="5-1-4-创建表时通过Location指定加载数据路径"><a href="#5-1-4-创建表时通过Location指定加载数据路径" class="headerlink" title="5.1.4 创建表时通过Location指定加载数据路径"></a>5.1.4 创建表时通过Location指定加载数据路径</h3><ol>
<li>上传数据到hdfs上 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> dfs <span class="operator">-</span>put <span class="operator">/</span>home<span class="operator">/</span>atguigu<span class="operator">/</span>hive<span class="operator">/</span>load_student.txt <span class="operator">/</span>hive<span class="operator">/</span>db<span class="operator">/</span>mock_data<span class="operator">/</span>load_student<span class="operator">/</span>load_student.txt;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+</span></span><br><span class="line"><span class="operator">|</span> DFS Output  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+</span></span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> selected (<span class="number">0.019</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>创建表，并指定在hdfs上的位置 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> load_student (</span><br><span class="line">    id   <span class="type">int</span>,</span><br><span class="line">    name string</span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">stored <span class="keyword">as</span> textfile</span><br><span class="line">location <span class="string">&#x27;/hive/db/mock_data/load_student&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li>查询数据 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> mock_data.load_student limit <span class="number">10</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">------------------+--------------------+</span></span><br><span class="line"><span class="operator">|</span> load_student.id  <span class="operator">|</span> load_student.name  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------+--------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">22852294</span>         <span class="operator">|</span> 司寇俊                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">22852295</span>         <span class="operator">|</span> 安投悬                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">22852296</span>         <span class="operator">|</span> 申燎赢                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">22852297</span>         <span class="operator">|</span> 洪谎                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">22852298</span>         <span class="operator">|</span> 丰觅                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">22852299</span>         <span class="operator">|</span> 拓跋卷                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">22852300</span>         <span class="operator">|</span> 汪舶                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">22852301</span>         <span class="operator">|</span> 涂钦羡                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">22852302</span>         <span class="operator">|</span> 濮崭                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">22852303</span>         <span class="operator">|</span> 阚撑                 <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------+--------------------+</span></span><br><span class="line"><span class="number">10</span> <span class="keyword">rows</span> selected (<span class="number">0.057</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="5-1-5-Import数据到指定Hive表中"><a href="#5-1-5-Import数据到指定Hive表中" class="headerlink" title="5.1.5 Import数据到指定Hive表中"></a>5.1.5 Import数据到指定Hive表中</h3><ul>
<li>注意：先用export导出后，再将数据导入。多用于小规模迁移，会自动创建表。<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> export <span class="keyword">table</span> mock_data.person <span class="keyword">to</span> <span class="string">&#x27;/hive/source_data/person/export&#x27;</span>;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">17.558</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> import <span class="keyword">table</span> mock_data.import_person <span class="keyword">from</span> <span class="string">&#x27;/hive/source_data/person/export&#x27;</span>;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">4.487</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> mock_data.import_person;</span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+</span></span><br><span class="line"><span class="operator">|</span>    _c0    <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">24307000</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> selected (<span class="number">19.358</span> seconds)</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="5-2-数据导出"><a href="#5-2-数据导出" class="headerlink" title="5.2 数据导出"></a>5.2 数据导出</h2><h3 id="5-2-1-Insert导出"><a href="#5-2-1-Insert导出" class="headerlink" title="5.2.1 Insert导出"></a>5.2.1 Insert导出</h3><ol>
<li>将查询的结果导出到本地 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">local</span> directory <span class="string">&#x27;/home/atguigu/hive/export/person&#x27;</span> <span class="keyword">select</span> id,name <span class="keyword">from</span> mock_data.person;</span><br></pre></td></tr></table></figure></li>
<li>将查询的结果格式化导出到本地 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">local</span> directory <span class="string">&#x27;/home/atguigu/hive/export/person&#x27;</span> <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\t&#x27;</span> <span class="keyword">select</span> id,name <span class="keyword">from</span> mock_data.person;</span><br></pre></td></tr></table></figure></li>
<li>将查询的结果导出到HDFS上(没有local) <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">insert</span> overwrite directory <span class="string">&#x27;/hive/source_data/person&#x27;</span> <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\t&#x27;</span> <span class="keyword">select</span> id,name <span class="keyword">from</span> mock_data.person;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">21.398</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> dfs <span class="operator">-</span>ls <span class="operator">/</span>hive<span class="operator">/</span>source_data<span class="operator">/</span>person;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span>                     DFS Output                     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> Found <span class="number">5</span> items                                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="operator">-</span>rw<span class="operator">-</span>r<span class="comment">--r--   3 atguigu supergroup  115767751 2021-10-25 19:13 /hive/source_data/person/000000_0 |</span></span><br><span class="line"><span class="operator">|</span> <span class="operator">-</span>rw<span class="operator">-</span>r<span class="comment">--r--   3 atguigu supergroup  115656456 2021-10-25 19:13 /hive/source_data/person/000001_0 |</span></span><br><span class="line"><span class="operator">|</span> <span class="operator">-</span>rw<span class="operator">-</span>r<span class="comment">--r--   3 atguigu supergroup  111382098 2021-10-25 19:13 /hive/source_data/person/000002_0 |</span></span><br><span class="line"><span class="operator">|</span> <span class="operator">-</span>rw<span class="operator">-</span>r<span class="comment">--r--   3 atguigu supergroup   55441386 2021-10-25 19:13 /hive/source_data/person/000003_0 |</span></span><br><span class="line"><span class="operator">|</span> <span class="operator">-</span>rw<span class="operator">-</span>r<span class="comment">--r--   3 atguigu supergroup   27719097 2021-10-25 19:13 /hive/source_data/person/000004_0 |</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="number">6</span> <span class="keyword">rows</span> selected (<span class="number">0.012</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="5-2-2-Export导出到HDFS上"><a href="#5-2-2-Export导出到HDFS上" class="headerlink" title="5.2.2 Export导出到HDFS上"></a>5.2.2 Export导出到HDFS上</h3><p>export和import主要用于两个Hadoop平台集群之间Hive表迁移。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export <span class="keyword">table</span> mock_data.person <span class="keyword">to</span> <span class="string">&#x27;/hive/source_data/person/export&#x27;</span>;</span><br></pre></td></tr></table></figure>

<h3 id="5-2-3-Hive-Shell-命令导出"><a href="#5-2-3-Hive-Shell-命令导出" class="headerlink" title="5.2.3 Hive Shell 命令导出"></a>5.2.3 Hive Shell 命令导出</h3><ul>
<li>基本语法：（hive -f/-e 执行语句或者脚本 &gt; file）  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hive]$ bin/hive -e <span class="string">&#x27;select * from default.student;&#x27;</span> &gt;</span><br><span class="line"> /opt/module/hive/datas/<span class="built_in">export</span>/student4.txt;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="5-2-4-Export导出到HDFS上"><a href="#5-2-4-Export导出到HDFS上" class="headerlink" title="5.2.4 Export导出到HDFS上"></a>5.2.4 Export导出到HDFS上</h3><ul>
<li>export和import主要用于两个Hadoop平台集群之间Hive表迁移。  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(defahiveult)<span class="operator">&gt;</span> export <span class="keyword">table</span> default.student <span class="keyword">to</span></span><br><span class="line"> <span class="string">&#x27;/user/hive/warehouse/export/student&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="5-2-5-清除表中数据（Truncate）"><a href="#5-2-5-清除表中数据（Truncate）" class="headerlink" title="5.2.5 清除表中数据（Truncate）"></a>5.2.5 清除表中数据（Truncate）</h3><ul>
<li>注意：Truncate只能删除管理表，不能删除外部表中数据<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">truncate</span> <span class="keyword">table</span> student;</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="六、查询"><a href="#六、查询" class="headerlink" title="六、查询"></a>六、查询</h1><h3 id="6-1-1-全表和特定列查询"><a href="#6-1-1-全表和特定列查询" class="headerlink" title="6.1.1 全表和特定列查询"></a>6.1.1 全表和特定列查询</h3><ol>
<li>数据准备 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">dept:</span><br><span class="line">10	ACCOUNTING	1700</span><br><span class="line">20	RESEARCH	1800</span><br><span class="line">30	SALES	1900</span><br><span class="line">40	OPERATIONS	1700</span><br><span class="line">emp：</span><br><span class="line">7369	SMITH	CLERK	7902	1980-12-17	800.00		20</span><br><span class="line">7499	ALLEN	SALESMAN	7698	1981-2-20	1600.00	300.00	30</span><br><span class="line">7521	WARD	SALESMAN	7698	1981-2-22	1250.00	500.00	30</span><br><span class="line">7566	JONES	MANAGER	7839	1981-4-2	2975.00		20</span><br><span class="line">7654	MARTIN	SALESMAN	7698	1981-9-28	1250.00	1400.00	30</span><br><span class="line">7698	BLAKE	MANAGER	7839	1981-5-1	2850.00		30</span><br><span class="line">7782	CLARK	MANAGER	7839	1981-6-9	2450.00		10</span><br><span class="line">7788	SCOTT	ANALYST	7566	1987-4-19	3000.00		20</span><br><span class="line">7839	KING	PRESIDENT		1981-11-17	5000.00		10</span><br><span class="line">7844	TURNER	SALESMAN	7698	1981-9-8	1500.00	0.00	30</span><br><span class="line">7876	ADAMS	CLERK	7788	1987-5-23	1100.00		20</span><br><span class="line">7900	JAMES	CLERK	7698	1981-12-3	950.00		30</span><br><span class="line">7902	FORD	ANALYST	7566	1981-12-3	3000.00		20</span><br><span class="line">7934	MILLER	CLERK	7782	1982-1-23	1300.00		10</span><br></pre></td></tr></table></figure></li>
<li>创建表结构 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 部门表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> dept(</span><br><span class="line">    deptno <span class="type">int</span>,</span><br><span class="line">    dname string,</span><br><span class="line">    loc <span class="type">int</span></span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line"><span class="comment">-- 员工表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> emp(</span><br><span class="line">    empno <span class="type">int</span>,</span><br><span class="line">    ename string,</span><br><span class="line">    job string,</span><br><span class="line">    mgr <span class="type">int</span>,</span><br><span class="line">    hiredate string, </span><br><span class="line">    sal <span class="keyword">double</span>, </span><br><span class="line">    comm <span class="keyword">double</span>,</span><br><span class="line">    deptno <span class="type">int</span></span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li>导入数据 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/datas/dept.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span></span><br><span class="line">dept;	</span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/datas/emp.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> emp;</span><br></pre></td></tr></table></figure></li>
<li>全表查询 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp;</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> empno,ename,job,mgr,hiredate,sal,comm,deptno <span class="keyword">from</span> emp ;</span><br></pre></td></tr></table></figure></li>
<li>选择特定列查询 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> empno, ename <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure></li>
<li>注意：<ul>
<li>（1）SQL 语言大小写不敏感。 </li>
<li>（2）SQL 可以写在一行或者多行</li>
<li>（3）关键字不能被缩写也不能分行</li>
<li>（4）各子句一般要分行写。</li>
<li>（5）使用缩进提高语句的可读性。</li>
</ul>
</li>
</ol>
<h3 id="6-1-2-列别名"><a href="#6-1-2-列别名" class="headerlink" title="6.1.2 列别名"></a>6.1.2 列别名</h3><ol>
<li>用途<ol>
<li>重命名一个列</li>
<li>便于计算</li>
<li>紧跟列名，也可以在列名和别名之间加入关键字‘AS’ </li>
<li>案例实操 </li>
</ol>
</li>
<li>查询名称和部门 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> ename <span class="keyword">AS</span> name, deptno dn <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="6-1-3-算术运算符"><a href="#6-1-3-算术运算符" class="headerlink" title="6.1.3 算术运算符"></a>6.1.3 算术运算符</h3><table>
<thead>
<tr>
<th>运算符</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>A+B</td>
<td>A和B 相加</td>
</tr>
<tr>
<td>A-B</td>
<td>A减去B</td>
</tr>
<tr>
<td>A*B</td>
<td>A和B 相乘</td>
</tr>
<tr>
<td>A/B</td>
<td>A除以B</td>
</tr>
<tr>
<td>A%B</td>
<td>A对B取余</td>
</tr>
<tr>
<td>A&amp;B</td>
<td>A和B按位取与</td>
</tr>
<tr>
<td>A</td>
<td>B</td>
</tr>
<tr>
<td>A^B</td>
<td>A和B按位取异或</td>
</tr>
<tr>
<td>~A</td>
<td>A按位取反</td>
</tr>
</tbody></table>
<ul>
<li>案例实操：查询出所有员工的薪水后加1显示。<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> sal <span class="operator">+</span><span class="number">1</span> <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure>
<h3 id="6-1-4-常用函数"><a href="#6-1-4-常用函数" class="headerlink" title="6.1.4 常用函数"></a>6.1.4 常用函数</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 求总行数（count）</span></span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">count</span>(<span class="operator">*</span>) cnt <span class="keyword">from</span> emp;</span><br><span class="line"><span class="comment">-- 求工资的最大值（max）</span></span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">max</span>(sal) max_sal <span class="keyword">from</span> emp;</span><br><span class="line"><span class="comment">-- 求工资的最小值（min）</span></span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">min</span>(sal) min_sal <span class="keyword">from</span> emp;</span><br><span class="line"><span class="comment">-- 求工资的总和（sum）</span></span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">sum</span>(sal) sum_sal <span class="keyword">from</span> emp; </span><br><span class="line"><span class="comment">-- 求工资的平均值（avg）</span></span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">avg</span>(sal) avg_sal <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="6-1-5-Limit语句"><a href="#6-1-5-Limit语句" class="headerlink" title="6.1.5 Limit语句"></a>6.1.5 Limit语句</h3><ul>
<li>LIMIT子句用于限制返回的行数。  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp limit <span class="number">5</span>;</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp limit <span class="number">2</span>,<span class="number">3</span>;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="6-1-6-Where语句"><a href="#6-1-6-Where语句" class="headerlink" title="6.1.6 Where语句"></a>6.1.6 Where语句</h3><ol>
<li>使用WHERE子句，将不满足条件的行过滤掉</li>
<li>WHERE子句紧随FROM子句</li>
<li>案例实操<ul>
<li>查询出薪水大于1000的所有员工  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> sal <span class="operator">&gt;</span><span class="number">1000</span>;</span><br></pre></td></tr></table></figure></li>
<li>注意：where子句中不能使用字段别名。</li>
</ul>
</li>
</ol>
<h3 id="6-1-7-比较运算符（Between-In-Is-Null）"><a href="#6-1-7-比较运算符（Between-In-Is-Null）" class="headerlink" title="6.1.7 比较运算符（Between/In/ Is Null）"></a>6.1.7 比较运算符（Between/In/ Is Null）</h3><ol>
<li><p>下面表中描述了谓词操作符，这些操作符同样可以用于JOIN…ON和HAVING语句中。</p>
<table>
<thead>
<tr>
<th>操作符</th>
<th>支持的数据类型</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>A=B</td>
<td>基本数据类型</td>
<td>如果A等于B则返回TRUE，反之返回FALSE</td>
</tr>
<tr>
<td>A&lt;=&gt;B</td>
<td>基本数据类型</td>
<td>如果A和B都为NULL，则返回TRUE，如果一边为NULL，返回False</td>
</tr>
<tr>
<td>A&lt;&gt;B, A!=B</td>
<td>基本数据类型</td>
<td>A或者B为NULL则返回NULL；如果A不等于B，则返回TRUE，反之返回FALSE</td>
</tr>
<tr>
<td>A&lt;B</td>
<td>基本数据类型</td>
<td>A或者B为NULL，则返回NULL；如果A小于B，则返回TRUE，反之返回FALSE</td>
</tr>
<tr>
<td>A&lt;=B</td>
<td>基本数据类型</td>
<td>A或者B为NULL，则返回NULL；如果A小于等于B，则返回TRUE，反之返回FALSE</td>
</tr>
<tr>
<td>A&gt;B</td>
<td>基本数据类型</td>
<td>A或者B为NULL，则返回NULL；如果A大于B，则返回TRUE，反之返回FALSE</td>
</tr>
<tr>
<td>A&gt;=B</td>
<td>基本数据类型</td>
<td>A或者B为NULL，则返回NULL；如果A大于等于B，则返回TRUE，反之返回FALSE</td>
</tr>
<tr>
<td>A [NOT] BETWEEN B AND C</td>
<td>基本数据类型</td>
<td>如果A，B或者C任一为NULL，则结果为NULL。如果A的值大于等于B而且小于或等于C，则结果为TRUE，反之为FALSE。如果使用NOT关键字则可达到相反的效果。</td>
</tr>
<tr>
<td>A IS NULL</td>
<td>所有数据类型</td>
<td>如果A等于NULL，则返回TRUE，反之返回FALSE</td>
</tr>
<tr>
<td>A IS NOT NULL</td>
<td>所有数据类型</td>
<td>如果A不等于NULL，则返回TRUE，反之返回FALSE</td>
</tr>
<tr>
<td>IN(数值1, 数值2)</td>
<td>所有数据类型</td>
<td>使用 IN运算显示列表中的值</td>
</tr>
<tr>
<td>A [NOT] LIKE B</td>
<td>STRING 类型</td>
<td>B是一个SQL下的简单正则表达式，也叫通配符模式，如果A与其匹配的话，则返回TRUE；反之返回FALSE。B的表达式说明如下：‘x%’表示A必须以字母‘x’开头，‘%x’表示A必须以字母’x’结尾，而‘%x%’表示A包含有字母’x’,可以位于开头，结尾或者字符串中间。如果使用NOT关键字则可达到相反的效果。</td>
</tr>
<tr>
<td>A RLIKE B, A REGEXP B</td>
<td>STRING 类型</td>
<td>B是基于java的正则表达式，如果A与其匹配，则返回TRUE；反之返回FALSE。匹配使用的是JDK中的正则表达式接口实现的，因为正则也依据其中的规则。例如，正则表达式必须和整个字符串A相匹配，而不是只需与其字符串匹配。</td>
</tr>
</tbody></table>
</li>
<li><p>案例实操</p>
<ul>
<li>查询出薪水等于5000的所有员工  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp <span class="built_in">where</span> sal =5000;</span><br></pre></td></tr></table></figure></li>
<li>查询工资在500到1000的员工信息  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> sal <span class="keyword">between</span> <span class="number">500</span> <span class="keyword">and</span> <span class="number">1000</span>;</span><br></pre></td></tr></table></figure></li>
<li>查询comm为空的所有员工信息  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> comm <span class="keyword">is</span> <span class="keyword">null</span>;</span><br></pre></td></tr></table></figure></li>
<li>查询工资是1500或5000的员工信息  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> sal <span class="keyword">IN</span> (<span class="number">1500</span>, <span class="number">5000</span>);</span><br></pre></td></tr></table></figure>
<h3 id="6-1-8-Like和RLike"><a href="#6-1-8-Like和RLike" class="headerlink" title="6.1.8 Like和RLike"></a>6.1.8 Like和RLike</h3></li>
</ul>
</li>
<li><p>使用LIKE运算选择类似的值</p>
</li>
<li><p>选择条件可以包含字符或数字:</p>
<ul>
<li>% 代表零个或多个字符(任意个字符)。</li>
<li>_ 代表一个字符。</li>
</ul>
</li>
<li><p>RLIKE子句</p>
<ul>
<li>RLIKE子句是Hive中这个功能的一个扩展，其可以通过Java的正则表达式这个更强大的语言来指定匹配条件。</li>
</ul>
</li>
<li><p>案例实操</p>
<ol>
<li>查找名字以A开头的员工信息 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> ename <span class="keyword">LIKE</span> <span class="string">&#x27;A%&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li>查找名字中第二个字母为A的员工信息 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> ename <span class="keyword">LIKE</span> <span class="string">&#x27;_A%&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li>查找名字中带有A-N的员工信息 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> ename  RLIKE <span class="string">&#x27;[A-N]&#x27;</span>;</span><br></pre></td></tr></table></figure>
<h3 id="6-1-9-逻辑运算符（And-Or-Not）"><a href="#6-1-9-逻辑运算符（And-Or-Not）" class="headerlink" title="6.1.9 逻辑运算符（And/Or/Not）"></a>6.1.9 逻辑运算符（And/Or/Not）</h3><table>
<thead>
<tr>
<th>操作符</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>AND</td>
<td>逻辑并</td>
</tr>
<tr>
<td>OR</td>
<td>逻辑或</td>
</tr>
<tr>
<td>NOT</td>
<td>逻辑否</td>
</tr>
</tbody></table>
</li>
</ol>
</li>
<li><p>案例实操</p>
<ol>
<li>查询薪水大于1000，部门是30 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> sal<span class="operator">&gt;</span><span class="number">1000</span> <span class="keyword">and</span> deptno<span class="operator">=</span><span class="number">30</span>;</span><br></pre></td></tr></table></figure></li>
<li>查询薪水大于1000，或者部门是30 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> sal<span class="operator">&gt;</span><span class="number">1000</span> <span class="keyword">or</span> deptno<span class="operator">=</span><span class="number">30</span>;</span><br></pre></td></tr></table></figure></li>
<li>查询除了20部门和30部门以外的员工信息 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> deptno <span class="keyword">not</span> <span class="keyword">IN</span>(<span class="number">30</span>, <span class="number">20</span>);</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h2 id="6-2-分组"><a href="#6-2-分组" class="headerlink" title="6.2 分组"></a>6.2 分组</h2><h3 id="6-2-1-Group-By语句"><a href="#6-2-1-Group-By语句" class="headerlink" title="6.2.1 Group By语句"></a>6.2.1 Group By语句</h3><p>GROUP BY语句通常会和聚合函数一起使用，按照一个或者多个列队结果进行分组，然后对每个组执行聚合操作。</p>
<ol>
<li>案例实操：<ol>
<li>计算emp表每个部门的平均工资 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> t.deptno, <span class="built_in">avg</span>(t.sal) avg_sal <span class="keyword">from</span> emp t <span class="keyword">group</span> <span class="keyword">by</span> t.deptno;</span><br></pre></td></tr></table></figure></li>
<li>计算emp每个部门中每个岗位的最高薪水 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> t.deptno, t.job, <span class="built_in">max</span>(t.sal) max_sal <span class="keyword">from</span> emp t <span class="keyword">group</span> <span class="keyword">by</span> t.deptno, t.job;</span><br></pre></td></tr></table></figure>
<h3 id="6-2-2-Having语句"><a href="#6-2-2-Having语句" class="headerlink" title="6.2.2 Having语句"></a>6.2.2 Having语句</h3></li>
</ol>
</li>
<li>having与where不同点<ol>
<li>where后面不能写分组函数，而having后面可以使用分组函数。</li>
<li>having只用于group by分组统计语句。</li>
</ol>
</li>
<li>案例实操<ol>
<li>求每个部门的平均薪水大于2000的部门<ol>
<li>求每个部门的平均工资 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> deptno, <span class="built_in">avg</span>(sal) <span class="keyword">from</span> emp <span class="keyword">group</span> <span class="keyword">by</span> deptno;</span><br></pre></td></tr></table></figure></li>
<li>求每个部门的平均薪水大于2000的部门  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> deptno, <span class="built_in">avg</span>(sal) avg_sal <span class="keyword">from</span> emp <span class="keyword">group</span> <span class="keyword">by</span> deptno <span class="keyword">having</span> avg_sal <span class="operator">&gt;</span> <span class="number">2000</span>;</span><br></pre></td></tr></table></figure>
<h2 id="6-3-Join语句"><a href="#6-3-Join语句" class="headerlink" title="6.3 Join语句"></a>6.3 Join语句</h2><h3 id="6-3-1-等值Join"><a href="#6-3-1-等值Join" class="headerlink" title="6.3.1 等值Join"></a>6.3.1 等值Join</h3>Hive支持通常的SQL JOIN语句。 </li>
</ol>
</li>
</ol>
</li>
<li>案例实操<ol>
<li>根据员工表和部门表中的部门编号相等，查询员工编号、员工名称和部门名称； <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> e.empno, e.ename, d.deptno, d.dname <span class="keyword">from</span> emp e <span class="keyword">join</span> dept d <span class="keyword">on</span> e.deptno <span class="operator">=</span> d.deptno;</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h3 id="6-3-2-表的别名"><a href="#6-3-2-表的别名" class="headerlink" title="6.3.2 表的别名"></a>6.3.2 表的别名</h3><ol>
<li>好处<ol>
<li>使用别名可以简化查询。</li>
<li>使用表名前缀可以提高执行效率。</li>
</ol>
</li>
<li>案例实操<ol>
<li>合并员工表和部门表 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> e.empno, e.ename, d.deptno <span class="keyword">from</span> emp e <span class="keyword">join</span> dept d <span class="keyword">on</span> e.deptno <span class="operator">=</span> d.deptno;</span><br></pre></td></tr></table></figure>
<h3 id="6-3-3-内连接"><a href="#6-3-3-内连接" class="headerlink" title="6.3.3 内连接"></a>6.3.3 内连接</h3></li>
</ol>
</li>
</ol>
<ul>
<li>只有进行连接的两个表中都存在与连接条件相匹配的数据才会被保留下来。  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> e.empno, e.ename, d.deptno <span class="keyword">from</span> emp e <span class="keyword">join</span> dept d <span class="keyword">on</span> e.deptno <span class="operator">=</span> d.deptno;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="6-3-4-左外连接"><a href="#6-3-4-左外连接" class="headerlink" title="6.3.4 左外连接"></a>6.3.4 左外连接</h3><ul>
<li>JOIN操作符左边表中符合WHERE子句的所有记录将会被返回。  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> e.empno, e.ename, d.deptno <span class="keyword">from</span> emp e <span class="keyword">left</span> <span class="keyword">join</span> dept d <span class="keyword">on</span> e.deptno <span class="operator">=</span> d.deptno;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="6-3-5-右外连接"><a href="#6-3-5-右外连接" class="headerlink" title="6.3.5 右外连接"></a>6.3.5 右外连接</h3><ul>
<li>JOIN操作符右边表中符合WHERE子句的所有记录将会被返回。  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> e.empno, e.ename, d.deptno <span class="keyword">from</span> emp e <span class="keyword">right</span> <span class="keyword">join</span> dept d <span class="keyword">on</span> e.deptno <span class="operator">=</span> d.deptno;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="6-3-6-满外连接"><a href="#6-3-6-满外连接" class="headerlink" title="6.3.6 满外连接"></a>6.3.6 满外连接</h3><ul>
<li>将会返回所有表中符合WHERE语句条件的所有记录。如果任一表的指定字段没有符合条件的值的话，那么就使用NULL值替代。  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> e.empno, e.ename, d.deptno <span class="keyword">from</span> emp e <span class="keyword">full</span> <span class="keyword">join</span> dept d <span class="keyword">on</span> e.deptno <span class="operator">=</span> d.deptno;</span><br></pre></td></tr></table></figure>
<h3 id="6-3-7-多表连接"><a href="#6-3-7-多表连接" class="headerlink" title="6.3.7 多表连接"></a>6.3.7 多表连接</h3></li>
<li>注意：连接 n个表，至少需要n-1个连接条件。例如：连接三个表，至少需要两个连接条件。</li>
<li>数据准备  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">location</span><br><span class="line">1700	Beijing</span><br><span class="line">1800	London</span><br><span class="line">1900	Tokyo</span><br></pre></td></tr></table></figure></li>
</ul>
<ol>
<li>创建位置表 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> if <span class="keyword">not</span> <span class="keyword">exists</span> location(</span><br><span class="line">    loc <span class="type">int</span>,</span><br><span class="line">    loc_name string</span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li>导入数据 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/datas/location.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> location;</span><br></pre></td></tr></table></figure></li>
<li>多表连接查询 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span><span class="keyword">SELECT</span></span><br><span class="line">       e.emp_name,</span><br><span class="line">       d.dept_name,</span><br><span class="line">       l.loc_name</span><br><span class="line"><span class="keyword">FROM</span> emp e</span><br><span class="line"><span class="keyword">JOIN</span> dept d <span class="keyword">ON</span> d.dept_no <span class="operator">=</span> e.dept_no</span><br><span class="line"><span class="keyword">JOIN</span> location l <span class="keyword">ON</span> d.loc <span class="operator">=</span> l.loc;</span><br></pre></td></tr></table></figure>
<ul>
<li>大多数情况下，Hive会对每对JOIN连接对象启动一个MapReduce任务。本例中会首先启动一个MapReduce job对表e和表d进行连接操作，然后会再启动一个MapReduce job将第一个MapReduce job的输出和表l;进行连接操作。</li>
<li>注意：为什么不是表d和表l先进行连接操作呢？这是因为Hive总是按照从左到右的顺序执行的。</li>
<li>优化：当对3个或者更多表进行join连接时，如果每个on子句都使用相同的连接键的话，那么只会产生一个MapReduce job。</li>
</ul>
</li>
</ol>
<h3 id="6-3-8-笛卡尔积"><a href="#6-3-8-笛卡尔积" class="headerlink" title="6.3.8 笛卡尔积"></a>6.3.8 笛卡尔积</h3><ol>
<li>笛卡尔积会在下面条件下产生<ol>
<li>省略连接条件</li>
<li>连接条件无效</li>
<li>所有表中的所有行互相连接</li>
</ol>
</li>
<li>案例实操 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> emp_name, dept_name <span class="keyword">from</span> emp, dept;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="6-4-排序"><a href="#6-4-排序" class="headerlink" title="6.4 排序"></a>6.4 排序</h2><h3 id="6-4-1-全局排序（Order-By）"><a href="#6-4-1-全局排序（Order-By）" class="headerlink" title="6.4.1 全局排序（Order By）"></a>6.4.1 全局排序（Order By）</h3><p>Order By：全局排序，只有一个Reducer</p>
<ol>
<li>使用 ORDER BY 子句排序<ul>
<li>ASC（ascend）: 升序（默认）</li>
<li>DESC（descend）: 降序</li>
</ul>
</li>
<li>ORDER BY 子句在SELECT语句的结尾</li>
<li>案例实操 <ol>
<li>查询员工信息按工资升序排列 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">order</span> <span class="keyword">by</span> sal;</span><br></pre></td></tr></table></figure></li>
<li>查询员工信息按工资降序排列 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">order</span> <span class="keyword">by</span> sal <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure>
<h3 id="6-4-2-按照别名排序"><a href="#6-4-2-按照别名排序" class="headerlink" title="6.4.2 按照别名排序"></a>6.4.2 按照别名排序</h3></li>
</ol>
</li>
</ol>
<ul>
<li>按照员工薪水的2倍排序  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> ename, sal<span class="operator">*</span><span class="number">2</span> twosal <span class="keyword">from</span> emp <span class="keyword">order</span> <span class="keyword">by</span> twosal;</span><br></pre></td></tr></table></figure>
<h3 id="6-4-3-多个列排序"><a href="#6-4-3-多个列排序" class="headerlink" title="6.4.3 多个列排序"></a>6.4.3 多个列排序</h3></li>
<li>按照部门和工资升序排序  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> ename, deptno, sal <span class="keyword">from</span> emp <span class="keyword">order</span> <span class="keyword">by</span> deptno, sal ;</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="6-4-4-Sort-By-每个Reduce内部排序"><a href="#6-4-4-Sort-By-每个Reduce内部排序" class="headerlink" title="6.4.4 Sort By 每个Reduce内部排序"></a>6.4.4 Sort By 每个Reduce内部排序</h3><ul>
<li>Sort By：对于大规模的数据集order by的效率非常低。在很多情况下，并不需要全局排序，此时可以使用sort by。</li>
<li>Sort by为每个reducer产生一个排序文件。每个Reducer内部进行排序，对全局结果集来说不是排序。</li>
</ul>
<ol>
<li>设置reduce个数 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="number">2</span>;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.005</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">set</span> mapreduce.job.reduces;</span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------------+</span></span><br><span class="line"><span class="operator">|</span>           <span class="keyword">set</span>            <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------------+</span></span><br><span class="line"><span class="operator">|</span> mapreduce.job.reduces<span class="operator">=</span><span class="number">2</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> selected (<span class="number">0.204</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>根据部门编号降序查看员工信息 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> mock_data.emp sort <span class="keyword">by</span> dept_no <span class="keyword">desc</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+---------------+------------+----------+----------------+----------+-----------+--------------+</span></span><br><span class="line"><span class="operator">|</span> emp.emp_no  <span class="operator">|</span> emp.emp_name  <span class="operator">|</span>  emp.job   <span class="operator">|</span> emp.mgr  <span class="operator">|</span> emp.hire_date  <span class="operator">|</span> emp.sal  <span class="operator">|</span> emp.comm  <span class="operator">|</span> emp.dept_no  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+---------------+------------+----------+----------------+----------+-----------+--------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">7521</span>        <span class="operator">|</span> WARD          <span class="operator">|</span> SALESMAN   <span class="operator">|</span> <span class="number">7698</span>     <span class="operator">|</span> <span class="number">1981</span><span class="number">-2</span><span class="number">-22</span>      <span class="operator">|</span> <span class="number">1250.0</span>   <span class="operator">|</span> <span class="number">500.0</span>     <span class="operator">|</span> <span class="number">30</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">7900</span>        <span class="operator">|</span> JAMES         <span class="operator">|</span> CLERK      <span class="operator">|</span> <span class="number">7698</span>     <span class="operator">|</span> <span class="number">1981</span><span class="number">-12</span><span class="number">-3</span>      <span class="operator">|</span> <span class="number">950.0</span>    <span class="operator">|</span> <span class="keyword">NULL</span>      <span class="operator">|</span> <span class="number">30</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">7844</span>        <span class="operator">|</span> TURNER        <span class="operator">|</span> SALESMAN   <span class="operator">|</span> <span class="number">7698</span>     <span class="operator">|</span> <span class="number">1981</span><span class="number">-9</span><span class="number">-8</span>       <span class="operator">|</span> <span class="number">1500.0</span>   <span class="operator">|</span> <span class="number">0.0</span>       <span class="operator">|</span> <span class="number">30</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">7654</span>        <span class="operator">|</span> MARTIN        <span class="operator">|</span> SALESMAN   <span class="operator">|</span> <span class="number">7698</span>     <span class="operator">|</span> <span class="number">1981</span><span class="number">-9</span><span class="number">-28</span>      <span class="operator">|</span> <span class="number">1250.0</span>   <span class="operator">|</span> <span class="number">1400.0</span>    <span class="operator">|</span> <span class="number">30</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">7876</span>        <span class="operator">|</span> ADAMS         <span class="operator">|</span> CLERK      <span class="operator">|</span> <span class="number">7788</span>     <span class="operator">|</span> <span class="number">1987</span><span class="number">-5</span><span class="number">-23</span>      <span class="operator">|</span> <span class="number">1100.0</span>   <span class="operator">|</span> <span class="keyword">NULL</span>      <span class="operator">|</span> <span class="number">20</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">7902</span>        <span class="operator">|</span> FORD          <span class="operator">|</span> ANALYST    <span class="operator">|</span> <span class="number">7566</span>     <span class="operator">|</span> <span class="number">1981</span><span class="number">-12</span><span class="number">-3</span>      <span class="operator">|</span> <span class="number">3000.0</span>   <span class="operator">|</span> <span class="keyword">NULL</span>      <span class="operator">|</span> <span class="number">20</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">7788</span>        <span class="operator">|</span> SCOTT         <span class="operator">|</span> ANALYST    <span class="operator">|</span> <span class="number">7566</span>     <span class="operator">|</span> <span class="number">1987</span><span class="number">-4</span><span class="number">-19</span>      <span class="operator">|</span> <span class="number">3000.0</span>   <span class="operator">|</span> <span class="keyword">NULL</span>      <span class="operator">|</span> <span class="number">20</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">7369</span>        <span class="operator">|</span> SMITH         <span class="operator">|</span> CLERK      <span class="operator">|</span> <span class="number">7902</span>     <span class="operator">|</span> <span class="number">1980</span><span class="number">-12</span><span class="number">-17</span>     <span class="operator">|</span> <span class="number">800.0</span>    <span class="operator">|</span> <span class="keyword">NULL</span>      <span class="operator">|</span> <span class="number">20</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">7566</span>        <span class="operator">|</span> JONES         <span class="operator">|</span> MANAGER    <span class="operator">|</span> <span class="number">7839</span>     <span class="operator">|</span> <span class="number">1981</span><span class="number">-4</span><span class="number">-2</span>       <span class="operator">|</span> <span class="number">2975.0</span>   <span class="operator">|</span> <span class="keyword">NULL</span>      <span class="operator">|</span> <span class="number">20</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">7499</span>        <span class="operator">|</span> ALLEN         <span class="operator">|</span> SALESMAN   <span class="operator">|</span> <span class="number">7698</span>     <span class="operator">|</span> <span class="number">1981</span><span class="number">-2</span><span class="number">-20</span>      <span class="operator">|</span> <span class="number">1600.0</span>   <span class="operator">|</span> <span class="number">300.0</span>     <span class="operator">|</span> <span class="number">30</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">7698</span>        <span class="operator">|</span> BLAKE         <span class="operator">|</span> MANAGER    <span class="operator">|</span> <span class="number">7839</span>     <span class="operator">|</span> <span class="number">1981</span><span class="number">-5</span><span class="number">-1</span>       <span class="operator">|</span> <span class="number">2850.0</span>   <span class="operator">|</span> <span class="keyword">NULL</span>      <span class="operator">|</span> <span class="number">30</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">7934</span>        <span class="operator">|</span> MILLER        <span class="operator">|</span> CLERK      <span class="operator">|</span> <span class="number">7782</span>     <span class="operator">|</span> <span class="number">1982</span><span class="number">-1</span><span class="number">-23</span>      <span class="operator">|</span> <span class="number">1300.0</span>   <span class="operator">|</span> <span class="keyword">NULL</span>      <span class="operator">|</span> <span class="number">10</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">7839</span>        <span class="operator">|</span> KING          <span class="operator">|</span> PRESIDENT  <span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">1981</span><span class="number">-11</span><span class="number">-17</span>     <span class="operator">|</span> <span class="number">5000.0</span>   <span class="operator">|</span> <span class="keyword">NULL</span>      <span class="operator">|</span> <span class="number">10</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">7782</span>        <span class="operator">|</span> CLARK         <span class="operator">|</span> MANAGER    <span class="operator">|</span> <span class="number">7839</span>     <span class="operator">|</span> <span class="number">1981</span><span class="number">-6</span><span class="number">-9</span>       <span class="operator">|</span> <span class="number">2450.0</span>   <span class="operator">|</span> <span class="keyword">NULL</span>      <span class="operator">|</span> <span class="number">10</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+---------------+------------+----------+----------------+----------+-----------+--------------+</span></span><br><span class="line"><span class="number">14</span> <span class="keyword">rows</span> selected (<span class="number">16.877</span> seconds)</span><br></pre></td></tr></table></figure></li>
<li>将查询结果导入到文件中（按照部门编号降序排序） <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="number">2</span>;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.037</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">insert</span> overwrite <span class="keyword">local</span> directory <span class="string">&#x27;/home/atguigu/hive/emp&#x27;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> mock_data.emp sort <span class="keyword">by</span> dept_no <span class="keyword">desc</span>;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">17.73</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="operator">!</span>quit</span><br><span class="line">Closing: <span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span></span><br><span class="line">[atguigu<span class="variable">@hadoop001</span> emp]$ ls</span><br><span class="line"><span class="number">000000</span>_0  <span class="number">000001</span>_0</span><br><span class="line">[atguigu<span class="variable">@hadoop001</span> emp]$</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="6-4-5-分区（Distribute-By）"><a href="#6-4-5-分区（Distribute-By）" class="headerlink" title="6.4.5 分区（Distribute By）"></a>6.4.5 分区（Distribute By）</h3><ul>
<li>Distribute By： 在有些情况下，我们需要控制某个特定行应该到哪个reducer，通常是为了进行后续的聚集操作。distribute by 子句可以做这件事。</li>
<li>Distribute by类似MR中partition（自定义分区），进行分区，结合sort by使用。 </li>
<li>对于distribute by进行测试，一定要分配多reduce进行处理，否则无法看到distribute by的效果。</li>
</ul>
<ol>
<li>案例实操：<ol>
<li>先按照部门编号分区，再按照员工编号降序排序。 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">set</span> mapreduce.job.reduces<span class="operator">=</span><span class="number">3</span>;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.035</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">insert</span> overwrite <span class="keyword">local</span> directory <span class="string">&#x27;/home/atguigu/hive/emp/distribute&#x27;</span> <span class="type">ROW</span> FORMAT DELIMITED FIELDS TERMINATED <span class="keyword">BY</span> <span class="string">&#x27;\t&#x27;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> mock_data.emp distribute <span class="keyword">by</span> dept_no sort <span class="keyword">by</span> emp_no <span class="keyword">desc</span> ;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">18.69</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="operator">!</span>quit</span><br><span class="line">Closing: <span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span></span><br><span class="line">[atguigu<span class="variable">@hadoop001</span> distribute]$ ls</span><br><span class="line"><span class="number">000000</span>_0  <span class="number">000001</span>_0  <span class="number">000002</span>_0</span><br><span class="line">[atguigu<span class="variable">@hadoop001</span> distribute]$ cat <span class="number">000000</span>_0</span><br><span class="line"><span class="number">7900</span>	JAMES	CLERK	<span class="number">7698</span>	<span class="number">1981</span><span class="number">-12</span><span class="number">-3</span>	<span class="number">950.0</span>	\N	<span class="number">30</span></span><br><span class="line"><span class="number">7844</span>	TURNER	SALESMAN	<span class="number">7698</span>	<span class="number">1981</span><span class="number">-9</span><span class="number">-8</span>	<span class="number">1500.0</span>	<span class="number">0.0</span>	<span class="number">30</span></span><br><span class="line"><span class="number">7698</span>	BLAKE	MANAGER	<span class="number">7839</span>	<span class="number">1981</span><span class="number">-5</span><span class="number">-1</span>	<span class="number">2850.0</span>	\N	<span class="number">30</span></span><br><span class="line"><span class="number">7654</span>	MARTIN	SALESMAN	<span class="number">7698</span>	<span class="number">1981</span><span class="number">-9</span><span class="number">-28</span>	<span class="number">1250.0</span>	<span class="number">1400.0</span>	<span class="number">30</span></span><br><span class="line"><span class="number">7521</span>	WARD	SALESMAN	<span class="number">7698</span>	<span class="number">1981</span><span class="number">-2</span><span class="number">-22</span>	<span class="number">1250.0</span>	<span class="number">500.0</span>	<span class="number">30</span></span><br><span class="line"><span class="number">7499</span>	ALLEN	SALESMAN	<span class="number">7698</span>	<span class="number">1981</span><span class="number">-2</span><span class="number">-20</span>	<span class="number">1600.0</span>	<span class="number">300.0</span>	<span class="number">30</span></span><br><span class="line">[atguigu<span class="variable">@hadoop001</span> distribute]$ cat <span class="number">000001</span>_0</span><br><span class="line"><span class="number">7934</span>	MILLER	CLERK	<span class="number">7782</span>	<span class="number">1982</span><span class="number">-1</span><span class="number">-23</span>	<span class="number">1300.0</span>	\N	<span class="number">10</span></span><br><span class="line"><span class="number">7839</span>	KING	PRESIDENT	\N	<span class="number">1981</span><span class="number">-11</span><span class="number">-17</span>	<span class="number">5000.0</span>	\N	<span class="number">10</span></span><br><span class="line"><span class="number">7782</span>	CLARK	MANAGER	<span class="number">7839</span>	<span class="number">1981</span><span class="number">-6</span><span class="number">-9</span>	<span class="number">2450.0</span>	\N	<span class="number">10</span></span><br><span class="line">[atguigu<span class="variable">@hadoop001</span> distribute]$ cat <span class="number">000002</span>_0</span><br><span class="line"><span class="number">7902</span>	FORD	ANALYST	<span class="number">7566</span>	<span class="number">1981</span><span class="number">-12</span><span class="number">-3</span>	<span class="number">3000.0</span>	\N	<span class="number">20</span></span><br><span class="line"><span class="number">7876</span>	ADAMS	CLERK	<span class="number">7788</span>	<span class="number">1987</span><span class="number">-5</span><span class="number">-23</span>	<span class="number">1100.0</span>	\N	<span class="number">20</span></span><br><span class="line"><span class="number">7788</span>	SCOTT	ANALYST	<span class="number">7566</span>	<span class="number">1987</span><span class="number">-4</span><span class="number">-19</span>	<span class="number">3000.0</span>	\N	<span class="number">20</span></span><br><span class="line"><span class="number">7566</span>	JONES	MANAGER	<span class="number">7839</span>	<span class="number">1981</span><span class="number">-4</span><span class="number">-2</span>	<span class="number">2975.0</span>	\N	<span class="number">20</span></span><br><span class="line"><span class="number">7369</span>	SMITH	CLERK	<span class="number">7902</span>	<span class="number">1980</span><span class="number">-12</span><span class="number">-17</span>	<span class="number">800.0</span>	\N	<span class="number">20</span></span><br><span class="line">[atguigu<span class="variable">@hadoop001</span> distribute]$</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li>注意：<ul>
<li>distribute by的分区规则是根据分区字段的hash码与reduce的个数进行模除后，余数相同的分到一个区。</li>
<li>Hive要求DISTRIBUTE BY语句要写在SORT BY语句之前。</li>
</ul>
</li>
</ol>
<h3 id="6-4-6-Cluster-By"><a href="#6-4-6-Cluster-By" class="headerlink" title="6.4.6 Cluster By"></a>6.4.6 Cluster By</h3><ul>
<li>当distribute by和sort by字段相同时，可以使用cluster by方式。</li>
<li>cluster by除了具有distribute by的功能外还兼具sort by的功能。但是排序只能是升序排序，不能指定排序规则为ASC或者DESC。</li>
<li>以下两种写法等价  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp cluster <span class="keyword">by</span> deptno;</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp distribute <span class="keyword">by</span> deptno sort <span class="keyword">by</span> deptno;</span><br></pre></td></tr></table></figure></li>
<li>注意：按照部门编号分区，不一定就是固定死的数值，可以是20号和30号部门分到一个分区里面去。</li>
</ul>
<h1 id="七、分区表和分桶表"><a href="#七、分区表和分桶表" class="headerlink" title="七、分区表和分桶表"></a>七、分区表和分桶表</h1><h2 id="7-1-分区表"><a href="#7-1-分区表" class="headerlink" title="7.1 分区表"></a>7.1 分区表</h2><ul>
<li>概念：<ol>
<li>出于对数据查询的优化，考虑Hive常规查询会进行全表扫描，效率低下。在建表的时候使用分区表规划更合理的存储结构</li>
<li>分区表实际上就是对应一个HDFS文件系统上的独立的文件夹，该文件夹下是该分区所有的数据文件。</li>
<li>Hive中的分区就是分目录，把一个大的数据集根据业务需要分割成小的数据集。在查询时通过WHERE子句中的表达式选择查询所需要的指定的分区，这样的查询效率会提高很多。</li>
</ol>
</li>
</ul>
<h3 id="7-1-1-分区表基本操作"><a href="#7-1-1-分区表基本操作" class="headerlink" title="7.1.1 分区表基本操作"></a>7.1.1 分区表基本操作</h3><ol>
<li><p>创建分区表语法</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> dept_partition (</span><br><span class="line">    deptno <span class="type">int</span>,</span><br><span class="line">    dname  string,</span><br><span class="line">    loc    string</span><br><span class="line">)</span><br><span class="line">partitioned <span class="keyword">by</span> (<span class="keyword">day</span> string)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br></pre></td></tr></table></figure>
<ul>
<li>注意：分区字段不能是表中已经存在的数据，可以将分区字段看作表的伪列。</li>
</ul>
</li>
<li><p>加载数据到分区表中</p>
<ul>
<li>数据准备  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">dept_20200401.log</span><br><span class="line">10	ACCOUNTING	1700</span><br><span class="line">20	RESEARCH	1800</span><br><span class="line"></span><br><span class="line">dept_20200402.log</span><br><span class="line">30	SALES	1900</span><br><span class="line">40	OPERATIONS	1700</span><br><span class="line"></span><br><span class="line">dept_20200403.log</span><br><span class="line">50	TEST	2000</span><br><span class="line">60	DEV	1900</span><br></pre></td></tr></table></figure></li>
<li>加载数据  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">0: jdbc:hive2://hadoop001:10000&gt; load data local inpath &#x27;/home/atguigu/hive/emp/partitioned/dept_20200401.log&#x27; into table mock_data.dept_partition partition(day=&#x27;20200401&#x27;);</span><br><span class="line">No rows affected (1.197 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt; load data local inpath &#x27;/home/atguigu/hive/emp/partitioned/dept_20200402.log&#x27; into table mock_data.dept_partition partition(day=&#x27;20200402&#x27;);</span><br><span class="line">No rows affected (0.363 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt; load data local inpath &#x27;/home/atguigu/hive/emp/partitioned/dept_20200403.log&#x27; into table mock_data.dept_partition partition(day=&#x27;20200403&#x27;);</span><br><span class="line">No rows affected (0.307 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt; dfs -ls /user/hive/warehouse/mock_data.db/dept_partition;</span><br><span class="line">+----------------------------------------------------+</span><br><span class="line">|                     DFS Output                     |</span><br><span class="line">+----------------------------------------------------+</span><br><span class="line">| Found 3 items                                      |</span><br><span class="line">| drwxr-xr-x   - atguigu supergroup          0 2021-10-26 14:18 /user/hive/warehouse/mock_data.db/dept_partition/day=20200401 |</span><br><span class="line">| drwxr-xr-x   - atguigu supergroup          0 2021-10-26 14:18 /user/hive/warehouse/mock_data.db/dept_partition/day=20200402 |</span><br><span class="line">| drwxr-xr-x   - atguigu supergroup          0 2021-10-26 14:18 /user/hive/warehouse/mock_data.db/dept_partition/day=20200403 |</span><br><span class="line">+----------------------------------------------------+</span><br><span class="line">4 rows selected (0.01 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt;</span><br></pre></td></tr></table></figure></li>
<li>注意：分区表加载数据时，必须指定分区</li>
</ul>
</li>
<li><p>查询分区表中数据</p>
<ul>
<li>单分区查询  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dept_partition <span class="keyword">where</span> <span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;20200401&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li>多分区联合查询  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dept_partition <span class="keyword">where</span> <span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;20200401&#x27;</span></span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dept_partition <span class="keyword">where</span> <span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;20200402&#x27;</span></span><br><span class="line"><span class="keyword">union</span> <span class="keyword">all</span></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dept_partition <span class="keyword">where</span> <span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;20200403&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dept_partition <span class="keyword">where</span> <span class="keyword">day</span> <span class="keyword">in</span> (<span class="string">&#x27;20200401&#x27;</span>,<span class="string">&#x27;20200402&#x27;</span>,<span class="string">&#x27;20200403&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dept_partition <span class="keyword">where</span> <span class="keyword">day</span> <span class="keyword">between</span> <span class="number">20200401</span> <span class="keyword">and</span> <span class="number">20200403</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dept_partition <span class="keyword">where</span> (<span class="keyword">day</span> <span class="operator">=</span> <span class="string">&#x27;20200401&#x27;</span> <span class="keyword">or</span> <span class="keyword">day</span> <span class="operator">=</span><span class="string">&#x27;20200402&#x27;</span> <span class="keyword">or</span> <span class="keyword">day</span> <span class="operator">=</span> <span class="string">&#x27;20200403&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>增加分区</p>
<ul>
<li>创建单个分区  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">alter</span> <span class="keyword">table</span> mock_data.dept_partition <span class="keyword">add</span> <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;20200404&#x27;</span>) ;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.099</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> partitions mock_data.dept_partition;</span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+</span></span><br><span class="line"><span class="operator">|</span>   <span class="keyword">partition</span>   <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">20200401</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">20200402</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">20200403</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">20200404</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+</span></span><br><span class="line"><span class="number">4</span> <span class="keyword">rows</span> selected (<span class="number">0.075</span> seconds)</span><br></pre></td></tr></table></figure></li>
<li>同时创建多个分区  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">alter</span> <span class="keyword">table</span> mock_data.dept_partition <span class="keyword">add</span> <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;20200405&#x27;</span>) <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;20200406&#x27;</span>);</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.135</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> partitions mock_data.dept_partition;</span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+</span></span><br><span class="line"><span class="operator">|</span>   <span class="keyword">partition</span>   <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">20200401</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">20200402</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">20200403</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">20200404</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">20200405</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">20200406</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+</span></span><br><span class="line"><span class="number">6</span> <span class="keyword">rows</span> selected (<span class="number">0.094</span> seconds)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>删除分区</p>
<ul>
<li>删除单个分区  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">alter</span> <span class="keyword">table</span> mock_data.dept_partition <span class="keyword">drop</span> <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;20200404&#x27;</span>) ;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.154</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> partitions mock_data.dept_partition;</span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+</span></span><br><span class="line"><span class="operator">|</span>   <span class="keyword">partition</span>   <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">20200401</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">20200402</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">20200403</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">20200405</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">20200406</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+</span></span><br><span class="line"><span class="number">5</span> <span class="keyword">rows</span> selected (<span class="number">0.065</span> seconds)</span><br></pre></td></tr></table></figure></li>
<li>同时删除多个分区  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">alter</span> <span class="keyword">table</span> mock_data.dept_partition <span class="keyword">drop</span> <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;20200405&#x27;</span>), <span class="keyword">partition</span>(<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;20200406&#x27;</span>);</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.223</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> partitions mock_data.dept_partition;</span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+</span></span><br><span class="line"><span class="operator">|</span>   <span class="keyword">partition</span>   <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">20200401</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">20200402</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">20200403</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+</span></span><br><span class="line"><span class="number">3</span> <span class="keyword">rows</span> selected (<span class="number">0.068</span> seconds)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>查看分区表有多少分区</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> partitions mock_data.dept_partition;</span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+</span></span><br><span class="line"><span class="operator">|</span>   <span class="keyword">partition</span>   <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">20200401</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">20200402</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">day</span><span class="operator">=</span><span class="number">20200403</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+</span></span><br><span class="line"><span class="number">3</span> <span class="keyword">rows</span> selected (<span class="number">0.068</span> seconds)</span><br></pre></td></tr></table></figure></li>
<li><p>查看分区表结构(关注Partition Information.numPartitions)</p>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">desc</span> formatted mock_data.dept_partition;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------------+----------------------------------------------------+-----------------------+</span></span><br><span class="line"><span class="operator">|</span>           col_name            <span class="operator">|</span>                     data_type                      <span class="operator">|</span>        comment        <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------------+----------------------------------------------------+-----------------------+</span></span><br><span class="line"><span class="operator">|</span> # col_name                    <span class="operator">|</span> data_type                                          <span class="operator">|</span> comment               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> deptno                        <span class="operator">|</span> <span class="type">int</span>                                                <span class="operator">|</span>                       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> dname                         <span class="operator">|</span> string                                             <span class="operator">|</span>                       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> loc                           <span class="operator">|</span> string                                             <span class="operator">|</span>                       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                               <span class="operator">|</span> <span class="keyword">NULL</span>                                               <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> # <span class="keyword">Partition</span> Information       <span class="operator">|</span> <span class="keyword">NULL</span>                                               <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> # col_name                    <span class="operator">|</span> data_type                                          <span class="operator">|</span> comment               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">day</span>                           <span class="operator">|</span> string                                             <span class="operator">|</span>                       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                               <span class="operator">|</span> <span class="keyword">NULL</span>                                               <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> # Detailed <span class="keyword">Table</span> Information  <span class="operator">|</span> <span class="keyword">NULL</span>                                               <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Database:                     <span class="operator">|</span> mock_data                                          <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> OwnerType:                    <span class="operator">|</span> <span class="keyword">USER</span>                                               <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Owner:                        <span class="operator">|</span> atguigu                                            <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> CreateTime:                   <span class="operator">|</span> Tue Oct <span class="number">26</span> <span class="number">14</span>:<span class="number">10</span>:<span class="number">53</span> CST <span class="number">2021</span>                       <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> LastAccessTime:               <span class="operator">|</span> <span class="literal">UNKNOWN</span>                                            <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Retention:                    <span class="operator">|</span> <span class="number">0</span>                                                  <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Location:                     <span class="operator">|</span> hdfs:<span class="operator">/</span><span class="operator">/</span>mycluster<span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>mock_data.db<span class="operator">/</span>dept_partition <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">Table</span> Type:                   <span class="operator">|</span> MANAGED_TABLE                                      <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">Table</span> Parameters:             <span class="operator">|</span> <span class="keyword">NULL</span>                                               <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                               <span class="operator">|</span> bucketing_version                                  <span class="operator">|</span> <span class="number">2</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                               <span class="operator">|</span> numFiles                                           <span class="operator">|</span> <span class="number">3</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                               <span class="operator">|</span> numPartitions                                      <span class="operator">|</span> <span class="number">3</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                               <span class="operator">|</span> numRows                                            <span class="operator">|</span> <span class="number">0</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                               <span class="operator">|</span> rawDataSize                                        <span class="operator">|</span> <span class="number">0</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                               <span class="operator">|</span> totalSize                                          <span class="operator">|</span> <span class="number">95</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                               <span class="operator">|</span> transient_lastDdlTime                              <span class="operator">|</span> <span class="number">1635228653</span>            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                               <span class="operator">|</span> <span class="keyword">NULL</span>                                               <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> # Storage Information         <span class="operator">|</span> <span class="keyword">NULL</span>                                               <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> SerDe Library:                <span class="operator">|</span> org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> InputFormat:                  <span class="operator">|</span> org.apache.hadoop.mapred.TextInputFormat           <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> OutputFormat:                 <span class="operator">|</span> org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Compressed:                   <span class="operator">|</span> <span class="keyword">No</span>                                                 <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Num Buckets:                  <span class="operator">|</span> <span class="number">-1</span>                                                 <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Bucket Columns:               <span class="operator">|</span> []                                                 <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Sort Columns:                 <span class="operator">|</span> []                                                 <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Storage <span class="keyword">Desc</span> Params:          <span class="operator">|</span> <span class="keyword">NULL</span>                                               <span class="operator">|</span> <span class="keyword">NULL</span>                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                               <span class="operator">|</span> field.delim                                        <span class="operator">|</span> \t                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                               <span class="operator">|</span> serialization.format                               <span class="operator">|</span> \t                    <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------------------------+----------------------------------------------------+-----------------------+</span></span><br><span class="line"><span class="number">38</span> <span class="keyword">rows</span> selected (<span class="number">0.151</span> seconds)</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="7-1-2-二级分区"><a href="#7-1-2-二级分区" class="headerlink" title="7.1.2 二级分区"></a>7.1.2 二级分区</h3><p>思考: 如何一天的日志数据量也很大，如何再将数据拆分?</p>
<ol>
<li>创建多级级分区表 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> dept_partition_level (</span><br><span class="line">    deptno <span class="type">int</span>,</span><br><span class="line">    dname  string,</span><br><span class="line">    loc    string</span><br><span class="line">)</span><br><span class="line">partitioned <span class="keyword">by</span> (<span class="keyword">year</span> string,<span class="keyword">month</span> string, <span class="keyword">day</span> string)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li>正常的加载数据<ul>
<li>加载数据到分区表中  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/home/atguigu/hive/emp/partitioned/dept_20200401.log&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> mock_data.dept_partition_level <span class="keyword">partition</span>(<span class="keyword">year</span><span class="operator">=</span><span class="string">&#x27;2020&#x27;</span>, <span class="keyword">month</span><span class="operator">=</span><span class="string">&#x27;04&#x27;</span>,<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;01&#x27;</span>);</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.292</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/home/atguigu/hive/emp/partitioned/dept_20200402.log&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> mock_data.dept_partition_level <span class="keyword">partition</span>(<span class="keyword">year</span><span class="operator">=</span><span class="string">&#x27;2020&#x27;</span>, <span class="keyword">month</span><span class="operator">=</span><span class="string">&#x27;04&#x27;</span>,<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;02&#x27;</span>);</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.295</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/home/atguigu/hive/emp/partitioned/dept_20200403.log&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> mock_data.dept_partition_level <span class="keyword">partition</span>(<span class="keyword">year</span><span class="operator">=</span><span class="string">&#x27;2020&#x27;</span>, <span class="keyword">month</span><span class="operator">=</span><span class="string">&#x27;04&#x27;</span>,<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;03&#x27;</span>);</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.279</span> seconds)</span><br></pre></td></tr></table></figure></li>
<li>查询分区数据  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> </span><br><span class="line">    <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> dept_partition_level</span><br><span class="line"><span class="keyword">where</span> <span class="keyword">year</span> <span class="operator">=</span> <span class="number">2020</span></span><br><span class="line">  <span class="keyword">and</span> <span class="keyword">month</span> <span class="operator">=</span> <span class="number">04</span></span><br><span class="line">  <span class="keyword">and</span> <span class="keyword">day</span> <span class="operator">=</span> <span class="number">01</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>把数据直接上传到分区目录上，让分区表和数据产生关联的三种方式<ul>
<li>方式一：上传数据后修复<ul>
<li>上传数据  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 partitioned]$ hadoop fs -mkdir -p /user/hive/warehouse/mock_data.db/dept_partition_level/year=2021/month=06/day=09</span><br><span class="line">[atguigu@hadoop001 partitioned]$ hadoop fs -put dept_20210609.log /user/hive/warehouse/mock_data.db/dept_partition_level/year=2021/month=06/day=09</span><br><span class="line">2021-10-26 15:36:57,908 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">[atguigu@hadoop001 partitioned]$</span><br></pre></td></tr></table></figure></li>
<li>查询数据（查询不到刚上传的数据）  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">0: jdbc:hive2://hadoop001:10000&gt; select *</span><br><span class="line"> from mock_data.dept_partition_level</span><br><span class="line"> <span class="built_in">where</span> year = 2021;</span><br><span class="line">+------------------------------+-----------------------------+---------------------------+----------------------------+-----------------------------+---------------------------+</span><br><span class="line">| dept_partition_level.deptno  | dept_partition_level.dname  | dept_partition_level.loc  | dept_partition_level.year  | dept_partition_level.month  | dept_partition_level.day  |</span><br><span class="line">+------------------------------+-----------------------------+---------------------------+----------------------------+-----------------------------+---------------------------+</span><br><span class="line">| 60                           | ACCOUNTING                  | 1700                      | 2021                       | 04                          | 01                        |</span><br><span class="line">+------------------------------+-----------------------------+---------------------------+----------------------------+-----------------------------+---------------------------+</span><br><span class="line">1 row selected (0.118 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt;</span><br></pre></td></tr></table></figure></li>
<li>执行修复命令再次查询数据  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> msck repair <span class="keyword">table</span> mock_data.dept_partition_level;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.139</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span></span><br><span class="line"> <span class="keyword">from</span> mock_data.dept_partition_level</span><br><span class="line"> <span class="keyword">where</span> <span class="keyword">year</span> <span class="operator">=</span> <span class="number">2021</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------+-----------------------------+---------------------------+----------------------------+-----------------------------+---------------------------+</span></span><br><span class="line"><span class="operator">|</span> dept_partition_level.deptno  <span class="operator">|</span> dept_partition_level.dname  <span class="operator">|</span> dept_partition_level.loc  <span class="operator">|</span> dept_partition_level.year  <span class="operator">|</span> dept_partition_level.month  <span class="operator">|</span> dept_partition_level.day  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------+-----------------------------+---------------------------+----------------------------+-----------------------------+---------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">60</span>                           <span class="operator">|</span> ACCOUNTING                  <span class="operator">|</span> <span class="number">1700</span>                      <span class="operator">|</span> <span class="number">2021</span>                       <span class="operator">|</span> <span class="number">04</span>                          <span class="operator">|</span> <span class="number">01</span>                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">10</span>                           <span class="operator">|</span> ACCOUNTING                  <span class="operator">|</span> <span class="number">1700</span>                      <span class="operator">|</span> <span class="number">2021</span>                       <span class="operator">|</span> <span class="number">06</span>                          <span class="operator">|</span> <span class="number">09</span>                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">20</span>                           <span class="operator">|</span> RESEARCH                    <span class="operator">|</span> <span class="number">1800</span>                      <span class="operator">|</span> <span class="number">2021</span>                       <span class="operator">|</span> <span class="number">06</span>                          <span class="operator">|</span> <span class="number">09</span>                        <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------+-----------------------------+---------------------------+----------------------------+-----------------------------+---------------------------+</span></span><br><span class="line"><span class="number">3</span> <span class="keyword">rows</span> selected (<span class="number">0.114</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>方式二：上传数据后添加分区<ul>
<li>上传数据  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 partitioned]$ hadoop fs -mkdir -p /user/hive/warehouse/mock_data.db/dept_partition_level/year=2021/month=10/day=26</span><br><span class="line">[atguigu@hadoop001 partitioned]$ hadoop fs -put dept_20211026.log /user/hive/warehouse/mock_data.db/dept_partition_level/year=2021/month=10/day=26</span><br><span class="line">2021-10-26 15:51:40,926 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br></pre></td></tr></table></figure></li>
<li>执行添加分区  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">alter</span> <span class="keyword">table</span> mock_data.dept_partition_level <span class="keyword">add</span> <span class="keyword">partition</span>(<span class="keyword">year</span><span class="operator">=</span><span class="string">&#x27;2021&#x27;</span>, <span class="keyword">month</span><span class="operator">=</span><span class="string">&#x27;10&#x27;</span>, <span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;26&#x27;</span>) ;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.062</span> seconds)</span><br></pre></td></tr></table></figure></li>
<li>查询数据  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span></span><br><span class="line"> <span class="keyword">from</span> mock_data.dept_partition_level</span><br><span class="line"> <span class="keyword">where</span> <span class="keyword">year</span> <span class="operator">=</span> <span class="number">2021</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------+-----------------------------+---------------------------+----------------------------+-----------------------------+---------------------------+</span></span><br><span class="line"><span class="operator">|</span> dept_partition_level.deptno  <span class="operator">|</span> dept_partition_level.dname  <span class="operator">|</span> dept_partition_level.loc  <span class="operator">|</span> dept_partition_level.year  <span class="operator">|</span> dept_partition_level.month  <span class="operator">|</span> dept_partition_level.day  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------+-----------------------------+---------------------------+----------------------------+-----------------------------+---------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">60</span>                           <span class="operator">|</span> ACCOUNTING                  <span class="operator">|</span> <span class="number">1700</span>                      <span class="operator">|</span> <span class="number">2021</span>                       <span class="operator">|</span> <span class="number">04</span>                          <span class="operator">|</span> <span class="number">01</span>                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">10</span>                           <span class="operator">|</span> ACCOUNTING                  <span class="operator">|</span> <span class="number">1700</span>                      <span class="operator">|</span> <span class="number">2021</span>                       <span class="operator">|</span> <span class="number">06</span>                          <span class="operator">|</span> <span class="number">09</span>                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">20</span>                           <span class="operator">|</span> RESEARCH                    <span class="operator">|</span> <span class="number">1800</span>                      <span class="operator">|</span> <span class="number">2021</span>                       <span class="operator">|</span> <span class="number">06</span>                          <span class="operator">|</span> <span class="number">09</span>                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">10</span>                           <span class="operator">|</span> ACCOUNTING                  <span class="operator">|</span> <span class="number">1700</span>                      <span class="operator">|</span> <span class="number">2021</span>                       <span class="operator">|</span> <span class="number">10</span>                          <span class="operator">|</span> <span class="number">26</span>                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">20</span>                           <span class="operator">|</span> RESEARCH                    <span class="operator">|</span> <span class="number">1800</span>                      <span class="operator">|</span> <span class="number">2021</span>                       <span class="operator">|</span> <span class="number">10</span>                          <span class="operator">|</span> <span class="number">26</span>                        <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------+-----------------------------+---------------------------+----------------------------+-----------------------------+---------------------------+</span></span><br><span class="line"><span class="number">5</span> <span class="keyword">rows</span> selected (<span class="number">0.094</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>方式三：创建文件夹后load数据到分区<ul>
<li>创建目录  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> dfs <span class="operator">-</span>mkdir <span class="operator">-</span>p <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>mock_data.db<span class="operator">/</span>dept_partition_level<span class="operator">/</span><span class="keyword">year</span><span class="operator">=</span><span class="number">2021</span><span class="operator">/</span><span class="keyword">month</span><span class="operator">=</span><span class="number">12</span><span class="operator">/</span><span class="keyword">day</span><span class="operator">=</span><span class="number">28</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+</span></span><br><span class="line"><span class="operator">|</span> DFS Output  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+</span></span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> selected (<span class="number">0.017</span> seconds)</span><br></pre></td></tr></table></figure></li>
<li>上传数据  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/home/atguigu/hive/emp/partitioned/dept_20210609.log&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> mock_data.dept_partition_level <span class="keyword">partition</span>(<span class="keyword">year</span><span class="operator">=</span><span class="string">&#x27;2021&#x27;</span>, <span class="keyword">month</span><span class="operator">=</span><span class="string">&#x27;12&#x27;</span>,<span class="keyword">day</span><span class="operator">=</span><span class="string">&#x27;28&#x27;</span>);</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.275</span> seconds)</span><br></pre></td></tr></table></figure></li>
<li>查询数据  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span></span><br><span class="line"> <span class="keyword">from</span> mock_data.dept_partition_level</span><br><span class="line"> <span class="keyword">where</span> <span class="keyword">year</span> <span class="operator">=</span> <span class="number">2021</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------+-----------------------------+---------------------------+----------------------------+-----------------------------+---------------------------+</span></span><br><span class="line"><span class="operator">|</span> dept_partition_level.deptno  <span class="operator">|</span> dept_partition_level.dname  <span class="operator">|</span> dept_partition_level.loc  <span class="operator">|</span> dept_partition_level.year  <span class="operator">|</span> dept_partition_level.month  <span class="operator">|</span> dept_partition_level.day  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------+-----------------------------+---------------------------+----------------------------+-----------------------------+---------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">60</span>                           <span class="operator">|</span> ACCOUNTING                  <span class="operator">|</span> <span class="number">1700</span>                      <span class="operator">|</span> <span class="number">2021</span>                       <span class="operator">|</span> <span class="number">04</span>                          <span class="operator">|</span> <span class="number">01</span>                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">10</span>                           <span class="operator">|</span> ACCOUNTING                  <span class="operator">|</span> <span class="number">1700</span>                      <span class="operator">|</span> <span class="number">2021</span>                       <span class="operator">|</span> <span class="number">06</span>                          <span class="operator">|</span> <span class="number">09</span>                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">20</span>                           <span class="operator">|</span> RESEARCH                    <span class="operator">|</span> <span class="number">1800</span>                      <span class="operator">|</span> <span class="number">2021</span>                       <span class="operator">|</span> <span class="number">06</span>                          <span class="operator">|</span> <span class="number">09</span>                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">10</span>                           <span class="operator">|</span> ACCOUNTING                  <span class="operator">|</span> <span class="number">1700</span>                      <span class="operator">|</span> <span class="number">2021</span>                       <span class="operator">|</span> <span class="number">10</span>                          <span class="operator">|</span> <span class="number">26</span>                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">20</span>                           <span class="operator">|</span> RESEARCH                    <span class="operator">|</span> <span class="number">1800</span>                      <span class="operator">|</span> <span class="number">2021</span>                       <span class="operator">|</span> <span class="number">10</span>                          <span class="operator">|</span> <span class="number">26</span>                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">10</span>                           <span class="operator">|</span> ACCOUNTING                  <span class="operator">|</span> <span class="number">1700</span>                      <span class="operator">|</span> <span class="number">2021</span>                       <span class="operator">|</span> <span class="number">12</span>                          <span class="operator">|</span> <span class="number">28</span>                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">20</span>                           <span class="operator">|</span> RESEARCH                    <span class="operator">|</span> <span class="number">1800</span>                      <span class="operator">|</span> <span class="number">2021</span>                       <span class="operator">|</span> <span class="number">12</span>                          <span class="operator">|</span> <span class="number">28</span>                        <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------+-----------------------------+---------------------------+----------------------------+-----------------------------+---------------------------+</span></span><br><span class="line"><span class="number">7</span> <span class="keyword">rows</span> selected (<span class="number">0.107</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="7-1-3-动态分区"><a href="#7-1-3-动态分区" class="headerlink" title="7.1.3 动态分区"></a>7.1.3 动态分区</h3></li>
</ul>
</li>
</ul>
</li>
</ol>
<ul>
<li>关系型数据库中，对分区表Insert数据时候，数据库自动会根据分区字段的值，将数据插入到相应的分区中，Hive中也提供了类似的机制，即动态分区(Dynamic Partition)，只不过，使用Hive的动态分区，需要进行相应的配置。<ol>
<li>开启动态分区参数设置<ol>
<li>开启动态分区功能（默认true，开启） <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.exec.dynamic.partition=true</span><br></pre></td></tr></table></figure></li>
<li>设置为非严格模式（动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区。） <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.exec.dynamic.partition.mode=nonstrict</span><br></pre></td></tr></table></figure></li>
<li>在所有执行MR的节点上，最大一共可以创建多少个动态分区。默认1000 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.exec.max.dynamic.partitions=1000</span><br></pre></td></tr></table></figure></li>
<li>在每个执行MR的节点上，最大可以创建多少个动态分区。该参数需要根据实际的数据来设定。比如：源数据中包含了一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认值100，则会报错。 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.exec.max.dynamic.partitions.pernode=100</span><br></pre></td></tr></table></figure></li>
<li>整个MR Job中，最大可以创建多少个HDFS文件。默认100000 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.exec.max.created.files=100000</span><br></pre></td></tr></table></figure></li>
<li>当有空分区生成时，是否抛出异常。一般不需要设置。默认false <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.error.on.empty.partition=false</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li>案例实操</li>
</ol>
<ul>
<li>需求：将dept表中的数据按照地区（loc字段），插入到目标表dept_partition的相应分区中。<ol>
<li>创建目标分区表 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> dept_partition_dynamic (</span><br><span class="line">    deptno <span class="type">int</span>,</span><br><span class="line">    dname  string</span><br><span class="line">)</span><br><span class="line">partitioned <span class="keyword">by</span> (loc string)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li>设置动态分区，插入数据 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">set</span> hive.exec.dynamic.partition.mode <span class="operator">=</span> nonstrict;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.005</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">insert</span> <span class="keyword">into</span> mock_data.dept_partition_dynamic <span class="keyword">partition</span>(loc)</span><br><span class="line"> <span class="keyword">select</span> deptno,dname,loc</span><br><span class="line"> <span class="keyword">from</span> mock_data.dept_partition_level;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">30.709</span> seconds)</span><br></pre></td></tr></table></figure></li>
<li>查看目标分区表的分区情况 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> partitions mock_data.dept_partition_dynamic;</span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------------+</span></span><br><span class="line"><span class="operator">|</span>            <span class="keyword">partition</span>            <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------------+</span></span><br><span class="line"><span class="operator">|</span> loc<span class="operator">=</span><span class="number">1700</span>                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> loc<span class="operator">=</span><span class="number">1800</span>                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> loc<span class="operator">=</span><span class="number">1900</span>                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> loc<span class="operator">=</span><span class="number">2000</span>                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> loc<span class="operator">=</span>__HIVE_DEFAULT_PARTITION__  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------------------------+</span></span><br><span class="line"><span class="number">5</span> <span class="keyword">rows</span> selected (<span class="number">0.096</span> seconds)</span><br></pre></td></tr></table></figure></li>
<li>思考：目标分区表是如何匹配到分区字段的？<ul>
<li>通过元数据获取分区表和分区字段</li>
<li>通过分区字段匹配查询结果中的字段</li>
</ul>
</li>
</ol>
</li>
</ul>
</li>
</ul>
<h2 id="7-2-分桶表"><a href="#7-2-分桶表" class="headerlink" title="7.2 分桶表"></a>7.2 分桶表</h2><ul>
<li>分区提供一个隔离数据和优化查询的便利方式。不过，并非所有的数据集都可形成合理的分区。对于一张表或者分区，Hive 可以进一步组织成桶，也就是更为细粒度的数据范围划分。</li>
<li>分桶是将数据集分解成更容易管理的若干部分的另一个技术。</li>
<li>分区针对的是数据的存储路径；分桶针对的是数据文件。</li>
</ul>
<ol>
<li>先创建分桶表<ol>
<li>数据准备 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">1001	ss1</span><br><span class="line">1002	ss2</span><br><span class="line">1003	ss3</span><br><span class="line">1004	ss4</span><br><span class="line">1005	ss5</span><br><span class="line">1006	ss6</span><br><span class="line">1007	ss7</span><br><span class="line">1008	ss8</span><br><span class="line">1009	ss9</span><br><span class="line">1010	ss10</span><br><span class="line">1011	ss11</span><br><span class="line">1012	ss12</span><br><span class="line">1013	ss13</span><br><span class="line">1014	ss14</span><br><span class="line">1015	ss15</span><br><span class="line">1016	ss16</span><br></pre></td></tr></table></figure></li>
<li>创建分桶表 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> stu_bucket(</span><br><span class="line">    id   <span class="type">int</span>,</span><br><span class="line">    name string</span><br><span class="line">)</span><br><span class="line">clustered <span class="keyword">by</span> (id) <span class="keyword">into</span> <span class="number">4</span> buckets</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> &quot;\t&quot;;</span><br></pre></td></tr></table></figure></li>
<li>查看表结构   <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">desc</span> formatted stu_bucket;</span><br><span class="line">Num Buckets:            <span class="number">4</span>   </span><br></pre></td></tr></table></figure></li>
<li>导入数据到分桶表中，load的方式 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/home/atguigu/hive/bucket/stu_bucket.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> stu_bucket;</span><br></pre></td></tr></table></figure></li>
<li>查看创建的分桶表中是否分成4个桶 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> dfs <span class="operator">-</span>ls <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>mock_data.db<span class="operator">/</span>stu_bucket;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span>                     DFS Output                     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> Found <span class="number">4</span> items                                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="operator">-</span>rw<span class="operator">-</span>r<span class="comment">--r--   3 atguigu supergroup         38 2021-10-26 18:44 /user/hive/warehouse/mock_data.db/stu_bucket/000000_0 |</span></span><br><span class="line"><span class="operator">|</span> <span class="operator">-</span>rw<span class="operator">-</span>r<span class="comment">--r--   3 atguigu supergroup         37 2021-10-26 18:44 /user/hive/warehouse/mock_data.db/stu_bucket/000001_0 |</span></span><br><span class="line"><span class="operator">|</span> <span class="operator">-</span>rw<span class="operator">-</span>r<span class="comment">--r--   3 atguigu supergroup         38 2021-10-26 18:44 /user/hive/warehouse/mock_data.db/stu_bucket/000002_0 |</span></span><br><span class="line"><span class="operator">|</span> <span class="operator">-</span>rw<span class="operator">-</span>r<span class="comment">--r--   3 atguigu supergroup         38 2021-10-26 18:44 /user/hive/warehouse/mock_data.db/stu_bucket/000003_0 |</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="number">5</span> <span class="keyword">rows</span> selected (<span class="number">0.01</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>分桶规则：<ul>
<li>根据结果可知：Hive的分桶采用对分桶字段的值进行哈希，然后除以桶的个数求余的方式决定该条记录存放在哪个桶当中</li>
</ul>
</li>
</ol>
</li>
<li>分桶表操作需要注意的事项:<ol>
<li>reduce的个数设置为-1,让Job自行决定需要用多少个reduce或者将reduce的个数设置为大于等于分桶表的桶数</li>
<li>从hdfs中load数据到分桶表中，避免本地文件找不到问题</li>
<li>不要使用本地模式(考虑到资源问题，防止MR执行失败，yarn会分配任务到不同节点)</li>
</ol>
</li>
<li>insert方式将数据导入分桶表 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> stu_bucket <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student;</span><br></pre></td></tr></table></figure>
<h2 id="7-3-抽样查询"><a href="#7-3-抽样查询" class="headerlink" title="7.3 抽样查询"></a>7.3 抽样查询</h2></li>
</ol>
<ul>
<li>对于非常大的数据集，有时用户需要使用的是一个具有代表性的查询结果而不是全部结果。Hive可以通过对表进行抽样来满足这个需求。</li>
<li>语法: TABLESAMPLE(BUCKET x OUT OF y ON 分桶字段) </li>
<li>查询表stu_buck中的数据。  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> stu_buck <span class="keyword">tablesample</span>(bucket <span class="number">1</span> <span class="keyword">out</span> <span class="keyword">of</span> <span class="number">4</span> <span class="keyword">on</span> id);</span><br></pre></td></tr></table></figure></li>
<li>注意：x的值必须小于等于y的值，否则</li>
</ul>
<h1 id="八、函数"><a href="#八、函数" class="headerlink" title="八、函数"></a>八、函数</h1><h2 id="8-1-系统内置函数"><a href="#8-1-系统内置函数" class="headerlink" title="8.1 系统内置函数"></a>8.1 系统内置函数</h2><ol>
<li>查看系统自带的函数 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">show</span> functions <span class="keyword">like</span> count;</span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+</span></span><br><span class="line"><span class="operator">|</span> tab_name  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+</span></span><br><span class="line"><span class="operator">|</span> count     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> selected (<span class="number">0.019</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>显示自带的函数的用法 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">desc</span> <span class="keyword">function</span> upper;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span>                      tab_name                      <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="built_in">upper</span>(str) <span class="operator">-</span> <span class="keyword">Returns</span> str <span class="keyword">with</span> <span class="keyword">all</span> characters changed <span class="keyword">to</span> uppercase <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> selected (<span class="number">0.019</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>详细显示自带的函数的用法 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">desc</span> <span class="keyword">function</span> extended upper;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span>                      tab_name                      <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="built_in">upper</span>(str) <span class="operator">-</span> <span class="keyword">Returns</span> str <span class="keyword">with</span> <span class="keyword">all</span> characters changed <span class="keyword">to</span> uppercase <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Synonyms: ucase                                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> Example:                                           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>   <span class="operator">&gt;</span> <span class="keyword">SELECT</span> <span class="built_in">upper</span>(<span class="string">&#x27;Facebook&#x27;</span>) <span class="keyword">FROM</span> src LIMIT <span class="number">1</span>;     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>   <span class="string">&#x27;FACEBOOK&#x27;</span>                                       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">Function</span> class:org.apache.hadoop.hive.ql.udf.generic.GenericUDFUpper <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">Function</span> type:BUILTIN                              <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="number">7</span> <span class="keyword">rows</span> selected (<span class="number">0.079</span> seconds)</span><br></pre></td></tr></table></figure>
<h2 id="8-2-常用内置函数"><a href="#8-2-常用内置函数" class="headerlink" title="8.2 常用内置函数"></a>8.2 常用内置函数</h2><h3 id="8-2-1-空字段赋值"><a href="#8-2-1-空字段赋值" class="headerlink" title="8.2.1 空字段赋值"></a>8.2.1 空字段赋值</h3></li>
<li>函数说明</li>
</ol>
<ul>
<li>NVL：给值为NULL的数据赋值，它的格式是NVL( value，default_value)。它的功能是如果value为NULL，则NVL函数返回default_value的值，否则返回value的值，如果两个参数都为NULL ，则返回NULL。<ul>
<li>示例  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> dept;</span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+-----------------+-----------+-----------------+</span></span><br><span class="line"><span class="operator">|</span> dept.dept_no  <span class="operator">|</span> dept.dept_name  <span class="operator">|</span> dept.loc  <span class="operator">|</span> dept.dept_desc  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+-----------------+-----------+-----------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">10</span>            <span class="operator">|</span> CEO             <span class="operator">|</span> <span class="number">1700</span>      <span class="operator">|</span> 这是老板            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">10</span>            <span class="operator">|</span> ACCOUNTING      <span class="operator">|</span> <span class="number">1700</span>      <span class="operator">|</span> <span class="keyword">NULL</span>            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">20</span>            <span class="operator">|</span> RESEARCH        <span class="operator">|</span> <span class="number">1800</span>      <span class="operator">|</span> <span class="keyword">NULL</span>            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">30</span>            <span class="operator">|</span> SALES           <span class="operator">|</span> <span class="number">1900</span>      <span class="operator">|</span> <span class="keyword">NULL</span>            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">40</span>            <span class="operator">|</span> OPERATIONS      <span class="operator">|</span> <span class="number">1700</span>      <span class="operator">|</span> <span class="keyword">NULL</span>            <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">---------------+-----------------+-----------+-----------------+</span></span><br><span class="line"><span class="number">5</span> <span class="keyword">rows</span> selected (<span class="number">0.058</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> dept_no, dept_name, loc, nvl(dept_desc,&quot;无描述&quot;) <span class="keyword">from</span> dept;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-------------+-------+-------+</span></span><br><span class="line"><span class="operator">|</span> dept_no  <span class="operator">|</span>  dept_name  <span class="operator">|</span>  loc  <span class="operator">|</span>  _c3  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-------------+-------+-------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">10</span>       <span class="operator">|</span> CEO         <span class="operator">|</span> <span class="number">1700</span>  <span class="operator">|</span> 这是老板  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">10</span>       <span class="operator">|</span> ACCOUNTING  <span class="operator">|</span> <span class="number">1700</span>  <span class="operator">|</span> 无描述   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">20</span>       <span class="operator">|</span> RESEARCH    <span class="operator">|</span> <span class="number">1800</span>  <span class="operator">|</span> 无描述   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">30</span>       <span class="operator">|</span> SALES       <span class="operator">|</span> <span class="number">1900</span>  <span class="operator">|</span> 无描述   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">40</span>       <span class="operator">|</span> OPERATIONS  <span class="operator">|</span> <span class="number">1700</span>  <span class="operator">|</span> 无描述   <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-------------+-------+-------+</span></span><br><span class="line"><span class="number">5</span> <span class="keyword">rows</span> selected (<span class="number">0.06</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h3 id="8-2-2-CASE-WHEN-THEN-ELSE-END"><a href="#8-2-2-CASE-WHEN-THEN-ELSE-END" class="headerlink" title="8.2.2 CASE WHEN THEN ELSE END"></a>8.2.2 CASE WHEN THEN ELSE END</h3><ul>
<li>示例1  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span></span><br><span class="line">        emp_name,</span><br><span class="line">         <span class="keyword">case</span> emp_name</span><br><span class="line">             <span class="keyword">when</span> <span class="string">&#x27;SMITH&#x27;</span> <span class="keyword">then</span> <span class="string">&#x27;史密斯&#x27;</span></span><br><span class="line">             <span class="keyword">when</span> <span class="string">&#x27;ALLEN&#x27;</span> <span class="keyword">then</span> <span class="string">&#x27;艾伦&#x27;</span></span><br><span class="line">             <span class="keyword">when</span> <span class="string">&#x27;WARD&#x27;</span> <span class="keyword">then</span> <span class="string">&#x27;沃德&#x27;</span></span><br><span class="line">             <span class="keyword">when</span> <span class="string">&#x27;JONES&#x27;</span> <span class="keyword">then</span> <span class="string">&#x27;琼斯&#x27;</span></span><br><span class="line">             <span class="keyword">when</span> <span class="string">&#x27;MARTIN&#x27;</span> <span class="keyword">then</span> <span class="string">&#x27;马丁&#x27;</span></span><br><span class="line">             <span class="keyword">when</span> <span class="string">&#x27;BLAKE&#x27;</span> <span class="keyword">then</span> <span class="string">&#x27;布莱克&#x27;</span></span><br><span class="line">             <span class="keyword">when</span> <span class="string">&#x27;CLARK&#x27;</span> <span class="keyword">then</span> <span class="string">&#x27;克拉克&#x27;</span></span><br><span class="line">             <span class="keyword">when</span> <span class="string">&#x27;SCOTT&#x27;</span> <span class="keyword">then</span> <span class="string">&#x27;斯科特&#x27;</span></span><br><span class="line">             <span class="keyword">when</span> <span class="string">&#x27;KING&#x27;</span> <span class="keyword">then</span> <span class="string">&#x27;肯&#x27;</span></span><br><span class="line">             <span class="keyword">when</span> <span class="string">&#x27;TURNER&#x27;</span> <span class="keyword">then</span> <span class="string">&#x27;特纳&#x27;</span></span><br><span class="line">             <span class="keyword">else</span> <span class="string">&#x27;爱啥啥&#x27;</span> <span class="keyword">end</span> chinese_name</span><br><span class="line"> <span class="keyword">from</span> emp;</span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+---------------+</span></span><br><span class="line"><span class="operator">|</span> emp_name  <span class="operator">|</span> chinese_name  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+---------------+</span></span><br><span class="line"><span class="operator">|</span> SMITH     <span class="operator">|</span> 史密斯           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> ALLEN     <span class="operator">|</span> 艾伦            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> WARD      <span class="operator">|</span> 沃德            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> JONES     <span class="operator">|</span> 琼斯            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> MARTIN    <span class="operator">|</span> 马丁            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> BLAKE     <span class="operator">|</span> 布莱克           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> CLARK     <span class="operator">|</span> 克拉克           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> SCOTT     <span class="operator">|</span> 斯科特           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> KING      <span class="operator">|</span> 肯             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> TURNER    <span class="operator">|</span> 特纳            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> ADAMS     <span class="operator">|</span> 爱啥啥           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> JAMES     <span class="operator">|</span> 爱啥啥           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> FORD      <span class="operator">|</span> 爱啥啥           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> MILLER    <span class="operator">|</span> 爱啥啥           <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------+---------------+</span></span><br><span class="line"><span class="number">14</span> <span class="keyword">rows</span> selected (<span class="number">0.09</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>示例2  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">    dept_no,</span><br><span class="line">       <span class="built_in">sum</span>(<span class="keyword">case</span> <span class="keyword">when</span> sal <span class="keyword">between</span> <span class="number">3000</span> <span class="keyword">and</span> <span class="number">8000</span> <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">end</span> ) <span class="keyword">as</span> `<span class="number">3000</span>到<span class="number">8000</span>`,</span><br><span class="line">       <span class="built_in">sum</span>(if(sal <span class="operator">&lt;</span> <span class="number">3000</span>, <span class="number">1</span>, <span class="number">0</span>)) <span class="keyword">as</span> `小于<span class="number">3000</span>`</span><br><span class="line"><span class="keyword">from</span> emp</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> dept_no;</span><br></pre></td></tr></table></figure>
<h3 id="8-2-3-行转列"><a href="#8-2-3-行转列" class="headerlink" title="8.2.3 行转列"></a>8.2.3 行转列</h3></li>
</ul>
<ol>
<li>相关函数说明<ol>
<li>CONCAT(string A/col, string B/col…)：返回输入字符串连接后的结果，支持任意个输入字符串;</li>
<li>CONCAT_WS(separator, str1, str2,…)：它是一个特殊形式的 CONCAT()。第一个参数剩余参数间的分隔符。分隔符可以是与剩余参数一样的字符串。如果分隔符是 NULL，返回值也将为 NULL。这个函数会跳过分隔符参数后的任何 NULL 和空字符串。分隔符将被加到被连接的字符串之间;<ul>
<li>注意: CONCAT_WS must be “string or array<string>”</li>
</ul>
</li>
<li>COLLECT_SET(col)：函数只接受基本数据类型，它的主要作用是将某字段的值进行去重汇总，产生array类型字段。 </li>
</ol>
</li>
<li>数据准备  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">name	constellation	blood_type</span><br><span class="line">孙悟空	白羊座	A</span><br><span class="line">大海	射手座	A</span><br><span class="line">宋宋	白羊座	B</span><br><span class="line">猪八戒	白羊座	A</span><br><span class="line">凤姐	射手座	A</span><br><span class="line">苍老师	白羊座	B</span><br></pre></td></tr></table></figure></li>
<li>需求：把星座和血型一样的人归类到一起。结果如下： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">射手座,A            大海|凤姐</span><br><span class="line">白羊座,A            孙悟空|猪八戒</span><br><span class="line">白羊座,B            宋宋|苍老师</span><br></pre></td></tr></table></figure></li>
<li>创建hive表并导入数据 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">0: jdbc:hive2://hadoop001:10000&gt; create table person_constellation_blood</span><br><span class="line"> (</span><br><span class="line">     name          string,</span><br><span class="line">     constellation string,</span><br><span class="line">     blood_type    string</span><br><span class="line"> )</span><br><span class="line"> row format delimited fields terminated by <span class="string">&quot;\t&quot;</span>;</span><br><span class="line">No rows affected (5.123 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt; load data <span class="built_in">local</span> inpath <span class="string">&quot;/home/atguigu/hive/person_constellation_blood/person_constellation_blood.txt&quot;</span> into table person_constellation_blood;</span><br><span class="line">No rows affected (0.111 seconds)</span><br><span class="line">0: jdbc:hive2://hadoop001:10000&gt;</span><br></pre></td></tr></table></figure></li>
<li>按需求查询数据 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> t1.cb,</span><br><span class="line">        concat_ws(&quot;|&quot;, collect_set(t1.name))</span><br><span class="line"> <span class="keyword">from</span> (<span class="keyword">select</span> name,</span><br><span class="line">              concat_ws(&quot;,&quot;, constellation, blood_type) cb</span><br><span class="line">       <span class="keyword">from</span> person_constellation_blood) t1</span><br><span class="line"> <span class="keyword">group</span> <span class="keyword">by</span> t1.cb;</span><br><span class="line"><span class="operator">+</span><span class="comment">--------+----------+</span></span><br><span class="line"><span class="operator">|</span> t1.cb  <span class="operator">|</span>   _c1    <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------+----------+</span></span><br><span class="line"><span class="operator">|</span> 射手座,A  <span class="operator">|</span> 大海<span class="operator">|</span>凤姐    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 白羊座,A  <span class="operator">|</span> 孙悟空<span class="operator">|</span>猪八戒  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 白羊座,B  <span class="operator">|</span> 宋宋<span class="operator">|</span>苍老师   <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------+----------+</span></span><br><span class="line"><span class="number">3</span> <span class="keyword">rows</span> selected (<span class="number">14.797</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="8-2-4-列转行"><a href="#8-2-4-列转行" class="headerlink" title="8.2.4 列转行"></a>8.2.4 列转行</h3><ol>
<li>函数说明<ul>
<li>EXPLODE(col)：炸裂函数，将hive一列中复杂的array或者map结构拆分成多行。  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> explode(split(&quot;1,2,3,4,5&quot;,&quot;,&quot;));</span><br><span class="line"><span class="operator">+</span><span class="comment">------+</span></span><br><span class="line"><span class="operator">|</span> col  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span>    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2</span>    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">3</span>    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">4</span>    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">5</span>    <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+</span></span><br><span class="line"><span class="number">5</span> <span class="keyword">rows</span> selected (<span class="number">0.057</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>LATERAL VIEW<ul>
<li>用法：LATERAL VIEW udtf(expression) tableAlias AS columnAlias</li>
<li>解释：用于和split, explode等UDTF一起使用，它能够将一列数据拆成多行数据，在此基础上可以对拆分后的数据进行聚合。</li>
</ul>
</li>
</ul>
</li>
<li>数据准备<table>
<thead>
<tr>
<th>movie</th>
<th>category</th>
</tr>
</thead>
<tbody><tr>
<td>《疑犯追踪》</td>
<td>悬疑,动作,科幻,剧情</td>
</tr>
<tr>
<td>《Lie to me》</td>
<td>悬疑,警匪,动作,心理,剧情</td>
</tr>
<tr>
<td>《战狼2》</td>
<td>战争,动作,灾难</td>
</tr>
</tbody></table>
</li>
<li>需求：将电影分类中的数组数据展开。结果如下： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">《疑犯追踪》	悬疑</span><br><span class="line">《疑犯追踪》	动作</span><br><span class="line">《疑犯追踪》	科幻</span><br><span class="line">《疑犯追踪》	剧情</span><br><span class="line">《Lie to me》	悬疑</span><br><span class="line">《Lie to me》	警匪</span><br><span class="line">《Lie to me》	动作</span><br><span class="line">《Lie to me》	心理</span><br><span class="line">《Lie to me》	剧情</span><br><span class="line">《战狼2》	战争</span><br><span class="line">《战狼2》	动作</span><br><span class="line">《战狼2》	灾难</span><br></pre></td></tr></table></figure></li>
<li>创建hive表并导入数据 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">table</span> movie_info(</span><br><span class="line">     movie string,</span><br><span class="line">     category string)</span><br><span class="line"> <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> &quot;\t&quot;;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.065</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/home/atguigu/hive/movie_info/movie_info.txt&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> mock_data.movie_info;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.113</span> seconds)</span><br></pre></td></tr></table></figure></li>
<li>按需求查询数据 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span></span><br><span class="line">        movie, category_name</span><br><span class="line"> <span class="keyword">from</span> movie_info</span><br><span class="line"> <span class="keyword">lateral</span> <span class="keyword">view</span></span><br><span class="line">     explode(split(category,<span class="string">&#x27;,&#x27;</span>)) movie_info_tmp <span class="keyword">as</span> category_name;</span><br><span class="line"><span class="operator">+</span><span class="comment">--------------+----------------+</span></span><br><span class="line"><span class="operator">|</span>    movie     <span class="operator">|</span> category_name  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------+----------------+</span></span><br><span class="line"><span class="operator">|</span> 《疑犯追踪》       <span class="operator">|</span> 悬疑             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 《疑犯追踪》       <span class="operator">|</span> 动作             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 《疑犯追踪》       <span class="operator">|</span> 科幻             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 《疑犯追踪》       <span class="operator">|</span> 剧情             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 《Lie <span class="keyword">to</span> me》  <span class="operator">|</span> 悬疑             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 《Lie <span class="keyword">to</span> me》  <span class="operator">|</span> 警匪             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 《Lie <span class="keyword">to</span> me》  <span class="operator">|</span> 动作             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 《Lie <span class="keyword">to</span> me》  <span class="operator">|</span> 心理             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 《Lie <span class="keyword">to</span> me》  <span class="operator">|</span> 剧情             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 《战狼<span class="number">2</span>》        <span class="operator">|</span> 战争             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 《战狼<span class="number">2</span>》        <span class="operator">|</span> 动作             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 《战狼<span class="number">2</span>》        <span class="operator">|</span> 灾难             <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------------+----------------+</span></span><br><span class="line"><span class="number">12</span> <span class="keyword">rows</span> selected (<span class="number">0.105</span> seconds)</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="8-2-5-窗口函数（开窗函数）"><a href="#8-2-5-窗口函数（开窗函数）" class="headerlink" title="8.2.5 窗口函数（开窗函数）"></a>8.2.5 窗口函数（开窗函数）</h3><h4 id="8-2-5-1-窗口函数基本使用"><a href="#8-2-5-1-窗口函数基本使用" class="headerlink" title="8.2.5.1 窗口函数基本使用"></a>8.2.5.1 窗口函数基本使用</h4><ol>
<li>介绍：<ul>
<li>普通聚合函数聚合的行集是组，开窗函数聚合的行集是窗口。因此，普通聚合函数每组（Group by）只有一个返回值，而<font color ='red' >开窗函数则可以为窗口中的每行都返回一个值</font>。</li>
</ul>
</li>
<li>基本结构 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">分析函数(如：sum(), max(), row_number()...) 窗口子句over(partition by 列名 order by 列名 rows between 开始位置 and 结束位置)</span><br></pre></td></tr></table></figure></li>
<li>over函数<ul>
<li>语法结构  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">over(partition by [column_n] order by [column_m])</span><br></pre></td></tr></table></figure>
<ul>
<li>先按照column_n分区，相同的column_n分为一区，每个分区根据column_m排序（默认升序）。</li>
</ul>
</li>
</ul>
</li>
<li>测试数据<ul>
<li>建表并插入数据  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> student_scores <span class="keyword">as</span></span><br><span class="line"><span class="keyword">select</span> stack(<span class="number">20</span>,</span><br><span class="line">   <span class="number">1</span>, <span class="number">111</span>, <span class="number">68</span>, <span class="number">69</span>, <span class="number">90</span>, <span class="string">&#x27;class1&#x27;</span>, <span class="string">&#x27;department1&#x27;</span>,</span><br><span class="line">   <span class="number">2</span>, <span class="number">112</span>, <span class="number">73</span>, <span class="number">80</span>, <span class="number">96</span>, <span class="string">&#x27;class1&#x27;</span>, <span class="string">&#x27;department1&#x27;</span>,</span><br><span class="line">   <span class="number">3</span>, <span class="number">113</span>, <span class="number">90</span>, <span class="number">74</span>, <span class="number">75</span>, <span class="string">&#x27;class1&#x27;</span>, <span class="string">&#x27;department1&#x27;</span>,</span><br><span class="line">   <span class="number">4</span>, <span class="number">114</span>, <span class="number">89</span>, <span class="number">94</span>, <span class="number">93</span>, <span class="string">&#x27;class1&#x27;</span>, <span class="string">&#x27;department1&#x27;</span>,</span><br><span class="line">   <span class="number">5</span>, <span class="number">115</span>, <span class="number">99</span>, <span class="number">93</span>, <span class="number">89</span>, <span class="string">&#x27;class1&#x27;</span>, <span class="string">&#x27;department1&#x27;</span>,</span><br><span class="line">   <span class="number">6</span>, <span class="number">121</span>, <span class="number">96</span>, <span class="number">74</span>, <span class="number">79</span>, <span class="string">&#x27;class2&#x27;</span>, <span class="string">&#x27;department1&#x27;</span>,</span><br><span class="line">   <span class="number">7</span>, <span class="number">122</span>, <span class="number">89</span>, <span class="number">86</span>, <span class="number">85</span>, <span class="string">&#x27;class2&#x27;</span>, <span class="string">&#x27;department1&#x27;</span>,</span><br><span class="line">   <span class="number">8</span>, <span class="number">123</span>, <span class="number">70</span>, <span class="number">78</span>, <span class="number">61</span>, <span class="string">&#x27;class2&#x27;</span>, <span class="string">&#x27;department1&#x27;</span>,</span><br><span class="line">   <span class="number">9</span>, <span class="number">124</span>, <span class="number">76</span>, <span class="number">70</span>, <span class="number">76</span>, <span class="string">&#x27;class2&#x27;</span>, <span class="string">&#x27;department1&#x27;</span>,</span><br><span class="line">   <span class="number">10</span>, <span class="number">211</span>, <span class="number">89</span>, <span class="number">93</span>, <span class="number">60</span>, <span class="string">&#x27;class1&#x27;</span>, <span class="string">&#x27;department2&#x27;</span>,</span><br><span class="line">   <span class="number">11</span>, <span class="number">212</span>, <span class="number">76</span>, <span class="number">83</span>, <span class="number">75</span>, <span class="string">&#x27;class1&#x27;</span>, <span class="string">&#x27;department2&#x27;</span>,</span><br><span class="line">   <span class="number">12</span>, <span class="number">213</span>, <span class="number">71</span>, <span class="number">94</span>, <span class="number">90</span>, <span class="string">&#x27;class1&#x27;</span>, <span class="string">&#x27;department2&#x27;</span>,</span><br><span class="line">   <span class="number">13</span>, <span class="number">214</span>, <span class="number">94</span>, <span class="number">94</span>, <span class="number">66</span>, <span class="string">&#x27;class1&#x27;</span>, <span class="string">&#x27;department2&#x27;</span>,</span><br><span class="line">   <span class="number">14</span>, <span class="number">215</span>, <span class="number">84</span>, <span class="number">82</span>, <span class="number">73</span>, <span class="string">&#x27;class1&#x27;</span>, <span class="string">&#x27;department2&#x27;</span>,</span><br><span class="line">   <span class="number">15</span>, <span class="number">216</span>, <span class="number">85</span>, <span class="number">74</span>, <span class="number">93</span>, <span class="string">&#x27;class1&#x27;</span>, <span class="string">&#x27;department2&#x27;</span>,</span><br><span class="line">   <span class="number">16</span>, <span class="number">221</span>, <span class="number">77</span>, <span class="number">99</span>, <span class="number">61</span>, <span class="string">&#x27;class2&#x27;</span>, <span class="string">&#x27;department2&#x27;</span>,</span><br><span class="line">   <span class="number">17</span>, <span class="number">222</span>, <span class="number">80</span>, <span class="number">78</span>, <span class="number">96</span>, <span class="string">&#x27;class2&#x27;</span>, <span class="string">&#x27;department2&#x27;</span>,</span><br><span class="line">   <span class="number">18</span>, <span class="number">223</span>, <span class="number">79</span>, <span class="number">74</span>, <span class="number">96</span>, <span class="string">&#x27;class2&#x27;</span>, <span class="string">&#x27;department2&#x27;</span>,</span><br><span class="line">   <span class="number">19</span>, <span class="number">224</span>, <span class="number">75</span>, <span class="number">80</span>, <span class="number">78</span>, <span class="string">&#x27;class2&#x27;</span>, <span class="string">&#x27;department2&#x27;</span>,</span><br><span class="line">   <span class="number">20</span>, <span class="number">225</span>, <span class="number">82</span>, <span class="number">85</span>, <span class="number">63</span>, <span class="string">&#x27;class2&#x27;</span>, <span class="string">&#x27;department2&#x27;</span></span><br><span class="line">) <span class="keyword">as</span> (id,studentId,<span class="keyword">language</span>,math,english,classId,departmentId);</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>窗口示例<ul>
<li>运行sql  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> studentId,</span><br><span class="line">       math,</span><br><span class="line">       departmentId,</span><br><span class="line">       classId,</span><br><span class="line">       <span class="comment">-- 符合所有条件的行作为窗口聚合的行集，这里符合department1的有9个</span></span><br><span class="line">       <span class="built_in">count</span>(math) <span class="keyword">over</span> ()                                                                                    <span class="keyword">as</span> count1,</span><br><span class="line">       <span class="comment">-- 符合条件的行，按照classId分组，每组数据作为窗口聚合的行集</span></span><br><span class="line">       <span class="built_in">count</span>(math) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> classId)                                                                <span class="keyword">as</span> count2,</span><br><span class="line">       <span class="comment">-- 符合条件的行，按照classId分组，每组数据按照math升序排列后作为窗口聚合的行集</span></span><br><span class="line">       <span class="built_in">count</span>(math) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> classId <span class="keyword">order</span> <span class="keyword">by</span> math)                                                  <span class="keyword">as</span> count3,</span><br><span class="line">       <span class="comment">-- 符合条件的行，按照classId分组，每组数据按照math升序排列后，当前行向前1行，向后2行（n-1,n,n+1,n+2共四行数据）作为窗口聚合的行集</span></span><br><span class="line">       <span class="built_in">count</span>(math) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> classId <span class="keyword">order</span> <span class="keyword">by</span> math <span class="keyword">rows</span> <span class="keyword">between</span> <span class="number">1</span> preceding <span class="keyword">and</span> <span class="number">2</span> following)         <span class="keyword">as</span> count4,</span><br><span class="line">       <span class="comment">-- 符合条件的行，按照classId分组，每组数据按照math升序排列后，当前行向后到结束行作为窗口聚合的行集</span></span><br><span class="line">       <span class="built_in">count</span>(math) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> classId <span class="keyword">order</span> <span class="keyword">by</span> math <span class="keyword">rows</span> <span class="keyword">between</span> <span class="keyword">current</span> <span class="type">row</span> <span class="keyword">and</span> unbounded following) <span class="keyword">as</span> count5,</span><br><span class="line">       <span class="comment">-- 符合条件的行，按照classId分组，每组数据按照math升序排列后，从起点行到当前行作为窗口聚合的行集</span></span><br><span class="line">       <span class="built_in">count</span>(math) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> classId <span class="keyword">order</span> <span class="keyword">by</span> math <span class="keyword">rows</span> <span class="keyword">between</span> unbounded preceding <span class="keyword">and</span> <span class="keyword">current</span> <span class="type">row</span> ) <span class="keyword">as</span> count6</span><br><span class="line"><span class="keyword">from</span> student_scores</span><br><span class="line"><span class="keyword">where</span> departmentId <span class="operator">=</span> <span class="string">&#x27;department1&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li>结果  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">+</span><span class="comment">------------+-------+---------------+----------+---------+---------+---------+---------+---------+---------+</span></span><br><span class="line"><span class="operator">|</span> studentid  <span class="operator">|</span> math  <span class="operator">|</span> departmentid  <span class="operator">|</span> classid  <span class="operator">|</span> count1  <span class="operator">|</span> count2  <span class="operator">|</span> count3  <span class="operator">|</span> count4  <span class="operator">|</span> count5  <span class="operator">|</span> count6  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------+---------------+----------+---------+---------+---------+---------+---------+---------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">111</span>        <span class="operator">|</span> <span class="number">69</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">9</span>       <span class="operator">|</span> <span class="number">5</span>       <span class="operator">|</span> <span class="number">1</span>       <span class="operator">|</span> <span class="number">3</span>       <span class="operator">|</span> <span class="number">5</span>       <span class="operator">|</span> <span class="number">1</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">113</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">9</span>       <span class="operator">|</span> <span class="number">5</span>       <span class="operator">|</span> <span class="number">2</span>       <span class="operator">|</span> <span class="number">4</span>       <span class="operator">|</span> <span class="number">4</span>       <span class="operator">|</span> <span class="number">2</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">112</span>        <span class="operator">|</span> <span class="number">80</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">9</span>       <span class="operator">|</span> <span class="number">5</span>       <span class="operator">|</span> <span class="number">3</span>       <span class="operator">|</span> <span class="number">4</span>       <span class="operator">|</span> <span class="number">3</span>       <span class="operator">|</span> <span class="number">3</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">115</span>        <span class="operator">|</span> <span class="number">93</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">9</span>       <span class="operator">|</span> <span class="number">5</span>       <span class="operator">|</span> <span class="number">4</span>       <span class="operator">|</span> <span class="number">3</span>       <span class="operator">|</span> <span class="number">2</span>       <span class="operator">|</span> <span class="number">4</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">114</span>        <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">9</span>       <span class="operator">|</span> <span class="number">5</span>       <span class="operator">|</span> <span class="number">5</span>       <span class="operator">|</span> <span class="number">2</span>       <span class="operator">|</span> <span class="number">1</span>       <span class="operator">|</span> <span class="number">5</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">124</span>        <span class="operator">|</span> <span class="number">70</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">9</span>       <span class="operator">|</span> <span class="number">4</span>       <span class="operator">|</span> <span class="number">1</span>       <span class="operator">|</span> <span class="number">3</span>       <span class="operator">|</span> <span class="number">4</span>       <span class="operator">|</span> <span class="number">1</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">121</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">9</span>       <span class="operator">|</span> <span class="number">4</span>       <span class="operator">|</span> <span class="number">2</span>       <span class="operator">|</span> <span class="number">4</span>       <span class="operator">|</span> <span class="number">3</span>       <span class="operator">|</span> <span class="number">2</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">123</span>        <span class="operator">|</span> <span class="number">78</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">9</span>       <span class="operator">|</span> <span class="number">4</span>       <span class="operator">|</span> <span class="number">3</span>       <span class="operator">|</span> <span class="number">3</span>       <span class="operator">|</span> <span class="number">2</span>       <span class="operator">|</span> <span class="number">3</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">122</span>        <span class="operator">|</span> <span class="number">86</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">9</span>       <span class="operator">|</span> <span class="number">4</span>       <span class="operator">|</span> <span class="number">4</span>       <span class="operator">|</span> <span class="number">2</span>       <span class="operator">|</span> <span class="number">1</span>       <span class="operator">|</span> <span class="number">4</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------+---------------+----------+---------+---------+---------+---------+---------+---------+</span></span><br></pre></td></tr></table></figure></li>
<li>结果解析：  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">studentid=114 为例</span><br><span class="line">count1: 为departmentId=department1的行数为9，</span><br><span class="line">count2: 为分区class1中的行数5，</span><br><span class="line">count3: 为分区class1中math升序排列到当前行94 match&lt;=94行数5</span><br><span class="line">count4: 为分区class1中math升序排列后取，当前行-1=115，114，当前行+1=不存在，当前行+2=不存在，行数2</span><br><span class="line">count5: 为分区class1中math升序排列后取，当前行到结束行，114为当前分区最后一行，行数1</span><br><span class="line">count6: 为分区class1中math升序排列后取，开始行到当前行，行数5</span><br></pre></td></tr></table></figure>
<ul>
<li>如果不指定ROWS BETWEEN，默认统计窗口是从起点到当前行</li>
<li>ROWS BETWEEN，也叫做window子句。<ul>
<li>PRECEDING：往前<ul>
<li>n PRECEDING：往前n行数据</li>
</ul>
</li>
<li>FOLLOWING：往后<ul>
<li>n FOLLOWING：往后n行数据</li>
</ul>
</li>
<li>CURRENT ROW：当前行</li>
<li>UNBOUNDED：无边界（一般结合PRECEDING，FOLLOWING使用）</li>
<li>UNBOUNDED PRECEDING 表示该窗口最前面的行（起点）</li>
<li>UNBOUNDED FOLLOWING：表示该窗口最后面的行（终点）</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="8-2-5-2-聚合开窗函数"><a href="#8-2-5-2-聚合开窗函数" class="headerlink" title="8.2.5.2 聚合开窗函数"></a>8.2.5.2 聚合开窗函数</h4><ol>
<li>sum()，min()，max()，avg()都与count()类似<ul>
<li>示例  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> studentId,</span><br><span class="line">       math,</span><br><span class="line">       departmentId,</span><br><span class="line">       classId,</span><br><span class="line">       <span class="comment">-- 符合所有条件的行作为窗口聚合的行集，这里符合department1的有9个</span></span><br><span class="line">       <span class="built_in">avg</span>(math) <span class="keyword">over</span> ()                                                                                    <span class="keyword">as</span> avg1,</span><br><span class="line">       <span class="comment">-- 符合条件的行，按照classId分组，每组数据作为窗口聚合的行集</span></span><br><span class="line">       <span class="built_in">avg</span>(math) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> classId)                                                                <span class="keyword">as</span> avg2,</span><br><span class="line">       <span class="comment">-- 符合条件的行，按照classId分组，每组数据按照math升序排列后到当前行截止，作为窗口聚合的行集</span></span><br><span class="line">       <span class="built_in">avg</span>(math) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> classId <span class="keyword">order</span> <span class="keyword">by</span> math)                                                  <span class="keyword">as</span> avg3,</span><br><span class="line">       <span class="comment">-- 符合条件的行，按照classId分组，每组数据按照math升序排列后，当前行向前1行，向后2行（n-1,n,n+1,n+2共四行数据）作为窗口聚合的行集</span></span><br><span class="line">       <span class="built_in">avg</span>(math) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> classId <span class="keyword">order</span> <span class="keyword">by</span> math <span class="keyword">rows</span> <span class="keyword">between</span> <span class="number">1</span> preceding <span class="keyword">and</span> <span class="number">2</span> following)         <span class="keyword">as</span> avg4,</span><br><span class="line">       <span class="comment">-- 符合条件的行，按照classId分组，每组数据按照math升序排列后，当前行向后到结束行作为窗口聚合的行集</span></span><br><span class="line">       <span class="built_in">avg</span>(math) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> classId <span class="keyword">order</span> <span class="keyword">by</span> math <span class="keyword">rows</span> <span class="keyword">between</span> <span class="keyword">current</span> <span class="type">row</span> <span class="keyword">and</span> unbounded following) <span class="keyword">as</span> avg5,</span><br><span class="line">       <span class="comment">-- 符合条件的行，按照classId分组，每组数据按照math升序排列后，从起点行到当前行作为窗口聚合的行集</span></span><br><span class="line">       <span class="built_in">avg</span>(math) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> classId <span class="keyword">order</span> <span class="keyword">by</span> math <span class="keyword">rows</span> <span class="keyword">between</span> unbounded preceding <span class="keyword">and</span> <span class="keyword">current</span> <span class="type">row</span> ) <span class="keyword">as</span> avg6</span><br><span class="line"><span class="keyword">from</span> student_scores</span><br><span class="line"><span class="keyword">where</span> departmentId <span class="operator">=</span> <span class="string">&#x27;department1&#x27;</span>;</span><br><span class="line">       </span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------+---------------+----------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+</span></span><br><span class="line"><span class="operator">|</span> studentid  <span class="operator">|</span> math  <span class="operator">|</span> departmentid  <span class="operator">|</span> classid  <span class="operator">|</span>        avg1        <span class="operator">|</span> avg2  <span class="operator">|</span>        avg3        <span class="operator">|</span>        avg4        <span class="operator">|</span>        avg5        <span class="operator">|</span>        avg6        <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------+---------------+----------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">111</span>        <span class="operator">|</span> <span class="number">69</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">79.77777777777777</span>  <span class="operator">|</span> <span class="number">82.0</span>  <span class="operator">|</span> <span class="number">69.0</span>               <span class="operator">|</span> <span class="number">74.33333333333333</span>  <span class="operator">|</span> <span class="number">82.0</span>               <span class="operator">|</span> <span class="number">69.0</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">113</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">79.77777777777777</span>  <span class="operator">|</span> <span class="number">82.0</span>  <span class="operator">|</span> <span class="number">71.5</span>               <span class="operator">|</span> <span class="number">79.0</span>               <span class="operator">|</span> <span class="number">85.25</span>              <span class="operator">|</span> <span class="number">71.5</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">112</span>        <span class="operator">|</span> <span class="number">80</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">79.77777777777777</span>  <span class="operator">|</span> <span class="number">82.0</span>  <span class="operator">|</span> <span class="number">74.33333333333333</span>  <span class="operator">|</span> <span class="number">85.25</span>              <span class="operator">|</span> <span class="number">89.0</span>               <span class="operator">|</span> <span class="number">74.33333333333333</span>  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">115</span>        <span class="operator">|</span> <span class="number">93</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">79.77777777777777</span>  <span class="operator">|</span> <span class="number">82.0</span>  <span class="operator">|</span> <span class="number">79.0</span>               <span class="operator">|</span> <span class="number">89.0</span>               <span class="operator">|</span> <span class="number">93.5</span>               <span class="operator">|</span> <span class="number">79.0</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">114</span>        <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">79.77777777777777</span>  <span class="operator">|</span> <span class="number">82.0</span>  <span class="operator">|</span> <span class="number">82.0</span>               <span class="operator">|</span> <span class="number">93.5</span>               <span class="operator">|</span> <span class="number">94.0</span>               <span class="operator">|</span> <span class="number">82.0</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">124</span>        <span class="operator">|</span> <span class="number">70</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">79.77777777777777</span>  <span class="operator">|</span> <span class="number">77.0</span>  <span class="operator">|</span> <span class="number">70.0</span>               <span class="operator">|</span> <span class="number">74.0</span>               <span class="operator">|</span> <span class="number">77.0</span>               <span class="operator">|</span> <span class="number">70.0</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">121</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">79.77777777777777</span>  <span class="operator">|</span> <span class="number">77.0</span>  <span class="operator">|</span> <span class="number">72.0</span>               <span class="operator">|</span> <span class="number">77.0</span>               <span class="operator">|</span> <span class="number">79.33333333333333</span>  <span class="operator">|</span> <span class="number">72.0</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">123</span>        <span class="operator">|</span> <span class="number">78</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">79.77777777777777</span>  <span class="operator">|</span> <span class="number">77.0</span>  <span class="operator">|</span> <span class="number">74.0</span>               <span class="operator">|</span> <span class="number">79.33333333333333</span>  <span class="operator">|</span> <span class="number">82.0</span>               <span class="operator">|</span> <span class="number">74.0</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">122</span>        <span class="operator">|</span> <span class="number">86</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">79.77777777777777</span>  <span class="operator">|</span> <span class="number">77.0</span>  <span class="operator">|</span> <span class="number">77.0</span>               <span class="operator">|</span> <span class="number">82.0</span>               <span class="operator">|</span> <span class="number">86.0</span>               <span class="operator">|</span> <span class="number">77.0</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------+---------------+----------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>first_value <ul>
<li>作用：返回分区中的第一个值</li>
<li>sql示例  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> studentId,</span><br><span class="line">       math,</span><br><span class="line">       departmentId,</span><br><span class="line">       classId,</span><br><span class="line">       <span class="built_in">first_value</span>(math) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> classId <span class="keyword">order</span> <span class="keyword">by</span> math) first_value_1,</span><br><span class="line">       <span class="built_in">first_value</span>(math) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> classId <span class="keyword">order</span> <span class="keyword">by</span> math <span class="keyword">rows</span> <span class="keyword">between</span> <span class="number">1</span> preceding <span class="keyword">and</span> <span class="number">2</span> following) first_value_2</span><br><span class="line"><span class="keyword">from</span> student_scores</span><br><span class="line"><span class="keyword">where</span> departmentId <span class="operator">=</span> <span class="string">&#x27;department1&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------+---------------+----------+----------------+----------------+</span></span><br><span class="line"><span class="operator">|</span> studentid  <span class="operator">|</span> math  <span class="operator">|</span> departmentid  <span class="operator">|</span> classid  <span class="operator">|</span> first_value_1  <span class="operator">|</span> first_value_2  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------+---------------+----------+----------------+----------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">111</span>        <span class="operator">|</span> <span class="number">69</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">69</span>             <span class="operator">|</span> <span class="number">69</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">113</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">69</span>             <span class="operator">|</span> <span class="number">69</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">112</span>        <span class="operator">|</span> <span class="number">80</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">69</span>             <span class="operator">|</span> <span class="number">74</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">115</span>        <span class="operator">|</span> <span class="number">93</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">69</span>             <span class="operator">|</span> <span class="number">80</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">114</span>        <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">69</span>             <span class="operator">|</span> <span class="number">93</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">124</span>        <span class="operator">|</span> <span class="number">70</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">70</span>             <span class="operator">|</span> <span class="number">70</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">121</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">70</span>             <span class="operator">|</span> <span class="number">70</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">123</span>        <span class="operator">|</span> <span class="number">78</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">70</span>             <span class="operator">|</span> <span class="number">74</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">122</span>        <span class="operator">|</span> <span class="number">86</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">70</span>             <span class="operator">|</span> <span class="number">78</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------+---------------+----------+----------------+----------------+</span></span><br></pre></td></tr></table></figure></li>
<li>解析  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">studentId=115为例</span><br><span class="line">first_value1：为分区class1中按照math排序的第一个值69(rows between未指定为第一行到当前行)，</span><br><span class="line">first_value2：为分区class2中按照math排序后当前行向前1行向后2行区间的第一个值80。</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>last_vlaue <ul>
<li>作用：返回分区最后一个值</li>
<li>示例sql  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">+</span><span class="comment">------------+-------+---------------+----------+---------------+---------------+</span></span><br><span class="line"><span class="operator">|</span> studentid  <span class="operator">|</span> math  <span class="operator">|</span> departmentid  <span class="operator">|</span> classid  <span class="operator">|</span> last_value_1  <span class="operator">|</span> last_value_2  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------+---------------+----------+---------------+---------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">111</span>        <span class="operator">|</span> <span class="number">69</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">69</span>            <span class="operator">|</span> <span class="number">80</span>            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">113</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">74</span>            <span class="operator">|</span> <span class="number">93</span>            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">112</span>        <span class="operator">|</span> <span class="number">80</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">80</span>            <span class="operator">|</span> <span class="number">94</span>            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">115</span>        <span class="operator">|</span> <span class="number">93</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">93</span>            <span class="operator">|</span> <span class="number">94</span>            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">114</span>        <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">94</span>            <span class="operator">|</span> <span class="number">94</span>            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">124</span>        <span class="operator">|</span> <span class="number">70</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">70</span>            <span class="operator">|</span> <span class="number">78</span>            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">121</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">74</span>            <span class="operator">|</span> <span class="number">86</span>            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">123</span>        <span class="operator">|</span> <span class="number">78</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">78</span>            <span class="operator">|</span> <span class="number">86</span>            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">122</span>        <span class="operator">|</span> <span class="number">86</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">86</span>            <span class="operator">|</span> <span class="number">86</span>            <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------+---------------+----------+---------------+---------------+</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>lag <ul>
<li>作用：LAG(col, n, DEFAULT)用于统计窗口内向上第n行的值<ul>
<li>col：列名</li>
<li>n：向上n行，[可选，默认为1]</li>
<li>DEFAULT：当向上n行为NULL时，取默认值；如果不指定，则为NULL</li>
</ul>
</li>
<li>示例sql:  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> studentId,</span><br><span class="line">       math,</span><br><span class="line">       departmentId,</span><br><span class="line">       classId,</span><br><span class="line">       <span class="built_in">lag</span>(math,<span class="number">1</span>,<span class="number">60</span>) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> classId <span class="keyword">order</span> <span class="keyword">by</span> math) lag_1,</span><br><span class="line">       <span class="built_in">lag</span>(math,<span class="number">2</span>) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> classId <span class="keyword">order</span> <span class="keyword">by</span> math) lag_1</span><br><span class="line"><span class="keyword">from</span> student_scores</span><br><span class="line"><span class="keyword">where</span> departmentId <span class="operator">=</span> <span class="string">&#x27;department1&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------+---------------+----------+--------+--------+</span></span><br><span class="line"><span class="operator">|</span> studentid  <span class="operator">|</span> math  <span class="operator">|</span> departmentid  <span class="operator">|</span> classid  <span class="operator">|</span> lag_1  <span class="operator">|</span> lag_1  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------+---------------+----------+--------+--------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">111</span>        <span class="operator">|</span> <span class="number">69</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">60</span>     <span class="operator">|</span> <span class="keyword">NULL</span>   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">113</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">69</span>     <span class="operator">|</span> <span class="keyword">NULL</span>   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">112</span>        <span class="operator">|</span> <span class="number">80</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">74</span>     <span class="operator">|</span> <span class="number">69</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">115</span>        <span class="operator">|</span> <span class="number">93</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">80</span>     <span class="operator">|</span> <span class="number">74</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">114</span>        <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">93</span>     <span class="operator">|</span> <span class="number">80</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">124</span>        <span class="operator">|</span> <span class="number">70</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">60</span>     <span class="operator">|</span> <span class="keyword">NULL</span>   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">121</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">70</span>     <span class="operator">|</span> <span class="keyword">NULL</span>   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">123</span>        <span class="operator">|</span> <span class="number">78</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">74</span>     <span class="operator">|</span> <span class="number">70</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">122</span>        <span class="operator">|</span> <span class="number">86</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">78</span>     <span class="operator">|</span> <span class="number">74</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------+---------------+----------+--------+--------+</span></span><br></pre></td></tr></table></figure></li>
<li>解析  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">studentId=113，</span><br><span class="line">lag1为分区class1按照math排序后当前行向上2行的值NULL，但是设置了DEFUALT，所以为60，</span><br><span class="line">lag2因为没有设置DEFAULT，所以为NULL。</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>lead<ul>
<li>作用：LEAD(col, n, DEFAULT)与LAG相反，用于统计窗口内向下n行的值<ul>
<li>col：列名</li>
<li>n：向下n行，[可选，默认为1]</li>
<li>DEFAULT：当向下n行为NULL时，取默认值；如果不指定，则为NULL</li>
</ul>
</li>
<li>sql示例  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> studentId,</span><br><span class="line">       math,</span><br><span class="line">       departmentId,</span><br><span class="line">       classId,</span><br><span class="line">       <span class="built_in">lead</span>(math,<span class="number">1</span>,<span class="number">60</span>) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> classId <span class="keyword">order</span> <span class="keyword">by</span> math) lead_1,</span><br><span class="line">       <span class="built_in">lead</span>(math,<span class="number">2</span>) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> classId <span class="keyword">order</span> <span class="keyword">by</span> math) lead_1</span><br><span class="line"><span class="keyword">from</span> student_scores</span><br><span class="line"><span class="keyword">where</span> departmentId <span class="operator">=</span> <span class="string">&#x27;department1&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------+---------------+----------+--------+--------+</span></span><br><span class="line"><span class="operator">|</span> studentid  <span class="operator">|</span> math  <span class="operator">|</span> departmentid  <span class="operator">|</span> classid  <span class="operator">|</span> lead_1  <span class="operator">|</span> lead_1  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------+---------------+----------+--------+--------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">111</span>        <span class="operator">|</span> <span class="number">69</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">74</span>     <span class="operator">|</span> <span class="number">80</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">113</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">80</span>     <span class="operator">|</span> <span class="number">93</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">112</span>        <span class="operator">|</span> <span class="number">80</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">93</span>     <span class="operator">|</span> <span class="number">94</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">115</span>        <span class="operator">|</span> <span class="number">93</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">94</span>     <span class="operator">|</span> <span class="keyword">NULL</span>   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">114</span>        <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">60</span>     <span class="operator">|</span> <span class="keyword">NULL</span>   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">124</span>        <span class="operator">|</span> <span class="number">70</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">74</span>     <span class="operator">|</span> <span class="number">78</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">121</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">78</span>     <span class="operator">|</span> <span class="number">86</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">123</span>        <span class="operator">|</span> <span class="number">78</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">86</span>     <span class="operator">|</span> <span class="keyword">NULL</span>   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">122</span>        <span class="operator">|</span> <span class="number">86</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">60</span>     <span class="operator">|</span> <span class="keyword">NULL</span>   <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------+---------------+----------+--------+--------+</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>cume_dist<ul>
<li>作用：计算某个窗口或分区中某个值的累积分布。假定升序排序，则使用以下公式确定累积分布：(小于等于当前值的行数) / (分区内总行数)</li>
<li>sql示例  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> studentId,</span><br><span class="line">       math,</span><br><span class="line">       departmentId,</span><br><span class="line">       classId,</span><br><span class="line">       <span class="built_in">cume_dist</span>() <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> math)                      <span class="keyword">as</span> cume_dist1,</span><br><span class="line">       <span class="built_in">cume_dist</span>() <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> math <span class="keyword">desc</span>)                 <span class="keyword">as</span> cume_dist2,</span><br><span class="line">       <span class="built_in">cume_dist</span>() <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> classId <span class="keyword">order</span> <span class="keyword">by</span> math) <span class="keyword">as</span> cume_dist3</span><br><span class="line"><span class="keyword">from</span> student_scores</span><br><span class="line"><span class="keyword">where</span> departmentId <span class="operator">=</span> <span class="string">&#x27;department1&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------+---------------+----------+---------------------+---------------------+-------------+</span></span><br><span class="line"><span class="operator">|</span> studentid  <span class="operator">|</span> math  <span class="operator">|</span> departmentid  <span class="operator">|</span> classid  <span class="operator">|</span>     cume_dist1      <span class="operator">|</span>     cume_dist2      <span class="operator">|</span> cume_dist3  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------+---------------+----------+---------------------+---------------------+-------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">111</span>        <span class="operator">|</span> <span class="number">69</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">0.1111111111111111</span>  <span class="operator">|</span> <span class="number">1.0</span>                 <span class="operator">|</span> <span class="number">0.2</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">113</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">0.4444444444444444</span>  <span class="operator">|</span> <span class="number">0.7777777777777778</span>  <span class="operator">|</span> <span class="number">0.4</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">112</span>        <span class="operator">|</span> <span class="number">80</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">0.6666666666666666</span>  <span class="operator">|</span> <span class="number">0.4444444444444444</span>  <span class="operator">|</span> <span class="number">0.6</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">115</span>        <span class="operator">|</span> <span class="number">93</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">0.8888888888888888</span>  <span class="operator">|</span> <span class="number">0.2222222222222222</span>  <span class="operator">|</span> <span class="number">0.8</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">114</span>        <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class1   <span class="operator">|</span> <span class="number">1.0</span>                 <span class="operator">|</span> <span class="number">0.1111111111111111</span>  <span class="operator">|</span> <span class="number">1.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">124</span>        <span class="operator">|</span> <span class="number">70</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">0.2222222222222222</span>  <span class="operator">|</span> <span class="number">0.8888888888888888</span>  <span class="operator">|</span> <span class="number">0.25</span>        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">121</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">0.4444444444444444</span>  <span class="operator">|</span> <span class="number">0.7777777777777778</span>  <span class="operator">|</span> <span class="number">0.5</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">123</span>        <span class="operator">|</span> <span class="number">78</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">0.5555555555555556</span>  <span class="operator">|</span> <span class="number">0.5555555555555556</span>  <span class="operator">|</span> <span class="number">0.75</span>        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">122</span>        <span class="operator">|</span> <span class="number">86</span>    <span class="operator">|</span> department1   <span class="operator">|</span> class2   <span class="operator">|</span> <span class="number">0.7777777777777778</span>  <span class="operator">|</span> <span class="number">0.3333333333333333</span>  <span class="operator">|</span> <span class="number">1.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+-------+---------------+----------+---------------------+---------------------+-------------+</span></span><br></pre></td></tr></table></figure></li>
<li>结果解析  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">studentId=115为例</span><br><span class="line">cume_dist1=小于等于93的行数8/总行数9=0.8888888888888888</span><br><span class="line">cume_dist2=大于等于93的行数2/总行数9=0.2222222222222222</span><br><span class="line">cume_dist3=class1分区内小于等于93的行数4/总行数5=0.8</span><br></pre></td></tr></table></figure>
<h4 id="8-2-5-3-排序开窗函数"><a href="#8-2-5-3-排序开窗函数" class="headerlink" title="8.2.5.3 排序开窗函数"></a>8.2.5.3 排序开窗函数</h4></li>
</ul>
</li>
<li>row_number<ul>
<li>作用：row_number() over([partition by col1] [order by col2])开窗函数是基于over子句中order by列的一个排名。在窗口或分区内从1开始排序，即使遇到col2相等时，名次依旧增加。例如：有两条记录相等，但一个是第一，一个是第二</li>
<li>sql示例  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id,</span><br><span class="line">       studentId,</span><br><span class="line">       <span class="keyword">language</span>,</span><br><span class="line">       math,</span><br><span class="line">       english,</span><br><span class="line">       classId,</span><br><span class="line">       departmentId,</span><br><span class="line">       <span class="built_in">row_number</span>() <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> math) <span class="keyword">as</span> math_order,</span><br><span class="line">       <span class="built_in">row_number</span>() <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> english) <span class="keyword">as</span> english_order,</span><br><span class="line">       <span class="built_in">row_number</span>() <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> classId <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">language</span>) <span class="keyword">as</span> class_language_order</span><br><span class="line"><span class="keyword">from</span> student_scores;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-----+------------+-----------+-------+----------+----------+---------------+------------+---------------+----------------------+</span></span><br><span class="line"><span class="operator">|</span> id  <span class="operator">|</span> studentid  <span class="operator">|</span> <span class="keyword">language</span>  <span class="operator">|</span> math  <span class="operator">|</span> english  <span class="operator">|</span> classid  <span class="operator">|</span> departmentid  <span class="operator">|</span> math_order  <span class="operator">|</span> english_order  <span class="operator">|</span> class_language_order  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----+------------+-----------+-------+----------+----------+---------------+------------+---------------+----------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span>   <span class="operator">|</span> <span class="number">111</span>        <span class="operator">|</span> <span class="number">68</span>        <span class="operator">|</span> <span class="number">69</span>    <span class="operator">|</span> <span class="number">90</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">1</span>          <span class="operator">|</span> <span class="number">14</span>            <span class="operator">|</span> <span class="number">1</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">12</span>  <span class="operator">|</span> <span class="number">213</span>        <span class="operator">|</span> <span class="number">71</span>        <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> <span class="number">90</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">17</span>         <span class="operator">|</span> <span class="number">15</span>            <span class="operator">|</span> <span class="number">2</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">112</span>        <span class="operator">|</span> <span class="number">73</span>        <span class="operator">|</span> <span class="number">80</span>    <span class="operator">|</span> <span class="number">96</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">10</span>         <span class="operator">|</span> <span class="number">20</span>            <span class="operator">|</span> <span class="number">3</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">11</span>  <span class="operator">|</span> <span class="number">212</span>        <span class="operator">|</span> <span class="number">76</span>        <span class="operator">|</span> <span class="number">83</span>    <span class="operator">|</span> <span class="number">75</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">12</span>         <span class="operator">|</span> <span class="number">8</span>             <span class="operator">|</span> <span class="number">4</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">14</span>  <span class="operator">|</span> <span class="number">215</span>        <span class="operator">|</span> <span class="number">84</span>        <span class="operator">|</span> <span class="number">82</span>    <span class="operator">|</span> <span class="number">73</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">11</span>         <span class="operator">|</span> <span class="number">6</span>             <span class="operator">|</span> <span class="number">5</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">15</span>  <span class="operator">|</span> <span class="number">216</span>        <span class="operator">|</span> <span class="number">85</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> <span class="number">93</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">4</span>          <span class="operator">|</span> <span class="number">16</span>            <span class="operator">|</span> <span class="number">6</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">10</span>  <span class="operator">|</span> <span class="number">211</span>        <span class="operator">|</span> <span class="number">89</span>        <span class="operator">|</span> <span class="number">93</span>    <span class="operator">|</span> <span class="number">60</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">16</span>         <span class="operator">|</span> <span class="number">1</span>             <span class="operator">|</span> <span class="number">7</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">4</span>   <span class="operator">|</span> <span class="number">114</span>        <span class="operator">|</span> <span class="number">89</span>        <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> <span class="number">93</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">18</span>         <span class="operator">|</span> <span class="number">17</span>            <span class="operator">|</span> <span class="number">8</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">3</span>   <span class="operator">|</span> <span class="number">113</span>        <span class="operator">|</span> <span class="number">90</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> <span class="number">75</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">5</span>          <span class="operator">|</span> <span class="number">7</span>             <span class="operator">|</span> <span class="number">9</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">13</span>  <span class="operator">|</span> <span class="number">214</span>        <span class="operator">|</span> <span class="number">94</span>        <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> <span class="number">66</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">19</span>         <span class="operator">|</span> <span class="number">5</span>             <span class="operator">|</span> <span class="number">10</span>                   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">5</span>   <span class="operator">|</span> <span class="number">115</span>        <span class="operator">|</span> <span class="number">99</span>        <span class="operator">|</span> <span class="number">93</span>    <span class="operator">|</span> <span class="number">89</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">15</span>         <span class="operator">|</span> <span class="number">13</span>            <span class="operator">|</span> <span class="number">11</span>                   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">8</span>   <span class="operator">|</span> <span class="number">123</span>        <span class="operator">|</span> <span class="number">70</span>        <span class="operator">|</span> <span class="number">78</span>    <span class="operator">|</span> <span class="number">61</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">7</span>          <span class="operator">|</span> <span class="number">2</span>             <span class="operator">|</span> <span class="number">1</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">19</span>  <span class="operator">|</span> <span class="number">224</span>        <span class="operator">|</span> <span class="number">75</span>        <span class="operator">|</span> <span class="number">80</span>    <span class="operator">|</span> <span class="number">78</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">9</span>          <span class="operator">|</span> <span class="number">10</span>            <span class="operator">|</span> <span class="number">2</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">9</span>   <span class="operator">|</span> <span class="number">124</span>        <span class="operator">|</span> <span class="number">76</span>        <span class="operator">|</span> <span class="number">70</span>    <span class="operator">|</span> <span class="number">76</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">2</span>          <span class="operator">|</span> <span class="number">9</span>             <span class="operator">|</span> <span class="number">3</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">16</span>  <span class="operator">|</span> <span class="number">221</span>        <span class="operator">|</span> <span class="number">77</span>        <span class="operator">|</span> <span class="number">99</span>    <span class="operator">|</span> <span class="number">61</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">20</span>         <span class="operator">|</span> <span class="number">3</span>             <span class="operator">|</span> <span class="number">4</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">18</span>  <span class="operator">|</span> <span class="number">223</span>        <span class="operator">|</span> <span class="number">79</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> <span class="number">96</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">3</span>          <span class="operator">|</span> <span class="number">19</span>            <span class="operator">|</span> <span class="number">5</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">17</span>  <span class="operator">|</span> <span class="number">222</span>        <span class="operator">|</span> <span class="number">80</span>        <span class="operator">|</span> <span class="number">78</span>    <span class="operator">|</span> <span class="number">96</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">8</span>          <span class="operator">|</span> <span class="number">18</span>            <span class="operator">|</span> <span class="number">6</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">20</span>  <span class="operator">|</span> <span class="number">225</span>        <span class="operator">|</span> <span class="number">82</span>        <span class="operator">|</span> <span class="number">85</span>    <span class="operator">|</span> <span class="number">63</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">13</span>         <span class="operator">|</span> <span class="number">4</span>             <span class="operator">|</span> <span class="number">7</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">7</span>   <span class="operator">|</span> <span class="number">122</span>        <span class="operator">|</span> <span class="number">89</span>        <span class="operator">|</span> <span class="number">86</span>    <span class="operator">|</span> <span class="number">85</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">14</span>         <span class="operator">|</span> <span class="number">12</span>            <span class="operator">|</span> <span class="number">8</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">6</span>   <span class="operator">|</span> <span class="number">121</span>        <span class="operator">|</span> <span class="number">96</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> <span class="number">79</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">6</span>          <span class="operator">|</span> <span class="number">11</span>            <span class="operator">|</span> <span class="number">9</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----+------------+-----------+-------+----------+----------+---------------+------------+---------------+----------------------+</span></span><br></pre></td></tr></table></figure></li>
<li>结果解析   <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">math_order: 以match排序</span><br><span class="line">english_order: 以english排序</span><br><span class="line">class_order: 以classId,departmentId分组后组内排序</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>rank<ul>
<li>作用：rank() over([partition by col1] [order by col2])，当遇到col2相等时，名次相同，但是下一个col2值的名次递增N（N是重复的次数）。例如：有两条记录是并列第一，下一个是第三，没有第二。</li>
<li>sql示例  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id,</span><br><span class="line">       studentId,</span><br><span class="line">       <span class="keyword">language</span>,</span><br><span class="line">       math,</span><br><span class="line">       english,</span><br><span class="line">       classId,</span><br><span class="line">       departmentId,</span><br><span class="line">       <span class="built_in">rank</span>() <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> math) <span class="keyword">as</span> math_rank,</span><br><span class="line">       <span class="built_in">rank</span>() <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> english) <span class="keyword">as</span> english_rank,</span><br><span class="line">       <span class="built_in">rank</span>() <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> classId,departmentId <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">language</span> ) <span class="keyword">as</span> class_language_rank</span><br><span class="line"><span class="keyword">from</span> student_scores;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-----+------------+-----------+-------+----------+----------+---------------+------------+---------------+----------------------+</span></span><br><span class="line"><span class="operator">|</span> id  <span class="operator">|</span> studentid  <span class="operator">|</span> <span class="keyword">language</span>  <span class="operator">|</span> math  <span class="operator">|</span> english  <span class="operator">|</span> classid  <span class="operator">|</span> departmentid  <span class="operator">|</span> math_rank  <span class="operator">|</span> english_rank  <span class="operator">|</span> class_language_rank  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----+------------+-----------+-------+----------+----------+---------------+------------+---------------+----------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span>   <span class="operator">|</span> <span class="number">111</span>        <span class="operator">|</span> <span class="number">68</span>        <span class="operator">|</span> <span class="number">69</span>    <span class="operator">|</span> <span class="number">90</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">1</span>          <span class="operator">|</span> <span class="number">14</span>            <span class="operator">|</span> <span class="number">1</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">112</span>        <span class="operator">|</span> <span class="number">73</span>        <span class="operator">|</span> <span class="number">80</span>    <span class="operator">|</span> <span class="number">96</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">9</span>          <span class="operator">|</span> <span class="number">18</span>            <span class="operator">|</span> <span class="number">2</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">4</span>   <span class="operator">|</span> <span class="number">114</span>        <span class="operator">|</span> <span class="number">89</span>        <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> <span class="number">93</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">17</span>         <span class="operator">|</span> <span class="number">16</span>            <span class="operator">|</span> <span class="number">3</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">3</span>   <span class="operator">|</span> <span class="number">113</span>        <span class="operator">|</span> <span class="number">90</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> <span class="number">75</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">3</span>          <span class="operator">|</span> <span class="number">7</span>             <span class="operator">|</span> <span class="number">4</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">5</span>   <span class="operator">|</span> <span class="number">115</span>        <span class="operator">|</span> <span class="number">99</span>        <span class="operator">|</span> <span class="number">93</span>    <span class="operator">|</span> <span class="number">89</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">15</span>         <span class="operator">|</span> <span class="number">13</span>            <span class="operator">|</span> <span class="number">5</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">12</span>  <span class="operator">|</span> <span class="number">213</span>        <span class="operator">|</span> <span class="number">71</span>        <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> <span class="number">90</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">17</span>         <span class="operator">|</span> <span class="number">14</span>            <span class="operator">|</span> <span class="number">1</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">11</span>  <span class="operator">|</span> <span class="number">212</span>        <span class="operator">|</span> <span class="number">76</span>        <span class="operator">|</span> <span class="number">83</span>    <span class="operator">|</span> <span class="number">75</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">12</span>         <span class="operator">|</span> <span class="number">7</span>             <span class="operator">|</span> <span class="number">2</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">14</span>  <span class="operator">|</span> <span class="number">215</span>        <span class="operator">|</span> <span class="number">84</span>        <span class="operator">|</span> <span class="number">82</span>    <span class="operator">|</span> <span class="number">73</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">11</span>         <span class="operator">|</span> <span class="number">6</span>             <span class="operator">|</span> <span class="number">3</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">15</span>  <span class="operator">|</span> <span class="number">216</span>        <span class="operator">|</span> <span class="number">85</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> <span class="number">93</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">3</span>          <span class="operator">|</span> <span class="number">16</span>            <span class="operator">|</span> <span class="number">4</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">10</span>  <span class="operator">|</span> <span class="number">211</span>        <span class="operator">|</span> <span class="number">89</span>        <span class="operator">|</span> <span class="number">93</span>    <span class="operator">|</span> <span class="number">60</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">15</span>         <span class="operator">|</span> <span class="number">1</span>             <span class="operator">|</span> <span class="number">5</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">13</span>  <span class="operator">|</span> <span class="number">214</span>        <span class="operator">|</span> <span class="number">94</span>        <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> <span class="number">66</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">17</span>         <span class="operator">|</span> <span class="number">5</span>             <span class="operator">|</span> <span class="number">6</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">8</span>   <span class="operator">|</span> <span class="number">123</span>        <span class="operator">|</span> <span class="number">70</span>        <span class="operator">|</span> <span class="number">78</span>    <span class="operator">|</span> <span class="number">61</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">7</span>          <span class="operator">|</span> <span class="number">2</span>             <span class="operator">|</span> <span class="number">1</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">9</span>   <span class="operator">|</span> <span class="number">124</span>        <span class="operator">|</span> <span class="number">76</span>        <span class="operator">|</span> <span class="number">70</span>    <span class="operator">|</span> <span class="number">76</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">2</span>          <span class="operator">|</span> <span class="number">9</span>             <span class="operator">|</span> <span class="number">2</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">7</span>   <span class="operator">|</span> <span class="number">122</span>        <span class="operator">|</span> <span class="number">89</span>        <span class="operator">|</span> <span class="number">86</span>    <span class="operator">|</span> <span class="number">85</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">14</span>         <span class="operator">|</span> <span class="number">12</span>            <span class="operator">|</span> <span class="number">3</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">6</span>   <span class="operator">|</span> <span class="number">121</span>        <span class="operator">|</span> <span class="number">96</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> <span class="number">79</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">3</span>          <span class="operator">|</span> <span class="number">11</span>            <span class="operator">|</span> <span class="number">4</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">19</span>  <span class="operator">|</span> <span class="number">224</span>        <span class="operator">|</span> <span class="number">75</span>        <span class="operator">|</span> <span class="number">80</span>    <span class="operator">|</span> <span class="number">78</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">9</span>          <span class="operator">|</span> <span class="number">10</span>            <span class="operator">|</span> <span class="number">1</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">16</span>  <span class="operator">|</span> <span class="number">221</span>        <span class="operator">|</span> <span class="number">77</span>        <span class="operator">|</span> <span class="number">99</span>    <span class="operator">|</span> <span class="number">61</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">20</span>         <span class="operator">|</span> <span class="number">2</span>             <span class="operator">|</span> <span class="number">2</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">18</span>  <span class="operator">|</span> <span class="number">223</span>        <span class="operator">|</span> <span class="number">79</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> <span class="number">96</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">3</span>          <span class="operator">|</span> <span class="number">18</span>            <span class="operator">|</span> <span class="number">3</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">17</span>  <span class="operator">|</span> <span class="number">222</span>        <span class="operator">|</span> <span class="number">80</span>        <span class="operator">|</span> <span class="number">78</span>    <span class="operator">|</span> <span class="number">96</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">7</span>          <span class="operator">|</span> <span class="number">18</span>            <span class="operator">|</span> <span class="number">4</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">20</span>  <span class="operator">|</span> <span class="number">225</span>        <span class="operator">|</span> <span class="number">82</span>        <span class="operator">|</span> <span class="number">85</span>    <span class="operator">|</span> <span class="number">63</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">13</span>         <span class="operator">|</span> <span class="number">4</span>             <span class="operator">|</span> <span class="number">5</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----+------------+-----------+-------+----------+----------+---------------+------------+---------------+----------------------+</span></span><br></pre></td></tr></table></figure></li>
<li>结果解析  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">math_rank: 以match排序 ,student_id：113、216、121、223 math相同，排名都为3，123序号=7</span><br><span class="line">class_language_rank: 以classId,departmentId分组后组内排序</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>dense_rank<ul>
<li>作用：dense_rank() over([partition by col1] [order by col2])与rank类似，当遇到col2相等时，名次同样相等，不同的是，下一个col2值的名次+1，而不是+N。</li>
<li>sql示例  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id,</span><br><span class="line">       studentId,</span><br><span class="line">       <span class="keyword">language</span>,</span><br><span class="line">       math,</span><br><span class="line">       english,</span><br><span class="line">       classId,</span><br><span class="line">       departmentId,</span><br><span class="line">       <span class="built_in">dense_rank</span>() <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> math) <span class="keyword">as</span> math_dense_rank,</span><br><span class="line">       <span class="built_in">dense_rank</span>() <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> english) <span class="keyword">as</span> english_dense_rank,</span><br><span class="line">       <span class="built_in">dense_rank</span>() <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> classId,departmentId <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">language</span> ) <span class="keyword">as</span> class_language_dense_rank</span><br><span class="line"><span class="keyword">from</span> student_scores;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-----+------------+-----------+-------+----------+----------+---------------+------------------+---------------------+----------------------------+</span></span><br><span class="line"><span class="operator">|</span> id  <span class="operator">|</span> studentid  <span class="operator">|</span> <span class="keyword">language</span>  <span class="operator">|</span> math  <span class="operator">|</span> english  <span class="operator">|</span> classid  <span class="operator">|</span> departmentid  <span class="operator">|</span> math_dense_rank  <span class="operator">|</span> english_dense_rank  <span class="operator">|</span> class_language_dense_rank  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----+------------+-----------+-------+----------+----------+---------------+------------------+---------------------+----------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span>   <span class="operator">|</span> <span class="number">111</span>        <span class="operator">|</span> <span class="number">68</span>        <span class="operator">|</span> <span class="number">69</span>    <span class="operator">|</span> <span class="number">90</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">1</span>                <span class="operator">|</span> <span class="number">12</span>                  <span class="operator">|</span> <span class="number">1</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">112</span>        <span class="operator">|</span> <span class="number">73</span>        <span class="operator">|</span> <span class="number">80</span>    <span class="operator">|</span> <span class="number">96</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">5</span>                <span class="operator">|</span> <span class="number">14</span>                  <span class="operator">|</span> <span class="number">2</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">4</span>   <span class="operator">|</span> <span class="number">114</span>        <span class="operator">|</span> <span class="number">89</span>        <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> <span class="number">93</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">11</span>               <span class="operator">|</span> <span class="number">13</span>                  <span class="operator">|</span> <span class="number">3</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">3</span>   <span class="operator">|</span> <span class="number">113</span>        <span class="operator">|</span> <span class="number">90</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> <span class="number">75</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">3</span>                <span class="operator">|</span> <span class="number">6</span>                   <span class="operator">|</span> <span class="number">4</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">5</span>   <span class="operator">|</span> <span class="number">115</span>        <span class="operator">|</span> <span class="number">99</span>        <span class="operator">|</span> <span class="number">93</span>    <span class="operator">|</span> <span class="number">89</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">10</span>               <span class="operator">|</span> <span class="number">11</span>                  <span class="operator">|</span> <span class="number">5</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">12</span>  <span class="operator">|</span> <span class="number">213</span>        <span class="operator">|</span> <span class="number">71</span>        <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> <span class="number">90</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">11</span>               <span class="operator">|</span> <span class="number">12</span>                  <span class="operator">|</span> <span class="number">1</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">11</span>  <span class="operator">|</span> <span class="number">212</span>        <span class="operator">|</span> <span class="number">76</span>        <span class="operator">|</span> <span class="number">83</span>    <span class="operator">|</span> <span class="number">75</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">7</span>                <span class="operator">|</span> <span class="number">6</span>                   <span class="operator">|</span> <span class="number">2</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">14</span>  <span class="operator">|</span> <span class="number">215</span>        <span class="operator">|</span> <span class="number">84</span>        <span class="operator">|</span> <span class="number">82</span>    <span class="operator">|</span> <span class="number">73</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">6</span>                <span class="operator">|</span> <span class="number">5</span>                   <span class="operator">|</span> <span class="number">3</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">15</span>  <span class="operator">|</span> <span class="number">216</span>        <span class="operator">|</span> <span class="number">85</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> <span class="number">93</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">3</span>                <span class="operator">|</span> <span class="number">13</span>                  <span class="operator">|</span> <span class="number">4</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">10</span>  <span class="operator">|</span> <span class="number">211</span>        <span class="operator">|</span> <span class="number">89</span>        <span class="operator">|</span> <span class="number">93</span>    <span class="operator">|</span> <span class="number">60</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">10</span>               <span class="operator">|</span> <span class="number">1</span>                   <span class="operator">|</span> <span class="number">5</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">13</span>  <span class="operator">|</span> <span class="number">214</span>        <span class="operator">|</span> <span class="number">94</span>        <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> <span class="number">66</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">11</span>               <span class="operator">|</span> <span class="number">4</span>                   <span class="operator">|</span> <span class="number">6</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">8</span>   <span class="operator">|</span> <span class="number">123</span>        <span class="operator">|</span> <span class="number">70</span>        <span class="operator">|</span> <span class="number">78</span>    <span class="operator">|</span> <span class="number">61</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">4</span>                <span class="operator">|</span> <span class="number">2</span>                   <span class="operator">|</span> <span class="number">1</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">9</span>   <span class="operator">|</span> <span class="number">124</span>        <span class="operator">|</span> <span class="number">76</span>        <span class="operator">|</span> <span class="number">70</span>    <span class="operator">|</span> <span class="number">76</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">2</span>                <span class="operator">|</span> <span class="number">7</span>                   <span class="operator">|</span> <span class="number">2</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">7</span>   <span class="operator">|</span> <span class="number">122</span>        <span class="operator">|</span> <span class="number">89</span>        <span class="operator">|</span> <span class="number">86</span>    <span class="operator">|</span> <span class="number">85</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">9</span>                <span class="operator">|</span> <span class="number">10</span>                  <span class="operator">|</span> <span class="number">3</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">6</span>   <span class="operator">|</span> <span class="number">121</span>        <span class="operator">|</span> <span class="number">96</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> <span class="number">79</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">3</span>                <span class="operator">|</span> <span class="number">9</span>                   <span class="operator">|</span> <span class="number">4</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">19</span>  <span class="operator">|</span> <span class="number">224</span>        <span class="operator">|</span> <span class="number">75</span>        <span class="operator">|</span> <span class="number">80</span>    <span class="operator">|</span> <span class="number">78</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">5</span>                <span class="operator">|</span> <span class="number">8</span>                   <span class="operator">|</span> <span class="number">1</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">16</span>  <span class="operator">|</span> <span class="number">221</span>        <span class="operator">|</span> <span class="number">77</span>        <span class="operator">|</span> <span class="number">99</span>    <span class="operator">|</span> <span class="number">61</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">12</span>               <span class="operator">|</span> <span class="number">2</span>                   <span class="operator">|</span> <span class="number">2</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">18</span>  <span class="operator">|</span> <span class="number">223</span>        <span class="operator">|</span> <span class="number">79</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> <span class="number">96</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">3</span>                <span class="operator">|</span> <span class="number">14</span>                  <span class="operator">|</span> <span class="number">3</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">17</span>  <span class="operator">|</span> <span class="number">222</span>        <span class="operator">|</span> <span class="number">80</span>        <span class="operator">|</span> <span class="number">78</span>    <span class="operator">|</span> <span class="number">96</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">4</span>                <span class="operator">|</span> <span class="number">14</span>                  <span class="operator">|</span> <span class="number">4</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">20</span>  <span class="operator">|</span> <span class="number">225</span>        <span class="operator">|</span> <span class="number">82</span>        <span class="operator">|</span> <span class="number">85</span>    <span class="operator">|</span> <span class="number">63</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">8</span>                <span class="operator">|</span> <span class="number">3</span>                   <span class="operator">|</span> <span class="number">5</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----+------------+-----------+-------+----------+----------+---------------+------------------+---------------------+----------------------------+</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>ntile<ul>
<li>作用：ntile(N) over([partition by col1] [order by col2])，将分区中的数据按照顺序划分为N片，返回当前片的值。<ul>
<li>注1：如果切片分布不均匀，默认增加第一个切片的分布</li>
<li>注2：ntile不支持ROWS BETWEEN</li>
</ul>
</li>
<li>sql示例  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id,</span><br><span class="line">       studentId,</span><br><span class="line">       <span class="keyword">language</span>,</span><br><span class="line">       math,</span><br><span class="line">       english,</span><br><span class="line">       classId,</span><br><span class="line">       departmentId,</span><br><span class="line">       <span class="built_in">ntile</span>(<span class="number">2</span>) <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> math) <span class="keyword">as</span> math_ntile,</span><br><span class="line">       <span class="built_in">ntile</span>(<span class="number">2</span>) <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> english) <span class="keyword">as</span> english_ntile,</span><br><span class="line">       <span class="built_in">ntile</span>(<span class="number">2</span>) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> classId,departmentId <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">language</span> ) <span class="keyword">as</span> class_language_ntile</span><br><span class="line"><span class="keyword">from</span> student_scores;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-----+------------+-----------+-------+----------+----------+---------------+-------------+----------------+-----------------------+</span></span><br><span class="line"><span class="operator">|</span> id  <span class="operator">|</span> studentid  <span class="operator">|</span> <span class="keyword">language</span>  <span class="operator">|</span> math  <span class="operator">|</span> english  <span class="operator">|</span> classid  <span class="operator">|</span> departmentid  <span class="operator">|</span> math_ntile  <span class="operator">|</span> english_ntile  <span class="operator">|</span> class_language_ntile  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----+------------+-----------+-------+----------+----------+---------------+-------------+----------------+-----------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span>   <span class="operator">|</span> <span class="number">111</span>        <span class="operator">|</span> <span class="number">68</span>        <span class="operator">|</span> <span class="number">69</span>    <span class="operator">|</span> <span class="number">90</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">1</span>           <span class="operator">|</span> <span class="number">2</span>              <span class="operator">|</span> <span class="number">1</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">112</span>        <span class="operator">|</span> <span class="number">73</span>        <span class="operator">|</span> <span class="number">80</span>    <span class="operator">|</span> <span class="number">96</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">1</span>           <span class="operator">|</span> <span class="number">2</span>              <span class="operator">|</span> <span class="number">1</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">4</span>   <span class="operator">|</span> <span class="number">114</span>        <span class="operator">|</span> <span class="number">89</span>        <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> <span class="number">93</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">2</span>           <span class="operator">|</span> <span class="number">2</span>              <span class="operator">|</span> <span class="number">1</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">3</span>   <span class="operator">|</span> <span class="number">113</span>        <span class="operator">|</span> <span class="number">90</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> <span class="number">75</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">1</span>           <span class="operator">|</span> <span class="number">1</span>              <span class="operator">|</span> <span class="number">2</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">5</span>   <span class="operator">|</span> <span class="number">115</span>        <span class="operator">|</span> <span class="number">99</span>        <span class="operator">|</span> <span class="number">93</span>    <span class="operator">|</span> <span class="number">89</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">2</span>           <span class="operator">|</span> <span class="number">2</span>              <span class="operator">|</span> <span class="number">2</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">12</span>  <span class="operator">|</span> <span class="number">213</span>        <span class="operator">|</span> <span class="number">71</span>        <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> <span class="number">90</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">2</span>           <span class="operator">|</span> <span class="number">2</span>              <span class="operator">|</span> <span class="number">1</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">11</span>  <span class="operator">|</span> <span class="number">212</span>        <span class="operator">|</span> <span class="number">76</span>        <span class="operator">|</span> <span class="number">83</span>    <span class="operator">|</span> <span class="number">75</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">2</span>           <span class="operator">|</span> <span class="number">1</span>              <span class="operator">|</span> <span class="number">1</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">14</span>  <span class="operator">|</span> <span class="number">215</span>        <span class="operator">|</span> <span class="number">84</span>        <span class="operator">|</span> <span class="number">82</span>    <span class="operator">|</span> <span class="number">73</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">2</span>           <span class="operator">|</span> <span class="number">1</span>              <span class="operator">|</span> <span class="number">1</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">15</span>  <span class="operator">|</span> <span class="number">216</span>        <span class="operator">|</span> <span class="number">85</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> <span class="number">93</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">1</span>           <span class="operator">|</span> <span class="number">2</span>              <span class="operator">|</span> <span class="number">2</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">10</span>  <span class="operator">|</span> <span class="number">211</span>        <span class="operator">|</span> <span class="number">89</span>        <span class="operator">|</span> <span class="number">93</span>    <span class="operator">|</span> <span class="number">60</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">2</span>           <span class="operator">|</span> <span class="number">1</span>              <span class="operator">|</span> <span class="number">2</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">13</span>  <span class="operator">|</span> <span class="number">214</span>        <span class="operator">|</span> <span class="number">94</span>        <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> <span class="number">66</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">2</span>           <span class="operator">|</span> <span class="number">1</span>              <span class="operator">|</span> <span class="number">2</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">8</span>   <span class="operator">|</span> <span class="number">123</span>        <span class="operator">|</span> <span class="number">70</span>        <span class="operator">|</span> <span class="number">78</span>    <span class="operator">|</span> <span class="number">61</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">1</span>           <span class="operator">|</span> <span class="number">1</span>              <span class="operator">|</span> <span class="number">1</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">9</span>   <span class="operator">|</span> <span class="number">124</span>        <span class="operator">|</span> <span class="number">76</span>        <span class="operator">|</span> <span class="number">70</span>    <span class="operator">|</span> <span class="number">76</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">1</span>           <span class="operator">|</span> <span class="number">1</span>              <span class="operator">|</span> <span class="number">1</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">7</span>   <span class="operator">|</span> <span class="number">122</span>        <span class="operator">|</span> <span class="number">89</span>        <span class="operator">|</span> <span class="number">86</span>    <span class="operator">|</span> <span class="number">85</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">2</span>           <span class="operator">|</span> <span class="number">2</span>              <span class="operator">|</span> <span class="number">2</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">6</span>   <span class="operator">|</span> <span class="number">121</span>        <span class="operator">|</span> <span class="number">96</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> <span class="number">79</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">1</span>           <span class="operator">|</span> <span class="number">2</span>              <span class="operator">|</span> <span class="number">2</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">19</span>  <span class="operator">|</span> <span class="number">224</span>        <span class="operator">|</span> <span class="number">75</span>        <span class="operator">|</span> <span class="number">80</span>    <span class="operator">|</span> <span class="number">78</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">1</span>           <span class="operator">|</span> <span class="number">1</span>              <span class="operator">|</span> <span class="number">1</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">16</span>  <span class="operator">|</span> <span class="number">221</span>        <span class="operator">|</span> <span class="number">77</span>        <span class="operator">|</span> <span class="number">99</span>    <span class="operator">|</span> <span class="number">61</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">2</span>           <span class="operator">|</span> <span class="number">1</span>              <span class="operator">|</span> <span class="number">1</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">18</span>  <span class="operator">|</span> <span class="number">223</span>        <span class="operator">|</span> <span class="number">79</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> <span class="number">96</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">1</span>           <span class="operator">|</span> <span class="number">2</span>              <span class="operator">|</span> <span class="number">1</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">17</span>  <span class="operator">|</span> <span class="number">222</span>        <span class="operator">|</span> <span class="number">80</span>        <span class="operator">|</span> <span class="number">78</span>    <span class="operator">|</span> <span class="number">96</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">1</span>           <span class="operator">|</span> <span class="number">2</span>              <span class="operator">|</span> <span class="number">2</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">20</span>  <span class="operator">|</span> <span class="number">225</span>        <span class="operator">|</span> <span class="number">82</span>        <span class="operator">|</span> <span class="number">85</span>    <span class="operator">|</span> <span class="number">63</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">2</span>           <span class="operator">|</span> <span class="number">1</span>              <span class="operator">|</span> <span class="number">2</span>                     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----+------------+-----------+-------+----------+----------+---------------+-------------+----------------+-----------------------+</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>percent_rank<ul>
<li>作用：percent_rank() over([partition by col1] [order by col2])，计算给定行的百分比排名。分组内当前行的RANK值-1/分组内总行数-1，可以用来计算超过了百分之多少的人。</li>
<li>sql示例  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> id,</span><br><span class="line">       studentid,</span><br><span class="line">       <span class="keyword">language</span>,</span><br><span class="line">       math,</span><br><span class="line">       english,</span><br><span class="line">       classid,</span><br><span class="line">       departmentid,</span><br><span class="line">       <span class="built_in">percent_rank</span>() <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> math)                                        <span class="keyword">as</span> math_percent_rank,</span><br><span class="line">       <span class="built_in">percent_rank</span>() <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> english)                                     <span class="keyword">as</span> english_percent_rank,</span><br><span class="line">       <span class="built_in">percent_rank</span>() <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> classId,departmentId <span class="keyword">order</span> <span class="keyword">by</span> <span class="keyword">language</span> ) <span class="keyword">as</span> class_language_percent_rank</span><br><span class="line"><span class="keyword">from</span> student_scores;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-----+------------+-----------+-------+----------+----------+---------------+----------------------+-----------------------+------------------------------+</span></span><br><span class="line"><span class="operator">|</span> id  <span class="operator">|</span> studentid  <span class="operator">|</span> <span class="keyword">language</span>  <span class="operator">|</span> math  <span class="operator">|</span> english  <span class="operator">|</span> classid  <span class="operator">|</span> departmentid  <span class="operator">|</span>  math_percent_rank   <span class="operator">|</span> english_percent_rank  <span class="operator">|</span> class_language_percent_rank  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----+------------+-----------+-------+----------+----------+---------------+----------------------+-----------------------+------------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span>   <span class="operator">|</span> <span class="number">111</span>        <span class="operator">|</span> <span class="number">68</span>        <span class="operator">|</span> <span class="number">69</span>    <span class="operator">|</span> <span class="number">90</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">0.0</span>                  <span class="operator">|</span> <span class="number">0.6842105263157895</span>    <span class="operator">|</span> <span class="number">0.0</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">112</span>        <span class="operator">|</span> <span class="number">73</span>        <span class="operator">|</span> <span class="number">80</span>    <span class="operator">|</span> <span class="number">96</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">0.42105263157894735</span>  <span class="operator">|</span> <span class="number">0.8947368421052632</span>    <span class="operator">|</span> <span class="number">0.25</span>                         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">4</span>   <span class="operator">|</span> <span class="number">114</span>        <span class="operator">|</span> <span class="number">89</span>        <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> <span class="number">93</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">0.8421052631578947</span>   <span class="operator">|</span> <span class="number">0.7894736842105263</span>    <span class="operator">|</span> <span class="number">0.5</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">3</span>   <span class="operator">|</span> <span class="number">113</span>        <span class="operator">|</span> <span class="number">90</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> <span class="number">75</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">0.10526315789473684</span>  <span class="operator">|</span> <span class="number">0.3157894736842105</span>    <span class="operator">|</span> <span class="number">0.75</span>                         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">5</span>   <span class="operator">|</span> <span class="number">115</span>        <span class="operator">|</span> <span class="number">99</span>        <span class="operator">|</span> <span class="number">93</span>    <span class="operator">|</span> <span class="number">89</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">0.7368421052631579</span>   <span class="operator">|</span> <span class="number">0.631578947368421</span>     <span class="operator">|</span> <span class="number">1.0</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">12</span>  <span class="operator">|</span> <span class="number">213</span>        <span class="operator">|</span> <span class="number">71</span>        <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> <span class="number">90</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">0.8421052631578947</span>   <span class="operator">|</span> <span class="number">0.6842105263157895</span>    <span class="operator">|</span> <span class="number">0.0</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">11</span>  <span class="operator">|</span> <span class="number">212</span>        <span class="operator">|</span> <span class="number">76</span>        <span class="operator">|</span> <span class="number">83</span>    <span class="operator">|</span> <span class="number">75</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">0.5789473684210527</span>   <span class="operator">|</span> <span class="number">0.3157894736842105</span>    <span class="operator">|</span> <span class="number">0.2</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">14</span>  <span class="operator">|</span> <span class="number">215</span>        <span class="operator">|</span> <span class="number">84</span>        <span class="operator">|</span> <span class="number">82</span>    <span class="operator">|</span> <span class="number">73</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">0.5263157894736842</span>   <span class="operator">|</span> <span class="number">0.2631578947368421</span>    <span class="operator">|</span> <span class="number">0.4</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">15</span>  <span class="operator">|</span> <span class="number">216</span>        <span class="operator">|</span> <span class="number">85</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> <span class="number">93</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">0.10526315789473684</span>  <span class="operator">|</span> <span class="number">0.7894736842105263</span>    <span class="operator">|</span> <span class="number">0.6</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">10</span>  <span class="operator">|</span> <span class="number">211</span>        <span class="operator">|</span> <span class="number">89</span>        <span class="operator">|</span> <span class="number">93</span>    <span class="operator">|</span> <span class="number">60</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">0.7368421052631579</span>   <span class="operator">|</span> <span class="number">0.0</span>                   <span class="operator">|</span> <span class="number">0.8</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">13</span>  <span class="operator">|</span> <span class="number">214</span>        <span class="operator">|</span> <span class="number">94</span>        <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> <span class="number">66</span>       <span class="operator">|</span> class1   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">0.8421052631578947</span>   <span class="operator">|</span> <span class="number">0.21052631578947367</span>   <span class="operator">|</span> <span class="number">1.0</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">8</span>   <span class="operator">|</span> <span class="number">123</span>        <span class="operator">|</span> <span class="number">70</span>        <span class="operator">|</span> <span class="number">78</span>    <span class="operator">|</span> <span class="number">61</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">0.3157894736842105</span>   <span class="operator">|</span> <span class="number">0.05263157894736842</span>   <span class="operator">|</span> <span class="number">0.0</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">9</span>   <span class="operator">|</span> <span class="number">124</span>        <span class="operator">|</span> <span class="number">76</span>        <span class="operator">|</span> <span class="number">70</span>    <span class="operator">|</span> <span class="number">76</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">0.05263157894736842</span>  <span class="operator">|</span> <span class="number">0.42105263157894735</span>   <span class="operator">|</span> <span class="number">0.3333333333333333</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">7</span>   <span class="operator">|</span> <span class="number">122</span>        <span class="operator">|</span> <span class="number">89</span>        <span class="operator">|</span> <span class="number">86</span>    <span class="operator">|</span> <span class="number">85</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">0.6842105263157895</span>   <span class="operator">|</span> <span class="number">0.5789473684210527</span>    <span class="operator">|</span> <span class="number">0.6666666666666666</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">6</span>   <span class="operator">|</span> <span class="number">121</span>        <span class="operator">|</span> <span class="number">96</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> <span class="number">79</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department1   <span class="operator">|</span> <span class="number">0.10526315789473684</span>  <span class="operator">|</span> <span class="number">0.5263157894736842</span>    <span class="operator">|</span> <span class="number">1.0</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">19</span>  <span class="operator">|</span> <span class="number">224</span>        <span class="operator">|</span> <span class="number">75</span>        <span class="operator">|</span> <span class="number">80</span>    <span class="operator">|</span> <span class="number">78</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">0.42105263157894735</span>  <span class="operator">|</span> <span class="number">0.47368421052631576</span>   <span class="operator">|</span> <span class="number">0.0</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">16</span>  <span class="operator">|</span> <span class="number">221</span>        <span class="operator">|</span> <span class="number">77</span>        <span class="operator">|</span> <span class="number">99</span>    <span class="operator">|</span> <span class="number">61</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">1.0</span>                  <span class="operator">|</span> <span class="number">0.05263157894736842</span>   <span class="operator">|</span> <span class="number">0.25</span>                         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">18</span>  <span class="operator">|</span> <span class="number">223</span>        <span class="operator">|</span> <span class="number">79</span>        <span class="operator">|</span> <span class="number">74</span>    <span class="operator">|</span> <span class="number">96</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">0.10526315789473684</span>  <span class="operator">|</span> <span class="number">0.8947368421052632</span>    <span class="operator">|</span> <span class="number">0.5</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">17</span>  <span class="operator">|</span> <span class="number">222</span>        <span class="operator">|</span> <span class="number">80</span>        <span class="operator">|</span> <span class="number">78</span>    <span class="operator">|</span> <span class="number">96</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">0.3157894736842105</span>   <span class="operator">|</span> <span class="number">0.8947368421052632</span>    <span class="operator">|</span> <span class="number">0.75</span>                         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">20</span>  <span class="operator">|</span> <span class="number">225</span>        <span class="operator">|</span> <span class="number">82</span>        <span class="operator">|</span> <span class="number">85</span>    <span class="operator">|</span> <span class="number">63</span>       <span class="operator">|</span> class2   <span class="operator">|</span> department2   <span class="operator">|</span> <span class="number">0.631578947368421</span>    <span class="operator">|</span> <span class="number">0.15789473684210525</span>   <span class="operator">|</span> <span class="number">1.0</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----+------------+-----------+-------+----------+----------+---------------+----------------------+-----------------------+------------------------------+</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h4 id="8-2-5-4-多维度分析"><a href="#8-2-5-4-多维度分析" class="headerlink" title="8.2.5.4 多维度分析"></a>8.2.5.4 多维度分析</h4><ol>
<li>GROUPING SETS<ul>
<li>作用：在一个GROUP BY查询中，根据不同的维度组合进行聚合，等价于将不同维度的GROUP BY结果集进行UNION ALL</li>
<li>示例  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">month</span>,</span><br><span class="line">       <span class="keyword">day</span>,</span><br><span class="line">       <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv</span><br><span class="line"><span class="keyword">FROM</span> visit_log</span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">month</span>, <span class="keyword">day</span></span><br><span class="line">    <span class="keyword">GROUPING</span> SETS ( <span class="keyword">month</span>, <span class="keyword">day</span>);</span><br><span class="line">    </span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-------------+-----+</span></span><br><span class="line"><span class="operator">|</span>  <span class="keyword">month</span>   <span class="operator">|</span>     <span class="keyword">day</span>     <span class="operator">|</span> uv  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-------------+-----+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span><span class="number">-10</span>  <span class="operator">|</span> <span class="number">4</span>   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span><span class="number">-12</span>  <span class="operator">|</span> <span class="number">1</span>   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-12</span>  <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-13</span>  <span class="operator">|</span> <span class="number">3</span>   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-15</span>  <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-16</span>  <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span>  <span class="operator">|</span> <span class="keyword">NULL</span>        <span class="operator">|</span> <span class="number">5</span>   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span>  <span class="operator">|</span> <span class="keyword">NULL</span>        <span class="operator">|</span> <span class="number">6</span>   <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-------------+-----+</span></span><br></pre></td></tr></table></figure></li>
<li>分析  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 等价于</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">month</span>,<span class="keyword">NULL</span> <span class="keyword">as</span> <span class="keyword">day</span>,<span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv <span class="keyword">FROM</span> test2 <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">month</span> </span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span> </span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">NULL</span> <span class="keyword">as</span> <span class="keyword">month</span>,<span class="keyword">day</span>,<span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv <span class="keyword">FROM</span> test2 <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">day</span>;</span><br></pre></td></tr></table></figure></li>
<li>升级版 GROUPING__ID，表示结果属于哪一个分组集合。（<font color ='red' >GROUPING__ID</font>两个下划线__）  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    <span class="keyword">month</span>,</span><br><span class="line">    <span class="keyword">day</span>,</span><br><span class="line">    <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,</span><br><span class="line">    GROUPING__ID</span><br><span class="line"><span class="keyword">FROM</span> visit_log</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">month</span>,<span class="keyword">day</span></span><br><span class="line">    <span class="keyword">GROUPING</span> SETS (<span class="keyword">month</span>,<span class="keyword">day</span>,(<span class="keyword">month</span>,<span class="keyword">day</span>))</span><br><span class="line">    <span class="keyword">ORDER</span> <span class="keyword">BY</span> GROUPING__ID;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-------------+-----+---------------+</span></span><br><span class="line"><span class="operator">|</span>  <span class="keyword">month</span>   <span class="operator">|</span>     <span class="keyword">day</span>     <span class="operator">|</span> uv  <span class="operator">|</span> grouping__id  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-------------+-----+---------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span><span class="number">-10</span>  <span class="operator">|</span> <span class="number">4</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-16</span>  <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-13</span>  <span class="operator">|</span> <span class="number">3</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-12</span>  <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-15</span>  <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span><span class="number">-12</span>  <span class="operator">|</span> <span class="number">1</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span>  <span class="operator">|</span> <span class="keyword">NULL</span>        <span class="operator">|</span> <span class="number">5</span>   <span class="operator">|</span> <span class="number">1</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span>  <span class="operator">|</span> <span class="keyword">NULL</span>        <span class="operator">|</span> <span class="number">6</span>   <span class="operator">|</span> <span class="number">1</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-16</span>  <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">2</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-15</span>  <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">2</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-13</span>  <span class="operator">|</span> <span class="number">3</span>   <span class="operator">|</span> <span class="number">2</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-12</span>  <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">2</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span><span class="number">-12</span>  <span class="operator">|</span> <span class="number">1</span>   <span class="operator">|</span> <span class="number">2</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span><span class="number">-10</span>  <span class="operator">|</span> <span class="number">4</span>   <span class="operator">|</span> <span class="number">2</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-------------+-----+---------------+</span></span><br></pre></td></tr></table></figure></li>
<li>分析  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 等价</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">month</span>,<span class="keyword">NULL</span> <span class="keyword">as</span> <span class="keyword">day</span>,<span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,<span class="number">1</span> <span class="keyword">AS</span> GROUPING__ID <span class="keyword">FROM</span> test2 <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">month</span> </span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span> </span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">NULL</span> <span class="keyword">as</span> <span class="keyword">month</span>,<span class="keyword">day</span>,<span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,<span class="number">2</span> <span class="keyword">AS</span> GROUPING__ID <span class="keyword">FROM</span> test2 <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">day</span></span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span> </span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">month</span>,<span class="keyword">day</span>,<span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,<span class="number">3</span> <span class="keyword">AS</span> GROUPING__ID <span class="keyword">FROM</span> test2 <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">month</span>,<span class="keyword">day</span>;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>CUBE<ul>
<li>作用：根据GROUP BY的维度的所有组合进行聚合。</li>
<li>示例  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    <span class="keyword">month</span>,</span><br><span class="line">    <span class="keyword">day</span>,</span><br><span class="line">    <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,</span><br><span class="line">    GROUPING__ID</span><br><span class="line"><span class="keyword">FROM</span> visit_log</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">month</span>,<span class="keyword">day</span></span><br><span class="line">    <span class="keyword">WITH</span> <span class="keyword">CUBE</span></span><br><span class="line">    <span class="keyword">ORDER</span> <span class="keyword">BY</span> GROUPING__ID;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-------------+-----+---------------+</span></span><br><span class="line"><span class="operator">|</span>  <span class="keyword">month</span>   <span class="operator">|</span>     <span class="keyword">day</span>     <span class="operator">|</span> uv  <span class="operator">|</span> grouping__id  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-------------+-----+---------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span><span class="number">-10</span>  <span class="operator">|</span> <span class="number">4</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-16</span>  <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-13</span>  <span class="operator">|</span> <span class="number">3</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-12</span>  <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-15</span>  <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span><span class="number">-12</span>  <span class="operator">|</span> <span class="number">1</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span>  <span class="operator">|</span> <span class="keyword">NULL</span>        <span class="operator">|</span> <span class="number">5</span>   <span class="operator">|</span> <span class="number">1</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span>  <span class="operator">|</span> <span class="keyword">NULL</span>        <span class="operator">|</span> <span class="number">6</span>   <span class="operator">|</span> <span class="number">1</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-16</span>  <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">2</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-15</span>  <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">2</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-13</span>  <span class="operator">|</span> <span class="number">3</span>   <span class="operator">|</span> <span class="number">2</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-12</span>  <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">2</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span><span class="number">-12</span>  <span class="operator">|</span> <span class="number">1</span>   <span class="operator">|</span> <span class="number">2</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span><span class="number">-10</span>  <span class="operator">|</span> <span class="number">4</span>   <span class="operator">|</span> <span class="number">2</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="keyword">NULL</span>        <span class="operator">|</span> <span class="number">7</span>   <span class="operator">|</span> <span class="number">3</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-------------+-----+---------------+</span></span><br></pre></td></tr></table></figure></li>
<li>解析  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">等价于</span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">NULL</span> <span class="keyword">as</span> <span class="keyword">month</span>,<span class="keyword">NULL</span> <span class="keyword">as</span> <span class="keyword">day</span>,<span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,<span class="number">0</span> <span class="keyword">AS</span> GROUPING__ID <span class="keyword">FROM</span> test2</span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span> </span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">month</span>,<span class="keyword">NULL</span> <span class="keyword">as</span> <span class="keyword">day</span>,<span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,<span class="number">1</span> <span class="keyword">AS</span> GROUPING__ID <span class="keyword">FROM</span> test2 <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">month</span> </span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span> </span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">NULL</span> <span class="keyword">as</span> <span class="keyword">month</span>,<span class="keyword">day</span>,<span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,<span class="number">2</span> <span class="keyword">AS</span> GROUPING__ID <span class="keyword">FROM</span> test2 <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">day</span></span><br><span class="line"><span class="keyword">UNION</span> <span class="keyword">ALL</span> </span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">month</span>,<span class="keyword">day</span>,<span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,<span class="number">3</span> <span class="keyword">AS</span> GROUPING__ID <span class="keyword">FROM</span> test2 <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">month</span>,<span class="keyword">day</span>;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>ROLLUP<ul>
<li>作用：是CUBE的子集，以最左侧的维度为主，从该维度进行层级聚合。</li>
<li>比如，以month维度进行层级聚合：实现的上钻过程：月天的UV-&gt;月的UV-&gt;总UV  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    <span class="keyword">month</span>,</span><br><span class="line">    <span class="keyword">day</span>,</span><br><span class="line">    <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,</span><br><span class="line">    GROUPING__ID</span><br><span class="line"><span class="keyword">FROM</span> visit_log</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">month</span>,<span class="keyword">day</span></span><br><span class="line">    <span class="keyword">WITH</span> <span class="keyword">ROLLUP</span></span><br><span class="line">    <span class="keyword">ORDER</span> <span class="keyword">BY</span> GROUPING__ID;</span><br><span class="line">    </span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-------------+-----+---------------+</span></span><br><span class="line"><span class="operator">|</span>  <span class="keyword">month</span>   <span class="operator">|</span>     <span class="keyword">day</span>     <span class="operator">|</span> uv  <span class="operator">|</span> grouping__id  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-------------+-----+---------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-16</span>  <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-15</span>  <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-13</span>  <span class="operator">|</span> <span class="number">3</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-12</span>  <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span><span class="number">-12</span>  <span class="operator">|</span> <span class="number">1</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span><span class="number">-10</span>  <span class="operator">|</span> <span class="number">4</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span>  <span class="operator">|</span> <span class="keyword">NULL</span>        <span class="operator">|</span> <span class="number">6</span>   <span class="operator">|</span> <span class="number">1</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span>  <span class="operator">|</span> <span class="keyword">NULL</span>        <span class="operator">|</span> <span class="number">5</span>   <span class="operator">|</span> <span class="number">1</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="keyword">NULL</span>        <span class="operator">|</span> <span class="number">7</span>   <span class="operator">|</span> <span class="number">3</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+-------------+-----+---------------+</span></span><br></pre></td></tr></table></figure></li>
<li>如果把month和day调换顺序，则以day维度进行层级聚合：实现的上钻过程：天月的UV-&gt;天的UV-&gt;总UV  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span></span><br><span class="line">    <span class="keyword">day</span>,</span><br><span class="line">    <span class="keyword">month</span>,</span><br><span class="line">    <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> cookieid) <span class="keyword">AS</span> uv,</span><br><span class="line">    GROUPING__ID</span><br><span class="line"><span class="keyword">FROM</span> visit_log</span><br><span class="line">    <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">day</span>,<span class="keyword">month</span></span><br><span class="line">    <span class="keyword">WITH</span> <span class="keyword">ROLLUP</span></span><br><span class="line">    <span class="keyword">ORDER</span> <span class="keyword">BY</span> GROUPING__ID;</span><br><span class="line">    </span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+----------+-----+---------------+</span></span><br><span class="line"><span class="operator">|</span>     <span class="keyword">day</span>     <span class="operator">|</span>  <span class="keyword">month</span>   <span class="operator">|</span> uv  <span class="operator">|</span> grouping__id  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+----------+-----+---------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-16</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-15</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-13</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">3</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-12</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span><span class="number">-12</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span>  <span class="operator">|</span> <span class="number">1</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span><span class="number">-10</span>  <span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span>  <span class="operator">|</span> <span class="number">4</span>   <span class="operator">|</span> <span class="number">0</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-12</span>  <span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">1</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-16</span>  <span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">1</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span><span class="number">-10</span>  <span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">4</span>   <span class="operator">|</span> <span class="number">1</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-15</span>  <span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">2</span>   <span class="operator">|</span> <span class="number">1</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-03</span><span class="number">-12</span>  <span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">1</span>   <span class="operator">|</span> <span class="number">1</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">2015</span><span class="number">-04</span><span class="number">-13</span>  <span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">3</span>   <span class="operator">|</span> <span class="number">1</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">NULL</span>        <span class="operator">|</span> <span class="keyword">NULL</span>     <span class="operator">|</span> <span class="number">7</span>   <span class="operator">|</span> <span class="number">3</span>             <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------------+----------+-----+---------------+</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h4 id="8-2-5-5-开窗函数练习"><a href="#8-2-5-5-开窗函数练习" class="headerlink" title="8.2.5.5 开窗函数练习"></a>8.2.5.5 开窗函数练习</h4><h5 id="8-2-5-5-1-聚合开窗练习"><a href="#8-2-5-5-1-聚合开窗练习" class="headerlink" title="8.2.5.5.1 聚合开窗练习"></a>8.2.5.5.1 聚合开窗练习</h5><ol>
<li>建表导入数据 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> business <span class="keyword">as</span> </span><br><span class="line"><span class="keyword">select</span> stack(<span class="number">14</span>,</span><br><span class="line">    <span class="string">&#x27;jack&#x27;</span>,<span class="string">&#x27;2017-01-01&#x27;</span>,<span class="string">&#x27;10&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;tony&#x27;</span>,<span class="string">&#x27;2017-01-02&#x27;</span>,<span class="string">&#x27;15&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;jack&#x27;</span>,<span class="string">&#x27;2017-02-03&#x27;</span>,<span class="string">&#x27;23&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;tony&#x27;</span>,<span class="string">&#x27;2017-01-04&#x27;</span>,<span class="string">&#x27;29&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;jack&#x27;</span>,<span class="string">&#x27;2017-01-05&#x27;</span>,<span class="string">&#x27;46&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;jack&#x27;</span>,<span class="string">&#x27;2017-04-06&#x27;</span>,<span class="string">&#x27;42&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;tony&#x27;</span>,<span class="string">&#x27;2017-01-07&#x27;</span>,<span class="string">&#x27;50&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;jack&#x27;</span>,<span class="string">&#x27;2017-01-08&#x27;</span>,<span class="string">&#x27;55&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;mart&#x27;</span>,<span class="string">&#x27;2017-04-08&#x27;</span>,<span class="string">&#x27;62&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;mart&#x27;</span>,<span class="string">&#x27;2017-04-09&#x27;</span>,<span class="string">&#x27;68&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;neil&#x27;</span>,<span class="string">&#x27;2017-05-10&#x27;</span>,<span class="string">&#x27;12&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;mart&#x27;</span>,<span class="string">&#x27;2017-04-11&#x27;</span>,<span class="string">&#x27;75&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;neil&#x27;</span>,<span class="string">&#x27;2017-06-12&#x27;</span>,<span class="string">&#x27;80&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;mart&#x27;</span>,<span class="string">&#x27;2017-04-13&#x27;</span>,<span class="string">&#x27;94&#x27;</span>)</span><br><span class="line"><span class="keyword">as</span> (name, orderdate, cost)</span><br></pre></td></tr></table></figure></li>
<li>需求一： 查询在2017年4月份购买过的顾客及总人数 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">       name,</span><br><span class="line">       <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">over</span> ()</span><br><span class="line"><span class="keyword">from</span> business</span><br><span class="line"><span class="keyword">where</span> substr(orderdate, <span class="number">0</span>, <span class="number">7</span>) <span class="operator">=</span> <span class="string">&#x27;2017-04&#x27;</span></span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> name;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+-----------------+</span></span><br><span class="line"><span class="operator">|</span> name  <span class="operator">|</span> count_window_0  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+-----------------+</span></span><br><span class="line"><span class="operator">|</span> mart  <span class="operator">|</span> <span class="number">2</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> jack  <span class="operator">|</span> <span class="number">2</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+-----------------+</span></span><br></pre></td></tr></table></figure></li>
<li>需求二：查询顾客的购买明细及月购买总额 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">       name,</span><br><span class="line">       cost,</span><br><span class="line">       orderdate,</span><br><span class="line">       substr(orderdate, <span class="number">0</span>, <span class="number">7</span>),</span><br><span class="line">       <span class="built_in">sum</span>(cost) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> substr(orderdate, <span class="number">0</span>, <span class="number">7</span>))</span><br><span class="line"><span class="keyword">from</span> business;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+-------+-------------+----------+---------------+</span></span><br><span class="line"><span class="operator">|</span> name  <span class="operator">|</span> cost  <span class="operator">|</span>  orderdate  <span class="operator">|</span>   _c3    <span class="operator">|</span> sum_window_0  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+-------+-------------+----------+---------------+</span></span><br><span class="line"><span class="operator">|</span> jack  <span class="operator">|</span> <span class="number">10</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-01</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span>  <span class="operator">|</span> <span class="number">205.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> jack  <span class="operator">|</span> <span class="number">55</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-08</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span>  <span class="operator">|</span> <span class="number">205.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> tony  <span class="operator">|</span> <span class="number">50</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-07</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span>  <span class="operator">|</span> <span class="number">205.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> jack  <span class="operator">|</span> <span class="number">46</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-05</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span>  <span class="operator">|</span> <span class="number">205.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> tony  <span class="operator">|</span> <span class="number">29</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span>  <span class="operator">|</span> <span class="number">205.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> tony  <span class="operator">|</span> <span class="number">15</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-02</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span>  <span class="operator">|</span> <span class="number">205.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> jack  <span class="operator">|</span> <span class="number">23</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-02</span><span class="number">-03</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-02</span>  <span class="operator">|</span> <span class="number">23.0</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> mart  <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-13</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">341.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> jack  <span class="operator">|</span> <span class="number">42</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-06</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">341.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> mart  <span class="operator">|</span> <span class="number">75</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-11</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">341.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> mart  <span class="operator">|</span> <span class="number">68</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-09</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">341.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> mart  <span class="operator">|</span> <span class="number">62</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-08</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">341.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> neil  <span class="operator">|</span> <span class="number">12</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-05</span><span class="number">-10</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-05</span>  <span class="operator">|</span> <span class="number">12.0</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> neil  <span class="operator">|</span> <span class="number">80</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-06</span><span class="number">-12</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-06</span>  <span class="operator">|</span> <span class="number">80.0</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+-------+-------------+----------+---------------+</span></span><br></pre></td></tr></table></figure></li>
<li>需求三：查询每个顾客的购买明细及月购买总额 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">       name,</span><br><span class="line">       cost,</span><br><span class="line">       orderdate,</span><br><span class="line">       substr(orderdate, <span class="number">0</span>, <span class="number">7</span>),</span><br><span class="line">       <span class="built_in">sum</span>(cost) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> substr(orderdate, <span class="number">0</span>, <span class="number">7</span>),name)</span><br><span class="line"><span class="keyword">from</span> business;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+-------+-------------+----------+---------------+</span></span><br><span class="line"><span class="operator">|</span> name  <span class="operator">|</span> cost  <span class="operator">|</span>  orderdate  <span class="operator">|</span>   _c3    <span class="operator">|</span> sum_window_0  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+-------+-------------+----------+---------------+</span></span><br><span class="line"><span class="operator">|</span> jack  <span class="operator">|</span> <span class="number">55</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-08</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span>  <span class="operator">|</span> <span class="number">111.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> jack  <span class="operator">|</span> <span class="number">46</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-05</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span>  <span class="operator">|</span> <span class="number">111.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> jack  <span class="operator">|</span> <span class="number">10</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-01</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span>  <span class="operator">|</span> <span class="number">111.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> tony  <span class="operator">|</span> <span class="number">50</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-07</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span>  <span class="operator">|</span> <span class="number">94.0</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> tony  <span class="operator">|</span> <span class="number">29</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span>  <span class="operator">|</span> <span class="number">94.0</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> tony  <span class="operator">|</span> <span class="number">15</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-02</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span>  <span class="operator">|</span> <span class="number">94.0</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> jack  <span class="operator">|</span> <span class="number">23</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-02</span><span class="number">-03</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-02</span>  <span class="operator">|</span> <span class="number">23.0</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> jack  <span class="operator">|</span> <span class="number">42</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-06</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">42.0</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> mart  <span class="operator">|</span> <span class="number">75</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-11</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">299.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> mart  <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-13</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">299.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> mart  <span class="operator">|</span> <span class="number">68</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-09</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">299.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> mart  <span class="operator">|</span> <span class="number">62</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-08</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">299.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> neil  <span class="operator">|</span> <span class="number">12</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-05</span><span class="number">-10</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-05</span>  <span class="operator">|</span> <span class="number">12.0</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> neil  <span class="operator">|</span> <span class="number">80</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-06</span><span class="number">-12</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-06</span>  <span class="operator">|</span> <span class="number">80.0</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+-------+-------------+----------+---------------+</span></span><br></pre></td></tr></table></figure></li>
<li>需求四：查询每个顾客的购买明细及月购买总额, 将每个顾客的cost按照日期进行累加 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">       name,</span><br><span class="line">       cost,</span><br><span class="line">       orderdate,</span><br><span class="line">       substr(orderdate, <span class="number">0</span>, <span class="number">7</span>),</span><br><span class="line">       <span class="built_in">sum</span>(cost) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> name <span class="keyword">order</span> <span class="keyword">by</span> orderdate),</span><br><span class="line">       <span class="built_in">sum</span>(cost) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> substr(orderdate, <span class="number">0</span>, <span class="number">7</span>),name)</span><br><span class="line"><span class="keyword">from</span> business</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> name,orderdate;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+-------+-------------+----------+--------+---------------+</span></span><br><span class="line"><span class="operator">|</span> name  <span class="operator">|</span> cost  <span class="operator">|</span>  orderdate  <span class="operator">|</span>   _c3    <span class="operator">|</span>  _c4   <span class="operator">|</span> sum_window_1  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+-------+-------------+----------+--------+---------------+</span></span><br><span class="line"><span class="operator">|</span> jack  <span class="operator">|</span> <span class="number">10</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-01</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span>  <span class="operator">|</span> <span class="number">10.0</span>   <span class="operator">|</span> <span class="number">111.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> jack  <span class="operator">|</span> <span class="number">46</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-05</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span>  <span class="operator">|</span> <span class="number">56.0</span>   <span class="operator">|</span> <span class="number">111.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> jack  <span class="operator">|</span> <span class="number">55</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-08</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span>  <span class="operator">|</span> <span class="number">111.0</span>  <span class="operator">|</span> <span class="number">111.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> jack  <span class="operator">|</span> <span class="number">23</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-02</span><span class="number">-03</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-02</span>  <span class="operator">|</span> <span class="number">134.0</span>  <span class="operator">|</span> <span class="number">23.0</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> jack  <span class="operator">|</span> <span class="number">42</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-06</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">176.0</span>  <span class="operator">|</span> <span class="number">42.0</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> mart  <span class="operator">|</span> <span class="number">62</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-08</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">62.0</span>   <span class="operator">|</span> <span class="number">299.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> mart  <span class="operator">|</span> <span class="number">68</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-09</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">130.0</span>  <span class="operator">|</span> <span class="number">299.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> mart  <span class="operator">|</span> <span class="number">75</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-11</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">205.0</span>  <span class="operator">|</span> <span class="number">299.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> mart  <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-13</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">299.0</span>  <span class="operator">|</span> <span class="number">299.0</span>         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> neil  <span class="operator">|</span> <span class="number">12</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-05</span><span class="number">-10</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-05</span>  <span class="operator">|</span> <span class="number">12.0</span>   <span class="operator">|</span> <span class="number">12.0</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> neil  <span class="operator">|</span> <span class="number">80</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-06</span><span class="number">-12</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-06</span>  <span class="operator">|</span> <span class="number">92.0</span>   <span class="operator">|</span> <span class="number">80.0</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> tony  <span class="operator">|</span> <span class="number">15</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-02</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span>  <span class="operator">|</span> <span class="number">15.0</span>   <span class="operator">|</span> <span class="number">94.0</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> tony  <span class="operator">|</span> <span class="number">29</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span>  <span class="operator">|</span> <span class="number">44.0</span>   <span class="operator">|</span> <span class="number">94.0</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> tony  <span class="operator">|</span> <span class="number">50</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-07</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span>  <span class="operator">|</span> <span class="number">94.0</span>   <span class="operator">|</span> <span class="number">94.0</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+-------+-------------+----------+--------+---------------+</span></span><br></pre></td></tr></table></figure></li>
<li>需求五：查询每个顾客上次的购买时间以及下一次的购买时间 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">       name,</span><br><span class="line">       cost,</span><br><span class="line">       orderdate,</span><br><span class="line">       <span class="built_in">lag</span>(orderdate, <span class="number">1</span>, &quot;first&quot;) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> name <span class="keyword">order</span> <span class="keyword">by</span> orderdate),</span><br><span class="line">       <span class="built_in">lead</span>(orderdate, <span class="number">1</span>, &quot;last&quot;) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> name <span class="keyword">order</span> <span class="keyword">by</span> orderdate)</span><br><span class="line"><span class="keyword">from</span> business</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> name, orderdate;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+-------+-------------+---------------+----------------+</span></span><br><span class="line"><span class="operator">|</span> name  <span class="operator">|</span> cost  <span class="operator">|</span>  orderdate  <span class="operator">|</span> lag_window_0  <span class="operator">|</span> lead_window_1  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+-------+-------------+---------------+----------------+</span></span><br><span class="line"><span class="operator">|</span> jack  <span class="operator">|</span> <span class="number">10</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-01</span>  <span class="operator">|</span> <span class="keyword">first</span>         <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-05</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> jack  <span class="operator">|</span> <span class="number">46</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-05</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-01</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-08</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> jack  <span class="operator">|</span> <span class="number">55</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-08</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-05</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-02</span><span class="number">-03</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> jack  <span class="operator">|</span> <span class="number">23</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-02</span><span class="number">-03</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-08</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-06</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> jack  <span class="operator">|</span> <span class="number">42</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-06</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-02</span><span class="number">-03</span>    <span class="operator">|</span> <span class="keyword">last</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> mart  <span class="operator">|</span> <span class="number">62</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-08</span>  <span class="operator">|</span> <span class="keyword">first</span>         <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-09</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> mart  <span class="operator">|</span> <span class="number">68</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-09</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-08</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-11</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> mart  <span class="operator">|</span> <span class="number">75</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-11</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-09</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-13</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> mart  <span class="operator">|</span> <span class="number">94</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-13</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-04</span><span class="number">-11</span>    <span class="operator">|</span> <span class="keyword">last</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> neil  <span class="operator">|</span> <span class="number">12</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-05</span><span class="number">-10</span>  <span class="operator">|</span> <span class="keyword">first</span>         <span class="operator">|</span> <span class="number">2017</span><span class="number">-06</span><span class="number">-12</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> neil  <span class="operator">|</span> <span class="number">80</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-06</span><span class="number">-12</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-05</span><span class="number">-10</span>    <span class="operator">|</span> <span class="keyword">last</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> tony  <span class="operator">|</span> <span class="number">15</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-02</span>  <span class="operator">|</span> <span class="keyword">first</span>         <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-04</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> tony  <span class="operator">|</span> <span class="number">29</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-04</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-02</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-07</span>     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> tony  <span class="operator">|</span> <span class="number">50</span>    <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-07</span>  <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-04</span>    <span class="operator">|</span> <span class="keyword">last</span>           <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+-------+-------------+---------------+----------------+</span></span><br></pre></td></tr></table></figure></li>
<li>需求六：查询前20%时间的订单信息 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">         <span class="keyword">select</span> name,</span><br><span class="line">                cost,</span><br><span class="line">                orderdate,</span><br><span class="line">                <span class="built_in">ntile</span>(<span class="number">5</span>) <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> orderdate) num</span><br><span class="line">         <span class="keyword">from</span> business</span><br><span class="line">     ) t1</span><br><span class="line"><span class="keyword">where</span> t1.num <span class="operator">=</span> <span class="number">1</span></span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> name, orderdate;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+----------+---------------+---------+</span></span><br><span class="line"><span class="operator">|</span> t1.name  <span class="operator">|</span> t1.cost  <span class="operator">|</span> t1.orderdate  <span class="operator">|</span> t1.num  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+----------+---------------+---------+</span></span><br><span class="line"><span class="operator">|</span> jack     <span class="operator">|</span> <span class="number">10</span>       <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-01</span>    <span class="operator">|</span> <span class="number">1</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> tony     <span class="operator">|</span> <span class="number">15</span>       <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-02</span>    <span class="operator">|</span> <span class="number">1</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> tony     <span class="operator">|</span> <span class="number">29</span>       <span class="operator">|</span> <span class="number">2017</span><span class="number">-01</span><span class="number">-04</span>    <span class="operator">|</span> <span class="number">1</span>       <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------+----------+---------------+---------+</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h5 id="8-2-5-5-1-排序开窗练习"><a href="#8-2-5-5-1-排序开窗练习" class="headerlink" title="8.2.5.5.1 排序开窗练习"></a>8.2.5.5.1 排序开窗练习</h5><ol>
<li>建表导数据 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> score <span class="keyword">as</span></span><br><span class="line"><span class="keyword">select</span> stack(<span class="number">12</span>,</span><br><span class="line"> &quot;孙悟空&quot;, &quot;语文&quot;, &quot;87&quot;,</span><br><span class="line"> &quot;孙悟空&quot;, &quot;数学&quot;, &quot;95&quot;,</span><br><span class="line"> &quot;孙悟空&quot;, &quot;英语&quot;, &quot;68&quot;,</span><br><span class="line"> &quot;大海&quot;, &quot;语文&quot;, &quot;94&quot;,</span><br><span class="line"> &quot;大海&quot;, &quot;数学&quot;, &quot;56&quot;,</span><br><span class="line"> &quot;大海&quot;, &quot;英语&quot;, &quot;84&quot;,</span><br><span class="line"> &quot;宋宋&quot;, &quot;语文&quot;, &quot;64&quot;,</span><br><span class="line"> &quot;宋宋&quot;, &quot;数学&quot;, &quot;86&quot;,</span><br><span class="line"> &quot;宋宋&quot;, &quot;英语&quot;, &quot;84&quot;,</span><br><span class="line"> &quot;婷婷&quot;, &quot;语文&quot;, &quot;65&quot;,</span><br><span class="line"> &quot;婷婷&quot;, &quot;数学&quot;, &quot;85&quot;,</span><br><span class="line"> &quot;婷婷&quot;, &quot;英语&quot;, &quot;78&quot;)</span><br><span class="line"><span class="keyword">as</span> (name, subject, score);</span><br></pre></td></tr></table></figure></li>
<li>根据学科进行分区操作 并且按照成绩字段进行倒序，最后利用排名函数 完成排名  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> name,</span><br><span class="line">       subject,</span><br><span class="line">       score,</span><br><span class="line">       <span class="built_in">rank</span>() <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> subject <span class="keyword">order</span> <span class="keyword">by</span> score <span class="keyword">desc</span> ),</span><br><span class="line">       <span class="built_in">dense_rank</span>() <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> subject <span class="keyword">order</span> <span class="keyword">by</span> score <span class="keyword">desc</span> ),</span><br><span class="line">       <span class="built_in">row_number</span>() <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> subject <span class="keyword">order</span> <span class="keyword">by</span> score <span class="keyword">desc</span> )</span><br><span class="line"><span class="keyword">from</span> score;</span><br><span class="line"></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+----------+--------+----------------+----------------------+----------------------+</span></span><br><span class="line"><span class="operator">|</span> name  <span class="operator">|</span> subject  <span class="operator">|</span> score  <span class="operator">|</span> rank_window_0  <span class="operator">|</span> dense_rank_window_1  <span class="operator">|</span> row_number_window_2  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+----------+--------+----------------+----------------------+----------------------+</span></span><br><span class="line"><span class="operator">|</span> 孙悟空   <span class="operator">|</span> 数学       <span class="operator">|</span> <span class="number">95</span>     <span class="operator">|</span> <span class="number">1</span>              <span class="operator">|</span> <span class="number">1</span>                    <span class="operator">|</span> <span class="number">1</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 宋宋    <span class="operator">|</span> 数学       <span class="operator">|</span> <span class="number">86</span>     <span class="operator">|</span> <span class="number">2</span>              <span class="operator">|</span> <span class="number">2</span>                    <span class="operator">|</span> <span class="number">2</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 婷婷    <span class="operator">|</span> 数学       <span class="operator">|</span> <span class="number">85</span>     <span class="operator">|</span> <span class="number">3</span>              <span class="operator">|</span> <span class="number">3</span>                    <span class="operator">|</span> <span class="number">3</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 大海    <span class="operator">|</span> 数学       <span class="operator">|</span> <span class="number">56</span>     <span class="operator">|</span> <span class="number">4</span>              <span class="operator">|</span> <span class="number">4</span>                    <span class="operator">|</span> <span class="number">4</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 宋宋    <span class="operator">|</span> 英语       <span class="operator">|</span> <span class="number">84</span>     <span class="operator">|</span> <span class="number">1</span>              <span class="operator">|</span> <span class="number">1</span>                    <span class="operator">|</span> <span class="number">1</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 大海    <span class="operator">|</span> 英语       <span class="operator">|</span> <span class="number">84</span>     <span class="operator">|</span> <span class="number">1</span>              <span class="operator">|</span> <span class="number">1</span>                    <span class="operator">|</span> <span class="number">2</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 婷婷    <span class="operator">|</span> 英语       <span class="operator">|</span> <span class="number">78</span>     <span class="operator">|</span> <span class="number">3</span>              <span class="operator">|</span> <span class="number">2</span>                    <span class="operator">|</span> <span class="number">3</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 孙悟空   <span class="operator">|</span> 英语       <span class="operator">|</span> <span class="number">68</span>     <span class="operator">|</span> <span class="number">4</span>              <span class="operator">|</span> <span class="number">3</span>                    <span class="operator">|</span> <span class="number">4</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 大海    <span class="operator">|</span> 语文       <span class="operator">|</span> <span class="number">94</span>     <span class="operator">|</span> <span class="number">1</span>              <span class="operator">|</span> <span class="number">1</span>                    <span class="operator">|</span> <span class="number">1</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 孙悟空   <span class="operator">|</span> 语文       <span class="operator">|</span> <span class="number">87</span>     <span class="operator">|</span> <span class="number">2</span>              <span class="operator">|</span> <span class="number">2</span>                    <span class="operator">|</span> <span class="number">2</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 婷婷    <span class="operator">|</span> 语文       <span class="operator">|</span> <span class="number">65</span>     <span class="operator">|</span> <span class="number">3</span>              <span class="operator">|</span> <span class="number">3</span>                    <span class="operator">|</span> <span class="number">3</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> 宋宋    <span class="operator">|</span> 语文       <span class="operator">|</span> <span class="number">64</span>     <span class="operator">|</span> <span class="number">4</span>              <span class="operator">|</span> <span class="number">4</span>                    <span class="operator">|</span> <span class="number">4</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+----------+--------+----------------+----------------------+----------------------+</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="8-2-6-其他常用函数"><a href="#8-2-6-其他常用函数" class="headerlink" title="8.2.6 其他常用函数"></a>8.2.6 其他常用函数</h3><table>
<thead>
<tr>
<th>类别</th>
<th>函数</th>
<th>描述</th>
<th>示例</th>
</tr>
</thead>
<tbody><tr>
<td>常用日期函数</td>
<td>unix_timestamp</td>
<td>返回当前或指定时间的时间戳</td>
<td>select unix_timestamp();select unix_timestamp(“2020-10-28”,’yyyy-MM-dd’);</td>
</tr>
<tr>
<td></td>
<td>from_unixtime</td>
<td>将时间戳转为日期格式</td>
<td>select from_unixtime(1603843200);</td>
</tr>
<tr>
<td></td>
<td>current_date</td>
<td>当前日期</td>
<td>select current_date;</td>
</tr>
<tr>
<td></td>
<td>current_timestamp</td>
<td>当前的日期加时间</td>
<td>select current_timestamp;</td>
</tr>
<tr>
<td></td>
<td>to_date</td>
<td>抽取日期部分</td>
<td>select to_date(‘2020-10-28 12:12:12’);</td>
</tr>
<tr>
<td></td>
<td>year</td>
<td>获取年</td>
<td>select year(‘2020-10-28 12:12:12’);</td>
</tr>
<tr>
<td></td>
<td>month</td>
<td>获取月</td>
<td>select month(‘2020-10-28 12:12:12’);</td>
</tr>
<tr>
<td></td>
<td>day</td>
<td>获取日</td>
<td>select day(‘2020-10-28 12:12:12’);</td>
</tr>
<tr>
<td></td>
<td>hour</td>
<td>获取时</td>
<td>select hour(‘2020-10-28 12:12:12’);</td>
</tr>
<tr>
<td></td>
<td>minute</td>
<td>获取分</td>
<td>select minute(‘2020-10-28 12:12:12’);</td>
</tr>
<tr>
<td></td>
<td>second</td>
<td>获取秒</td>
<td>select second(‘2020-10-28 12:12:12’);</td>
</tr>
<tr>
<td></td>
<td>weekofyear</td>
<td>当前时间是一年中的第几周</td>
<td>select weekofyear(‘2020-10-28 12:12:12’);</td>
</tr>
<tr>
<td></td>
<td>dayofmonth</td>
<td>当前时间是一个月中的第几天</td>
<td>select dayofmonth(‘2020-10-28 12:12:12’);</td>
</tr>
<tr>
<td></td>
<td>months_between</td>
<td>两个日期间的月份</td>
<td>select months_between(‘2020-04-01’,’2020-10-28’);</td>
</tr>
<tr>
<td></td>
<td>add_months</td>
<td>日期加减月</td>
<td>select add_months(‘2020-10-28’,-3);</td>
</tr>
<tr>
<td></td>
<td>datediff</td>
<td>两个日期相差的天数</td>
<td>select datediff(‘2020-11-04’,’2020-10-28’);</td>
</tr>
<tr>
<td></td>
<td>date_add</td>
<td>日期加天数</td>
<td>select date_add(‘2020-10-28’,4);</td>
</tr>
<tr>
<td></td>
<td>date_sub</td>
<td>日期减天数</td>
<td>select date_sub(‘2020-10-28’,-4);</td>
</tr>
<tr>
<td></td>
<td>last_day</td>
<td>日期的当月的最后一天</td>
<td>select last_day(‘2020-02-30’);</td>
</tr>
<tr>
<td></td>
<td>date_format</td>
<td>格式化日期</td>
<td>select date_format(‘2020-10-28 12:12:12’,’yyyy/MM/dd HH:mm:ss’);</td>
</tr>
<tr>
<td>常用取整函数</td>
<td>round</td>
<td>四舍五入</td>
<td>select round(3.14);select round(3.54);</td>
</tr>
<tr>
<td></td>
<td>ceil</td>
<td>向上取整</td>
<td>select ceil(3.14);select ceil(3.54);</td>
</tr>
<tr>
<td></td>
<td>floor</td>
<td>向下取整</td>
<td>select floor(3.14);select floor(3.54);</td>
</tr>
<tr>
<td>常用字符串操作函数</td>
<td>upper</td>
<td>转大写</td>
<td>select upper(‘low’);</td>
</tr>
<tr>
<td></td>
<td>lower</td>
<td>转小写</td>
<td>select lower(‘low’);</td>
</tr>
<tr>
<td></td>
<td>length</td>
<td>长度</td>
<td>select length(“atguigu”);</td>
</tr>
<tr>
<td></td>
<td>trim</td>
<td>前后去空格</td>
<td>select trim(“ atguigu “);</td>
</tr>
<tr>
<td></td>
<td>lpad</td>
<td>向左补齐，到指定长度</td>
<td>select lpad(‘atguigu’,9,’g’);</td>
</tr>
<tr>
<td></td>
<td>rpad</td>
<td>向右补齐，到指定长度</td>
<td>select rpad(‘atguigu’,9,’g’);</td>
</tr>
<tr>
<td></td>
<td>regexp_replace</td>
<td>使用正则表达式匹配目标字符串，匹配成功后替换！</td>
<td>SELECT regexp_replace(‘2020/10/25’, ‘/‘, ‘-‘);</td>
</tr>
<tr>
<td>集合操作</td>
<td>size</td>
<td>集合中元素的个数</td>
<td>select size(friends) from person_info;</td>
</tr>
<tr>
<td></td>
<td>map_keys</td>
<td>返回map中的key</td>
<td>select map_keys(children) from person_info;</td>
</tr>
<tr>
<td></td>
<td>map_value</td>
<td>返回map中的value</td>
<td>select map_values(children) from person_info;</td>
</tr>
<tr>
<td></td>
<td>array_contains</td>
<td>判断array中是否包含某个元素</td>
<td>select array_contains(friends,’bingbing’) from person_info;</td>
</tr>
<tr>
<td></td>
<td>sort_array</td>
<td>将array中的元素排序</td>
<td>select sort_array(friends) from person_info;</td>
</tr>
<tr>
<td></td>
<td>grouping_set</td>
<td>多维分析</td>
<td></td>
</tr>
</tbody></table>
<h2 id="8-3-自定义函数"><a href="#8-3-自定义函数" class="headerlink" title="8.3 自定义函数"></a>8.3 自定义函数</h2><ol>
<li>Hive 自带了一些函数，比如：max/min等，但是数量有限，自己可以通过自定义UDF来方便的扩展。</li>
<li>当Hive提供的内置函数无法满足你的业务处理需要时，此时就可以考虑使用用户自定义函数（UDF：user-defined function）。</li>
<li>根据用户自定义函数类别分为以下三种：<ul>
<li>UDF（User-Defined-Function）：一进一出</li>
<li>UDAF（User-Defined Aggregation Function）：聚集函数，多进一出，类似于：count/max/min</li>
<li>UDTF（User-Defined Table-Generating Functions）一进多出，如lateral view explode()</li>
</ul>
</li>
<li>官方文档地址<ul>
<li><a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/HivePlugins">https://cwiki.apache.org/confluence/display/Hive/HivePlugins</a></li>
</ul>
</li>
<li>编程步骤：<ol>
<li>继承Hive提供的类<ul>
<li>org.apache.hadoop.hive.ql.udf.generic.GenericUDF  </li>
<li>org.apache.hadoop.hive.ql.udf.generic.GenericUDTF;</li>
</ul>
</li>
<li>实现类中的抽象方法</li>
<li>在hive的命令行窗口创建函数 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 添加jar</span></span><br><span class="line"><span class="keyword">add</span> jar linux_jar_path</span><br><span class="line"><span class="comment">-- 创建function</span></span><br><span class="line"><span class="keyword">create</span> [temporary] <span class="keyword">function</span> [dbname.]function_name <span class="keyword">AS</span> class_name;</span><br></pre></td></tr></table></figure></li>
<li>在hive的命令行窗口删除函数 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> [temporary] <span class="keyword">function</span> [if <span class="keyword">exists</span>] [dbname.]function_name;</span><br></pre></td></tr></table></figure>
<h2 id="8-4-自定义UDF函数"><a href="#8-4-自定义UDF函数" class="headerlink" title="8.4 自定义UDF函数"></a>8.4 自定义UDF函数</h2></li>
</ol>
</li>
<li>创建函数类</li>
<li>继承org.apache.hadoop.hive.ql.udf.generic.GenericUDF</li>
<li>重写initialize，evaluate，getDisplayString</li>
<li>执行hive add jar</li>
<li>创建函数</li>
<li>使用函数</li>
<li>示例 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 一进一出</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UDFTest</span> <span class="keyword">extends</span> <span class="title">GenericUDF</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> objectInspectors</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> UDFArgumentException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ObjectInspector <span class="title">initialize</span><span class="params">(ObjectInspector[] objectInspectors)</span> <span class="keyword">throws</span> UDFArgumentException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (objectInspectors == <span class="keyword">null</span> || objectInspectors.length != <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> UDFArgumentLengthException(<span class="string">&quot;参数数量有误&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        ObjectInspector objectInspector = objectInspectors[<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (objectInspector.getCategory() != ObjectInspector.Category.PRIMITIVE) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> UDFArgumentTypeException(<span class="number">0</span>, <span class="string">&quot;参数类型错误&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> PrimitiveObjectInspectorFactory.javaIntObjectInspector;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 函数体的核心逻辑</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> deferredObjects</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> HiveException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">evaluate</span><span class="params">(DeferredObject[] deferredObjects)</span> <span class="keyword">throws</span> HiveException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (deferredObjects == <span class="keyword">null</span> || deferredObjects.length != <span class="number">1</span> || deferredObjects[<span class="number">0</span>].get() == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> deferredObjects[<span class="number">0</span>].get().toString().length();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 针对当前函数的说明</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> strings</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getDisplayString</span><span class="params">(String[] strings)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;针对当前函数的说明&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">add</span> jar <span class="operator">/</span>home<span class="operator">/</span>atguigu<span class="operator">/</span>hive<span class="operator">/</span>custom_function<span class="operator">/</span>sgg<span class="operator">-</span>hive<span class="operator">-</span>custom<span class="operator">-</span><span class="keyword">function</span><span class="number">-0.0</span><span class="number">.1</span><span class="operator">-</span>SNAPSHOT.jar;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.037</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">create</span> temporary <span class="keyword">function</span> str_split <span class="keyword">as</span> <span class="string">&#x27;tech.anzhen.sgg.hive.custom.function.udf.UDTFTest&#x27;</span>;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.028</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> str_split(<span class="string">&#x27;a,d,d,w&#x27;</span>,<span class="string">&#x27;,&#x27;</span>,<span class="string">&#x27;12&#x27;</span>);</span><br><span class="line">Error: Error while compiling statement: FAILED: UDFArgumentLengthException 参数数量有误 (state<span class="operator">=</span><span class="number">42000</span>,code<span class="operator">=</span><span class="number">40000</span>)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> str_split(<span class="string">&#x27;a,d,d,w&#x27;</span>,<span class="string">&#x27;,&#x27;</span>);</span><br><span class="line"><span class="operator">+</span><span class="comment">-------+</span></span><br><span class="line"><span class="operator">|</span> word  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+</span></span><br><span class="line"><span class="operator">|</span> a     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> d     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> d     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> w     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-------+</span></span><br></pre></td></tr></table></figure>
<h2 id="8-5-自定义UDTF函数"><a href="#8-5-自定义UDTF函数" class="headerlink" title="8.5 自定义UDTF函数"></a>8.5 自定义UDTF函数</h2></li>
<li>创建函数类</li>
<li>继承org.apache.hadoop.hive.ql.udf.generic.GenericUDTF</li>
<li>重写initialize，process，close</li>
<li>执行hive add jar</li>
<li>创建函数</li>
<li>使用函数</li>
<li>示例 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UDTFMultiColumnTest</span> <span class="keyword">extends</span> <span class="title">GenericUDTF</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> StructObjectInspector <span class="title">initialize</span><span class="params">(StructObjectInspector argOIs)</span> <span class="keyword">throws</span> UDFArgumentException </span>&#123;</span><br><span class="line">        <span class="comment">//参数数量</span></span><br><span class="line">        List&lt;? extends StructField&gt; allStructFieldRefs = argOIs.getAllStructFieldRefs();</span><br><span class="line">        <span class="keyword">if</span> (allStructFieldRefs == <span class="keyword">null</span> || allStructFieldRefs.size() != <span class="number">3</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> UDFArgumentLengthException(<span class="string">&quot;参数数量有误&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//参数数据类型</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; allStructFieldRefs.size(); i++) &#123;</span><br><span class="line">            StructField structField = allStructFieldRefs.get(i);</span><br><span class="line">            <span class="keyword">if</span> (structField.getFieldObjectInspector().getCategory() != ObjectInspector.Category.PRIMITIVE) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> UDFArgumentTypeException(i, <span class="string">&quot;参数类型有误&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        ArrayList&lt;String&gt; fieldNames = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        fieldNames.add(<span class="string">&quot;word1&quot;</span>);</span><br><span class="line">        fieldNames.add(<span class="string">&quot;word2&quot;</span>);</span><br><span class="line">        ArrayList&lt;ObjectInspector&gt; fieldOIs = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        fieldOIs.add(PrimitiveObjectInspectorFactory.javaStringObjectInspector);</span><br><span class="line">        fieldOIs.add(PrimitiveObjectInspectorFactory.javaStringObjectInspector);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> ObjectInspectorFactory.getStandardStructObjectInspector(fieldNames,</span><br><span class="line">                fieldOIs);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(Object[] args)</span> <span class="keyword">throws</span> HiveException </span>&#123;</span><br><span class="line">        String str = args[<span class="number">0</span>].toString();</span><br><span class="line">        String split1 = args[<span class="number">1</span>].toString();</span><br><span class="line">        String split2 = args[<span class="number">2</span>].toString();</span><br><span class="line">        String[] split1Array = str.split(split1);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; split1Array.length; i++) &#123;</span><br><span class="line">            String split2Str = split1Array[i];</span><br><span class="line">            String[] split2Array = split2Str.split(split2);</span><br><span class="line">            forward(split2Array);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 收尾</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> HiveException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> HiveException </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">add</span> jar <span class="operator">/</span>home<span class="operator">/</span>atguigu<span class="operator">/</span>hive<span class="operator">/</span>custom_function<span class="operator">/</span>sgg<span class="operator">-</span>hive<span class="operator">-</span>custom<span class="operator">-</span><span class="keyword">function</span><span class="number">-0.0</span><span class="number">.1</span><span class="operator">-</span>SNAPSHOT.jar;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.037</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">create</span> temporary <span class="keyword">function</span> str_splits <span class="keyword">as</span> <span class="string">&#x27;tech.anzhen.sgg.hive.custom.function.udf.UDTFMultiColumnTest&#x27;</span>;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.037</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> str_splits(<span class="string">&#x27;a,d,d,w&#x27;</span>,<span class="string">&#x27;,&#x27;</span>);</span><br><span class="line">Error: Error while compiling statement: FAILED: UDFArgumentLengthException 参数数量有误 (state<span class="operator">=</span><span class="number">42000</span>,code<span class="operator">=</span><span class="number">40000</span>)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> str_splits(<span class="string">&#x27;a-1,b-2,c-3&#x27;</span>,<span class="string">&#x27;,&#x27;</span>,<span class="string">&#x27;-&#x27;</span>);</span><br><span class="line"><span class="operator">+</span><span class="comment">--------+--------+</span></span><br><span class="line"><span class="operator">|</span> word1  <span class="operator">|</span> word2  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------+--------+</span></span><br><span class="line"><span class="operator">|</span> a      <span class="operator">|</span> <span class="number">1</span>      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> b      <span class="operator">|</span> <span class="number">2</span>      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> c      <span class="operator">|</span> <span class="number">3</span>      <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------+--------+</span></span><br><span class="line"><span class="number">3</span> <span class="keyword">rows</span> selected (<span class="number">0.062</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="九、压缩和存储"><a href="#九、压缩和存储" class="headerlink" title="九、压缩和存储"></a>九、压缩和存储</h1><h2 id="9-1-Hadoop压缩配置"><a href="#9-1-Hadoop压缩配置" class="headerlink" title="9.1 Hadoop压缩配置"></a>9.1 Hadoop压缩配置</h2><h3 id="9-1-1-MR支持的压缩编码"><a href="#9-1-1-MR支持的压缩编码" class="headerlink" title="9.1.1 MR支持的压缩编码"></a>9.1.1 MR支持的压缩编码</h3><ul>
<li><p>MR支持的压缩编码</p>
<table>
<thead>
<tr>
<th>压缩格式</th>
<th>算法</th>
<th>文件扩展名</th>
<th>是否可切分</th>
</tr>
</thead>
<tbody><tr>
<td>DEFLATE</td>
<td>DEFLATE</td>
<td>.deflate</td>
<td>否</td>
</tr>
<tr>
<td>Gzip</td>
<td>DEFLATE</td>
<td>.gz</td>
<td>否</td>
</tr>
<tr>
<td>bzip2</td>
<td>bzip2</td>
<td>.bz2</td>
<td>是</td>
</tr>
<tr>
<td>LZO</td>
<td>LZO</td>
<td>.lzo</td>
<td>是</td>
</tr>
<tr>
<td>Snappy</td>
<td>Snappy</td>
<td>.snappy</td>
<td>否</td>
</tr>
</tbody></table>
</li>
<li><p>为了支持多种压缩/解压缩算法，Hadoop引入了编码/解码器，如下表所示：</p>
<table>
<thead>
<tr>
<th>压缩格式</th>
<th>对应的编码/解码器</th>
</tr>
</thead>
<tbody><tr>
<td>DEFLATE</td>
<td>org.apache.hadoop.io.compress.DefaultCodec</td>
</tr>
<tr>
<td>gzip</td>
<td>org.apache.hadoop.io.compress.GzipCodec</td>
</tr>
<tr>
<td>bzip2</td>
<td>org.apache.hadoop.io.compress.BZip2Codec</td>
</tr>
<tr>
<td>LZO</td>
<td>com.hadoop.compression.lzo.LzopCodec</td>
</tr>
<tr>
<td>Snappy</td>
<td>org.apache.hadoop.io.compress.SnappyCodec</td>
</tr>
</tbody></table>
</li>
<li><p>压缩性能的比较：</p>
<table>
<thead>
<tr>
<th>压缩算法</th>
<th>原始文件大小</th>
<th>压缩文件大小</th>
<th>压缩速度</th>
<th>解压速度</th>
</tr>
</thead>
<tbody><tr>
<td>gzip</td>
<td>8.3GB</td>
<td>1.8GB</td>
<td>17.5MB/s</td>
<td>58MB/s</td>
</tr>
<tr>
<td>bzip2</td>
<td>8.3GB</td>
<td>1.1GB</td>
<td>2.4MB/s</td>
<td>9.5MB/s</td>
</tr>
<tr>
<td>LZO</td>
<td>8.3GB</td>
<td>2.9GB</td>
<td>49.3MB/s</td>
<td>74.6MB/s</td>
</tr>
</tbody></table>
<blockquote>
<p><a target="_blank" rel="noopener" href="http://google.github.io/snappy/">http://google.github.io/snappy/</a><br>On a single core of a Core i7 processor in 64-bit mode, Snappy compresses at about 250 MB/sec or more and decompresses at about 500 MB/sec or more.</p>
</blockquote>
</li>
</ul>
<h3 id="9-1-2-压缩参数配置"><a href="#9-1-2-压缩参数配置" class="headerlink" title="9.1.2 压缩参数配置"></a>9.1.2 压缩参数配置</h3><ul>
<li>要在Hadoop中启用压缩，可以配置如下参数（mapred-site.xml文件中）：<table>
<thead>
<tr>
<th>参数</th>
<th>默认值</th>
<th>阶段</th>
<th>建议</th>
</tr>
</thead>
<tbody><tr>
<td>io.compression.codecs（在core-site.xml中配置）</td>
<td>org.apache.hadoop.io.compress.DefaultCodec, org.apache.hadoop.io.compress.GzipCodec, org.apache.hadoop.io.compress.BZip2Codec,</td>
<td></td>
<td></td>
</tr>
<tr>
<td>org.apache.hadoop.io.compress.Lz4Codec</td>
<td>输入压缩</td>
<td>Hadoop使用文件扩展名判断是否支持某种编解码器</td>
<td></td>
</tr>
<tr>
<td>mapreduce.map.output.compress</td>
<td>false</td>
<td>mapper输出</td>
<td>这个参数设为true启用压缩</td>
</tr>
<tr>
<td>mapreduce.map.output.compress.codec</td>
<td>org.apache.hadoop.io.compress.DefaultCodec</td>
<td>mapper输出</td>
<td>使用LZO、LZ4或snappy编解码器在此阶段压缩数据</td>
</tr>
<tr>
<td>mapreduce.output.fileoutputformat.compress</td>
<td>false</td>
<td>reducer输出</td>
<td>这个参数设为true启用压缩</td>
</tr>
<tr>
<td>mapreduce.output.fileoutputformat.compress.codec</td>
<td>org.apache.hadoop.io.compress. DefaultCodec</td>
<td>reducer输出</td>
<td>使用标准工具或者编解码器，如gzip和bzip2</td>
</tr>
<tr>
<td>mapreduce.output.fileoutputformat.compress.type</td>
<td>RECORD</td>
<td>reducer输出</td>
<td>SequenceFile输出使用的压缩类型：NONE和BLOCK</td>
</tr>
</tbody></table>
</li>
</ul>
<h2 id="9-2-开启Map输出阶段压缩"><a href="#9-2-开启Map输出阶段压缩" class="headerlink" title="9.2 开启Map输出阶段压缩"></a>9.2 开启Map输出阶段压缩</h2><p>开启map输出阶段压缩可以减少job中map和Reduce task间数据传输量。具体配置如下：</p>
<ol>
<li>开启hive中间传输数据压缩功能 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span><span class="keyword">set</span> hive.exec.compress.intermediate<span class="operator">=</span><span class="literal">true</span>;</span><br></pre></td></tr></table></figure></li>
<li>开启mapreduce中map输出压缩功能 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span><span class="keyword">set</span> mapreduce.map.output.compress<span class="operator">=</span><span class="literal">true</span>;</span><br></pre></td></tr></table></figure></li>
<li>设置mapreduce中map输出数据的压缩方式 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span><span class="keyword">set</span> mapreduce.map.output.compress.codec <span class="operator">=</span> org.apache.hadoop.io.compress.SnappyCodec;</span><br></pre></td></tr></table></figure></li>
<li>执行查询语句 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">count</span>(ename) name <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="9-3-开启Reduce输出阶段压缩"><a href="#9-3-开启Reduce输出阶段压缩" class="headerlink" title="9.3 开启Reduce输出阶段压缩"></a>9.3 开启Reduce输出阶段压缩</h2><p>当Hive将输出写入到表中时，输出内容同样可以进行压缩。属性hive.exec.compress.output控制着这个功能。用户可能需要保持默认设置文件中的默认值false，这样默认的输出就是非压缩的纯文本文件了。用户可以通过在查询语句或执行脚本中设置这个值为true，来开启输出结果压缩功能。</p>
<ol>
<li>开启hive最终输出数据压缩功能 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span><span class="keyword">set</span> hive.exec.compress.output<span class="operator">=</span><span class="literal">true</span>;</span><br></pre></td></tr></table></figure></li>
<li>开启mapreduce最终输出数据压缩 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span><span class="keyword">set</span> mapreduce.output.fileoutputformat.compress<span class="operator">=</span><span class="literal">true</span>;</span><br></pre></td></tr></table></figure></li>
<li>设置mapreduce最终数据输出压缩方式 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">set</span> mapreduce.output.fileoutputformat.compress.codec <span class="operator">=</span> org.apache.hadoop.io.compress.SnappyCodec;</span><br></pre></td></tr></table></figure></li>
<li>设置mapreduce最终数据输出压缩为块压缩 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">set</span> mapreduce.output.fileoutputformat.compress.type<span class="operator">=</span>BLOCK;</span><br></pre></td></tr></table></figure></li>
<li>测试一下输出结果是否是压缩文件 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">insert</span> overwrite <span class="keyword">local</span> directory <span class="string">&#x27;/opt/module/hive-3.1.2/datas/distribute-result&#x27;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp distribute <span class="keyword">by</span> deptno sort <span class="keyword">by</span> empno <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="9-4-文件存储格式"><a href="#9-4-文件存储格式" class="headerlink" title="9.4 文件存储格式"></a>9.4 文件存储格式</h2><ul>
<li>建表语法中以下规则就是确定Hive的存储格式  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[STORED <span class="keyword">AS</span> file_format] </span><br></pre></td></tr></table></figure></li>
<li>Hive中的存储格式<ul>
<li>textfile   (默认格式) — 行存</li>
<li>SEQUENCEFILE  二进制的序列文件 — 行存</li>
<li>ORC (Hive中最常用的一种存储格式) — 列存</li>
<li>PARQUET (和ORC接近的一种存储格式，hive中支持比较早的一种存储格式)– 列存</li>
</ul>
</li>
</ul>
<h3 id="9-4-1-列式存储和行式存储"><a href="#9-4-1-列式存储和行式存储" class="headerlink" title="9.4.1 列式存储和行式存储"></a>9.4.1 列式存储和行式存储</h3><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16355110552074.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"><br>如图所示左边为逻辑表，右边第一个为行式存储，第二个为列式存储。</p>
<ol>
<li>行存储的特点: 查询满足条件的一整行数据的时候，列存储则需要去每个聚集的字段找到对应的每个列的值，行存储只需要找到其中一个值，其余的值都在相邻地方，所以此时行存储查询的速度更快。</li>
<li>列存储的特点: 因为每个字段的数据聚集存储，在查询只需要少数几个字段的时候，能大大减少读取的数据量；每个字段的数据类型一定是相同的，列式存储可以针对性的设计更好的设计压缩算法。</li>
</ol>
<ul>
<li>TEXTFILE和SEQUENCEFILE的存储格式都是基于行存储的；</li>
<li>ORC和PARQUET是基于列式存储的。</li>
</ul>
<h3 id="9-4-2-TextFile格式"><a href="#9-4-2-TextFile格式" class="headerlink" title="9.4.2 TextFile格式"></a>9.4.2 TextFile格式</h3><p>默认格式，数据不做压缩，磁盘开销大，数据解析开销大。可结合Gzip、Bzip2使用，但使用Gzip这种方式，hive不会对数据进行切分，从而无法对数据进行并行操作</p>
<h3 id="9-4-3-Orc格式"><a href="#9-4-3-Orc格式" class="headerlink" title="9.4.3 Orc格式"></a>9.4.3 Orc格式</h3><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16355111657327.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<p>Orc (Optimized Row Columnar)是Hive 0.11版里引入的新的存储格式。<br>如图所示可以看到每个Orc文件由1个或多个stripe组成，每个stripe一般为HDFS的块大小，每一个stripe包含多条记录，这些记录按照列进行独立存储，对应到Parquet中的row group的概念。每个Stripe里有三部分组成，分别是Index Data，Row Data，Stripe Footer：</p>
<ol>
<li>Index Data：一个轻量级的index，默认是每隔1W行做一个索引。这里做的索引应该只是记录某行的各字段在Row Data中的offset。</li>
<li>Row Data：存的是具体的数据，先取部分行，然后对这些行按列进行存储。对每个列进行了编码，分成多个Stream来存储。</li>
<li>Stripe Footer：存的是各个Stream的类型，长度等信息。</li>
<li>每个文件有一个File Footer，这里面存的是每个Stripe的行数，每个Column的数据类型信息等；每个文件的尾部是一个PostScript，这里面记录了整个文件的压缩类型以及FileFooter的长度信息等。在读取文件时，会seek到文件尾部读PostScript，从里面解析到File Footer长度，再读FileFooter，从里面解析到各个Stripe信息，再读各个Stripe，即从后往前读。</li>
<li>以json方式查看orc文件 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive --orcfiledump -j -p /user/hive/warehouse/dim.db/dim_province/000000_0</span><br></pre></td></tr></table></figure>
<ul>
<li>文件示例：<a href="media/16346959668071/log_orc.json">log_orc.json</a><br>  <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16356457996704.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"><ul>
<li>schema: 为每一个字段做了编号，从1开始，编号为0的columnId中描述了整个表的字段定义。<br>  <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16356459007816.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>stripeStatistics:是ORC文件中所有stripes的统计信息，其中有每个stripe中每个字段的min/max值，是否有空值等等<br>  <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16356459954433.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>fileStatistics:整个文件中每个字段的统计信息，该表只有一个文件，也只有一个stripe<br>  <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16356461542820.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>stripes:这里列出了所有stripes的元数据信息，包括index data, row data和stripe footer。<br>  <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16356462325881.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="9-4-4-Parquet格式"><a href="#9-4-4-Parquet格式" class="headerlink" title="9.4.4 Parquet格式"></a>9.4.4 Parquet格式</h3><p>Parquet文件是以二进制方式存储的，所以是不可以直接读取的，文件中包括该文件的数据和元数据，因此Parquet格式文件是自解析的。</p>
<ol>
<li>行组(Row Group)：每一个行组包含一定的行数，在一个HDFS文件中至少存储一个行组，类似于orc的stripe的概念。</li>
<li>列块(Column Chunk)：在一个行组中每一列保存在一个列块中，行组中的所有列连续的存储在这个行组文件中。一个列块中的值都是相同类型的，不同的列块可能使用不同的算法进行压缩。</li>
<li>页(Page)：每一个列块划分为多个页，一个页是最小的编码的单位，在同一个列块的不同页可能使用不同的编码方式。</li>
<li>通常情况下，在存储Parquet数据的时候会按照Block大小设置行组的大小，由于一般情况下每一个Mapper任务处理数据的最小单位是一个Block，这样可以把每一个行组由一个Mapper任务处理，增大任务执行并行度。Parquet文件的格式。</li>
</ol>
<h3 id="9-4-5-主流文件存储格式对比实验"><a href="#9-4-5-主流文件存储格式对比实验" class="headerlink" title="9.4.5 主流文件存储格式对比实验"></a>9.4.5 主流文件存储格式对比实验</h3><p>数据文件 <a href="media/16346959668071/log.data">log.data</a></p>
<ol>
<li>textfile<ol>
<li>建表导数据 存储数据格式为TEXTFILE <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> log_text</span><br><span class="line">(</span><br><span class="line">    track_time  string,</span><br><span class="line">    url         string,</span><br><span class="line">    session_id  string,</span><br><span class="line">    referer     string,</span><br><span class="line">    ip          string,</span><br><span class="line">    end_user_id string,</span><br><span class="line">    city_id     string</span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">stored <span class="keyword">as</span> textfile;</span><br><span class="line"></span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/hive-3.1.2/datas/log.data&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> log_text ;</span><br></pre></td></tr></table></figure></li>
<li>查看占用空间占用 18.1 M <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> dfs <span class="operator">-</span>ls <span class="operator">-</span>h <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>mock_data.db<span class="operator">/</span>log_text;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span>                     DFS Output                     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> Found <span class="number">1</span> items                                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="operator">-</span>rw<span class="operator">-</span>r<span class="comment">--r--   3 atguigu supergroup     18.1 M 2021-10-30 10:34 /user/hive/warehouse/mock_data.db/log_text/log.data |</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> selected (<span class="number">0.008</span> seconds)</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li>orc<ol>
<li>建表导数据，指定orc格式 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> log_orc (</span><br><span class="line">    track_time  string,</span><br><span class="line">    url         string,</span><br><span class="line">    session_id  string,</span><br><span class="line">    referer     string,</span><br><span class="line">    ip          string,</span><br><span class="line">    end_user_id string,</span><br><span class="line">    city_id     string</span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">stored <span class="keyword">as</span> orc</span><br><span class="line">tblproperties (&quot;orc.compress&quot; <span class="operator">=</span> &quot;NONE&quot;); <span class="comment">-- 设置orc存储不使用压缩</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> log_orc <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> log_text ;</span><br></pre></td></tr></table></figure></li>
<li>查看文件大小 7.7 M <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> dfs <span class="operator">-</span>ls <span class="operator">-</span>h <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>mock_data.db<span class="operator">/</span>log_orc;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span>                     DFS Output                     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> Found <span class="number">1</span> items                                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="operator">-</span>rw<span class="operator">-</span>r<span class="comment">--r--   3 atguigu supergroup      7.7 M 2021-10-30 10:37 /user/hive/warehouse/mock_data.db/log_orc/000000_0 |</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> selected (<span class="number">0.005</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li>parquet<ol>
<li>建表导数据，指定parquet格式 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> log_parquet (</span><br><span class="line">    track_time  string,</span><br><span class="line">    url         string,</span><br><span class="line">    session_id  string,</span><br><span class="line">    referer     string,</span><br><span class="line">    ip          string,</span><br><span class="line">    end_user_id string,</span><br><span class="line">    city_id     string</span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">stored <span class="keyword">as</span> parquet;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> log_parquet <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> log_text ;</span><br></pre></td></tr></table></figure></li>
<li>查看文件大小 13.1 M <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> dfs <span class="operator">-</span>ls <span class="operator">-</span>h <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>mock_data.db<span class="operator">/</span>log_parquet;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span>                     DFS Output                     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> Found <span class="number">1</span> items                                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="operator">-</span>rw<span class="operator">-</span>r<span class="comment">--r--   3 atguigu supergroup     13.1 M 2021-10-30 10:49 /user/hive/warehouse/mock_data.db/log_parquet/000000_0 |</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> selected (<span class="number">0.009</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li>存储文件大小的对比总结：<br> ORC &gt;  Parquet &gt;  textFile</li>
<li>存储文件的查询速度测试<br> ORC &gt;  Parquet &gt;  textFile <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">from</span> person <span class="keyword">where</span> id<span class="operator">=</span><span class="number">4</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">------+</span></span><br><span class="line"><span class="operator">|</span> _c0  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span>    <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> selected (<span class="number">21.249</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">set</span> hive.optimize.index.filter<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.005</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">from</span> person_orc <span class="keyword">where</span> id<span class="operator">=</span><span class="number">4</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">------+</span></span><br><span class="line"><span class="operator">|</span> _c0  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span>    <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> selected (<span class="number">17.151</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">count</span>(<span class="number">1</span>) <span class="keyword">from</span> person_parquet <span class="keyword">where</span> id<span class="operator">=</span><span class="number">4</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">------+</span></span><br><span class="line"><span class="operator">|</span> _c0  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">1</span>    <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> selected (<span class="number">18.485</span> seconds)</span><br></pre></td></tr></table></figure>
<h2 id="9-5-存储和压缩结合"><a href="#9-5-存储和压缩结合" class="headerlink" title="9.5 存储和压缩结合"></a>9.5 存储和压缩结合</h2><h3 id="9-5-1-测试存储和压缩"><a href="#9-5-1-测试存储和压缩" class="headerlink" title="9.5.1 测试存储和压缩"></a>9.5.1 测试存储和压缩</h3></li>
</ol>
<ul>
<li><a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+ORC">官方文档</a></li>
<li>ORC存储方式的压缩：<table>
<thead>
<tr>
<th>Key</th>
<th>Default</th>
<th>Notes</th>
</tr>
</thead>
<tbody><tr>
<td>orc.compress</td>
<td>ZLIB</td>
<td>high level compression (one of NONE, ZLIB, SNAPPY)</td>
</tr>
<tr>
<td>orc.compress.size</td>
<td>262,144</td>
<td>number of bytes in each compression chunk</td>
</tr>
<tr>
<td>orc.stripe.size</td>
<td>268,435,456</td>
<td>number of bytes in each stripe</td>
</tr>
<tr>
<td>orc.row.index.stride</td>
<td>10,000</td>
<td>number of rows between index entries (must be &gt;= 1000)</td>
</tr>
<tr>
<td>orc.create.index</td>
<td>true</td>
<td>whether to create row indexes</td>
</tr>
<tr>
<td>orc.bloom.filter.columns</td>
<td>“”</td>
<td>comma separated list of column names for which bloom filter should be created</td>
</tr>
<tr>
<td>orc.bloom.filter.fpp</td>
<td>0.05</td>
<td>false positive probability for bloom filter (must &gt;0.0 and &lt;1.0)</td>
</tr>
</tbody></table>
</li>
<li>注意：所有关于ORCFile的参数都是在HQL语句的TBLPROPERTIES字段里面出现</li>
<li>测试<ol>
<li>创建ZLIB压缩的ORC存储方式<ul>
<li>建表导数据  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> log_orc_zlib (</span><br><span class="line">    track_time  string,</span><br><span class="line">    url         string,</span><br><span class="line">    session_id  string,</span><br><span class="line">    referer     string,</span><br><span class="line">    ip          string,</span><br><span class="line">    end_user_id string,</span><br><span class="line">    city_id     string</span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">stored <span class="keyword">as</span> orc</span><br><span class="line">tblproperties (&quot;orc.compress&quot; <span class="operator">=</span> &quot;ZLIB&quot;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> log_orc_zlib <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> log_text;</span><br></pre></td></tr></table></figure></li>
<li>查看文件大小 2.8 M  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> dfs <span class="operator">-</span>ls <span class="operator">-</span>h <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>mock_data.db<span class="operator">/</span>log_orc_zlib;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span>                     DFS Output                     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> Found <span class="number">1</span> items                                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="operator">-</span>rw<span class="operator">-</span>r<span class="comment">--r--   3 atguigu supergroup      2.8 M 2021-10-30 10:50 /user/hive/warehouse/mock_data.db/log_orc_zlib/000000_0 |</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> selected (<span class="number">0.011</span> seconds)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>创建一个SNAPPY压缩的ORC存储方式<ul>
<li>建表导数据  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> log_orc_snappy (</span><br><span class="line">    track_time  string,</span><br><span class="line">    url         string,</span><br><span class="line">    session_id  string,</span><br><span class="line">    referer     string,</span><br><span class="line">    ip          string,</span><br><span class="line">    end_user_id string,</span><br><span class="line">    city_id     string</span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">stored <span class="keyword">as</span> orc</span><br><span class="line">tblproperties (&quot;orc.compress&quot; <span class="operator">=</span> &quot;SNAPPY&quot;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> log_orc_snappy <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> log_text;</span><br></pre></td></tr></table></figure></li>
<li>查看文件大小 3.7 M  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> dfs <span class="operator">-</span>ls <span class="operator">-</span>h <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>mock_data.db<span class="operator">/</span>log_orc_snappy;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span>                     DFS Output                     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> Found <span class="number">1</span> items                                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="operator">-</span>rw<span class="operator">-</span>r<span class="comment">--r--   3 atguigu supergroup      3.7 M 2021-10-30 10:51 /user/hive/warehouse/mock_data.db/log_orc_snappy/000000_0 |</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> selected (<span class="number">0.009</span> seconds)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>创建一个SNAPPY压缩的parquet存储方式<ul>
<li>建表导数据  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> log_parquet_snappy (</span><br><span class="line">    track_time  string,</span><br><span class="line">    url         string,</span><br><span class="line">    session_id  string,</span><br><span class="line">    referer     string,</span><br><span class="line">    ip          string,</span><br><span class="line">    end_user_id string,</span><br><span class="line">    city_id     string</span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span></span><br><span class="line">stored <span class="keyword">as</span> parquet</span><br><span class="line">tblproperties (&quot;parquet.compression&quot; <span class="operator">=</span> &quot;SNAPPY&quot;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> log_parquet_snappy <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> log_text;</span><br></pre></td></tr></table></figure></li>
<li>查看文件大小 6.4 M  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> dfs <span class="operator">-</span>ls <span class="operator">-</span>h <span class="operator">/</span><span class="keyword">user</span><span class="operator">/</span>hive<span class="operator">/</span>warehouse<span class="operator">/</span>mock_data.db<span class="operator">/</span>log_parquet_snappy;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span>                     DFS Output                     <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> Found <span class="number">1</span> items                                      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="operator">-</span>rw<span class="operator">-</span>r<span class="comment">--r--   3 atguigu supergroup      6.4 M 2021-10-31 12:29 /user/hive/warehouse/mock_data.db/log_parquet_snappy/000000_0 |</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> selected (<span class="number">0.078</span> seconds)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>存储方式和压缩总结<ul>
<li>在实际的项目开发当中，hive表的数据存储格式一般选择：orc或parquet。压缩方式一般选择snappy，lzo。<h1 id="十、性能优化"><a href="#十、性能优化" class="headerlink" title="十、性能优化"></a>十、性能优化</h1><h2 id="10-1-执行计划（Explain）"><a href="#10-1-执行计划（Explain）" class="headerlink" title="10.1 执行计划（Explain）"></a>10.1 执行计划（Explain）</h2></li>
</ul>
</li>
</ol>
</li>
</ul>
<ol>
<li>概念：获取SQL执行的规划，主要用于分析SQL需要的优化依据信息</li>
<li>基本语法 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN [EXTENDED <span class="operator">|</span> DEPENDENCY <span class="operator">|</span> <span class="keyword">AUTHORIZATION</span>] query</span><br></pre></td></tr></table></figure></li>
<li>案例实操<ul>
<li>不生成MR任务(关注Fetch Operator)  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> explain <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span>                      Explain                       <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> STAGE DEPENDENCIES:                                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>   Stage<span class="number">-0</span> <span class="keyword">is</span> a root stage                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                                                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> STAGE PLANS:                                       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>   Stage: Stage<span class="number">-0</span>                                   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>     <span class="keyword">Fetch</span> Operator                                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       limit: <span class="number">-1</span>                                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       Processor Tree:                              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>         TableScan                                  <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           alias: emp                               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           Statistics: Num <span class="keyword">rows</span>: <span class="number">1</span> Data size: <span class="number">6570</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           <span class="keyword">Select</span> Operator                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>             expressions: emp_no (type: <span class="type">int</span>), emp_name (type: string), job (type: string), mgr (type: <span class="type">int</span>), hire_date (type: string), sal (type: <span class="keyword">double</span>), comm (type: <span class="keyword">double</span>), dept_no (type: <span class="type">int</span>) <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>             outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>             Statistics: Num <span class="keyword">rows</span>: <span class="number">1</span> Data size: <span class="number">6570</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>             ListSink                               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                                                    <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="number">17</span> <span class="keyword">rows</span> selected (<span class="number">0.076</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>生成MR任务的（关注Map Operator Tree）  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> explain <span class="keyword">select</span> dept_no, <span class="built_in">avg</span>(sal) avg_sal <span class="keyword">from</span> emp <span class="keyword">group</span> <span class="keyword">by</span> dept_no;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span>                      Explain                       <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> STAGE DEPENDENCIES:                                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>   Stage<span class="number">-1</span> <span class="keyword">is</span> a root stage                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>   Stage<span class="number">-0</span> depends <span class="keyword">on</span> stages: Stage<span class="number">-1</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                                                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> STAGE PLANS:                                       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>   Stage: Stage<span class="number">-1</span>                                   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>     Map Reduce                                     <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       Map Operator Tree:                           <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           TableScan                                <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>             alias: emp                             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>             Statistics: Num <span class="keyword">rows</span>: <span class="number">1</span> Data size: <span class="number">6570</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>             <span class="keyword">Select</span> Operator                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>               expressions: sal (type: <span class="keyword">double</span>), dept_no (type: <span class="type">int</span>) <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>               outputColumnNames: sal, dept_no      <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>               Statistics: Num <span class="keyword">rows</span>: <span class="number">1</span> Data size: <span class="number">6570</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>               <span class="keyword">Group</span> <span class="keyword">By</span> Operator                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                 aggregations: <span class="built_in">sum</span>(sal), <span class="built_in">count</span>(sal) <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                 keys: dept_no (type: <span class="type">int</span>)          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                 mode: hash                         <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                 outputColumnNames: _col0, _col1, _col2 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                 Statistics: Num <span class="keyword">rows</span>: <span class="number">1</span> Data size: <span class="number">6570</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                 Reduce Output Operator             <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                   key expressions: _col0 (type: <span class="type">int</span>) <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                   sort <span class="keyword">order</span>: <span class="operator">+</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                   Map<span class="operator">-</span>reduce <span class="keyword">partition</span> columns: _col0 (type: <span class="type">int</span>) <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                   Statistics: Num <span class="keyword">rows</span>: <span class="number">1</span> Data size: <span class="number">6570</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                   <span class="keyword">value</span> expressions: _col1 (type: <span class="keyword">double</span>), _col2 (type: <span class="type">bigint</span>) <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       Execution mode: vectorized                   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       Reduce Operator Tree:                        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>         <span class="keyword">Group</span> <span class="keyword">By</span> Operator                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           aggregations: <span class="built_in">sum</span>(VALUE._col0), <span class="built_in">count</span>(VALUE._col1) <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           keys: KEY._col0 (type: <span class="type">int</span>)              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           mode: mergepartial                       <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           outputColumnNames: _col0, _col1, _col2   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           Statistics: Num <span class="keyword">rows</span>: <span class="number">1</span> Data size: <span class="number">6570</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>           <span class="keyword">Select</span> Operator                          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>             expressions: _col0 (type: <span class="type">int</span>), (_col1 <span class="operator">/</span> _col2) (type: <span class="keyword">double</span>) <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>             outputColumnNames: _col0, _col1        <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>             Statistics: Num <span class="keyword">rows</span>: <span class="number">1</span> Data size: <span class="number">6570</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>             File Output Operator                   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>               compressed: <span class="literal">false</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>               Statistics: Num <span class="keyword">rows</span>: <span class="number">1</span> Data size: <span class="number">6570</span> Basic stats: COMPLETE <span class="keyword">Column</span> stats: <span class="keyword">NONE</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>               <span class="keyword">table</span>:                               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                   input format: org.apache.hadoop.mapred.SequenceFileInputFormat <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                   output format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                   serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                                                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>   Stage: Stage<span class="number">-0</span>                                   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>     <span class="keyword">Fetch</span> Operator                                 <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       limit: <span class="number">-1</span>                                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>       Processor Tree:                              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>         ListSink                                   <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>                                                    <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------+</span></span><br><span class="line"><span class="number">53</span> <span class="keyword">rows</span> selected (<span class="number">0.063</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>查看详细执行计划  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> explain extended <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp;</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> explain extended <span class="keyword">select</span> deptno, <span class="built_in">avg</span>(sal) avg_sal <span class="keyword">from</span> emp <span class="keyword">group</span> <span class="keyword">by</span> deptno;</span><br></pre></td></tr></table></figure>
<h2 id="10-2-Fetch抓取"><a href="#10-2-Fetch抓取" class="headerlink" title="10.2 Fetch抓取"></a>10.2 Fetch抓取</h2></li>
</ul>
</li>
</ol>
<ul>
<li>Fetch抓取是指，Hive中对某些情况的查询可以不必使用MapReduce计算。</li>
<li>例如：SELECT * FROM employees;在这种情况下，Hive可以简单地读取employee对应的存储目录下的文件，然后输出查询结果到控制台。</li>
<li>在hive-default.xml.template文件中hive.fetch.task.conversion默认是more，老版本hive默认是minimal，该属性修改为more以后，在全局查找、字段查找、limit查找等都不走mapreduce。  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.fetch.task.conversion<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>more<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">      Expects one of [none, minimal, more].</span><br><span class="line">      Some select queries can be converted to single FETCH task minimizing latency.</span><br><span class="line">      Currently the query should be single sourced not having any subquery and should not have any aggregations or distincts (which incurs RS), lateral views and joins.</span><br><span class="line">      0. none : disable hive.fetch.task.conversion</span><br><span class="line">      1. minimal : SELECT STAR, FILTER on partition columns, LIMIT only</span><br><span class="line">      2. more  : SELECT, FILTER, LIMIT only (support TABLESAMPLE and virtual columns)</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ul>
<ol>
<li>案例实操：<ol>
<li>把hive.fetch.task.conversion设置成none，然后执行查询语句，都会执行mapreduce程序。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; <span class="built_in">set</span> hive.fetch.task.conversion=none;</span><br><span class="line">hive (default)&gt; select * from emp;</span><br><span class="line">hive (default)&gt; select ename from emp;</span><br><span class="line">hive (default)&gt; select ename from emp <span class="built_in">limit</span> 3;</span><br></pre></td></tr></table></figure></li>
<li>把hive.fetch.task.conversion设置成more，然后执行查询语句，如下查询方式都不会执行mapreduce程序。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; <span class="built_in">set</span> hive.fetch.task.conversion=more;</span><br><span class="line">hive (default)&gt; select * from emp;</span><br><span class="line">hive (default)&gt; select ename from emp;</span><br><span class="line">hive (default)&gt; select ename from emp <span class="built_in">limit</span> 3;</span><br></pre></td></tr></table></figure>
<h2 id="10-3-本地模式"><a href="#10-3-本地模式" class="headerlink" title="10.3 本地模式"></a>10.3 本地模式</h2></li>
</ol>
</li>
</ol>
<ul>
<li>大多数的Hadoop Job是需要Hadoop提供的完整的可扩展性来处理大数据集的。不过，有时Hive的输入数据量是非常小的。在这种情况下，为查询触发执行任务消耗的时间可能会比实际job的执行时间要多的多。对于大多数这种情况，Hive可以通过本地模式在单台机器上处理所有的任务。对于小数据集，执行时间可以明显被缩短。</li>
<li>用户可以通过设置hive.exec.mode.local.auto的值为true，来让Hive在适当的时候自动启动这个优化。  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- //开启本地mr</span></span><br><span class="line"><span class="keyword">set</span> hive.exec.mode.local.auto<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"><span class="comment">-- 设置local mr的最大输入数据量，当输入数据量小于这个值时采用local  mr的方式，默认为134217728，即128M</span></span><br><span class="line"><span class="keyword">set</span> hive.exec.mode.local.auto.inputbytes.max<span class="operator">=</span><span class="number">134217728</span>;</span><br><span class="line"><span class="comment">-- 设置local mr的最大输入文件个数，当输入文件个数小于这个值时采用local mr的方式，默认为4</span></span><br><span class="line"><span class="keyword">set</span> hive.exec.mode.local.auto.input.files.max<span class="operator">=</span><span class="number">4</span>;</span><br></pre></td></tr></table></figure></li>
</ul>
<ol>
<li>开启本地模式，并执行查询语句 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">set</span> hive.exec.mode.local.auto<span class="operator">=</span><span class="literal">true</span>; </span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp cluster <span class="keyword">by</span> deptno;</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">1.328</span> seconds, Fetched: <span class="number">14</span> <span class="type">row</span>(s)</span><br></pre></td></tr></table></figure></li>
<li>关闭本地模式，并执行查询语句 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">set</span> hive.exec.mode.local.auto<span class="operator">=</span><span class="literal">false</span>; </span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp cluster <span class="keyword">by</span> deptno;</span><br><span class="line"><span class="type">Time</span> taken: <span class="number">20.09</span> seconds, Fetched: <span class="number">14</span> <span class="type">row</span>(s)</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="10-4-表的优化"><a href="#10-4-表的优化" class="headerlink" title="10.4 表的优化"></a>10.4 表的优化</h2><h3 id="10-4-1-小表大表Join-MapJoin-内连接场景"><a href="#10-4-1-小表大表Join-MapJoin-内连接场景" class="headerlink" title="10.4.1 小表大表Join(MapJoin)内连接场景"></a>10.4.1 小表大表Join(MapJoin)内连接场景</h3><ul>
<li>将key相对分散，并且数据量小的表放在join的左边，这样可以有效减少内存溢出错误发生的几率；再进一步，可以使用map join让小的维度表（1000条以下的记录条数）先进内存。在map端完成join。<blockquote>
<p>实际测试发现：新版的hive已经对小表JOIN大表和大表JOIN小表进行了优化。小表放在左边和右边已经没有明显区别。</p>
</blockquote>
</li>
<li>案例实操<ol>
<li>需求测试大表JOIN小表和小表JOIN大表的效率</li>
<li>开启MapJoin参数设置<ol>
<li>设置自动选择Mapjoin <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.auto.convert.join <span class="operator">=</span> <span class="literal">true</span>; 默认为<span class="literal">true</span></span><br></pre></td></tr></table></figure></li>
<li>大表小表的阈值设置（默认25M以下认为是小表）： <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.mapjoin.smalltable.filesize <span class="operator">=</span> <span class="number">25000000</span>;</span><br></pre></td></tr></table></figure></li>
<li>MapJoin工作机制<br> <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16355531696295.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>建大表、小表和JOIN后表的语句 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">-- 创建大表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> bigtable (</span><br><span class="line">     id        <span class="type">bigint</span>,</span><br><span class="line">     t         <span class="type">bigint</span>,</span><br><span class="line">     uid       string,</span><br><span class="line">     keyword   string,</span><br><span class="line">     url_rank  <span class="type">int</span>,</span><br><span class="line">     click_num <span class="type">int</span>,</span><br><span class="line">     click_url string</span><br><span class="line"> ) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line"> <span class="comment">-- 创建小表</span></span><br><span class="line"> <span class="keyword">create</span> <span class="keyword">table</span> smalltable (</span><br><span class="line">     id        <span class="type">bigint</span>,</span><br><span class="line">     t         <span class="type">bigint</span>,</span><br><span class="line">     uid       string,</span><br><span class="line">     keyword   string,</span><br><span class="line">     url_rank  <span class="type">int</span>,</span><br><span class="line">     click_num <span class="type">int</span>,</span><br><span class="line">     click_url string</span><br><span class="line"> ) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line"> </span><br><span class="line"> <span class="comment">-- 创建join后表的语句</span></span><br><span class="line"> <span class="keyword">create</span> <span class="keyword">table</span> jointable (</span><br><span class="line">     id        <span class="type">bigint</span>,</span><br><span class="line">     t         <span class="type">bigint</span>,</span><br><span class="line">     uid       string,</span><br><span class="line">     keyword   string,</span><br><span class="line">     url_rank  <span class="type">int</span>,</span><br><span class="line">     click_num <span class="type">int</span>,</span><br><span class="line">     click_url string</span><br><span class="line"> ) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li>分别向大表和小表中导入数据 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/hive-3.1.2/datas/bigtable&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> bigtable;</span><br><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span>load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/hive-3.1.2/datas/smalltable&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> smalltable;</span><br></pre></td></tr></table></figure></li>
<li>小表JOIN大表语句 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> jointable</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">       b.id, </span><br><span class="line">       b.t, </span><br><span class="line">       b.uid, </span><br><span class="line">       b.keyword, </span><br><span class="line">       b.url_rank, </span><br><span class="line">       b.click_num, </span><br><span class="line">       b.click_url</span><br><span class="line"><span class="keyword">from</span> smalltable s</span><br><span class="line">         <span class="keyword">join</span> bigtable b <span class="keyword">on</span> b.id <span class="operator">=</span> s.id;</span><br></pre></td></tr></table></figure></li>
<li>执行大表JOIN小表语句 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> jointable</span><br><span class="line"><span class="keyword">select</span> </span><br><span class="line">       b.id, </span><br><span class="line">       b.t, </span><br><span class="line">       b.uid, </span><br><span class="line">       b.keyword, </span><br><span class="line">       b.url_rank, </span><br><span class="line">       b.click_num, </span><br><span class="line">       b.click_url</span><br><span class="line"><span class="keyword">from</span> bigtable  b</span><br><span class="line">    <span class="keyword">join</span> smalltable  s <span class="keyword">on</span> s.id <span class="operator">=</span> b.id;</span><br></pre></td></tr></table></figure>
<h3 id="10-4-2-大表Join大表"><a href="#10-4-2-大表Join大表" class="headerlink" title="10.4.2 大表Join大表"></a>10.4.2 大表Join大表</h3></li>
</ol>
</li>
</ol>
</li>
</ul>
<ol>
<li>大表和大表join时，MR一定执行ReduceJoin操作，需要注意优化的点就是ReduceJoin带来的问题！！！<h4 id="10-4-2-1-空Key过滤（针对数据倾斜的一种解决方案）"><a href="#10-4-2-1-空Key过滤（针对数据倾斜的一种解决方案）" class="headerlink" title="10.4.2.1 空Key过滤（针对数据倾斜的一种解决方案）"></a>10.4.2.1 空Key过滤（针对数据倾斜的一种解决方案）</h4></li>
<li>当大表和大表Join走MR的时候，相同Key对应的values会进入一个Reduce，如果出现大量相同搞得key，会导致数据倾斜</li>
<li>案例实操<ol>
<li>创建原始数据表、空id表、合并后数据表 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 创建空id表</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> nullidtable (</span><br><span class="line">    id        <span class="type">bigint</span>,</span><br><span class="line">    t         <span class="type">bigint</span>,</span><br><span class="line">    uid       string,</span><br><span class="line">    keyword   string,</span><br><span class="line">    url_rank  <span class="type">int</span>,</span><br><span class="line">    click_num <span class="type">int</span>,</span><br><span class="line">    click_url string</span><br><span class="line">) <span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li>分别加载原始数据和空id数据到对应表中 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> load data <span class="keyword">local</span> inpath <span class="string">&#x27;/opt/module/hive-3.1.2/datas/nullid&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> nullidtable;</span><br></pre></td></tr></table></figure></li>
<li>测试不过滤空id <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">insert</span> overwrite <span class="keyword">table</span> jointable <span class="keyword">select</span> n.<span class="operator">*</span> <span class="keyword">from</span> nullidtable n <span class="keyword">left</span> <span class="keyword">join</span> bigtable o <span class="keyword">on</span> n.id <span class="operator">=</span> o.id;</span><br></pre></td></tr></table></figure></li>
<li>测试过滤空id <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">insert</span> overwrite <span class="keyword">table</span> jointable <span class="keyword">select</span> n.<span class="operator">*</span> <span class="keyword">from</span> (<span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> nullidtable <span class="keyword">where</span> id <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">null</span> ) n  <span class="keyword">left</span> <span class="keyword">join</span> bigtable o <span class="keyword">on</span> n.id <span class="operator">=</span> o.id;</span><br></pre></td></tr></table></figure>
<h4 id="10-4-2-1-SMB-Sort-Merge-Bucket-join"><a href="#10-4-2-1-SMB-Sort-Merge-Bucket-join" class="headerlink" title="10.4.2.1 SMB(Sort Merge Bucket join)"></a>10.4.2.1 SMB(Sort Merge Bucket join)</h4></li>
</ol>
</li>
<li>数据量超级大的时候可能导致Join时间过长，或者直接导致Job失败</li>
<li>原理：从建表的时候就将其创建为分桶表，两表的关联字段作为分桶字段，后续做Join的时候就对桶进行Join，避免了每一条数据进行Join</li>
<li>案例实操<ul>
<li>创建第二张大表  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> bigtable2 (</span><br><span class="line">    id        <span class="type">bigint</span>,</span><br><span class="line">    t         <span class="type">bigint</span>,</span><br><span class="line">    uid       string,</span><br><span class="line">    keyword   string,</span><br><span class="line">    url_rank  <span class="type">int</span>,</span><br><span class="line">    click_num <span class="type">int</span>,</span><br><span class="line">    click_url string</span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line">    </span><br><span class="line">load data <span class="keyword">local</span> inpath <span class="string">&#x27;/home/atguigu/hive/table_optimize/bigtable&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> bigtable2;</span><br></pre></td></tr></table></figure></li>
<li>测试大表直接JOIN 耗时51.176  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> jointable</span><br><span class="line"><span class="keyword">select</span> b.id,</span><br><span class="line">       b.t,</span><br><span class="line">       b.uid,</span><br><span class="line">       b.keyword,</span><br><span class="line">       b.url_rank,</span><br><span class="line">       b.click_num,</span><br><span class="line">       b.click_url</span><br><span class="line"><span class="keyword">from</span> bigtable s</span><br><span class="line"><span class="keyword">join</span> bigtable2 b <span class="keyword">on</span> b.id <span class="operator">=</span> s.id;</span><br><span class="line"></span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">51.176</span> seconds)</span><br></pre></td></tr></table></figure></li>
<li>创建分桶表1, 创建分桶表2, 桶的个数不要超过可用CPU的核数  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> bigtable_buck1 (</span><br><span class="line">    id        <span class="type">bigint</span>,</span><br><span class="line">    t         <span class="type">bigint</span>,</span><br><span class="line">    uid       string,</span><br><span class="line">    keyword   string,</span><br><span class="line">    url_rank  <span class="type">int</span>,</span><br><span class="line">    click_num <span class="type">int</span>,</span><br><span class="line">    click_url string</span><br><span class="line">)</span><br><span class="line">clustered <span class="keyword">by</span> (id)</span><br><span class="line">sorted <span class="keyword">by</span> (id)</span><br><span class="line"><span class="keyword">into</span> <span class="number">8</span> buckets</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> bigtable_buck2 (</span><br><span class="line">    id        <span class="type">bigint</span>,</span><br><span class="line">    t         <span class="type">bigint</span>,</span><br><span class="line">    uid       string,</span><br><span class="line">    keyword   string,</span><br><span class="line">    url_rank  <span class="type">int</span>,</span><br><span class="line">    click_num <span class="type">int</span>,</span><br><span class="line">    click_url string</span><br><span class="line">)</span><br><span class="line">clustered <span class="keyword">by</span> (id)</span><br><span class="line">sorted <span class="keyword">by</span> (id)</span><br><span class="line"><span class="keyword">into</span> <span class="number">8</span> buckets</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> <span class="string">&#x27;\t&#x27;</span>;</span><br><span class="line"></span><br><span class="line">load data inpath <span class="string">&#x27;/bigtable&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> bigtable_buck1;</span><br><span class="line">load data inpath <span class="string">&#x27;/bigtable&#x27;</span> <span class="keyword">into</span> <span class="keyword">table</span> bigtable_buck2;</span><br></pre></td></tr></table></figure></li>
<li>设置参数  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.optimize.bucketmapjoin <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.optimize.bucketmapjoin.sortedmerge <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.input.format<span class="operator">=</span>org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat;</span><br></pre></td></tr></table></figure></li>
<li>测试 耗时23.272 seconds  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> jointable</span><br><span class="line"><span class="keyword">select</span> b.id,</span><br><span class="line">       b.t,</span><br><span class="line">       b.uid,</span><br><span class="line">       b.keyword,</span><br><span class="line">       b.url_rank,</span><br><span class="line">       b.click_num,</span><br><span class="line">       b.click_url</span><br><span class="line"><span class="keyword">from</span> bigtable_buck1 s</span><br><span class="line"><span class="keyword">join</span> bigtable_buck2 b <span class="keyword">on</span> b.id <span class="operator">=</span> s.id;</span><br><span class="line"></span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">23.272</span> seconds)</span><br></pre></td></tr></table></figure>
<h3 id="10-4-3-Group-By"><a href="#10-4-3-Group-By" class="headerlink" title="10.4.3 Group By"></a>10.4.3 Group By</h3></li>
</ul>
</li>
</ol>
<ul>
<li>分组聚合操作时，如果一个组内出现大量的数据，都会交给一个reduce处理，很可能会造成数据倾斜<br>  <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16355799864007.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>解决思路<ol>
<li>是否在Map端进行聚合，默认为True<br> <code>set hive.map.aggr = true</code></li>
<li>在Map端进行聚合操作的条目数目<br><code>set   = 100000</code> </li>
<li>有数据倾斜的时候进行负载均衡（默认是false）<br> <code>set hive.groupby.skewindata = true</code><br> <font color ='red' >当选项设定为 true，生成的查询计划会有两个MR Job</font>。第一个MR Job中，Map的输出结果会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是<font color ='red' >相同的Group By Key有可能被分发到不同的Reduce中</font>，从而达到负载均衡的目的；第二个MR Job再根据预处理的数据结果按照Group By Key分布到Reduce中（这个过程可以保证相同的Group By Key被分布到同一个Reduce中），最后完成最终的聚合操作。</li>
</ol>
<ul>
<li>思路：会多执行一个Job做数据的负载均衡 解决数据倾斜！</li>
</ul>
</li>
<li>测试<ul>
<li>直接执行  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> </span><br><span class="line">       substr(birth, <span class="number">0</span>, <span class="number">7</span>), </span><br><span class="line">       <span class="built_in">count</span>(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">from</span> person</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> substr(birth, <span class="number">0</span>, <span class="number">7</span>)</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> <span class="number">2</span> <span class="keyword">desc</span>;</span><br><span class="line"></span><br><span class="line">INFO  : MapReduce Jobs Launched:</span><br><span class="line">INFO  : Stage<span class="operator">-</span>Stage<span class="number">-1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">1</span>   Cumulative CPU: <span class="number">2.12</span> sec   HDFS Read: <span class="number">14687</span> HDFS Write: <span class="number">138</span> SUCCESS</span><br><span class="line">INFO  : Total MapReduce CPU <span class="type">Time</span> Spent: <span class="number">2</span> seconds <span class="number">120</span> msec</span><br></pre></td></tr></table></figure></li>
<li>修改参数执行   <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.groupby.skewindata <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> </span><br><span class="line">       substr(birth, <span class="number">0</span>, <span class="number">7</span>), </span><br><span class="line">       <span class="built_in">count</span>(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">from</span> person</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> substr(birth, <span class="number">0</span>, <span class="number">7</span>)</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> <span class="number">2</span> <span class="keyword">desc</span>;</span><br><span class="line"></span><br><span class="line">INFO  : MapReduce Jobs Launched:</span><br><span class="line">INFO  : Stage<span class="operator">-</span>Stage<span class="number">-1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">1</span>   Cumulative CPU: <span class="number">2.47</span> sec   HDFS Read: <span class="number">14399</span> HDFS Write: <span class="number">153</span> SUCCESS</span><br><span class="line">INFO  : Stage<span class="operator">-</span>Stage<span class="number">-2</span>: Map: <span class="number">1</span>  Reduce: <span class="number">1</span>   Cumulative CPU: <span class="number">2.08</span> sec   HDFS Read: <span class="number">7574</span> HDFS Write: <span class="number">138</span> SUCCESS</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h3 id="10-4-4-Count-Distinct-去重统计"><a href="#10-4-4-Count-Distinct-去重统计" class="headerlink" title="10.4.4 Count(Distinct) 去重统计"></a>10.4.4 Count(Distinct) 去重统计</h3><p>数据量小的时候无所谓，数据量大的情况下，由于COUNT DISTINCT操作需要用一个Reduce Task来完成，这一个Reduce需要处理的数据量太大，就会导致整个Job很难完成，一般COUNT DISTINCT使用先GROUP BY再COUNT的方式替换,但是需要注意group by造成的数据倾斜问题.</p>
<ol>
<li>设置5个reduce个数 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> mapreduce.job.reduces <span class="operator">=</span> <span class="number">5</span>;</span><br></pre></td></tr></table></figure></li>
<li>执行去重id查询 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">count</span>(<span class="keyword">distinct</span> id) <span class="keyword">from</span> bigtable;</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">1</span>   Cumulative CPU: <span class="number">7.12</span> sec   HDFS Read: <span class="number">120741990</span> HDFS Write: <span class="number">7</span> SUCCESS</span><br><span class="line">Total MapReduce CPU <span class="type">Time</span> Spent: <span class="number">7</span> seconds <span class="number">120</span> msec</span><br><span class="line">OK</span><br><span class="line">c0</span><br><span class="line"><span class="number">100001</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">23.607</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)</span><br></pre></td></tr></table></figure></li>
<li>采用GROUP by去重id <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hive (<span class="keyword">default</span>)<span class="operator">&gt;</span> <span class="keyword">select</span> <span class="built_in">count</span>(id) <span class="keyword">from</span> (<span class="keyword">select</span> id <span class="keyword">from</span> bigtable <span class="keyword">group</span> <span class="keyword">by</span> id) a;</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-1</span>: Map: <span class="number">1</span>  Reduce: <span class="number">5</span>   Cumulative CPU: <span class="number">17.53</span> sec   HDFS Read: <span class="number">120752703</span> HDFS Write: <span class="number">580</span> SUCCESS</span><br><span class="line">Stage<span class="operator">-</span>Stage<span class="number">-2</span>: Map: <span class="number">1</span>  Reduce: <span class="number">1</span>   Cumulative CPU: <span class="number">4.29</span> sec2   HDFS Read: <span class="number">9409</span> HDFS Write: <span class="number">7</span> SUCCESS</span><br><span class="line">Total MapReduce CPU <span class="type">Time</span> Spent: <span class="number">21</span> seconds <span class="number">820</span> msec</span><br><span class="line">OK</span><br><span class="line">_c0</span><br><span class="line"><span class="number">100001</span></span><br><span class="line"><span class="type">Time</span> taken: <span class="number">50.795</span> seconds, Fetched: <span class="number">1</span> <span class="type">row</span>(s)</span><br></pre></td></tr></table></figure></li>
<li>虽然会多用一个Job来完成，但在数据量大的情况下，可以避免Reduce因为数据量大导致失败，所以是值得的。</li>
</ol>
<h3 id="10-4-5-笛卡尔积"><a href="#10-4-5-笛卡尔积" class="headerlink" title="10.4.5 笛卡尔积"></a>10.4.5 笛卡尔积</h3><p>尽量避免笛卡尔积，join的时候不加on条件，或者无效的on条件，Hive只能使用1个reducer来完成笛卡尔积。</p>
<h3 id="10-4-6-行列过滤"><a href="#10-4-6-行列过滤" class="headerlink" title="10.4.6 行列过滤"></a>10.4.6 行列过滤</h3><ul>
<li>列处理：在SELECT中，只拿需要的列，如果有分区，尽量使用分区过滤，少用SELECT *。</li>
<li>行处理：在分区剪裁中，当使用外关联时，如果将副表的过滤条件写在Where后面，那么就会先全表关联，之后再过滤，比如：</li>
<li>案例实操：<ol>
<li>测试先关联两张表，再用where条件过滤 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> </span><br><span class="line">       o.id </span><br><span class="line"><span class="keyword">from</span> bigtable b</span><br><span class="line"><span class="keyword">join</span> bigtable o <span class="keyword">on</span>  o.id <span class="operator">=</span> b.id</span><br><span class="line"><span class="keyword">where</span> o.id <span class="operator">&lt;=</span> <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"><span class="number">1</span>,<span class="number">081</span> <span class="keyword">rows</span> selected (<span class="number">18.979</span> seconds)</span><br></pre></td></tr></table></figure></li>
<li>通过子查询后，再关联表 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> </span><br><span class="line">       b.id</span><br><span class="line"><span class="keyword">from</span> bigtable b</span><br><span class="line"><span class="keyword">join</span> (<span class="keyword">select</span> </span><br><span class="line">             id</span><br><span class="line">    <span class="keyword">from</span> bigtable</span><br><span class="line">    <span class="keyword">where</span> id <span class="operator">&lt;=</span> <span class="number">10</span>) o </span><br><span class="line"><span class="keyword">on</span> b.id <span class="operator">=</span> o.id;</span><br><span class="line"></span><br><span class="line"><span class="number">1</span>,<span class="number">081</span> <span class="keyword">rows</span> selected (<span class="number">17.753</span> seconds)</span><br></pre></td></tr></table></figure>
<h3 id="10-4-7-分区"><a href="#10-4-7-分区" class="headerlink" title="10.4.7 分区"></a>10.4.7 分区</h3>详见7.1章。</li>
</ol>
</li>
</ul>
<h3 id="10-4-8-分桶"><a href="#10-4-8-分桶" class="headerlink" title="10.4.8 分桶"></a>10.4.8 分桶</h3><pre><code>详见7.2章。
</code></pre>
<h2 id="10-5-合理设置Map及Reduce数"><a href="#10-5-合理设置Map及Reduce数" class="headerlink" title="10.5 合理设置Map及Reduce数"></a>10.5 合理设置Map及Reduce数</h2><ol>
<li>通常情况下，作业会产生一个或者多个map任务。<ul>
<li>主要的决定因素有：input的文件总个数，input的文件大小，集群设置的文件块大小。</li>
</ul>
</li>
<li>是不是map数越多越好？<ul>
<li>答案是否定的。如果一个任务有很多小文件（远远小于块大小128m），则每个小文件也会被当做一个片，用一个map任务来完成，而一个map任务启动和初始化的时间远远大于逻辑处理的时间，就会造成很大的资源浪费。而且，同时可执行的map数是受限的。</li>
</ul>
</li>
<li>是不是保证每个map处理接近128m的文件块，就高枕无忧了？<ul>
<li>答案也是不一定。比如有一个127m的文件，正常会用一个map去完成，但这个文件只有一个或者两个小字段，却有几千万的记录，如果map处理的逻辑比较复杂，用一个map任务去做，肯定也比较耗时。</li>
</ul>
</li>
</ol>
<ul>
<li>针对上面的问题2和3，我们需要采取两种方式来解决：即减少map数和增加map数；</li>
</ul>
<h3 id="10-5-1-复杂文件增加Map数"><a href="#10-5-1-复杂文件增加Map数" class="headerlink" title="10.5.1 复杂文件增加Map数"></a>10.5.1 复杂文件增加Map数</h3><ul>
<li>当input的文件都很大，任务逻辑复杂，map执行非常慢的时候，可以考虑增加Map数，来使得每个map处理的数据量减少，从而提高任务的执行效率。</li>
<li>增加map的方法为：根据<br>computeSliteSize(Math.max(minSize,Math.min(maxSize,blocksize)))=blocksize=128M公式，调整maxSize最大值。让maxSize最大值低于blocksize就可以增加map的个数。</li>
<li>案例实操：<ol>
<li>执行查询 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="built_in">count</span>(<span class="operator">*</span>) <span class="keyword">from</span> bigtable;</span><br><span class="line"></span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number <span class="keyword">of</span> mappers: <span class="number">1</span>; number <span class="keyword">of</span> reducers: <span class="number">1</span></span><br></pre></td></tr></table></figure></li>
<li>设置最大切片值为100个字节 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> mapreduce.input.fileinputformat.split.maxsize<span class="operator">=</span><span class="number">10240</span>;</span><br><span class="line"></span><br><span class="line">Hadoop job information <span class="keyword">for</span> Stage<span class="number">-1</span>: number <span class="keyword">of</span> mappers: <span class="number">12613</span>; number <span class="keyword">of</span> reducers: <span class="number">1</span></span><br></pre></td></tr></table></figure>
<h3 id="10-5-2-小文件进行合并"><a href="#10-5-2-小文件进行合并" class="headerlink" title="10.5.2 小文件进行合并"></a>10.5.2 小文件进行合并</h3></li>
</ol>
</li>
</ul>
<ol>
<li>在map执行前合并小文件，减少map数：CombineHiveInputFormat具有对小文件进行合并的功能（系统默认的格式）。HiveInputFormat没有对小文件合并功能。 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.input.format<span class="operator">=</span> org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;</span><br></pre></td></tr></table></figure></li>
<li>在Map-Reduce的任务结束时合并小文件的设置：<ul>
<li>在map-only任务结束时合并小文件，默认true  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SET</span> hive.merge.mapfiles <span class="operator">=</span> <span class="literal">true</span>;</span><br></pre></td></tr></table></figure></li>
<li>在map-reduce任务结束时合并小文件，默认false  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SET</span> hive.merge.mapredfiles <span class="operator">=</span> <span class="literal">true</span>;</span><br></pre></td></tr></table></figure></li>
<li>合并文件的大小，默认256M  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SET</span> hive.merge.size.per.task <span class="operator">=</span> <span class="number">268435456</span>;</span><br></pre></td></tr></table></figure></li>
<li>当输出文件的平均大小小于该值时，启动一个独立的map-reduce任务进行文件merge  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SET</span> hive.merge.smallfiles.avgsize <span class="operator">=</span> <span class="number">16777216</span>;</span><br></pre></td></tr></table></figure>
<h3 id="10-5-3-合理设置Reduce数"><a href="#10-5-3-合理设置Reduce数" class="headerlink" title="10.5.3 合理设置Reduce数"></a>10.5.3 合理设置Reduce数</h3></li>
</ul>
</li>
<li>调整reduce个数方法一<ol>
<li>每个Reduce处理的数据量默认是256MB <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.exec.reducers.bytes.per.reducer<span class="operator">=</span><span class="number">256000000</span></span><br></pre></td></tr></table></figure></li>
<li>每个任务最大的reduce数，默认为1009 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive.exec.reducers.max<span class="operator">=</span><span class="number">1009</span></span><br></pre></td></tr></table></figure></li>
<li>计算reducer数的公式 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">N<span class="operator">=</span><span class="built_in">min</span>(参数<span class="number">2</span>，总输入数据量<span class="operator">/</span>参数<span class="number">1</span>)</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li>调整reduce个数方法二<ol>
<li>在hadoop的mapred-default.xml文件中修改，设置每个job的Reduce个数 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> mapreduce.job.reduces <span class="operator">=</span> <span class="number">15</span>;</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li>reduce个数并不是越多越好<ol>
<li>过多的启动和初始化reduce也会消耗时间和资源；</li>
<li>另外，有多少个reduce，就会有多少个输出文件，如果生成了很多个小文件，那么如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题；</li>
<li>在设置reduce个数的时候也需要考虑这两个原则：处理大数据量利用合适的reduce数；使单个reduce任务处理数据量大小要合适；</li>
</ol>
</li>
</ol>
<h3 id="10-6-并行执行"><a href="#10-6-并行执行" class="headerlink" title="10.6 并行执行"></a>10.6 并行执行</h3><ul>
<li>Hive会将一个查询转化成一个或者多个阶段。这样的阶段可以是MapReduce阶段、抽样阶段、合并阶段、limit阶段。或者Hive执行过程中可能需要的其他阶段。默认情况下，Hive一次只会执行一个阶段。不过，某个特定的job可能包含众多的阶段，而这些阶段可能并非完全互相依赖的，也就是说有些阶段是可以并行执行的，这样可能使得整个job的执行时间缩短。不过，如果有更多的阶段可以并行执行，那么job可能就越快完成。</li>
<li>通过设置参数hive.exec.parallel值为true，就可以开启并发执行。不过，在共享集群中，需要注意下，如果job中并行阶段增多，那么集群利用率就会增加。当然，得是在系统资源比较空闲的时候才有优势，否则，没资源，并行也起不来。  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 打开任务并行执行</span></span><br><span class="line"><span class="keyword">set</span> hive.exec.parallel<span class="operator">=</span><span class="literal">true</span>;</span><br><span class="line"><span class="comment">-- 同一个sql允许最大并行度，默认为8。</span></span><br><span class="line"><span class="keyword">set</span> hive.exec.parallel.thread.number<span class="operator">=</span><span class="number">8</span>; </span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="10-7-严格模式"><a href="#10-7-严格模式" class="headerlink" title="10.7 严格模式"></a>10.7 严格模式</h3><p>Hive可以通过设置防止一些危险操作：</p>
<ol>
<li>分区表不使用分区过滤<ul>
<li>将hive.strict.checks.no.partition.filter设置为true时，对于分区表，除非where语句中含有分区字段过滤条件来限制范围，否则不允许执行。换句话说，就是用户不允许扫描所有分区。进行这个限制的原因是，通常分区表都拥有非常大的数据集，而且数据增加迅速。没有进行分区限制的查询可能会消耗令人不可接受的巨大资源来处理这个表。</li>
</ul>
</li>
<li>使用order by没有limit过滤<ul>
<li>将hive.strict.checks.orderby.no.limit设置为true时，对于使用了order by语句的查询，要求必须使用limit语句。因为order by为了执行排序过程会将所有的结果数据分发到同一个Reducer中进行处理，强制要求用户增加这个LIMIT语句可以防止Reducer额外执行很长一段时间。</li>
</ul>
</li>
<li>笛卡尔积<ul>
<li>将hive.strict.checks.cartesian.product设置为true时，会限制笛卡尔积的查询。对关系型数据库非常了解的用户可能期望在 执行JOIN查询的时候不使用ON语句而是使用where语句，这样关系数据库的执行优化器就可以高效地将WHERE语句转化成那个ON语句。不幸的是，Hive并不会执行这种优化，因此，如果表足够大，那么这个查询就会出现不可控的情况。</li>
</ul>
</li>
</ol>
<h2 id="10-8-JVM重用"><a href="#10-8-JVM重用" class="headerlink" title="10.8 JVM重用"></a>10.8 JVM重用</h2><pre><code>详见hadoop优化文档中jvm重用
</code></pre>
<h2 id="10-9-压缩"><a href="#10-9-压缩" class="headerlink" title="10.9 压缩"></a>10.9 压缩</h2><pre><code>详见第9章。
</code></pre>
<h1 id="十一、Hive实战"><a href="#十一、Hive实战" class="headerlink" title="十一、Hive实战"></a>十一、Hive实战</h1><h2 id="11-1-需求描述"><a href="#11-1-需求描述" class="headerlink" title="11.1 需求描述"></a>11.1 需求描述</h2><p>统计硅谷影音视频网站的常规指标，各种TopN指标：</p>
<ul>
<li>统计视频观看数Top10</li>
<li>统计视频类别热度Top10</li>
<li>统计出视频观看数最高的20个视频的所属类别以及类别包含Top20视频的个数</li>
<li>统计视频观看数Top50所关联视频的所属类别Rank</li>
<li>统计每个类别中的视频热度Top10,以Music为例</li>
<li>统计每个类别视频观看数Top10</li>
<li>统计上传视频最多的用户Top10以及他们上传的视频观看次数在前20的视频 </li>
</ul>
<h2 id="11-2-数据结构"><a href="#11-2-数据结构" class="headerlink" title="11.2 数据结构"></a>11.2 数据结构</h2><ol>
<li>视频表<table>
<thead>
<tr>
<th>字段</th>
<th>备注</th>
<th>详细描述</th>
</tr>
</thead>
<tbody><tr>
<td>videoId</td>
<td>视频唯一id（String）</td>
<td>11位字符串</td>
</tr>
<tr>
<td>uploader</td>
<td>视频上传者（String）</td>
<td>上传视频的用户名String</td>
</tr>
<tr>
<td>age</td>
<td>视频年龄（int）</td>
<td>视频在平台上的整数天</td>
</tr>
<tr>
<td>category</td>
<td>视频类别（Array<String>）</td>
<td>上传视频指定的视频分类</td>
</tr>
<tr>
<td>length</td>
<td>视频长度（Int）</td>
<td>整形数字标识的视频长度</td>
</tr>
<tr>
<td>views</td>
<td>观看次数（Int）</td>
<td>视频被浏览的次数</td>
</tr>
<tr>
<td>rate</td>
<td>视频评分（Double）</td>
<td>满分5分</td>
</tr>
<tr>
<td>Ratings</td>
<td>流量（Int）</td>
<td>视频的流量，整型数字</td>
</tr>
<tr>
<td>conments</td>
<td>评论数（Int）</td>
<td>一个视频的整数评论数</td>
</tr>
<tr>
<td>relatedId</td>
<td>相关视频id（Array<String>）</td>
<td>相关视频的id，最多20个</td>
</tr>
</tbody></table>
</li>
<li>用户表<table>
<thead>
<tr>
<th>字段</th>
<th>备注</th>
<th>字段类型</th>
</tr>
</thead>
<tbody><tr>
<td>uploader</td>
<td>上传者用户名</td>
<td>string</td>
</tr>
<tr>
<td>videos</td>
<td>上传视频数</td>
<td>int</td>
</tr>
<tr>
<td>friends</td>
<td>朋友数量</td>
<td>int</td>
</tr>
</tbody></table>
</li>
</ol>
<h2 id="11-3-准备工作"><a href="#11-3-准备工作" class="headerlink" title="11.3 准备工作"></a>11.3 准备工作</h2><h3 id="11-3-1-ETL"><a href="#11-3-1-ETL" class="headerlink" title="11.3.1 ETL"></a>11.3.1 ETL</h3><h3 id="11-3-2-准备表"><a href="#11-3-2-准备表" class="headerlink" title="11.3.2 准备表"></a>11.3.2 准备表</h3><ol>
<li>需要准备的表<ul>
<li>创建原始数据表：gulivideo_ori，gulivideo_user_ori，</li>
<li>创建最终表：gulivideo_orc，gulivideo_user_orc</li>
</ul>
</li>
<li>创建原始数据表：<ul>
<li>创建视频原始数据表：gulivideo_ori  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> gulivideo_ori (</span><br><span class="line">    videoId   string,</span><br><span class="line">    uploader  string,</span><br><span class="line">    age       <span class="type">int</span>,</span><br><span class="line">    category  <span class="keyword">array</span><span class="operator">&lt;</span>string<span class="operator">&gt;</span>,</span><br><span class="line">    length    <span class="type">int</span>,</span><br><span class="line">    `views`     <span class="type">int</span>,</span><br><span class="line">    rate      <span class="type">float</span>,</span><br><span class="line">    ratings   <span class="type">int</span>,</span><br><span class="line">    comments  <span class="type">int</span>,</span><br><span class="line">    relatedId <span class="keyword">array</span><span class="operator">&lt;</span>string<span class="operator">&gt;</span></span><br><span class="line">)</span><br><span class="line"><span class="type">row</span> format delimited fields terminated <span class="keyword">by</span> &quot;\t&quot;</span><br><span class="line">collection items terminated <span class="keyword">by</span> &quot;&amp;&quot;</span><br><span class="line">stored <span class="keyword">as</span> textfile;</span><br></pre></td></tr></table></figure></li>
<li>创建用户原始数据表: gulivideo_user_ori  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> gulivideo_user_ori(</span><br><span class="line">    uploader string,</span><br><span class="line">    videos <span class="type">int</span>,</span><br><span class="line">    friends <span class="type">int</span>)</span><br><span class="line"><span class="type">row</span> format delimited </span><br><span class="line">fields terminated <span class="keyword">by</span> &quot;\t&quot; </span><br><span class="line">stored <span class="keyword">as</span> textfile;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>创建orc存储格式带snappy压缩的表：<ul>
<li>gulivideo_orc  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> gulivideo_orc(</span><br><span class="line">    videoId string, </span><br><span class="line">    uploader string, </span><br><span class="line">    age <span class="type">int</span>, </span><br><span class="line">    category <span class="keyword">array</span><span class="operator">&lt;</span>string<span class="operator">&gt;</span>, </span><br><span class="line">    length <span class="type">int</span>, </span><br><span class="line">    views <span class="type">int</span>, </span><br><span class="line">    rate <span class="type">float</span>, </span><br><span class="line">    ratings <span class="type">int</span>, </span><br><span class="line">    comments <span class="type">int</span>,</span><br><span class="line">    relatedId <span class="keyword">array</span><span class="operator">&lt;</span>string<span class="operator">&gt;</span>)</span><br><span class="line">stored <span class="keyword">as</span> orc</span><br><span class="line">tblproperties(&quot;orc.compress&quot;<span class="operator">=</span>&quot;SNAPPY&quot;);</span><br></pre></td></tr></table></figure></li>
<li>gulivideo_user_orc  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> gulivideo_user_orc(</span><br><span class="line">    uploader string,</span><br><span class="line">    videos <span class="type">int</span>,</span><br><span class="line">    friends <span class="type">int</span>)</span><br><span class="line"><span class="type">row</span> format delimited </span><br><span class="line">fields terminated <span class="keyword">by</span> &quot;\t&quot; </span><br><span class="line">stored <span class="keyword">as</span> orc</span><br><span class="line">tblproperties(&quot;orc.compress&quot;<span class="operator">=</span>&quot;SNAPPY&quot;);</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>向ori表插入数据 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">load data inpath &quot;/gulivideo/video/output&quot; <span class="keyword">into</span> <span class="keyword">table</span> gulivideo_ori;</span><br><span class="line">load data inpath &quot;/gulivideo/user&quot; <span class="keyword">into</span> <span class="keyword">table</span> gulivideo_user_ori;</span><br></pre></td></tr></table></figure></li>
<li>向orc表插入数据 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> gulivideo_orc <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> gulivideo_ori;</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> gulivideo_user_orc <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> gulivideo_user_ori;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="11-3-3-安装Tez引擎"><a href="#11-3-3-安装Tez引擎" class="headerlink" title="11.3.3 安装Tez引擎"></a>11.3.3 安装Tez引擎</h3><p>Tez是一个Hive的运行引擎，性能优于MR。为什么优于MR呢？看下<br><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16356724726440.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ul>
<li>用Hive直接编写MR程序，假设有四个有依赖关系的MR作业，上图中，绿色是Reduce Task，云状表示写屏蔽，需要将中间结果持久化写到HDFS。</li>
<li>Tez可以将多个有依赖的作业转换为一个作业，这样只需写一次HDFS，且中间节点较少，从而大大提升作业的计算性能。</li>
<li>安装步骤<ol>
<li>将tez安装包拷贝到集群，并解压tar包 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 software]$ mkdir /opt/module/tez</span><br><span class="line">[atguigu@hadoop102 software]$ tar -zxvf /opt/software/tez-0.10.1-SNAPSHOT-minimal.tar.gz -C /opt/module/tez</span><br></pre></td></tr></table></figure></li>
<li>上传tez依赖到HDFS <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 software]$ hadoop fs -mkdir /tez</span><br><span class="line">[atguigu@hadoop102 software]$ hadoop fs -put /opt/software/tez-0.10.1-SNAPSHOT.tar.gz /tez</span><br></pre></td></tr></table></figure></li>
<li>新建$HADOOP_HOME/etc/hadoop/tez-site.xml添加如下内容： <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.lib.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>$&#123;fs.defaultFS&#125;/tez/tez-0.10.1-SNAPSHOT.tar.gz<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.use.cluster.hadoop-libs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.am.resource.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1024<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.am.resource.cpu.vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.container.max.java.heap.fraction<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>0.4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.task.resource.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1024<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>tez.task.resource.cpu.vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ul>
<ol start="4">
<li>修改Hadoop环境变量$HADOOP_HOME/etc/hadoop/shellprofile.d/tez.sh <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加Tez的Jar包相关信息</span></span><br><span class="line">hadoop_add_profile tez</span><br><span class="line"><span class="keyword">function</span> _tez_hadoop_classpath</span><br><span class="line">&#123;</span><br><span class="line">    hadoop_add_classpath <span class="string">&quot;<span class="variable">$HADOOP_HOME</span>/etc/hadoop&quot;</span> after</span><br><span class="line">    hadoop_add_classpath <span class="string">&quot;/opt/module/tez/*&quot;</span> after</span><br><span class="line">    hadoop_add_classpath <span class="string">&quot;/opt/module/tez/lib/*&quot;</span> after</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li>修改Hive的计算引擎$HIVE_HOME/conf/hive-site.xml <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.execution.engine<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>tez<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.tez.container.size<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1024<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>解决日志Jar包冲突 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 software]$ rm /opt/module/tez/lib/slf4j-log4j12-1.7.10.jar</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="11-4-业务分析"><a href="#11-4-业务分析" class="headerlink" title="11.4 业务分析"></a>11.4 业务分析</h2><ul>
<li>统计视频观看数Top10  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> videoId,</span><br><span class="line">       uploader,</span><br><span class="line">       age,</span><br><span class="line">       category,</span><br><span class="line">       length,</span><br><span class="line">       `views`,</span><br><span class="line">       rate,</span><br><span class="line">       ratings,</span><br><span class="line">       comments,</span><br><span class="line">       relatedId</span><br><span class="line"><span class="keyword">from</span> gulivideo_orc</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> `views` <span class="keyword">desc</span></span><br><span class="line">limit <span class="number">10</span>;</span><br></pre></td></tr></table></figure></li>
<li>统计视频类别热度Top10  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">       category_name,</span><br><span class="line">       <span class="built_in">count</span>(videoId) video_count</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line"><span class="keyword">select</span></span><br><span class="line">    videoId,category_name</span><br><span class="line"><span class="keyword">from</span> gulivideo_orc</span><br><span class="line"> <span class="keyword">lateral</span> <span class="keyword">view</span> explode(category) explode_category <span class="keyword">as</span> category_name</span><br><span class="line">) t1</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> category_name</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> video_count <span class="keyword">desc</span> limit <span class="number">10</span>;</span><br></pre></td></tr></table></figure></li>
<li>统计出视频观看数最高的20个视频的所属类别以及类别包含Top20视频的个数  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span></span><br><span class="line">       t2.category_name,</span><br><span class="line">       <span class="built_in">count</span>(videoId) video_count</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">         <span class="keyword">select</span></span><br><span class="line">                t1.videoId,</span><br><span class="line">                category_name</span><br><span class="line">         <span class="keyword">from</span> (</span><br><span class="line">                  <span class="keyword">select</span></span><br><span class="line">                         videoId,</span><br><span class="line">                         category,</span><br><span class="line">                         `views`</span><br><span class="line">                  <span class="keyword">from</span> gulivideo_orc</span><br><span class="line">                  <span class="keyword">order</span> <span class="keyword">by</span> `views` <span class="keyword">desc</span></span><br><span class="line">                  limit <span class="number">20</span></span><br><span class="line">              ) t1</span><br><span class="line">                  <span class="keyword">lateral</span> <span class="keyword">view</span> explode(t1.category) explode_category <span class="keyword">as</span> category_name</span><br><span class="line">     ) t2</span><br><span class="line"><span class="keyword">group</span> <span class="keyword">by</span> t2.category_name</span><br><span class="line">;</span><br></pre></td></tr></table></figure>
</li>
<li>统计视频观看数Top50所关联视频的所属类别排名  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> category_name,</span><br><span class="line">       video_count,</span><br><span class="line">       <span class="built_in">rank</span>() <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> video_count) video_count_rank,</span><br><span class="line">       video_views,</span><br><span class="line">       <span class="built_in">rank</span>() <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> video_views) video_views_rank</span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">         <span class="keyword">select</span> category_name,</span><br><span class="line">                <span class="built_in">count</span>(t5.single_relatedId)  video_count,</span><br><span class="line">                <span class="built_in">sum</span>(t5.related_video_views) video_views</span><br><span class="line">         <span class="keyword">from</span> (</span><br><span class="line">                  <span class="keyword">select</span> t4.orign_video_id,</span><br><span class="line">                         t4.orign_video_views,</span><br><span class="line">                         t4.single_relatedId,</span><br><span class="line">                         t4.related_video_views,</span><br><span class="line">                         category_name</span><br><span class="line">                  <span class="keyword">from</span> (</span><br><span class="line">                           <span class="keyword">select</span> t2.videoId orign_video_id,</span><br><span class="line">                                  t2.views   orign_video_views,</span><br><span class="line">                                  t2.single_relatedId,</span><br><span class="line">                                  t3.views   related_video_views,</span><br><span class="line">                                  t3.category</span><br><span class="line">                           <span class="keyword">from</span> (<span class="keyword">select</span> t1.videoId,</span><br><span class="line">                                        t1.views,</span><br><span class="line">                                        single_relatedId</span><br><span class="line">                                 <span class="keyword">from</span> (</span><br><span class="line">                                          <span class="keyword">select</span> videoId,</span><br><span class="line">                                                 `views`,</span><br><span class="line">                                                 relatedId</span><br><span class="line">                                          <span class="keyword">from</span> gulivideo_orc</span><br><span class="line">                                          <span class="keyword">order</span> <span class="keyword">by</span> `views` <span class="keyword">desc</span></span><br><span class="line">                                          limit <span class="number">50</span></span><br><span class="line">                                      ) t1</span><br><span class="line">                                          <span class="keyword">lateral</span> <span class="keyword">view</span> explode(t1.relatedId) explode_relatedId <span class="keyword">as</span> single_relatedId) t2</span><br><span class="line">                                    <span class="keyword">left</span> <span class="keyword">join</span> gulivideo_orc t3 <span class="keyword">on</span> t2.single_relatedId <span class="operator">=</span> t3.videoId</span><br><span class="line">                           <span class="keyword">where</span> t3.videoId <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">null</span></span><br><span class="line">                       ) t4</span><br><span class="line">                           <span class="keyword">lateral</span> <span class="keyword">view</span> explode(t4.category) explode_category <span class="keyword">as</span> category_name</span><br><span class="line">              ) t5</span><br><span class="line">         <span class="keyword">group</span> <span class="keyword">by</span> t5.category_name</span><br><span class="line">     ) t6</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>统计每个类别中的视频热度Top10,以Music为例  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 统计每个类别中的视频热度Top10,以Music为例</span></span><br><span class="line"><span class="keyword">select</span> videoId,</span><br><span class="line">       `views`,</span><br><span class="line">       category_name</span><br><span class="line"><span class="keyword">from</span> gulivideo_orc</span><br><span class="line"><span class="keyword">lateral</span> <span class="keyword">VIEW</span> explode(category) gulivideo_orc_tmp <span class="keyword">AS</span> category_name</span><br><span class="line"><span class="keyword">where</span> array_contains(category, &quot;Music&quot;)</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> `views` <span class="keyword">desc</span></span><br><span class="line">limit <span class="number">10</span>;</span><br><span class="line"><span class="comment">-- 统计每个类别中的视频热度Top10,以Music为例2</span></span><br><span class="line"><span class="keyword">SELECT</span> t1.videoId,</span><br><span class="line">       t1.views,</span><br><span class="line">       t1.category_name</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">         <span class="keyword">SELECT</span> videoId,</span><br><span class="line">                `views`,</span><br><span class="line">                category_name</span><br><span class="line">         <span class="keyword">FROM</span> gulivideo_orc</span><br><span class="line">                  <span class="keyword">lateral</span> <span class="keyword">VIEW</span> explode(category) gulivideo_orc_tmp <span class="keyword">AS</span> category_name</span><br><span class="line">     ) t1</span><br><span class="line"><span class="keyword">WHERE</span> t1.category_name <span class="operator">=</span> &quot;Music&quot;</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> t1.views <span class="keyword">DESC</span></span><br><span class="line">LIMIT <span class="number">10</span>;</span><br></pre></td></tr></table></figure></li>
<li>统计每个类别视频观看数Top10  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">         <span class="keyword">SELECT</span> t1.videoId,</span><br><span class="line">                t1.views,</span><br><span class="line">                t1.category_name,</span><br><span class="line">                <span class="built_in">rank</span>() <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> t1.category_name <span class="keyword">order</span> <span class="keyword">by</span> t1.views <span class="keyword">desc</span>) video_rank</span><br><span class="line">         <span class="keyword">FROM</span> (</span><br><span class="line">                  <span class="keyword">SELECT</span> videoId,</span><br><span class="line">                         `views`,</span><br><span class="line">                         category_name</span><br><span class="line">                  <span class="keyword">FROM</span> gulivideo_orc</span><br><span class="line">                           <span class="keyword">lateral</span> <span class="keyword">VIEW</span> explode(category) gulivideo_orc_tmp <span class="keyword">AS</span> category_name</span><br><span class="line">              ) t1</span><br><span class="line">     ) t2</span><br><span class="line"><span class="keyword">where</span> t2.video_rank <span class="operator">&lt;=</span> <span class="number">10</span></span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> t2.category_name, t2.video_rank</span><br></pre></td></tr></table></figure></li>
<li>统计上传视频最多的用户Top10以及他们上传的视频观看次数在前20的视频  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">         <span class="keyword">select</span> uploader,</span><br><span class="line">                videoId,</span><br><span class="line">                `views`,</span><br><span class="line">                <span class="built_in">percent_rank</span>() <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> `views` )                                       views_percent_rank,</span><br><span class="line">                <span class="built_in">count</span>(videoId) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> uploader) video_count,</span><br><span class="line">                <span class="built_in">dense_rank</span>() <span class="keyword">over</span> (<span class="keyword">order</span> <span class="keyword">by</span> <span class="built_in">count</span>(videoId) <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> uploader) <span class="keyword">desc</span>) video_count_rank</span><br><span class="line">         <span class="keyword">from</span> gulivideo_orc</span><br><span class="line">     ) t1</span><br><span class="line"><span class="keyword">where</span> t1.views_percent_rank <span class="operator">&gt;=</span> <span class="number">0.8</span></span><br><span class="line">  <span class="keyword">and</span> t1.video_count_rank <span class="operator">&lt;</span> <span class="number">10</span>;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">SELECT</span> t2.videoId,</span><br><span class="line">       t2.views,</span><br><span class="line">       t2.uploader</span><br><span class="line"><span class="keyword">FROM</span> (</span><br><span class="line">         <span class="keyword">SELECT</span> uploader,</span><br><span class="line">                videos</span><br><span class="line">         <span class="keyword">FROM</span> gulivideo_user_orc</span><br><span class="line">         <span class="keyword">ORDER</span> <span class="keyword">BY</span> videos <span class="keyword">DESC</span></span><br><span class="line">         LIMIT <span class="number">10</span></span><br><span class="line">     ) t1</span><br><span class="line">         <span class="keyword">JOIN</span> gulivideo_orc t2</span><br><span class="line">              <span class="keyword">ON</span> t1.uploader <span class="operator">=</span> t2.uploader</span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> t2.views</span><br><span class="line">        <span class="keyword">DESC</span></span><br><span class="line">LIMIT <span class="number">20</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span></span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">         <span class="keyword">SELECT</span> t2.videoId,</span><br><span class="line">                t2.views,</span><br><span class="line">                t2.uploader,</span><br><span class="line">                <span class="built_in">rank</span>() <span class="keyword">over</span> (<span class="keyword">partition</span> <span class="keyword">by</span> t2.uploader <span class="keyword">order</span> <span class="keyword">by</span> t2.views <span class="keyword">desc</span> ) views_rank</span><br><span class="line">         <span class="keyword">FROM</span> (</span><br><span class="line">                  <span class="keyword">SELECT</span> uploader,</span><br><span class="line">                         videos</span><br><span class="line">                  <span class="keyword">FROM</span> gulivideo_user_orc</span><br><span class="line">                  <span class="keyword">ORDER</span> <span class="keyword">BY</span> videos <span class="keyword">DESC</span></span><br><span class="line">                  LIMIT <span class="number">10</span></span><br><span class="line">              ) t1</span><br><span class="line">                  <span class="keyword">JOIN</span> gulivideo_orc t2</span><br><span class="line">                       <span class="keyword">ON</span> t1.uploader <span class="operator">=</span> t2.uploader</span><br><span class="line">     ) t3</span><br><span class="line"><span class="keyword">where</span> t3.views_rank <span class="operator">&lt;=</span> <span class="number">20</span></span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> uploader, views_rank</span><br></pre></td></tr></table></figure></li>
</ul>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hive/" rel="tag">Hive</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%95%B0%E4%BB%93/" rel="tag">数仓</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Hadoop"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/11/07/Hadoop/"
    >Hadoop</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/11/07/Hadoop/" class="article-date">
  <time datetime="2021-11-07T00:08:34.000Z" itemprop="datePublished">2021-11-07</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><h3 id="1-Hadoop概念"><a href="#1-Hadoop概念" class="headerlink" title="1.Hadoop概念"></a>1.Hadoop概念</h3><p>Hadoop是一个综合性的架构（软件）</p>
<h3 id="2-Hadoop组件"><a href="#2-Hadoop组件" class="headerlink" title="2.Hadoop组件"></a>2.Hadoop组件</h3><ol>
<li>HDFS: 解决海量数据的存储和管理</li>
<li>MapReduce: 解决海量数据的计算分析 </li>
<li>Yarn: 负责MR程序运行的平台，做资源分配的工作</li>
<li>Zookeeper: 分布式资源协调管理</li>
</ol>
<h3 id="3-Hadoop集群搭建"><a href="#3-Hadoop集群搭建" class="headerlink" title="3.Hadoop集群搭建"></a>3.Hadoop集群搭建</h3><ol>
<li>HDFS集群</li>
<li>Yarn集群</li>
</ol>
<h2 id="一、大数据概论"><a href="#一、大数据概论" class="headerlink" title="一、大数据概论"></a>一、大数据概论</h2><h3 id="1-大数据概念"><a href="#1-大数据概念" class="headerlink" title="1.大数据概念"></a>1.大数据概念</h3><p>大数据: 解决海量数据的存储和分析计算</p>
<h3 id="2-大数据特点"><a href="#2-大数据特点" class="headerlink" title="2.大数据特点"></a>2.大数据特点</h3><ol>
<li>Volume: 大量</li>
<li>Velocity: 高速</li>
<li>Variety: 多样</li>
<li>Value: 低价值</li>
</ol>
<h3 id="3-大数据应用场景"><a href="#3-大数据应用场景" class="headerlink" title="3.大数据应用场景"></a>3.大数据应用场景</h3><ol>
<li>物流仓储、零售、旅游···</li>
</ol>
<h3 id="4-大数据部门组织结构"><a href="#4-大数据部门组织结构" class="headerlink" title="4.大数据部门组织结构"></a>4.大数据部门组织结构</h3><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16337824506474.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<h2 id="二、从Hadoop框架了解大数据生态"><a href="#二、从Hadoop框架了解大数据生态" class="headerlink" title="二、从Hadoop框架了解大数据生态"></a>二、从Hadoop框架了解大数据生态</h2><h3 id="1-Hadoop是什么"><a href="#1-Hadoop是什么" class="headerlink" title="1. Hadoop是什么"></a>1. Hadoop是什么</h3><ul>
<li>Hadoop是Apache基金会开发的<font color ='red' >分布式系统基础架构</font></li>
<li>解决海量数据的<font color ='red' ><font color ='red' ></font></font></li>
<li>广义上指更广泛的Hadoop生态圈</li>
</ul>
<h3 id="2-Hadoop发展历史"><a href="#2-Hadoop发展历史" class="headerlink" title="2.Hadoop发展历史"></a>2.Hadoop发展历史</h3><ol>
<li>Lucene开发者Doug Cutting实现全文搜索</li>
<li>2001年Lucene成为Apache基金会子项目</li>
<li>Lucene处理海量数据暴露数据存储困难，检索速度慢的问题</li>
<li>微型版Nutch解决问题</li>
<li>Google <ul>
<li>GFS–&gt;HDFS </li>
<li>Map-Reduce–&gt;MR</li>
<li>BigTable–&gt;Hbase</li>
</ul>
</li>
<li>2003-2004年，Google公开了部分GFS和MapReduce思想的细节，以此为基础Doug Cutting等人用了2年业余时间实现了DFS和MapReduce机制，使Nutch性能飙升。</li>
<li>2005 年Hadoop 作为 Lucene的子项目 Nutch的一部分正式引入Apache基金会。</li>
<li>2006 年 3 月份，Map-Reduce和Nutch Distributed File System （NDFS）分别被纳入到 Hadoop 项目中，Hadoop就此正式诞生，标志着大数据时代来临。</li>
<li>名字来源于Doug Cutting儿子的玩具大象</li>
</ol>
<h3 id="3-Hadoop发行版本"><a href="#3-Hadoop发行版本" class="headerlink" title="3.Hadoop发行版本"></a>3.Hadoop发行版本</h3><p>Hadoop 三大发行版本：Apache、Cloudera、Hortonworks。</p>
<ul>
<li>Apache 版本最原始（最基础）的版本，对于入门学习最好。</li>
<li>Cloudera 内部集成了很多大数据框架，对应产品 CDH。</li>
<li>Hortonworks 文档较好，对应产品 HDP。</li>
<li>Hortonworks 现在已经被 Cloudera 公司收购，推出新的品牌 CDP。</li>
</ul>
<h3 id="4-Hadoop优势"><a href="#4-Hadoop优势" class="headerlink" title="4.Hadoop优势"></a>4.Hadoop优势</h3><ol>
<li>高可靠性：Hadoop维护多个数据副本，单节点出现故障不会导致数据丢失</li>
<li>高拓展性：在集群间分配任务数据，可以方便的拓展数以千计的节点</li>
<li>高效性：在MapReduce的思想下，Hadoop是并行工作，加快任务处理速度</li>
<li>高容错性：能将失败的任务重新分配</li>
</ol>
<h3 id="5-Hadoop组成"><a href="#5-Hadoop组成" class="headerlink" title="5.Hadoop组成"></a>5.Hadoop组成</h3><p>1.x 2.x组成<br><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16337824731783.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<h4 id="5-1-HDFS架构概述"><a href="#5-1-HDFS架构概述" class="headerlink" title="5.1 HDFS架构概述"></a>5.1 HDFS架构概述</h4><p>Hadoop Distributed File System，简称 HDFS，是一个分布式文件系统。负责海量数据的存储。</p>
<ol>
<li>NameNode（nn）：存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的DataNode等。</li>
<li>DataNode(dn)：在本地文件系统存储文件块数据，以及块数据的校验和。</li>
<li>Secondary NameNode(2nn)：每隔一段时间对NameNode元数据备份。<h4 id="5-2-YARN"><a href="#5-2-YARN" class="headerlink" title="5.2 YARN"></a>5.2 YARN</h4>Yet Another Resource Negotiator 简称 YARN ，另一种资源协调者，是 Hadoop 的资源管理器。<br><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16337824915316.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
</ol>
<ol>
<li>ResourceManager（RM）：整个集群资源（内存、CPU等）的老大<ul>
<li>处理客户端请求</li>
<li>监控NodeManager</li>
<li>启动、监控ApplicationMaster</li>
<li>资源的分配与调度</li>
</ul>
</li>
<li>ApplicationMaster（AM）：单个任务运行的老大<ul>
<li>负责数据的切分</li>
<li>为用用程序申请资源并分配</li>
</ul>
</li>
<li>NodeManager（NM）：单个节点服务器资源老大</li>
<li>Container：容器，相当一台独立的服务器，里面封装了任务运行所需要的资源，如内存、CPU、磁盘、网络等。</li>
</ol>
<h4 id="5-3-MapReduce"><a href="#5-3-MapReduce" class="headerlink" title="5.3 MapReduce"></a>5.3 MapReduce</h4><p>MapReduce将计算过程分为两个阶段：Map和Reduce<br><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16337825183035.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ol>
<li>Map阶段并行处理输入数据</li>
<li>Reduce阶段对Map结果进行汇总<h3 id="6-大数据技术生态体系"><a href="#6-大数据技术生态体系" class="headerlink" title="6.大数据技术生态体系"></a>6.大数据技术生态体系</h3><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16337825330556.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
</ol>
<h3 id="7-推荐系统框架图"><a href="#7-推荐系统框架图" class="headerlink" title="7.推荐系统框架图"></a>7.推荐系统框架图</h3><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16337825489826.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<h2 id="三、-Hadoop运行环境搭建"><a href="#三、-Hadoop运行环境搭建" class="headerlink" title="三、 Hadoop运行环境搭建"></a>三、 Hadoop运行环境搭建</h2><h3 id="1-最小化安装Centos"><a href="#1-最小化安装Centos" class="headerlink" title="1. 最小化安装Centos"></a>1. 最小化安装Centos</h3><h3 id="2-配置虚拟机模板"><a href="#2-配置虚拟机模板" class="headerlink" title="2. 配置虚拟机模板"></a>2. 配置虚拟机模板</h3><ul>
<li>固定IP,修改主机名</li>
<li>Yum安装工具  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y epel-release psmisc nc net-tools rsync vim lrzsz ntp libzstd openssl-static tree iotop git</span><br></pre></td></tr></table></figure></li>
<li>关闭防火墙  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br></pre></td></tr></table></figure></li>
<li>创建用户  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">adduser atguigu</span><br><span class="line">passwd atguigu</span><br></pre></td></tr></table></figure></li>
<li>添加sudo权限/etc/sudoers添加内容  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">atguigu  ALL=(ALL)   ALL</span><br></pre></td></tr></table></figure>
<h3 id="3-安装JDK"><a href="#3-安装JDK" class="headerlink" title="3. 安装JDK"></a>3. 安装JDK</h3></li>
</ul>
<ol>
<li>上传jdk-8u212-linux-x64.tar.gz到/opt/software下</li>
<li>解压JDK到/opt/module目录下<code>tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/</code></li>
<li>配置JDK环境变量新建/etc/profile.d/set_env.sh文件 添加如下内容 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ cat /etc/profile.d/my_env.sh</span><br><span class="line">#JAVA_HOME</span><br><span class="line">export JAVA_HOME=/opt/module/jdk1.8.0_212</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="4-安装Hadoop"><a href="#4-安装Hadoop" class="headerlink" title="4. 安装Hadoop"></a>4. 安装Hadoop</h3><ol>
<li>上传 hadoop-3.1.3.tar.gz到/opt/software下</li>
<li>解压到/opt/module下面<code>tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/</code></li>
<li>配置环境变量/etc/profile.d/set_env.sh文件 添加如下内容 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#HADOOP_HOME</span><br><span class="line">export HADOOP_HOME=/opt/module/hadoop-3.1.3</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="四、Hadoop分布式部署"><a href="#四、Hadoop分布式部署" class="headerlink" title="四、Hadoop分布式部署"></a>四、Hadoop分布式部署</h2><h3 id="1-准备虚拟机"><a href="#1-准备虚拟机" class="headerlink" title="1. 准备虚拟机"></a>1. 准备虚拟机</h3><ol>
<li>静态IP<br> <code> BOOTPROTO=static  IPADDR=192.168.1.102  GATEWAY=192.168.1.2  DNS1=192.168.1.2 </code></li>
<li>关闭防火墙 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br></pre></td></tr></table></figure></li>
<li>设置hostname <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl set-hostname hadoop001</span><br></pre></td></tr></table></figure></li>
<li>修改/etc/hosts 添加解析内容 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.168.2.6 hadoop001</span><br><span class="line">192.168.2.7 hadoop002</span><br><span class="line">192.168.2.8 hadoop003</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="2-准备分发脚本xsync"><a href="#2-准备分发脚本xsync" class="headerlink" title="2. 准备分发脚本xsync"></a>2. 准备分发脚本xsync</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash">1. 判断参数个数</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">  echo Not Enough Arguement!</span><br><span class="line">  exit;</span><br><span class="line">fi</span><br><span class="line"><span class="meta">#</span><span class="bash">2. 遍历集群所有机器</span></span><br><span class="line">for host in hadoop102 hadoop103 hadoop104</span><br><span class="line">do</span><br><span class="line">  echo ====================  $host  ====================</span><br><span class="line"><span class="meta">  #</span><span class="bash">3. 遍历所有目录，挨个发送</span></span><br><span class="line">  for file in $@</span><br><span class="line">  do</span><br><span class="line">    #4. 判断文件是否存在</span><br><span class="line">    if [ -e $file ]</span><br><span class="line">    then</span><br><span class="line">      #5. 获取父目录</span><br><span class="line">      pdir=$(cd -P $(dirname $file); pwd)</span><br><span class="line">      #6. 获取当前文件的名称</span><br><span class="line">      fname=$(basename $file)</span><br><span class="line">      ssh $host &quot;mkdir -p $pdir&quot;</span><br><span class="line">      rsync -av $pdir/$fname $host:$pdir</span><br><span class="line">    else</span><br><span class="line">      echo $file does not exists!</span><br><span class="line">    fi</span><br><span class="line">  done</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<h3 id="3-免密登录"><a href="#3-免密登录" class="headerlink" title="3. 免密登录"></a>3. 免密登录</h3><ol>
<li><p>生成公私钥<code>ssh-keygen</code></p>
</li>
<li><p>拷贝公钥到目标服务器</p>
 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id hadoop102</span><br><span class="line">ssh-copy-id hadoop103</span><br><span class="line">ssh-copy-id hadoop104</span><br></pre></td></tr></table></figure></li>
<li><p>.ssh文件夹下（~/.ssh）的文件功能解释</p>
<table>
<thead>
<tr>
<th>文件</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>known_hosts</td>
<td>记录ssh访问过计算机的公钥(public key)</td>
</tr>
<tr>
<td>id_rsa</td>
<td>生成的私钥</td>
</tr>
<tr>
<td>id_rsa.pub</td>
<td>生成的公钥</td>
</tr>
<tr>
<td>authorized_keys</td>
<td>存放授权过的无密登录服务器公钥</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody></table>
</li>
<li><p>集群配置</p>
<ol>
<li><p>集群部署规划</p>
<ul>
<li><p>注意：NameNode和SecondaryNameNode不要安装在同一台服务器</p>
</li>
<li><p>注意：ResourceManager也很消耗内存，不要和NameNode、SecondaryNameNode配置在同一台机器上。</p>
<table>
<thead>
<tr>
<th align="left">服务器</th>
<th align="left">HDFS</th>
<th align="left">Yarn</th>
</tr>
</thead>
<tbody><tr>
<td align="left">hadoop102</td>
<td align="left">NameNode、DataNode</td>
<td align="left">NodeManager</td>
</tr>
<tr>
<td align="left">hadoop103</td>
<td align="left">DataNode</td>
<td align="left">ResourceManager、NodeManager</td>
</tr>
<tr>
<td align="left">hadoop104</td>
<td align="left">SecondaryNameNode、DataNode</td>
<td align="left">NodeManager</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
<li><p>配置文件说明<br> Hadoop配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。</p>
<ul>
<li><p>默认配置文件：</p>
<table>
<thead>
<tr>
<th align="left">配置文件</th>
<th align="left">默认文件存放在Hadoop的jar包中的位置</th>
</tr>
</thead>
<tbody><tr>
<td align="left">core-default.xml</td>
<td align="left">hadoop-common-3.1.3.jar/ core-default.xml</td>
</tr>
<tr>
<td align="left">hdfs-default.xml</td>
<td align="left">hadoop-hdfs-3.1.3.jar/ hdfs-default.xml</td>
</tr>
<tr>
<td align="left">yarn-default.xml</td>
<td align="left">hadoop-yarn-common-3.1.3.jar/yarn-default.xml</td>
</tr>
<tr>
<td align="left">mapred-default.xml</td>
<td align="left">hadoop-mapreduce-client-core-3.1.3.jar/ mapred-default.xml</td>
</tr>
</tbody></table>
</li>
<li><p>自定义配置文件：<br>  core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml四个配置文件存放在$HADOOP_HOME/etc/hadoop这个路径下，可以根据项目需求重新进行修改配置。</p>
</li>
<li><p>常用端口号说明</p>
<table>
<thead>
<tr>
<th align="left">Daemon</th>
<th align="left">App</th>
<th align="left">Hadoop2</th>
<th align="left">Hadoop3</th>
</tr>
</thead>
<tbody><tr>
<td align="left">NameNode Port</td>
<td align="left">Hadoop HDFS NameNode</td>
<td align="left">8020/9000</td>
<td align="left">9820</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">Hadoop HDFS NameNode HTTP UI</td>
<td align="left">50070</td>
<td align="left">9870</td>
</tr>
<tr>
<td align="left">SecondaryNameNode Port</td>
<td align="left">Secondary NameNode</td>
<td align="left">50091</td>
<td align="left">9869</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">Secondary NameNode HTTP UI</td>
<td align="left">50090</td>
<td align="left">9868</td>
</tr>
<tr>
<td align="left">DataNode Port</td>
<td align="left">Hadoop HDFS DataNode IPC</td>
<td align="left">50020</td>
<td align="left">9867</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">Hadoop HDFS DataNod</td>
<td align="left">50010</td>
<td align="left">9866</td>
</tr>
<tr>
<td align="left"></td>
<td align="left">Hadoop HDFS DataNode HTTP UI</td>
<td align="left">50075</td>
<td align="left">9864</td>
</tr>
<tr>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody></table>
</li>
</ul>
</li>
<li><p><strong>配置集群<code>$HADOOP_HOME/etc/hadoop</code></strong></p>
<ul>
<li><p>核心配置文件core-site.xml</p>
  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 指定NameNode的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop102:9820<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定hadoop数据的存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.1.3/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置HDFS网页登录使用的静态用户为atguigu --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>atguigu<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 配置该atguigu(superUser)允许通过代理访问的主机节点 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.atguigu.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置该atguigu(superUser)允许通过代理用户所属组 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.atguigu.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置该atguigu(superUser)允许通过代理的用户--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.atguigu.users<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>HDFS配置文件hdfs-site.xml</p>
  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- nn web端访问地址--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 2nn web端访问地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>YARN配置文件yarn-site.xml</p>
  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 指定MR走shuffle --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定ResourceManager的地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 环境变量的继承 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- yarn容器允许分配的最大最小内存 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>512<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- yarn容器允许管理的物理内存大小 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 关闭yarn对物理内存和虚拟内存的限制检查 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>MapReduce配置文件mapred-site.xml</p>
  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 指定MapReduce程序运行在Yarn上 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>集群配置workers</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br></pre></td></tr></table></figure></li>
<li><p>同步配置</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsync /opt/module/hadoop-3.1.3/etc</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
</li>
</ol>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/" rel="tag">Hadoop</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-HDFS"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/11/07/HDFS/"
    >HDFS</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/11/07/HDFS/" class="article-date">
  <time datetime="2021-11-07T00:08:32.000Z" itemprop="datePublished">2021-11-07</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/HDFS/">HDFS</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><h1 id="一、HDFS概述"><a href="#一、HDFS概述" class="headerlink" title="一、HDFS概述"></a>一、HDFS概述</h1><h2 id="1-1-背景及定义"><a href="#1-1-背景及定义" class="headerlink" title="1.1 背景及定义"></a>1.1 背景及定义</h2><h3 id="1-1-1-背景"><a href="#1-1-1-背景" class="headerlink" title="1.1.1 背景"></a>1.1.1 背景</h3><ol>
<li>海量数据无法单台服务器存储</li>
<li>需要管理多台机器上的文件</li>
</ol>
<h3 id="1-1-2-定义"><a href="#1-1-2-定义" class="headerlink" title="1.1.2 定义"></a>1.1.2 定义</h3><ol>
<li>HDFS: Hadoop Distributed File System 分布式文件系统，多台服务器联合实现功能，集群中各自承担不同角色</li>
<li>适合一次写入，多次读出的场景，<font color ='red' >支持文件追加，不支持文件修改</font>。适合做数据分析，不适合做网盘应用</li>
</ol>
<hr>
<h2 id="1-2-优缺点"><a href="#1-2-优缺点" class="headerlink" title="1.2 优缺点"></a>1.2 优缺点</h2><ul>
<li><p>优点</p>
<ol>
<li><p>高容错性</p>
<ul>
<li><p>数据自动保存多个副本，通过增加副本提高容错性<br>  <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16338313699180.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
</li>
<li><p>某个副本丢失以后，可以自动回复<br>  <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16338314377557.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
</li>
</ul>
</li>
<li><p>适合处理大数据</p>
<ul>
<li>数据规模：能处理GB,TB,PB级别的数据</li>
<li>文件规模：能处理百万千万规模以上的文件数量</li>
</ul>
</li>
<li><p>可构建在廉价机器上，通过多副本机制提高可靠性</p>
</li>
</ol>
</li>
<li><p>缺点</p>
<ol>
<li>不适合低延迟数据访问，比如毫秒级的数据存储 </li>
<li>无法高效的对大量小文件进行存储<ul>
<li>大量小文件会占用NameNode大量内存保存元数据信息（目录和块信息）</li>
<li>小文件存储的寻址时间超过读取时间，不符合HDFS设计目标</li>
</ul>
</li>
<li>不支持并发写入，文件随机修改<ul>
<li>同一个文件只能单线程写，不支持多线程并发写</li>
<li>仅支持数据append，不支持文件随机修改</li>
</ul>
</li>
</ol>
</li>
</ul>
<hr>
<h2 id="1-3-组成架构"><a href="#1-3-组成架构" class="headerlink" title="1.3 组成架构"></a>1.3 组成架构</h2><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16338314790454.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<h3 id="1-3-1-NameNode（NN）"><a href="#1-3-1-NameNode（NN）" class="headerlink" title="1.3.1 NameNode（NN）"></a>1.3.1 NameNode（NN）</h3><ol>
<li>Master，它是一个主管、管理者。负责：</li>
<li>管理HDFS的名称空间</li>
<li>配置副本策略</li>
<li>管理数据块（Block）映射信息</li>
<li>处理客户端读写请求</li>
</ol>
<h3 id="1-3-2-DataNode（DN）"><a href="#1-3-2-DataNode（DN）" class="headerlink" title="1.3.2 DataNode（DN）"></a>1.3.2 DataNode（DN）</h3><ol>
<li>Slave。NameNode下达命令，DataNode执行实际的操作</li>
<li>存储实际的数据块</li>
<li>执行数据块的读/写操作</li>
</ol>
<h3 id="1-3-3-Client客户端"><a href="#1-3-3-Client客户端" class="headerlink" title="1.3.3 Client客户端"></a>1.3.3 Client客户端</h3><ol>
<li>文件切分。文件上传HDFS的时候，Client将文件切分成一个一个的Block，然后进行上传</li>
<li>与NameNode交互，获取文件的位置信息</li>
<li>与DataNode交互，读取或者写入数据；</li>
<li>Client提供一些命令来管理HDFS，比如NameNode格式化</li>
<li>Client可以通过一些命令来访问HDFS，比如对HDFS增删查改操作</li>
</ol>
<h3 id="1-3-4-Secondary-NameNode-2NN"><a href="#1-3-4-Secondary-NameNode-2NN" class="headerlink" title="1.3.4 Secondary NameNode(2NN)"></a>1.3.4 Secondary NameNode(2NN)</h3><ol>
<li>并非NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。</li>
<li>辅助NameNode，分担其工作量，比如定期合并Fsimage和Edits，并推送给NameNode</li>
<li>在紧急情况下，可辅助恢复NameNode。</li>
</ol>
<hr>
<h2 id="1-4-HDFS文件块大小"><a href="#1-4-HDFS文件块大小" class="headerlink" title="1.4 HDFS文件块大小"></a>1.4 HDFS文件块大小</h2><p>HDFS中的文件在物理上是分块存储（Block），块的大小可以通过配置参数(dfs.blocksize）来规定，默认大小在Hadoop2.x/3.x版本中是128M，1.x版本中是64M。<br><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16338322175049.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"><br><em>思考：为什么块的大小不能设置太小，也不能设置太大？</em></p>
<blockquote>
<ol>
<li>HDFS的块设置太小，会增加寻址时间，程序一直在找块的开始位置；</li>
<li>如果块设置的太大，从磁盘传输数据的时间会明显大于定位这个块开始位置所需的时间。导致程序在处理这块数据时，会非常慢。</li>
</ol>
<p>总结：HDFS块的大小设置主要取决于磁盘传输速率。</p>
</blockquote>
<hr>
<h1 id="二、Shell操作HDFS"><a href="#二、Shell操作HDFS" class="headerlink" title="二、Shell操作HDFS"></a>二、Shell操作HDFS</h1><h2 id="2-1-基本语法"><a href="#2-1-基本语法" class="headerlink" title="2.1 基本语法"></a>2.1 基本语法</h2><p><code>hadoop fs [genericOptions] [commandOptions]</code></p>
<hr>
<h2 id="2-2-命令参考"><a href="#2-2-命令参考" class="headerlink" title="2.2 命令参考"></a>2.2 命令参考</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 ~]$ hadoop fs</span><br><span class="line">Usage: hadoop fs [generic options]</span><br><span class="line">	[-appendToFile &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-cat [-ignoreCrc] &lt;src&gt; ...]</span><br><span class="line">	[-checksum &lt;src&gt; ...]</span><br><span class="line">	[-chgrp [-R] GROUP PATH...]</span><br><span class="line">	[-chmod [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; PATH...]</span><br><span class="line">	[-chown [-R] [OWNER][:[GROUP]] PATH...]</span><br><span class="line">	[-copyFromLocal [-f] [-p] [-l] [-d] [-t &lt;thread count&gt;] &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</span><br><span class="line">	[-count [-q] [-h] [-v] [-t [&lt;storage <span class="built_in">type</span>&gt;]] [-u] [-x] [-e] &lt;path&gt; ...]</span><br><span class="line">	[-cp [-f] [-p | -p[topax]] [-d] &lt;src&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-createSnapshot &lt;snapshotDir&gt; [&lt;snapshotName&gt;]]</span><br><span class="line">	[-deleteSnapshot &lt;snapshotDir&gt; &lt;snapshotName&gt;]</span><br><span class="line">	[-df [-h] [&lt;path&gt; ...]]</span><br><span class="line">	[-du [-s] [-h] [-v] [-x] &lt;path&gt; ...]</span><br><span class="line">	[-expunge]</span><br><span class="line">	[-find &lt;path&gt; ... &lt;expression&gt; ...]</span><br><span class="line">	[-get [-f] [-p] [-ignoreCrc] [-crc] &lt;src&gt; ... &lt;localdst&gt;]</span><br><span class="line">	[-getfacl [-R] &lt;path&gt;]</span><br><span class="line">	[-getfattr [-R] &#123;-n name | -d&#125; [-e en] &lt;path&gt;]</span><br><span class="line">	[-getmerge [-nl] [-skip-empty-file] &lt;src&gt; &lt;localdst&gt;]</span><br><span class="line">	[-head &lt;file&gt;]</span><br><span class="line">	[-<span class="built_in">help</span> [cmd ...]]</span><br><span class="line">	[-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [&lt;path&gt; ...]]</span><br><span class="line">	[-mkdir [-p] &lt;path&gt; ...]</span><br><span class="line">	[-moveFromLocal &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-moveToLocal &lt;src&gt; &lt;localdst&gt;]</span><br><span class="line">	[-mv &lt;src&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-put [-f] [-p] [-l] [-d] &lt;localsrc&gt; ... &lt;dst&gt;]</span><br><span class="line">	[-renameSnapshot &lt;snapshotDir&gt; &lt;oldName&gt; &lt;newName&gt;]</span><br><span class="line">	[-rm [-f] [-r|-R] [-skipTrash] [-safely] &lt;src&gt; ...]</span><br><span class="line">	[-rmdir [--ignore-fail-on-non-empty] &lt;dir&gt; ...]</span><br><span class="line">	[-setfacl [-R] [&#123;-b|-k&#125; &#123;-m|-x &lt;acl_spec&gt;&#125; &lt;path&gt;]|[--<span class="built_in">set</span> &lt;acl_spec&gt; &lt;path&gt;]]</span><br><span class="line">	[-setfattr &#123;-n name [-v value] | -x name&#125; &lt;path&gt;]</span><br><span class="line">	[-setrep [-R] [-w] &lt;rep&gt; &lt;path&gt; ...]</span><br><span class="line">	[-<span class="built_in">stat</span> [format] &lt;path&gt; ...]</span><br><span class="line">	[-tail [-f] [-s &lt;sleep interval&gt;] &lt;file&gt;]</span><br><span class="line">	[-<span class="built_in">test</span> -[defsz] &lt;path&gt;]</span><br><span class="line">	[-text [-ignoreCrc] &lt;src&gt; ...]</span><br><span class="line">	[-touch [-a] [-m] [-t TIMESTAMP ] [-c] &lt;path&gt; ...]</span><br><span class="line">	[-touchz &lt;path&gt; ...]</span><br><span class="line">	[-truncate [-w] &lt;length&gt; &lt;path&gt; ...]</span><br><span class="line">	[-usage [cmd ...]]</span><br><span class="line">    </span><br><span class="line">Generic options supported are:</span><br><span class="line">-conf &lt;configuration file&gt;        specify an application configuration file</span><br><span class="line">-D &lt;property=value&gt;               define a value <span class="keyword">for</span> a given property</span><br><span class="line">-fs &lt;file:///|hdfs://namenode:port&gt; specify default filesystem URL to use, overrides <span class="string">&#x27;fs.defaultFS&#x27;</span> property from configurations.</span><br><span class="line">-jt &lt;<span class="built_in">local</span>|resourcemanager:port&gt;  specify a ResourceManager</span><br><span class="line">-files &lt;file1,...&gt;                specify a comma-separated list of files to be copied to the map reduce cluster</span><br><span class="line">-libjars &lt;jar1,...&gt;               specify a comma-separated list of jar files to be included <span class="keyword">in</span> the classpath</span><br><span class="line">-archives &lt;archive1,...&gt;          specify a comma-separated list of archives to be unarchived on the compute machines</span><br><span class="line">    </span><br><span class="line">The general <span class="built_in">command</span> line syntax is:</span><br><span class="line"><span class="built_in">command</span> [genericOptions] [commandOptions]</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="2-3-常用命令"><a href="#2-3-常用命令" class="headerlink" title="2.3 常用命令"></a>2.3 常用命令</h2><h3 id="2-3-1-上传"><a href="#2-3-1-上传" class="headerlink" title="2.3.1 上传"></a>2.3.1 上传</h3><ul>
<li>-moveFromLocal：从本地剪切粘贴到 HDFS  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 sanguo]$ ls</span><br><span class="line">guanyu.txt  liubei.txt  sanguo.txt  zhangfei.txt  zhaoyun.txt</span><br><span class="line">[atguigu@hadoop001 sanguo]$ hadoop fs -moveFromLocal zhangfei.txt /sanguo</span><br><span class="line">2021-10-10 11:01:49,884 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">[atguigu@hadoop001 sanguo]$ ls</span><br><span class="line">guanyu.txt  liubei.txt  sanguo.txt  zhaoyun.txt</span><br><span class="line">[atguigu@hadoop001 sanguo]$</span><br></pre></td></tr></table></figure></li>
<li>-copyFromLocal：从本地文件系统中拷贝文件到 HDFS 路径去  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 ~]$ hadoop fs -copyFromLocal zhaoyun.txt /sanguo</span><br><span class="line">2021-10-10 10:21:55,357 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">[atguigu@hadoop001 ~]$</span><br></pre></td></tr></table></figure></li>
<li>-put：等同于 copyFromLocal，生产环境更习惯用 put  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 sanguo]$ hadoop fs -put caocao.txt /sanguo</span><br><span class="line">2021-10-10 12:05:07,051 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = <span class="literal">false</span>, remoteHostTrusted = <span class="literal">false</span></span><br><span class="line">[atguigu@hadoop001 sanguo]$ hadoop fs -ls /sanguo</span><br><span class="line">Found 8 items</span><br><span class="line">-rw-r--r--   3 atguigu supergroup         34 2021-10-10 12:05 /sanguo/caocao.txt</span><br><span class="line">-rw-r--r--   3 atguigu supergroup         48 2021-10-10 10:26 /sanguo/guanyu.txt</span><br><span class="line">-rw-r--r--   3 atguigu supergroup  195013152 2021-10-10 10:21 /sanguo/jdk-8u212-linux-x64.tar.gz</span><br><span class="line">-rw-r--r--   3 atguigu supergroup         22 2021-10-10 10:25 /sanguo/liubei.txt</span><br><span class="line">drwxr-xr-x   - atguigu supergroup          0 2021-10-10 10:33 /sanguo/shu</span><br><span class="line">drwxr-xr-x   - atguigu supergroup          0 2021-10-10 10:33 /sanguo/wu</span><br><span class="line">-rw-r--r--   3 atguigu supergroup         22 2021-10-10 11:01 /sanguo/zhangfei.txt</span><br><span class="line">-rw-r--r--   6 atguigu supergroup         28 2021-10-10 10:21 /sanguo/zhaoyun.txt</span><br><span class="line">[atguigu@hadoop001 sanguo]$</span><br></pre></td></tr></table></figure></li>
<li>-appendToFile：追加一个文件到已经存在的文件末尾</li>
</ul>
<h3 id="2-3-2-查看"><a href="#2-3-2-查看" class="headerlink" title="2.3.2 查看"></a>2.3.2 查看</h3><h3 id="2-3-3-下载"><a href="#2-3-3-下载" class="headerlink" title="2.3.3 下载"></a>2.3.3 下载</h3><h3 id="2-3-4-删除"><a href="#2-3-4-删除" class="headerlink" title="2.3.4 删除"></a>2.3.4 删除</h3><h3 id="2-3-5-HDFS-直接操作"><a href="#2-3-5-HDFS-直接操作" class="headerlink" title="2.3.5 HDFS 直接操作"></a>2.3.5 HDFS 直接操作</h3><hr>
<h1 id="四、HDFS的数据流"><a href="#四、HDFS的数据流" class="headerlink" title="四、HDFS的数据流"></a>四、HDFS的数据流</h1><h2 id="4-1-HDFS写数据流程"><a href="#4-1-HDFS写数据流程" class="headerlink" title="4.1 HDFS写数据流程"></a>4.1 HDFS写数据流程</h2><h3 id="4-1-1-剖析文件写入"><a href="#4-1-1-剖析文件写入" class="headerlink" title="4.1.1 剖析文件写入"></a>4.1.1 剖析文件写入</h3><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16338477292310.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ol>
<li>请求上传文件<ol>
<li>创建Hadoop客户端DistributionFileSystem</li>
</ol>
</li>
<li>请求NN上传文件<ol>
<li>NN校验：权限，路径，文件名</li>
<li>NN响应允许上传</li>
</ol>
</li>
<li>请求NN上传Block</li>
<li>NN根据副本数量按照<font color ='red' >机架感知</font>规则返回副本存储节点DN</li>
<li>客户端创建输出流FSDataOutputStream，根据<font color ='red' >网络拓扑计算节点距离</font>，请求<font color ='red' ><font color ='red' ></font>最近节点</font>建立Block传输通道<ol>
<li>客户端请求DN1建立通道</li>
<li>DN1请求DN2建立通道</li>
<li>DN2请求DN3建立通道</li>
</ol>
</li>
<li>通道建立应答成功<ol>
<li>DN3应答DN2成功</li>
<li>DN2应答DN1成功</li>
<li>DN1应答客户端成功</li>
</ol>
</li>
<li>传输数据Packet<ol>
<li>block 分解成多个 packet （每个64K）,packet分解成多个chunk(每个512B)，每个chunk都有个校验和chacksum</li>
<li>DFSOutputStream负责把数据写入dataQueue，写入单位为packet</li>
<li>DataStreamer从dataQueue中提取packet,发送到管道中的第一个datanode,同时将该packet写入 ackQueue中（block是有副本的，在写block之前就已经确定了，这些副本要写到哪些datanode上，这些datanode形成一个数据管道，DataStreamer只会把数据写入管道的第一个datanode,然后第一个dataNode向第二个datanode写数据，第二个再向第三个写，它们之间使用socket传输数据）</li>
<li>ResponseProcessor会从datanodes接收ack（此ack是Datanode接收packet成功后的确定），ResponseProcessor接收到所有Datanote的ack后，就从ackQueue中移除相应的packet。</li>
<li>如果遇到异常，所有的packets都从ackQueue移除，并排除异常的Datanode，再重新申请一个管道 。</li>
<li>然后 DataStreamer又重新从dataQueue中，获得packets并发送。</li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/419a2068987c">参考</a></li>
</ol>
</li>
<li>当一个Block传输完成之后，客户端再次请求NameNode上传第二个Block的服务器。（重复执行3-7步）。</li>
</ol>
<h3 id="4-1-2-网络拓扑-节点距离计算"><a href="#4-1-2-网络拓扑-节点距离计算" class="headerlink" title="4.1.2 网络拓扑-节点距离计算"></a>4.1.2 网络拓扑-节点距离计算</h3><ul>
<li>在HDFS写数据的过程中，NameNode会选择距离待上传数据最近距离的DataNode接收数据。</li>
<li>节点距离：两个节点到达最近的共同祖先的距离总和。<br><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16339649640120.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
</ul>
<h3 id="4-1-3-机架感知（副本存储节点选择）"><a href="#4-1-3-机架感知（副本存储节点选择）" class="headerlink" title="4.1.3 机架感知（副本存储节点选择）"></a>4.1.3 机架感知（副本存储节点选择）</h3><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16339657833860.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ul>
<li>第一个副本在Client所处的节点上。如果客户端在集群外，随机选一个。</li>
<li>第二个副本在另一个机架的随机一个节点</li>
<li>第三个副本在第二个副本所在机架的随机节点</li>
</ul>
<blockquote>
<p>思考</p>
<ol>
<li>HDFS根据请求返回DataNode的节点的策略？– 机架感知</li>
</ol>
<ul>
<li>如果当前Client所在机器有DataNode节点，那就返回当前机器DN1,否则从集群中随机一台。</li>
<li>根据第一台机器的位置，然后再其他机架上随机一台，在第二台机器所在机架上再随机一台。</li>
<li>以上策略的缘由：为了提高数据的可靠性，同时一定程度也保证数据传输的效率！</li>
</ul>
<ol start="2">
<li>客户端建立传输通道的时候如何确定和哪一台DataNode先建立连接？– 网络拓扑</li>
</ol>
<ul>
<li>找离client最近的一台机器先建立通道。</li>
</ul>
<ol start="3">
<li>Client为什么是以串行的方式建立通道？</li>
</ol>
<ul>
<li>本质上就是为了降低client的IO开销</li>
</ul>
<ol start="4">
<li>数据传输的时候如何保证数据成功？（了解）</li>
</ol>
<ul>
<li>采用了ack回执的策略保证了数据完整成功上传。</li>
</ul>
</blockquote>
<hr>
<h2 id="4-2-HDFS读数据流程"><a href="#4-2-HDFS读数据流程" class="headerlink" title="4.2 HDFS读数据流程"></a>4.2 HDFS读数据流程</h2><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16339658069723.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ol>
<li>客户端通过DistributedFileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址。</li>
<li>挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。</li>
<li>DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以Packet为单位来做校验）。</li>
<li>客户端以Packet为单位接收，先在本地缓存，然后写入目标文件。</li>
</ol>
<hr>
<h1 id="五、NameNode和SecondaryNameNode"><a href="#五、NameNode和SecondaryNameNode" class="headerlink" title="五、NameNode和SecondaryNameNode"></a>五、NameNode和SecondaryNameNode</h1><h2 id="5-1-NN和2NN工作机制"><a href="#5-1-NN和2NN工作机制" class="headerlink" title="5.1 NN和2NN工作机制"></a>5.1 NN和2NN工作机制</h2><h3 id="5-1-1-元数据信息要保存在哪？"><a href="#5-1-1-元数据信息要保存在哪？" class="headerlink" title="5.1.1 元数据信息要保存在哪？"></a>5.1.1 元数据信息要保存在哪？</h3><ol>
<li><p>保存到磁盘</p>
<ul>
<li>优点：数据安全</li>
<li>不足：读写速度慢 效率低！</li>
</ul>
</li>
<li><p>保存内存</p>
<ul>
<li>优点： 读写效率高！</li>
<li>不足：数据不安全</li>
</ul>
</li>
<li><p>最终的解决方案： 磁盘 + 内存<br><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16339951016390.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ul>
<li>第一阶段：NameNode启动<ol>
<li>第一次启动NameNode格式化后，创建Fsimage和Edits文件。如果不是第一次启动，直接加载编辑日志和镜像文件到内存。</li>
<li>客户端对元数据进行增删改的请求。</li>
<li>NameNode记录操作日志，更新滚动日志。</li>
<li>NameNode在内存中对元数据进行增删改。 </li>
</ol>
</li>
<li>第二阶段：Secondary NameNode工作<ol>
<li>Secondary NameNode询问NameNode是否需要CheckPoint。直接带回NameNode是否检查结果。</li>
<li>Secondary NameNode请求执行CheckPoint。</li>
<li>NameNode滚动正在写的Edits日志。</li>
<li>将滚动前的编辑日志和镜像文件拷贝到Secondary NameNode。</li>
<li>Secondary NameNode加载编辑日志和镜像文件到内存，并合并。</li>
<li>生成新的镜像文件fsimage.chkpoint。</li>
<li>拷贝fsimage.chkpoint到NameNode。</li>
<li>NameNode将fsimage.chkpoint重新命名成fsimage。</li>
</ol>
</li>
</ul>
</li>
</ol>
<hr>
<h2 id="5-2-Fsimage和Edits解析"><a href="#5-2-Fsimage和Edits解析" class="headerlink" title="5.2 Fsimage和Edits解析"></a>5.2 Fsimage和Edits解析</h2><p>NameNode被格式化之后，将在/opt/module/hadoop-2.7.2/data/tmp/dfs/name/current目录中产生如下文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 subdir0]$ <span class="built_in">cd</span> /opt/module/hadoop-3.1.3/data/dfs/name/current/</span><br><span class="line">[atguigu@hadoop001 current]$ ll</span><br><span class="line">总用量 6320</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu 1048576 10月 12 07:26 edits_0000000000000000666-0000000000000000666</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu      42 10月 12 09:45 edits_0000000000000000667-0000000000000000668</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu 1048576 10月 12 09:45 edits_inprogress_0000000000000000669</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu    4452 10月 12 09:05 fsimage_0000000000000000666</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu      62 10月 12 09:05 fsimage_0000000000000000666.md5</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu    4452 10月 12 09:45 fsimage_0000000000000000668</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu      62 10月 12 09:45 fsimage_0000000000000000668.md5</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu       4 10月 12 09:45 seen_txid</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu     215 10月 12 09:05 VERSION</span><br><span class="line">[atguigu@hadoop001 current]$</span><br></pre></td></tr></table></figure>
<ol>
<li>Fsimage文件：HDFS文件系统元数据的一个永久性的检查点，其中包含HDFS文件系统的所有目录和文件inode的序列化信息。 </li>
<li>Edits文件：存放HDFS文件系统的所有更新操作的路径，文件系统客户端执行的所有写操作首先会被记录到Edits文件中。 </li>
<li>seen_txid文件保存的是一个数字，就是最后一个edits_的数字 </li>
<li>每次NameNode启动的时候都会将Fsimage文件读入内存，加载Edits里面的更新操作，保证内存中的元数据信息是最新的、同步的，可以看成NameNode启动的时候就将Fsimage和Edits文件进行了合并</li>
<li>解析Fsimage文件<ol>
<li>oiv查看Fsimage文件<ol>
<li>查看oiv和oev命令 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 current]$ hdfs --<span class="built_in">help</span> | grep -E <span class="string">&#x27;oev|oiv&#x27;</span></span><br><span class="line">oev                  apply the offline edits viewer to an edits file</span><br><span class="line">oiv                  apply the offline fsimage viewer to an fsimage</span><br><span class="line">[atguigu@hadoop001 current]$</span><br></pre></td></tr></table></figure></li>
<li>基本语法<br> <code>hdfs oiv -p 文件类型 -i镜像文件 -o 转换后文件输出路径</code></li>
<li>操作 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 current]$ hdfs oiv -p xml -i fsimage_0000000000000000666 -o ~/fsimage/fsimage.xml</span><br><span class="line">2021-10-12 10:02:40,652 INFO offlineImageViewer.FSImageHandler: Loading 3 strings</span><br><span class="line">[atguigu@hadoop001 current]$</span><br></pre></td></tr></table></figure></li>
<li>部分内容 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">INodeSection</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">lastInodeId</span>&gt;</span>16507<span class="tag">&lt;/<span class="name">lastInodeId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">numInodes</span>&gt;</span>54<span class="tag">&lt;/<span class="name">numInodes</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">inode</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>16385<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span><span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1633959143943<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">permission</span>&gt;</span>atguigu:supergroup:0755<span class="tag">&lt;/<span class="name">permission</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>9223372036854775807<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">inode</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>16470<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">type</span>&gt;</span>DIRECTORY<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>sanguo<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1633838707139<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">permission</span>&gt;</span>atguigu:supergroup:0755<span class="tag">&lt;/<span class="name">permission</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">nsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">nsquota</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dsquota</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">dsquota</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">inode</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>16471<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">type</span>&gt;</span>FILE<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>jdk-8u212-linux-x64.tar.gz<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">replication</span>&gt;</span>3<span class="tag">&lt;/<span class="name">replication</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">mtime</span>&gt;</span>1633832463721<span class="tag">&lt;/<span class="name">mtime</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">atime</span>&gt;</span>1633832462757<span class="tag">&lt;/<span class="name">atime</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">preferredBlockSize</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">preferredBlockSize</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">permission</span>&gt;</span>atguigu:supergroup:0644<span class="tag">&lt;/<span class="name">permission</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">blocks</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">block</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741861<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1037<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">block</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">id</span>&gt;</span>1073741862<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">genstamp</span>&gt;</span>1038<span class="tag">&lt;/<span class="name">genstamp</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">numBytes</span>&gt;</span>60795424<span class="tag">&lt;/<span class="name">numBytes</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">block</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">blocks</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">storagePolicyId</span>&gt;</span>0<span class="tag">&lt;/<span class="name">storagePolicyId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">inode</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">INodeSection</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">INodeDirectorySection</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">directory</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">parent</span>&gt;</span>16385<span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">child</span>&gt;</span>16470<span class="tag">&lt;/<span class="name">child</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">child</span>&gt;</span>16475<span class="tag">&lt;/<span class="name">child</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">child</span>&gt;</span>16386<span class="tag">&lt;/<span class="name">child</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">child</span>&gt;</span>16507<span class="tag">&lt;/<span class="name">child</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">child</span>&gt;</span>16392<span class="tag">&lt;/<span class="name">child</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">child</span>&gt;</span>16403<span class="tag">&lt;/<span class="name">child</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">child</span>&gt;</span>16430<span class="tag">&lt;/<span class="name">child</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">child</span>&gt;</span>16453<span class="tag">&lt;/<span class="name">child</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">directory</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">parent</span>&gt;</span>16470<span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">child</span>&gt;</span>16484<span class="tag">&lt;/<span class="name">child</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">child</span>&gt;</span>16473<span class="tag">&lt;/<span class="name">child</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">child</span>&gt;</span>16471<span class="tag">&lt;/<span class="name">child</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">child</span>&gt;</span>16474<span class="tag">&lt;/<span class="name">child</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">child</span>&gt;</span>16477<span class="tag">&lt;/<span class="name">child</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">child</span>&gt;</span>16478<span class="tag">&lt;/<span class="name">child</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">child</span>&gt;</span>16480<span class="tag">&lt;/<span class="name">child</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">child</span>&gt;</span>16472<span class="tag">&lt;/<span class="name">child</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">directory</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">INodeDirectorySection</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
<blockquote>
<p>思考：可以看出，Fsimage中没有记录块所对应DataNode，为什么？<br>  在集群启动后，要求DataNode上报数据块信息，并间隔一段时间后再次上报。</p>
</blockquote>
</li>
<li>oev查看Edits文件<ol>
<li>基本语法<br> <code>hdfs oev -p 文件类型 -i编辑日志 -o 转换后文件输出路径</code></li>
<li>操作 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 current]$ hdfs oev -p xml -i edits_0000000000000000666-0000000000000000666 -o ~/fsimage/edits.xml</span><br><span class="line">[atguigu@hadoop001 current]$ ll ~/fsimage/edits.xml</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu 221 10月 12 12:05 /home/atguigu/fsimage/edits.xml</span><br><span class="line">[atguigu@hadoop001 current]$</span><br></pre></td></tr></table></figure></li>
<li>内容 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">EDITS</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">EDITS_VERSION</span>&gt;</span>-64<span class="tag">&lt;/<span class="name">EDITS_VERSION</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_START_LOG_SEGMENT<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">TXID</span>&gt;</span>328<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_MKDIR<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">TXID</span>&gt;</span>329<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">LENGTH</span>&gt;</span>0<span class="tag">&lt;/<span class="name">LENGTH</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">INODEID</span>&gt;</span>16470<span class="tag">&lt;/<span class="name">INODEID</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">PATH</span>&gt;</span>/sanguo<span class="tag">&lt;/<span class="name">PATH</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">TIMESTAMP</span>&gt;</span>1633832427513<span class="tag">&lt;/<span class="name">TIMESTAMP</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">PERMISSION_STATUS</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">USERNAME</span>&gt;</span>atguigu<span class="tag">&lt;/<span class="name">USERNAME</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">GROUPNAME</span>&gt;</span>supergroup<span class="tag">&lt;/<span class="name">GROUPNAME</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">MODE</span>&gt;</span>493<span class="tag">&lt;/<span class="name">MODE</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;/<span class="name">PERMISSION_STATUS</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_ADD<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">TXID</span>&gt;</span>330<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">LENGTH</span>&gt;</span>0<span class="tag">&lt;/<span class="name">LENGTH</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">INODEID</span>&gt;</span>16471<span class="tag">&lt;/<span class="name">INODEID</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">PATH</span>&gt;</span>/sanguo/jdk-8u212-linux-x64.tar.gz._COPYING_<span class="tag">&lt;/<span class="name">PATH</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">REPLICATION</span>&gt;</span>3<span class="tag">&lt;/<span class="name">REPLICATION</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">MTIME</span>&gt;</span>1633832462757<span class="tag">&lt;/<span class="name">MTIME</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">ATIME</span>&gt;</span>1633832462757<span class="tag">&lt;/<span class="name">ATIME</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">BLOCKSIZE</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">BLOCKSIZE</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">CLIENT_NAME</span>&gt;</span>DFSClient_NONMAPREDUCE_-1241738550_1<span class="tag">&lt;/<span class="name">CLIENT_NAME</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">CLIENT_MACHINE</span>&gt;</span>192.168.2.6<span class="tag">&lt;/<span class="name">CLIENT_MACHINE</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">OVERWRITE</span>&gt;</span>true<span class="tag">&lt;/<span class="name">OVERWRITE</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">PERMISSION_STATUS</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">USERNAME</span>&gt;</span>atguigu<span class="tag">&lt;/<span class="name">USERNAME</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">GROUPNAME</span>&gt;</span>supergroup<span class="tag">&lt;/<span class="name">GROUPNAME</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">MODE</span>&gt;</span>420<span class="tag">&lt;/<span class="name">MODE</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;/<span class="name">PERMISSION_STATUS</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">ERASURE_CODING_POLICY_ID</span>&gt;</span>0<span class="tag">&lt;/<span class="name">ERASURE_CODING_POLICY_ID</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">RPC_CLIENTID</span>&gt;</span>a0a774c6-277a-43ec-9f31-a8c2cbcaa322<span class="tag">&lt;/<span class="name">RPC_CLIENTID</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">RPC_CALLID</span>&gt;</span>3<span class="tag">&lt;/<span class="name">RPC_CALLID</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_ALLOCATE_BLOCK_ID<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">TXID</span>&gt;</span>331<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">BLOCK_ID</span>&gt;</span>1073741861<span class="tag">&lt;/<span class="name">BLOCK_ID</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_SET_GENSTAMP_V2<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">TXID</span>&gt;</span>332<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">GENSTAMPV2</span>&gt;</span>1037<span class="tag">&lt;/<span class="name">GENSTAMPV2</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_ADD_BLOCK<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">TXID</span>&gt;</span>333<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">PATH</span>&gt;</span>/sanguo/jdk-8u212-linux-x64.tar.gz._COPYING_<span class="tag">&lt;/<span class="name">PATH</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">BLOCK</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">BLOCK_ID</span>&gt;</span>1073741861<span class="tag">&lt;/<span class="name">BLOCK_ID</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">NUM_BYTES</span>&gt;</span>0<span class="tag">&lt;/<span class="name">NUM_BYTES</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">GENSTAMP</span>&gt;</span>1037<span class="tag">&lt;/<span class="name">GENSTAMP</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;/<span class="name">BLOCK</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">RPC_CLIENTID</span>/&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">RPC_CALLID</span>&gt;</span>-2<span class="tag">&lt;/<span class="name">RPC_CALLID</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_ALLOCATE_BLOCK_ID<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">TXID</span>&gt;</span>334<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">BLOCK_ID</span>&gt;</span>1073741862<span class="tag">&lt;/<span class="name">BLOCK_ID</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_SET_GENSTAMP_V2<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">TXID</span>&gt;</span>335<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">GENSTAMPV2</span>&gt;</span>1038<span class="tag">&lt;/<span class="name">GENSTAMPV2</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_ADD_BLOCK<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">TXID</span>&gt;</span>336<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">PATH</span>&gt;</span>/sanguo/jdk-8u212-linux-x64.tar.gz._COPYING_<span class="tag">&lt;/<span class="name">PATH</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">BLOCK</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">BLOCK_ID</span>&gt;</span>1073741861<span class="tag">&lt;/<span class="name">BLOCK_ID</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">NUM_BYTES</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">NUM_BYTES</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">GENSTAMP</span>&gt;</span>1037<span class="tag">&lt;/<span class="name">GENSTAMP</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;/<span class="name">BLOCK</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">BLOCK</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">BLOCK_ID</span>&gt;</span>1073741862<span class="tag">&lt;/<span class="name">BLOCK_ID</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">NUM_BYTES</span>&gt;</span>0<span class="tag">&lt;/<span class="name">NUM_BYTES</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">GENSTAMP</span>&gt;</span>1038<span class="tag">&lt;/<span class="name">GENSTAMP</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;/<span class="name">BLOCK</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">RPC_CLIENTID</span>/&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">RPC_CALLID</span>&gt;</span>-2<span class="tag">&lt;/<span class="name">RPC_CALLID</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_CLOSE<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">TXID</span>&gt;</span>337<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">LENGTH</span>&gt;</span>0<span class="tag">&lt;/<span class="name">LENGTH</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">INODEID</span>&gt;</span>0<span class="tag">&lt;/<span class="name">INODEID</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">PATH</span>&gt;</span>/sanguo/jdk-8u212-linux-x64.tar.gz._COPYING_<span class="tag">&lt;/<span class="name">PATH</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">REPLICATION</span>&gt;</span>3<span class="tag">&lt;/<span class="name">REPLICATION</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">MTIME</span>&gt;</span>1633832463721<span class="tag">&lt;/<span class="name">MTIME</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">ATIME</span>&gt;</span>1633832462757<span class="tag">&lt;/<span class="name">ATIME</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">BLOCKSIZE</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">BLOCKSIZE</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">CLIENT_NAME</span>/&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">CLIENT_MACHINE</span>/&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">OVERWRITE</span>&gt;</span>false<span class="tag">&lt;/<span class="name">OVERWRITE</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">BLOCK</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">BLOCK_ID</span>&gt;</span>1073741861<span class="tag">&lt;/<span class="name">BLOCK_ID</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">NUM_BYTES</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">NUM_BYTES</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">GENSTAMP</span>&gt;</span>1037<span class="tag">&lt;/<span class="name">GENSTAMP</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;/<span class="name">BLOCK</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">BLOCK</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">BLOCK_ID</span>&gt;</span>1073741862<span class="tag">&lt;/<span class="name">BLOCK_ID</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">NUM_BYTES</span>&gt;</span>60795424<span class="tag">&lt;/<span class="name">NUM_BYTES</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">GENSTAMP</span>&gt;</span>1038<span class="tag">&lt;/<span class="name">GENSTAMP</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;/<span class="name">BLOCK</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">PERMISSION_STATUS</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">USERNAME</span>&gt;</span>atguigu<span class="tag">&lt;/<span class="name">USERNAME</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">GROUPNAME</span>&gt;</span>supergroup<span class="tag">&lt;/<span class="name">GROUPNAME</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">MODE</span>&gt;</span>420<span class="tag">&lt;/<span class="name">MODE</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;/<span class="name">PERMISSION_STATUS</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_RENAME_OLD<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">TXID</span>&gt;</span>338<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">LENGTH</span>&gt;</span>0<span class="tag">&lt;/<span class="name">LENGTH</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">SRC</span>&gt;</span>/sanguo/jdk-8u212-linux-x64.tar.gz._COPYING_<span class="tag">&lt;/<span class="name">SRC</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">DST</span>&gt;</span>/sanguo/jdk-8u212-linux-x64.tar.gz<span class="tag">&lt;/<span class="name">DST</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">TIMESTAMP</span>&gt;</span>1633832463726<span class="tag">&lt;/<span class="name">TIMESTAMP</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">RPC_CLIENTID</span>&gt;</span>a0a774c6-277a-43ec-9f31-a8c2cbcaa322<span class="tag">&lt;/<span class="name">RPC_CLIENTID</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">RPC_CALLID</span>&gt;</span>9<span class="tag">&lt;/<span class="name">RPC_CALLID</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_END_LOG_SEGMENT<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">TXID</span>&gt;</span>339<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">EDITS</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p>思考：NameNode如何确定下次开机启动的时候合并哪些Edits？<br>通过最新合并的fsimage_的序号（例如fsimage_0000000000000000584）和seen_txid存放的序号（如585）取它们中间的edits序号合并即可<br><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16340122811449.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
</blockquote>
</li>
</ol>
</li>
</ol>
</li>
</ol>
<hr>
<h2 id="5-3-CheckPoint时间设置"><a href="#5-3-CheckPoint时间设置" class="headerlink" title="5.3 CheckPoint时间设置"></a>5.3 CheckPoint时间设置</h2><p>配置文件：hdfs-default.xml</p>
<ol>
<li>默认配置SecondaryNameNode一小时同步一次 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>3600s<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>一分钟检查一次操作次数，达到100W次触发一次同步 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.txns<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>1000000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>操作动作次数<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.check.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>60s<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span> 1分钟检查一次操作次数<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">&lt;/property &gt;</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h2 id="5-4-NameNode故障处理"><a href="#5-4-NameNode故障处理" class="headerlink" title="5.4 NameNode故障处理"></a>5.4 NameNode故障处理</h2><h3 id="5-4-1-使用SecondaryNameNode中的数据恢复"><a href="#5-4-1-使用SecondaryNameNode中的数据恢复" class="headerlink" title="5.4.1 使用SecondaryNameNode中的数据恢复"></a>5.4.1 使用SecondaryNameNode中的数据恢复</h3><p>将SecondaryNameNode中的数据拷贝到NameNode存储元数据的位置</p>
<ol>
<li>杀掉NameNode进程 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 name]$ jps</span><br><span class="line">1921 NodeManager</span><br><span class="line">4834 NameNode</span><br><span class="line">1638 DataNode</span><br><span class="line">4909 Jps</span><br><span class="line">2095 JobHistoryServer</span><br><span class="line">[atguigu@hadoop001 name]$ <span class="built_in">kill</span> -9 1921</span><br><span class="line">[atguigu@hadoop001 name]$ jps</span><br><span class="line">4834 NameNode</span><br><span class="line">1638 DataNode</span><br><span class="line">4922 Jps</span><br><span class="line">2095 JobHistoryServer</span><br><span class="line">[atguigu@hadoop001 name]$</span><br></pre></td></tr></table></figure></li>
<li>删除NameNode数据 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 name]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-3.1.3/data/dfs/name</span><br><span class="line">[atguigu@hadoop001 name]$ ls</span><br><span class="line">current  in_use.lock</span><br><span class="line">[atguigu@hadoop001 name]$ rm -rf *</span><br><span class="line">[atguigu@hadoop001 name]$ ll</span><br><span class="line">总用量 0</span><br><span class="line">[atguigu@hadoop001 name]$</span><br></pre></td></tr></table></figure></li>
<li>拷贝SecondaryNameNode数据到NameNode<br> SecondaryNameNode: <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop003 namesecondary]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-3.1.3/data/dfs/namesecondary</span><br><span class="line">[atguigu@hadoop003 namesecondary]$ ls</span><br><span class="line">current  in_use.lock</span><br><span class="line">[atguigu@hadoop003 namesecondary]$</span><br></pre></td></tr></table></figure>
 NameNode: <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 name]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-3.1.3/data/dfs/name</span><br><span class="line">[atguigu@hadoop001 name]$ scp -r hadoop003:/opt/module/hadoop-3.1.3/data/dfs/namesecondary/* ./</span><br><span class="line">edits_0000000000000000415-0000000000000000416          100%   42    71.3KB/s   00:00</span><br><span class="line">edits_0000000000000000618-0000000000000000623          100%  311   726.8KB/s   00:00</span><br><span class="line">edits_0000000000000000671-0000000000000000672          100%   42    96.1KB/s   00:00</span><br><span class="line">edits_0000000000000000002-0000000000000000217          100%   27KB  28.4MB/s   00:00</span><br><span class="line">edits_0000000000000000664-0000000000000000665          100%   42    96.8KB/s   00:00</span><br><span class="line">edits_0000000000000000667-0000000000000000668          100%   42   101.8KB/s   00:00</span><br><span class="line">VERSION                                                100%  215   519.5KB/s   00:00</span><br><span class="line">edits_0000000000000000218-0000000000000000219          100%   42   105.8KB/s   00:00</span><br><span class="line">edits_0000000000000000410-0000000000000000411          100%   42   102.3KB/s   00:00</span><br><span class="line">edits_0000000000000000645-0000000000000000649          100%  291   761.2KB/s   00:00</span><br><span class="line">edits_0000000000000000662-0000000000000000663          100%   42   113.7KB/s   00:00</span><br><span class="line">edits_0000000000000000220-0000000000000000221          100%   42   111.9KB/s   00:00</span><br><span class="line">edits_0000000000000000412-0000000000000000413          100%   42   102.2KB/s   00:00</span><br><span class="line">edits_0000000000000000654-0000000000000000655          100%   42   105.8KB/s   00:00</span><br><span class="line">edits_0000000000000000222-0000000000000000223          100%   42   102.6KB/s   00:00</span><br><span class="line">edits_0000000000000000408-0000000000000000409          100%   42   106.7KB/s   00:00</span><br><span class="line">edits_0000000000000000656-0000000000000000657          100%   42   109.0KB/s   00:00</span><br><span class="line">edits_0000000000000000225-0000000000000000325          100% 1024KB  88.8MB/s   00:00</span><br><span class="line">edits_0000000000000000326-0000000000000000327          100%   42   130.9KB/s   00:00</span><br><span class="line">edits_0000000000000000639-0000000000000000644          100%  310     1.0MB/s   00:00</span><br><span class="line">edits_0000000000000000650-0000000000000000651          100%   42   164.8KB/s   00:00</span><br><span class="line">edits_0000000000000000669-0000000000000000670          100%   42   170.4KB/s   00:00</span><br><span class="line">edits_0000000000000000328-0000000000000000339          100%  902     3.5MB/s   00:00</span><br><span class="line">fsimage_0000000000000000670                            100% 4452    13.4MB/s   00:00</span><br><span class="line">fsimage_0000000000000000672.md5                        100%   62   255.0KB/s   00:00</span><br><span class="line">edits_0000000000000000340-0000000000000000382          100% 3512    11.5MB/s   00:00</span><br><span class="line">edits_0000000000000000417-0000000000000000525          100% 6663    19.3MB/s   00:00</span><br><span class="line">edits_0000000000000000658-0000000000000000659          100%   42   166.4KB/s   00:00</span><br><span class="line">fsimage_0000000000000000670.md5                        100%   62   251.4KB/s   00:00</span><br><span class="line">edits_0000000000000000383-0000000000000000405          100% 1708     5.9MB/s   00:00</span><br><span class="line">edits_0000000000000000526-0000000000000000617          100% 5206    14.9MB/s   00:00</span><br><span class="line">edits_0000000000000000660-0000000000000000661          100%   42   168.7KB/s   00:00</span><br><span class="line">fsimage_0000000000000000672                            100% 4452    13.6MB/s   00:00</span><br><span class="line">edits_0000000000000000406-0000000000000000407          100%   42   167.7KB/s   00:00</span><br><span class="line">edits_0000000000000000624-0000000000000000638          100%  934     3.6MB/s   00:00</span><br><span class="line">edits_0000000000000000652-0000000000000000653          100%   42   162.7KB/s   00:00</span><br><span class="line">in_use.lock                                            100%   14    53.2KB/s   00:00</span><br><span class="line">[atguigu@hadoop001 name]$ ls</span><br><span class="line">current  in_use.lock</span><br><span class="line">[atguigu@hadoop001 name]$</span><br></pre></td></tr></table></figure></li>
<li>重新启动NameNode <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 name]$ jps</span><br><span class="line">4977 Jps</span><br><span class="line">1638 DataNode</span><br><span class="line">2095 JobHistoryServer</span><br><span class="line">[atguigu@hadoop001 name]$ hdfs --daemon start namenode</span><br><span class="line">[atguigu@hadoop001 name]$ jps</span><br><span class="line">1638 DataNode</span><br><span class="line">5030 NameNode</span><br><span class="line">5101 Jps</span><br><span class="line">2095 JobHistoryServer</span><br><span class="line">[atguigu@hadoop001 name]$</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="5-4-2-使用importCheckpoint恢复"><a href="#5-4-2-使用importCheckpoint恢复" class="headerlink" title="5.4.2 使用importCheckpoint恢复"></a>5.4.2 使用importCheckpoint恢复</h3><p>使用-importCheckpoint选项启动NameNode守护进程，从而将SecondaryNameNode中数据拷贝到NameNode目录中。</p>
<ol>
<li>修改hdfs-site.xml <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.period<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>120<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.1.3/data/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>杀掉NameNode进程</li>
<li>删除NameNode存储的数据（/opt/module/hadoop-3.1.3/data/dfs/name） <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ rm -rf /opt/module/hadoop-3.1.3/data/dfs/name/*</span><br></pre></td></tr></table></figure></li>
<li>如果SecondaryNameNode不和NameNode在一个主机节点上，需要将SecondaryNameNode存储数据的目录拷贝到NameNode存储数据的平级目录，并删除in_use.lock文件 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 dfs]$ scp -r atguigu@hadoop104:/opt/module/hadoop-3.1.3/data/dfs/namesecondary ./</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 namesecondary]$ rm -rf in_use.lock</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 dfs]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-3.1.3/data/dfs</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop102 dfs]$ ls</span><br><span class="line">data  name  namesecondary</span><br></pre></td></tr></table></figure></li>
<li>导入检查点数据（等待一会ctrl+c结束掉） <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ bin/hdfs namenode -importCheckpoint</span><br></pre></td></tr></table></figure></li>
<li>启动NameNode <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hdfs --daemon start namenode</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h2 id="5-5-集群安全模式"><a href="#5-5-集群安全模式" class="headerlink" title="5.5 集群安全模式"></a>5.5 集群安全模式</h2><ol>
<li>NameNode启动：NameNode启动时，首先降镜像文件FsImage载入内存，并执行编辑日志Edits中的各项操作。在内存中成功建立完整的文件系统元数据之后，创建一个空的编辑日志，生成新的Fsimage文件。此时，NameNode开始监听DateNode请求，这个过程期间，NameNode一直运行安全模式，即对于客户端来说是只读的</li>
<li>DateNode启动：系统中的数据块位置不由NameNode维护，而是以块列表的形式存储在DateNode中。在系统的正常操作期间，NameNode会在内存中保留所有块位置的信息。在安全模式下，各个DateNode会向NameNode发送最新的块列表信息，NomeNode获取到足够多的块信息之后，即可高效运行文件系统</li>
<li>安全模式退出判断：如果满足<font color ='red' >最小副本条件</font>（在整个文件系统中99.9%的块满足最小副本级别（默认值：dfs.replication.min=1））。在启动一个刚刚格式化的HDFS集群时，因为系统中还没有任何块，所以NameNode不会进入安全模式。</li>
<li>手动进入安全模式 <ol>
<li>基本语法<br> 集群处于安全模式，不能执行重要操作（写操作）。集群启动完成后，自动退出安全模式。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看安全模式状态</span></span><br><span class="line">[atguigu@hadoop001 name]$ hdfs dfsadmin -safemode get</span><br><span class="line">Safe mode is OFF</span><br><span class="line"><span class="comment"># 进入安全模式</span></span><br><span class="line">[atguigu@hadoop001 name]$ hdfs dfsadmin -safemode enter</span><br><span class="line">Safe mode is ON</span><br><span class="line"><span class="comment"># 查看安全模式状态</span></span><br><span class="line">[atguigu@hadoop001 name]$ hdfs dfsadmin -safemode get</span><br><span class="line">Safe mode is ON</span><br><span class="line"><span class="comment"># 离开安全模式</span></span><br><span class="line">[atguigu@hadoop001 name]$ hdfs dfsadmin -safemode leave</span><br><span class="line">Safe mode is OFF</span><br><span class="line"><span class="comment"># 查看安全模式状态</span></span><br><span class="line">[atguigu@hadoop001 name]$ hdfs dfsadmin -safemode get</span><br><span class="line">Safe mode is OFF</span><br><span class="line"><span class="comment"># 进入安全模式</span></span><br><span class="line">[atguigu@hadoop001 name]$ hdfs dfsadmin -safemode enter</span><br><span class="line">Safe mode is ON</span><br><span class="line"><span class="comment"># 等待安全模式退出，阻塞当前进程</span></span><br><span class="line">[atguigu@hadoop001 name]$ hdfs dfsadmin -safemode <span class="built_in">wait</span></span><br><span class="line"></span><br><span class="line">^C</span><br><span class="line">[atguigu@hadoop001 name]$ hdfs dfsadmin -safemode leave</span><br><span class="line">Safe mode is OFF</span><br><span class="line">[atguigu@hadoop001 name]$ hdfs dfsadmin -safemode get</span><br><span class="line">Safe mode is OFF</span><br><span class="line"><span class="comment"># 安全模式退出，wait进程继续</span></span><br><span class="line">[atguigu@hadoop001 name]$ hdfs dfsadmin -safemode <span class="built_in">wait</span></span><br><span class="line">Safe mode is OFF</span><br><span class="line">[atguigu@hadoop001 name]$</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>示例<br> <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16340146742555.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
</ol>
</li>
</ol>
<hr>
<h2 id="5-6-NameNode多目录配置"><a href="#5-6-NameNode多目录配置" class="headerlink" title="5.6 NameNode多目录配置"></a>5.6 NameNode多目录配置</h2><ol>
<li>NameNode的本地目录可以配置成多个，且每个目录存放内容相同，增加了可靠性（不同目录最好分布在不同的磁盘）</li>
<li>具体配置如下<ol>
<li>在hdfs-site.xml文件中添加如下内容 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file://$&#123;hadoop.tmp.dir&#125;/dfs/name1,file://$&#123;hadoop.tmp.dir&#125;/dfs/name2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>停止集群，删除三台节点的data和logs中所有数据。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ rm -rf data/ logs/</span><br><span class="line">[atguigu@hadoop103 hadoop-3.1.3]$ rm -rf data/ logs/</span><br><span class="line">[atguigu@hadoop104 hadoop-3.1.3]$ rm -rf data/ logs/</span><br></pre></td></tr></table></figure></li>
<li>格式化集群并启动。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ bin/hdfs namenode -format</span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ sbin/start-dfs.sh</span><br></pre></td></tr></table></figure></li>
<li>查看结果 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 dfs]$ ll</span><br><span class="line">总用量 12</span><br><span class="line">drwx------. 3 atguigu atguigu 4096 12月 11 08:03 data</span><br><span class="line">drwxrwxr-x. 3 atguigu atguigu 4096 12月 11 08:03 name1</span><br><span class="line">drwxrwxr-x. 3 atguigu atguigu 4096 12月 11 08:03 name2</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<hr>
<h1 id="六、DataNode"><a href="#六、DataNode" class="headerlink" title="六、DataNode"></a>六、DataNode</h1><h2 id="6-1-DateNode工作机制"><a href="#6-1-DateNode工作机制" class="headerlink" title="6.1 DateNode工作机制"></a>6.1 DateNode工作机制</h2><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16340068224418.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ol>
<li>一个数据块在DataNode上以文件形式存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据包括数据块的长度，块数据的校验和，以及时间戳。</li>
<li>DataNode启动后向NameNode注册，通过后，周期性（6小时）的向NameNode上报所有的块信息。 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hdfs-default.xml</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.blockreport.intervalMsec<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>21600000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Determines block reporting interval in milliseconds.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>心跳是每3秒一次，心跳返回结果带有NameNode给该DataNode的命令如复制块数据到另一台机器，或删除某个数据块。 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">hdfs-default.xml</span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.heartbeat.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>3s<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">    Determines datanode heartbeat interval in seconds.</span><br><span class="line">    Can use the following suffix (case insensitive):</span><br><span class="line">    ms(millis), s(sec), m(min), h(hour), d(day)</span><br><span class="line">    to specify the time (such as 2s, 2m, 1h, etc.).</span><br><span class="line">    Or provide complete number in seconds (such as 30 for 30 seconds).</span><br><span class="line">    If no time unit is specified then seconds is assumed.</span><br><span class="line">  <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>如果超过10分钟30秒没有收到某个DataNode的心跳，则认为该节点不可用。</li>
<li>集群运行中可以安全加入和退出一些机器。</li>
</ol>
<hr>
<h2 id="6-2-数据完整性"><a href="#6-2-数据完整性" class="headerlink" title="6.2 数据完整性"></a>6.2 数据完整性</h2><p>思考：如果电脑磁盘里面存储的数据是控制高铁信号灯的红灯信号（1）和绿灯信号（0），但是存储该数据的磁盘坏了，一直显示是绿灯，是否很危险？同理DataNode节点上的数据损坏了，却没有发现，是否也很危险，那么如何解决呢？如下是DataNode节点保证数据完整性的方法。</p>
<ol>
<li>当DataNode读取Block的时候，它会计算CheckSum。</li>
<li>如果计算后的CheckSum，与Block创建时值不一样，说明Block已经损坏。</li>
<li>Client读取其他DataNode上的Block。</li>
<li>常见的校验算法 crc（32），md5（128），sha1（160）</li>
<li>DataNode在其文件创建后周期验证CheckSum。</li>
</ol>
<hr>
<h2 id="6-3-掉线时限参数设置"><a href="#6-3-掉线时限参数设置" class="headerlink" title="6.3 掉线时限参数设置"></a>6.3 掉线时限参数设置</h2><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16340157434025.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ol>
<li>需要注意的是hdfs-site.xml 配置文件中的heartbeat.recheck.interval的单位为毫秒，dfs.heartbeat.interval的单位为秒。 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.heartbeat.recheck-interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>300000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.heartbeat.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>效果如图<br> <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16340162105064.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
</ol>
<hr>
<h2 id="6-4-服役新节点"><a href="#6-4-服役新节点" class="headerlink" title="6.4 服役新节点"></a>6.4 服役新节点</h2><ol>
<li>需求：<br> 随着公司业务的增长，数据量越来越大，原有的数据节点的容量已经不能满足存储数据的需求，需要在原有集群基础上动态添加新的数据节点</li>
<li>环境准备<ol>
<li>在hadoop104主机上再克隆一台hadoop105主机</li>
<li>修改IP地址和主机名称</li>
<li>删除原来HDFS文件系统留存的文件（/opt/module/hadoop-3.1.3/data和logs）</li>
<li>source一下配置文件 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop105 hadoop-3.1.3]$ <span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li>具体步骤<ol>
<li>直接启动DataNode，即可关联到集群 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop105 hadoop-3.1.3]$ hdfs --daemon start datanode</span><br><span class="line">[atguigu@hadoop105 hadoop-3.1.3]$ yarn --daemon start nodemanager</span><br></pre></td></tr></table></figure></li>
<li>在hadoop105上上传文件 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop105 hadoop-3.1.3]$ hadoop fs -put /opt/module/hadoop-3.1.3/LICENSE.txt /</span><br></pre></td></tr></table></figure></li>
<li>如果数据不均衡，可以用命令实现集群的再平衡 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 sbin]$ ./start-balancer.sh</span><br><span class="line">starting balancer, logging to /opt/module/hadoop-3.1.3/logs/hadoop-atguigu-balancer-hadoop102.out</span><br><span class="line">Time Stamp               Iteration<span class="comment">#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved</span></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<hr>
<h2 id="6-5-退役旧数据节点"><a href="#6-5-退役旧数据节点" class="headerlink" title="6.5 退役旧数据节点"></a>6.5 退役旧数据节点</h2><h3 id="6-5-1-添加白名单和黑名单"><a href="#6-5-1-添加白名单和黑名单" class="headerlink" title="6.5.1 添加白名单和黑名单"></a>6.5.1 添加白名单和黑名单</h3><ul>
<li>白名单和黑名单是hadoop管理集群主机的一种机制。</li>
<li>添加到白名单的主机节点，都允许访问NameNode，不在白名单的主机节点，都会被退出。</li>
<li>添加到黑名单的主机节点，不允许访问NameNode，会在数据迁移后退出。</li>
<li>实际情况下，白名单用于确定允许访问NameNode的DataNode节点，内容配置一般与workers文件内容一致。 黑名单用于在集群运行过程中退役DataNode节点。<br>配置白名单和黑名单的具体步骤如下：<ol>
<li>在NameNode节点的/opt/module/hadoop-3.1.3/etc/hadoop目录下分别创建whitelist 和blacklist文件，白名单whitelist添加节点内容，blacklist黑名单暂时为空。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 hadoop]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-3.1.3/etc/hadoop</span><br><span class="line">[atguigu@hadoop001 hadoop]$ touch blacklist</span><br><span class="line">[atguigu@hadoop001 hadoop]$ touch whitelist</span><br><span class="line">[atguigu@hadoop001 hadoop]$ ll *list</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu 0 10月 12 18:50 blacklist</span><br><span class="line">-rw-rw-r--. 1 atguigu atguigu 0 10月 12 18:50 whitelist</span><br><span class="line">[atguigu@hadoop001 hadoop]$ vim whitelist</span><br><span class="line">[atguigu@hadoop001 hadoop]$ cat whitelist</span><br><span class="line">hadoop001</span><br><span class="line">hadoop002</span><br><span class="line">hadoop003</span><br><span class="line">hadoop004</span><br><span class="line">[atguigu@hadoop001 hadoop]$</span><br></pre></td></tr></table></figure></li>
<li>在hdfs-site.xml配置文件中增加dfs.hosts和 dfs.hosts.exclude配置参数 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 白名单 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.1.3/etc/hadoop/whitelist<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 黑名单 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.hosts.exclude<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.1.3/etc/hadoop/blacklist<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>分发配置文件whitelist，blacklist，hdfs-site.xml (注意：004节点也要发一份) <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 hadoop]$ xsync /opt/module/hadoop-3.1.3/etc/hadoop/</span><br><span class="line">[atguigu@hadoop001 hadoop]$ scp -r * hadoop004:/opt/module/hadoop-3.1.3/etc/hadoop/</span><br></pre></td></tr></table></figure></li>
<li>重新启动集群(注意：105节点没有添加到workers，因此要单独起停) <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ stop-dfs.sh</span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ start-dfs.sh</span><br><span class="line">[atguigu@hadoop105 hadoop-3.1.3]$ hdfs –daemon start datanode</span><br></pre></td></tr></table></figure></li>
<li>在web浏览器上查看目前正常工作的DN节点<br> <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16340373303979.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"><h3 id="6-5-2-黑名单退役"><a href="#6-5-2-黑名单退役" class="headerlink" title="6.5.2 黑名单退役"></a>6.5.2 黑名单退役</h3></li>
</ol>
</li>
</ul>
<ol>
<li>编辑/opt/module/hadoop-3.1.3/etc/hadoop目录下的blacklist文件 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 hadoop]$ vim blacklist</span><br><span class="line">[atguigu@hadoop001 hadoop]$ cat blacklist</span><br><span class="line">hadoop004</span><br><span class="line">[atguigu@hadoop001 hadoop]$</span><br></pre></td></tr></table></figure></li>
<li>分发blacklist到所有节点 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 hadoop]$ xsync /opt/module/hadoop-3.1.3/etc/hadoop/</span><br><span class="line">[atguigu@hadoop001 hadoop]$ scp -r * hadoop004:/opt/module/hadoop-3.1.3/etc/hadoop/</span><br></pre></td></tr></table></figure></li>
<li>刷新NameNode、刷新ResourceManager <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 hadoop]$ hdfs dfsadmin -refreshNodes</span><br><span class="line">Refresh nodes successful</span><br><span class="line">[atguigu@hadoop001 hadoop]$ yarn rmadmin -refreshNodes</span><br><span class="line">2021-10-12 19:20:20,896 INFO client.RMProxy: Connecting to ResourceManager at hadoop002/192.168.2.7:8033</span><br><span class="line">[atguigu@hadoop001 hadoop]$</span><br></pre></td></tr></table></figure></li>
<li>检查Web浏览器，退役节点的状态为decommission in progress（退役中），说明数据节点正在复制块到其他节点<img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16340378419483.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>等待退役节点状态为decommissioned（所有块已经复制完成），停止该节点及节点资源管理器。注意：如果副本数是3，服役的节点小于等于3，是不能退役成功的，需要修改副本数后才能退役<img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16340378878057.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>如果数据不均衡，可以用命令实现集群的再平衡 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 hadoop-3.1.3]$ sbin/start-balancer.sh</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：不允许白名单和黑名单中同时出现同一个主机名称，既然使用了黑名单blacklist成功退役了hadoop105节点，因此要将白名单whitelist里面的hadoop105去掉。</p>
</blockquote>
</li>
</ol>
<hr>
<h2 id="6-6-DataNode多目录配置"><a href="#6-6-DataNode多目录配置" class="headerlink" title="6.6 DataNode多目录配置"></a>6.6 DataNode多目录配置</h2><ol>
<li>DataNode可以配置成多个目录，每个目录存储的数据不一样。即：数据不是副本</li>
<li>具体配置如下<ol>
<li>在hdfs-site.xml文件中添加如下内容 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file://$&#123;hadoop.tmp.dir&#125;/dfs/data1,file://$&#123;hadoop.tmp.dir&#125;/dfs/data2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>停止集群，删除三台节点的data和logs中所有数据。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ rm -rf data/ logs/</span><br><span class="line">[atguigu@hadoop103 hadoop-3.1.3]$ rm -rf data/ logs/</span><br><span class="line">[atguigu@hadoop104 hadoop-3.1.3]$ rm -rf data/ logs/</span><br></pre></td></tr></table></figure></li>
<li>格式化集群并启动。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ bin/hdfs namenode –format</span><br><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ sbin/start-dfs.sh</span><br></pre></td></tr></table></figure></li>
<li>查看结果 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 dfs]$ ll</span><br><span class="line">总用量 12</span><br><span class="line">drwx------. 3 atguigu atguigu 4096 4月   4 14:22 data1</span><br><span class="line">drwx------. 3 atguigu atguigu 4096 4月   4 14:22 data2</span><br><span class="line">drwxrwxr-x. 3 atguigu atguigu 4096 12月 11 08:03 name1</span><br><span class="line">drwxrwxr-x. 3 atguigu atguigu 4096 12月 11 08:03 name2</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<hr>
<h2 id="问答"><a href="#问答" class="headerlink" title="问答"></a>问答</h2><h3 id="一、描述一下HDFS的数据写入流程"><a href="#一、描述一下HDFS的数据写入流程" class="headerlink" title="一、描述一下HDFS的数据写入流程"></a>一、描述一下HDFS的数据写入流程</h3><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16340443194587.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ol>
<li>客户端调用DistributedFileSystem#create方法通过DfsClient请求NameNode上传文件</li>
<li>NameNode校验：权限，路径，文件名通过后在对应路径创建空文件，写入Edits操作记录，返回文件信息</li>
<li>DistributedFileSystem#create 返回值为FSDataOutputStream输出流，FSDataOutputStream#create方法会初始化DFSOutputStream和DataStreamer；</li>
<li>调用DFSOutputStream#addBlock请求NN申请新的Block</li>
<li>NN根据机架感知-网络拓扑计算节点距离返回合适的DN列表</li>
<li>客户端调用FSDataOutputStream.PositionCache#write -&gt; DFSOutputStream#writeChunk写入数据</li>
<li>读取满一个packet(128个chunk)放入DFSOutputStream#enqueueCurrentPacketFull</li>
<li>DataStreamer#setPipeline初始化pipeline 首先和最近的DN1建立连接，然后DN1传输给DN2,DN2传输给DN3</li>
<li>DataStreamer把packet从dataqueue移动到ackqueue</li>
<li>DN3校验后返回ack给DN2,DN2校验后返回ack给DN1,DN1校验后返回ack给客户端</li>
<li>ResponseProcessor.ResponseProcessor接收响应并把packet从ackqueue移除</li>
<li>出现异常后ackqueue会重新移动到dataqueue再次创建连接重新发送</li>
<li>全部packet发送完成后当前block上传结束</li>
<li>读取下一个block重复4-13步骤</li>
<li>全部读取完成通知NN上传结束</li>
</ol>
<ul>
<li>block(文件块): 类似Linux中常见文件系统的最小操作单位, HDFS也是如此, block就是HDFS操作文件的最小单元, 默认128MB/个 (逻辑上设置的大小)</li>
<li>chunk(校验块): 文件块(block)实际存储/校验的最小单位, 严谨说chunk分为数据域和校验域两个部分组成, 但一般情况大家指的是数据域<ul>
<li>数据域: 默认512字节, 比如你写513个字节数据, 它占据一个block (而此block内部是两个chunk组成) , 又称为chunk data</li>
<li>校验域: 固定4字节, 存放校验码, 它与数据域一一对应, 又称chunk checksum</li>
</ul>
</li>
<li>packet(数据包): HDFS各组件间数据传输的基本单位, 默认64KB, 类似网络传输中数据包的概念, 主要是 header + body/data 两个部分组成<ul>
<li>packet header : 存储传输数据过程中的一些基本信息(数据包长度/版本/标志位等), 变长</li>
<li>packet body: 存储实际传输的数据(chunk), 同样packet里实际分布的最小单位也是chunk</li>
</ul>
</li>
</ul>
<h3 id="二、描述一下HDFS的数据读取流程"><a href="#二、描述一下HDFS的数据读取流程" class="headerlink" title="二、描述一下HDFS的数据读取流程"></a>二、描述一下HDFS的数据读取流程</h3><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16340854804776.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ol>
<li>客户端向namenode发RPC请求, 读取文件对应blocks的DN信息</li>
<li>namenode检查文件是否存在，如果存在则获取文件的元信息（按顺序返回BlockId以及对应所在的datanode列表）</li>
<li>客户端收到block对应的DN信息后选取一个网络访问最近的DN, 依次读取每个数据块(客户端这里有校验逻辑, 如果发现异常会汇报坏块)</li>
<li>客户端与DN建立socket连接，通过流以packet为单位传输对应的数据块, 客户端收到数据写入本地磁盘</li>
<li>依次传输剩下的数据块，直到整个文件读取完成, 最后关闭输入流</li>
</ol>
<h3 id="三、简述HDFS的架构，其中每个服务的作用"><a href="#三、简述HDFS的架构，其中每个服务的作用" class="headerlink" title="三、简述HDFS的架构，其中每个服务的作用"></a>三、简述HDFS的架构，其中每个服务的作用</h3><ol>
<li>NameNode: HDFS集群的管理者<ol>
<li>管理HDFS的命名空间</li>
<li>配置副本策略</li>
<li>维护元数据信息：文件基本属性，目录层级，文件-块的映射</li>
<li>处理客户端的读写请求</li>
</ol>
</li>
<li>DataNode：HDFS集群的数据存储节点<ol>
<li>存储Block数据</li>
<li>保证数据完整性</li>
<li>接受NameNode指令，执行实际操作</li>
<li>接受客户端请求读写Block</li>
</ol>
</li>
<li>SecondaryNameNode: NameNode的备份<ol>
<li>并非NameNode的热备。当NameNode挂掉的时候，它并不能马上替换NameNode并提供服务。</li>
<li>辅助NameNode，分担其工作量，比如定期合并Fsimage和Edits，并推送给NameNode</li>
<li>在紧急情况下，可辅助恢复NameNode。</li>
</ol>
</li>
<li>Client<ol>
<li>文件切分。文件上传HDFS的时候，Client将文件切分成一个一个的Block，然后进行上传</li>
<li>与NameNode交互，获取文件的位置信息</li>
<li>与DataNode交互，读取或者写入数据；</li>
<li>Client提供一些命令来管理HDFS，比如NameNode格式化</li>
<li>Client可以通过一些命令来访问HDFS，比如对HDFS增删查改操作</li>
</ol>
</li>
</ol>
<h3 id="四、HDFS中如何实现元数据的维护？"><a href="#四、HDFS中如何实现元数据的维护？" class="headerlink" title="四、HDFS中如何实现元数据的维护？"></a>四、HDFS中如何实现元数据的维护？</h3><ol>
<li>存储<ul>
<li>内存：保存全量元数据信息</li>
<li>磁盘：FsImage + Edits = 完整的元数据信息<ol>
<li>FsImage：NameNode内存中的元数据镜像</li>
<li>Edits：NameNode已经执行的的操作记录</li>
</ol>
</li>
</ul>
</li>
<li>NameNode启动操作<ol>
<li>加载FsImage到内存</li>
<li>在内存中根据seen_txid执行Edits记录生成完整元数据</li>
<li>内存中完整的元数据信息写入新的FsImage</li>
<li>生成新的Edits</li>
</ol>
</li>
<li>SecondaryNameNode定期合并<ol>
<li>触发合并时机<ol>
<li>默认配置一小时合并一次</li>
<li>每分钟检查操作次数，到达100W条，立即触发一次</li>
</ol>
</li>
<li>合并流程 <ol>
<li>SecondaryNameNode请求NameNode进行合并</li>
<li>NameNode停止使用当前的Edits文件，生成新的Edits文件继续执行操作</li>
<li>SecondaryNameNode拉取FsImage和Edits，加载到内存总合并，生成新的FsImage.checkpoint</li>
<li>SecondaryNameNode推送FsImage.checkpoint到NameNode</li>
<li>NameNode重命名FsImage.checkpoint为FsImage，合并流程结束</li>
</ol>
</li>
</ol>
</li>
<li>正常运行<ol>
<li>client对数据进行操作时，将这些操作记录到Edits</li>
</ol>
</li>
</ol>
<h3 id="五、2NN如何对NN的元数据进行合并？"><a href="#五、2NN如何对NN的元数据进行合并？" class="headerlink" title="五、2NN如何对NN的元数据进行合并？"></a>五、2NN如何对NN的元数据进行合并？</h3><ol>
<li>触发合并时机<ol>
<li>默认配置一小时合并一次</li>
<li>每分钟检查操作次数，到达100W条，立即触发一次</li>
</ol>
</li>
<li>合并流程 <ol>
<li>SecondaryNameNode请求NameNode进行合并</li>
<li>NameNode停止使用当前的Edits文件，生成新的Edits文件继续执行操作</li>
<li>SecondaryNameNode拉取FsImage和Edits，加载到内存总合并，生成新的FsImage.checkpoint</li>
<li>SecondaryNameNode推送FsImage.checkpoint到NameNode</li>
<li>NameNode重命名FsImage.checkpoint为FsImage，合并流程结束</li>
</ol>
</li>
</ol>
<h3 id="六、假如NN的数据发生的丢失，依靠2NN恢复完全靠谱？"><a href="#六、假如NN的数据发生的丢失，依靠2NN恢复完全靠谱？" class="headerlink" title="六、假如NN的数据发生的丢失，依靠2NN恢复完全靠谱？"></a>六、假如NN的数据发生的丢失，依靠2NN恢复完全靠谱？</h3><ol>
<li>可能会造成部分数据丢失原因如下：<ol>
<li>NN数据发生丢之前，完整元数据保存在内存中，在磁盘中Fsimage+edits=完整元数据</li>
<li>如果edits包含操作记录，且未合并到Fsimage，2NN中的Fsimage和NN的Fsimage相同</li>
<li>如果丢失edits，使用2NN的Fsimage恢复NN的Fsimage，会丢失NN的Edits部分的数据</li>
</ol>
</li>
</ol>
<h3 id="七、HDFS集群的安全模式有了解吗？"><a href="#七、HDFS集群的安全模式有了解吗？" class="headerlink" title="七、HDFS集群的安全模式有了解吗？"></a>七、HDFS集群的安全模式有了解吗？</h3><ol>
<li>HDFS集群的安全模式是对数据完整性的一种保护措施</li>
<li>NameNode启动进入安全模式，对客户端保持只读<ol>
<li>加载磁盘Fsimage到内存</li>
<li>执行edits操作记录，生成完整的元数据信息</li>
<li>生成新的edits</li>
<li>内存中的元数据信息，生成新的Fsimage</li>
<li>开始监听DateNode请求</li>
</ol>
</li>
<li>DataNode启动<ol>
<li>向NameNode注册，加入集群</li>
<li>注册成功向NameNode发送Block数据块信息</li>
</ol>
</li>
<li>NameNode接收到足够多的Block数据块位置信息退出安全模式<ol>
<li>满足“最小副本条件”， NameNode会在30秒钟之后就退出安全模式<ol>
<li>最小副本条件指的是在整个文件系统中99.9%的块满足最小副本级别（默认值：dfs.replication.min=1）</li>
</ol>
</li>
</ol>
</li>
<li>clien正常读写</li>
</ol>
<h3 id="八、如何在合理利用HDFS安全模式的操作命令完成一些工作？"><a href="#八、如何在合理利用HDFS安全模式的操作命令完成一些工作？" class="headerlink" title="八、如何在合理利用HDFS安全模式的操作命令完成一些工作？"></a>八、如何在合理利用HDFS安全模式的操作命令完成一些工作？</h3><ol>
<li>利用安全模式的wait命令实现等待集群恢复后自动执行某些操作</li>
<li><code>hdfs dfsadmin -safemode wait</code></li>
</ol>
<h3 id="九、描述一下NN和DN的关系，以及DN的工作流程"><a href="#九、描述一下NN和DN的关系，以及DN的工作流程" class="headerlink" title="九、描述一下NN和DN的关系，以及DN的工作流程"></a>九、描述一下NN和DN的关系，以及DN的工作流程</h3><ol>
<li>NN负责管理集群，维护元数据信息，接收客户端请求</li>
<li>DN负责保存Block数据块信息，保证数据完整性，接收客户端读写block请求</li>
<li>DataNode启动后会向NameNode注册，注册成功后，发送Block数据块的信息</li>
<li>DataNode运行过程中会周期性（6小时，hdfs-default.xml&gt;dfs.blockreport.intervalMsecp配置）的向NameNode上报Block数据块的信息</li>
<li>DataNode运行过程中每3秒（dfs.heartbeat.interval）会向NameNode发送心跳，并带回NameNode的命令</li>
<li>NameNode超过配置时间（2<em>心跳重新检测间隔默认五分钟+10</em>心跳间隔默认三秒=10分钟30秒）未收到心跳会下线DataNode</li>
<li>服役新节点通过配置白名单和works文件</li>
<li>退役节点通过配置黑名单，NameNode执行刷新集群，退役节点变成退役中（移动数据块），移动完成，变成退役状态</li>
</ol>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HDFS/" rel="tag">HDFS</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-HBase"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/11/07/HBase/"
    >HBase</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/11/07/HBase/" class="article-date">
  <time datetime="2021-11-07T00:08:30.000Z" itemprop="datePublished">2021-11-07</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/HBase/">HBase</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h1><h1 id="第1章-HBase简介"><a href="#第1章-HBase简介" class="headerlink" title="第1章 HBase简介"></a>第1章 HBase简介</h1><h2 id="1-1-HBase定义"><a href="#1-1-HBase定义" class="headerlink" title="1.1 HBase定义"></a>1.1 HBase定义</h2><p>HBase是一种分布式、可扩展、支持海量数据存储的NoSQL数据库。</p>
<ul>
<li>HBase是一种面向列簇存储的非关系型数据库。</li>
<li>用于存储结构化和非结构化的数据，适用于单表非关系型数据的存储，不适合做关联查询，类似JOIN等操作。</li>
<li>基于HDFS，数据持久化存储的体现形式是HFile，存放于DataNode中，被ResionServer以region的形式进行管理。</li>
<li>延迟较低，接入在线业务使用，面对大量的企业数据，HBase可以实现单表大量数据的存储，同时提供了高效的数据访问速度。<h2 id="1-2-HBase数据模型"><a href="#1-2-HBase数据模型" class="headerlink" title="1.2 HBase数据模型"></a>1.2 HBase数据模型</h2>逻辑上，HBase的数据模型同关系型数据库很类似，数据存储在一张表中，有行有列。但从HBase的底层物理存储结构（K-V）来看，HBase更像是一个multi-dimensional map。</li>
</ul>
<h3 id="1-2-1-HBase逻辑结构"><a href="#1-2-1-HBase逻辑结构" class="headerlink" title="1.2.1 HBase逻辑结构"></a>1.2.1 HBase逻辑结构</h3><p><img src="https://i.loli.net/2021/11/07/MIeQBJnp3RSNElH.jpg"></p>
<h3 id="1-2-2HBase物理存储结构"><a href="#1-2-2HBase物理存储结构" class="headerlink" title="1.2.2HBase物理存储结构"></a>1.2.2HBase物理存储结构</h3><p><img src="https://i.loli.net/2021/11/07/BbljIXvo31RaptL.jpg"></p>
<h3 id="1-2-3-数据模型"><a href="#1-2-3-数据模型" class="headerlink" title="1.2.3 数据模型"></a>1.2.3 数据模型</h3><ol>
<li>Name Space<ul>
<li>命名空间，类似于关系型数据库的DatabBase概念，每个命名空间下有多个表。HBase有两个自带的命名空间，分别是hbase和default，hbase中存放的是HBase内置的表，default表是用户默认使用的命名空间。</li>
</ul>
</li>
<li>Region<ul>
<li>类似于关系型数据库的表概念。不同的是，HBase定义表时只需要声明列族即可，不需要声明具体的列。这意味着，往HBase写入数据时，字段可以动态、按需指定。因此，和关系型数据库相比，HBase能够轻松应对字段变更的场景。</li>
</ul>
</li>
<li>Row<ul>
<li>HBase表中的每行数据都由一个RowKey和多个Column（列）组成，数据是按照RowKey的字典顺序存储的，并且查询数据时只能根据RowKey进行检索，所以RowKey的设计十分重要。</li>
</ul>
</li>
<li>Row Key<ul>
<li>Rowkey 的概念和 mysql 中的主键类似，Hbase 使用 Rowkey 来唯一的区分某一行的数据。Hbase只支持3种查询方式： 1、基于Rowkey的单行查询，2、基于Rowkey的范围扫描 ，3、全表扫描</li>
<li>因此，Rowkey对Hbase的性能影响非常大。设计的时候要兼顾基于Rowkey的单行查询也要键入Rowkey的范围扫描。</li>
<li>Rowkey 行键可以是任意字符串(最大长度是64KB，实际应用中长度一般为 10-100bytes)，最好是16。在HBase 内部，Rowkey 保存为字节数组。HBase会对表中的数据按照 Rowkey 字典序排序</li>
</ul>
</li>
<li>Column Family（列簇）<ul>
<li>Hbase 通过列簇划分数据的存储，列簇下面可以包含任意多的列，实现灵活的数据存取。列簇是由一个一个的列组成（任意多），在列数据为空的情况下，不会占用存储空间。</li>
<li>Hbase 创建表的时候必须指定列簇。就像关系型数据库创建的时候必须指定具体的列是一样的。</li>
<li>Hbase的列簇不是越多越好，官方推荐的是列簇最好小于或者等于3。一般是1个列簇。</li>
<li>新的列簇成员（列）可以随后动态加入，Family下面可以有多个Qualifier，所以可以简单的理解为，HBase中的列是二级列，也就是说Family是第一级列，Qualifier是第二级列。</li>
<li>权限控制、存储以及调优都是在列簇层面进行的；</li>
<li>HBase把同一列簇里面的数据存储在同一目录下，由几个文件保存。</li>
</ul>
</li>
<li>Column<ul>
<li>HBase中的每个列都由Column Family(列族)和Column Qualifier（列限定符）进行限定，例如info：name，info：age。建表时，只需指明列族，而列限定符无需预先定义。</li>
</ul>
</li>
<li>Time Stamp<ul>
<li>用于标识数据的不同版本（version），每条数据写入时，如果不指定时间戳，系统会自动为其加上该字段，其值为写入HBase的时间。</li>
</ul>
</li>
<li>Cell<ul>
<li>由{rowkey, column Family：column Qualifier, time Stamp} 唯一确定的单元。cell中的数据是没有类型的，全部是字节数组形式存贮。</li>
</ul>
</li>
</ol>
<h2 id="1-3-HBase基本架构"><a href="#1-3-HBase基本架构" class="headerlink" title="1.3 HBase基本架构"></a>1.3 HBase基本架构</h2><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16359030360669.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ol>
<li>Region Server<ul>
<li>Region Server为 Region的管理者，其实现类为HRegionServer，主要作用如下:<ul>
<li>对于数据的操作：get, put, delete；</li>
<li>对于Region的操作：splitRegion、compactRegion。</li>
</ul>
</li>
</ul>
</li>
<li>Master<ul>
<li>Master是所有Region Server的管理者，其实现类为HMaster，主要作用如下：<ul>
<li>对于表的操作：create, delete, alter</li>
<li>对于RegionServer的操作：分配regions到每个RegionServer，监控每个RegionServer的状态，负载均衡和故障转移。</li>
</ul>
</li>
</ul>
</li>
<li>Zookeeper<ul>
<li>HBase通过Zookeeper来做Master的高可用、RegionServer的监控、元数据的入口以及集群配置的维护等工作。</li>
</ul>
</li>
<li>HDFS<ul>
<li>HDFS为HBase提供最终的底层数据存储服务，同时为HBase提供高可用的支持。</li>
</ul>
</li>
</ol>
<h1 id="第2章-HBase快速入门"><a href="#第2章-HBase快速入门" class="headerlink" title="第2章 HBase快速入门"></a>第2章 HBase快速入门</h1><h2 id="2-1-HBase安装部署"><a href="#2-1-HBase安装部署" class="headerlink" title="2.1 HBase安装部署"></a>2.1 HBase安装部署</h2><h3 id="2-1-1-Zookeeper正常部署"><a href="#2-1-1-Zookeeper正常部署" class="headerlink" title="2.1.1 Zookeeper正常部署"></a>2.1.1 Zookeeper正常部署</h3><ul>
<li>首先保证Zookeeper集群的正常部署，并启动之：  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 zookeeper-3.5.7]$ bin/zkServer.sh start</span><br><span class="line">[atguigu@hadoop103 zookeeper-3.5.7]$ bin/zkServer.sh start</span><br><span class="line">[atguigu@hadoop104 zookeeper-3.5.7]$ bin/zkServer.sh start</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="2-1-2-Hadoop正常部署"><a href="#2-1-2-Hadoop正常部署" class="headerlink" title="2.1.2 Hadoop正常部署"></a>2.1.2 Hadoop正常部署</h3><ul>
<li>Hadoop集群的正常部署并启动：  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ sbin/start-dfs.sh</span><br><span class="line">[atguigu@hadoop103 hadoop-3.1.3]$ sbin/start-yarn.sh</span><br></pre></td></tr></table></figure></li>
<li>集群启动异常<ol>
<li>时间同步 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ntpdate ntp.aliyun.com</span><br></pre></td></tr></table></figure></li>
<li>hdfs坏块 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">        </span><br></pre></td></tr></table></figure>
<h3 id="2-1-3-HBase的解压"><a href="#2-1-3-HBase的解压" class="headerlink" title="2.1.3 HBase的解压"></a>2.1.3 HBase的解压</h3></li>
</ol>
</li>
</ul>
<ol>
<li>解压Hbase到指定目录： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 software]$ tar -zxvf hbase-2.2.4-bin.tar.gz -C /opt/module</span><br><span class="line">[atguigu@hadoop102 software]$ mv /opt/module/hbase-2.2.4 /opt/module/hbase</span><br></pre></td></tr></table></figure>
</li>
<li>配置环境变量 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ sudo vim /etc/profile.d/my_env.sh</span><br><span class="line"><span class="comment"># 添加</span></span><br><span class="line"><span class="comment">#HBASE_HOME</span></span><br><span class="line"><span class="built_in">export</span> HBASE_HOME=/opt/module/hbase</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HBASE_HOME</span>/bin</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="2-1-4-HBase的配置文件"><a href="#2-1-4-HBase的配置文件" class="headerlink" title="2.1.4 HBase的配置文件"></a>2.1.4 HBase的配置文件</h3>修改HBase对应的配置文件。</li>
<li>hbase-env.sh修改内容： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HBASE_MANAGES_ZK=<span class="literal">false</span></span><br></pre></td></tr></table></figure></li>
<li>hbase-site.xml修改内容： <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop102:8020/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102,hadoop103,hadoop104<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.unsafe.stream.capability.enforce<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.wal.provider<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>filesystem<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>regionservers： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="2-1-5-HBase远程发送到其他集群"><a href="#2-1-5-HBase远程发送到其他集群" class="headerlink" title="2.1.5 HBase远程发送到其他集群"></a>2.1.5 HBase远程发送到其他集群</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]$ xsync hbase/</span><br></pre></td></tr></table></figure>

<h3 id="2-1-6-HBase服务的启动"><a href="#2-1-6-HBase服务的启动" class="headerlink" title="2.1.6 HBase服务的启动"></a>2.1.6 HBase服务的启动</h3><ol>
<li>启动方式1 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hbase]$ bin/hbase-daemon.sh start master</span><br><span class="line">[atguigu@hadoop102 hbase]$ bin/hbase-daemon.sh start regionserver</span><br></pre></td></tr></table></figure>
<blockquote>
<p>提示：如果集群之间的节点时间不同步，会导致regionserver无法启动，抛出ClockOutOfSyncException异常。<br> 修复提示：</p>
</blockquote>
<ul>
<li>a、同步时间服务<ul>
<li>请参看帮助文档：《尚硅谷大数据技术之Hadoop入门》</li>
</ul>
</li>
<li>b、属性：hbase.master.maxclockskew设置更大的值  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.master.maxclockskew<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>180000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Time difference of regionserver from master<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>启动方式2 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">启动服务：</span><br><span class="line">[atguigu@hadoop102 hbase]$ bin/start-hbase.sh</span><br><span class="line">停止服务：</span><br><span class="line">[atguigu@hadoop102 hbase]$ bin/stop-hbase.sh</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="2-1-7-查看HBase页面"><a href="#2-1-7-查看HBase页面" class="headerlink" title="2.1.7 查看HBase页面"></a>2.1.7 查看HBase页面</h3><p>启动成功后，可以通过“host:port”的方式来访问HBase管理页面，例如：<br><a target="_blank" rel="noopener" href="http://hadoop001:16010/">http://hadoop001:16010</a> </p>
<h3 id="2-1-8高可用-可选"><a href="#2-1-8高可用-可选" class="headerlink" title="2.1.8高可用(可选)"></a>2.1.8高可用(可选)</h3><p>在HBase中HMaster负责监控HRegionServer的生命周期，均衡RegionServer的负载，如果HMaster挂掉了，那么整个HBase集群将陷入不健康的状态，并且此时的工作状态并不会维持太久。所以HBase支持对HMaster的高可用配置。</p>
<ol>
<li>关闭HBase集群（如果没有开启则跳过此步） <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hbase]$ bin/stop-hbase.sh</span><br></pre></td></tr></table></figure></li>
<li>在conf目录下创建backup-masters文件 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hbase]$ touch conf/backup-masters</span><br></pre></td></tr></table></figure></li>
<li>在backup-masters文件中配置高可用HMaster节点 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hbase]$ <span class="built_in">echo</span> hadoop103 &gt; conf/backup-masters</span><br></pre></td></tr></table></figure></li>
<li>将整个conf目录scp到其他节点 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hbase]$ scp -r conf/ hadoop103:/opt/module/hbase/</span><br><span class="line">[atguigu@hadoop102 hbase]$ scp -r conf/ hadoop104:/opt/module/hbase/</span><br></pre></td></tr></table></figure></li>
<li>打开页面测试查看<br> <a target="_blank" rel="noopener" href="http://hadooo102:16010/">http://hadooo102:16010</a> </li>
</ol>
<h2 id="2-2-HBase-Shell操作"><a href="#2-2-HBase-Shell操作" class="headerlink" title="2.2 HBase Shell操作"></a>2.2 HBase Shell操作</h2><h3 id="2-2-1-基本操作"><a href="#2-2-1-基本操作" class="headerlink" title="2.2.1 基本操作"></a>2.2.1 基本操作</h3><ol>
<li>进入HBase客户端命令行 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 hbase]$ bin/hbase shell</span><br></pre></td></tr></table></figure></li>
<li>查看帮助命令 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):001:0&gt; <span class="built_in">help</span></span><br></pre></td></tr></table></figure></li>
<li>查看当前数据库中有哪些表 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):002:0&gt; list</span><br></pre></td></tr></table></figure></li>
<li>查看命名空间 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):004:0&gt; list_namespace</span><br><span class="line">NAMESPACE</span><br><span class="line">api_test</span><br><span class="line">default</span><br><span class="line">hbase</span><br><span class="line">3 row(s)</span><br><span class="line">Took 0.0494 seconds</span><br><span class="line">hbase(main):005:0&gt;</span><br></pre></td></tr></table></figure></li>
<li>创建命名空间 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):005:0&gt; create_namespace <span class="string">&#x27;test&#x27;</span></span><br><span class="line">Took 0.2427 seconds</span><br><span class="line">hbase(main):006:0&gt; list_namespace</span><br><span class="line">NAMESPACE</span><br><span class="line">api_test</span><br><span class="line">default</span><br><span class="line">hbase</span><br><span class="line"><span class="built_in">test</span></span><br><span class="line">4 row(s)</span><br><span class="line">Took 0.0081 seconds</span><br><span class="line">hbase(main):007:0&gt;</span><br></pre></td></tr></table></figure></li>
<li>删除命名空间: 必须是空的 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):007:0&gt; drop_namespace <span class="string">&#x27;test&#x27;</span></span><br><span class="line">Took 0.2408 seconds</span><br><span class="line">hbase(main):008:0&gt; list_namespace</span><br><span class="line">NAMESPACE</span><br><span class="line">api_test</span><br><span class="line">default</span><br><span class="line">hbase</span><br><span class="line">3 row(s)</span><br><span class="line">Took 0.0102 seconds</span><br><span class="line">hbase(main):009:0&gt;</span><br></pre></td></tr></table></figure></li>
<li>查看命名空间中的表格 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):011:0&gt; list_namespace_tables <span class="string">&#x27;hbase&#x27;</span></span><br><span class="line">TABLE</span><br><span class="line">meta</span><br><span class="line">namespace</span><br><span class="line">2 row(s)</span><br><span class="line">Took 0.0051 seconds</span><br><span class="line">=&gt; [<span class="string">&quot;meta&quot;</span>, <span class="string">&quot;namespace&quot;</span>]</span><br><span class="line">hbase(main):012:0&gt;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="2-2-2-表的操作"><a href="#2-2-2-表的操作" class="headerlink" title="2.2.2 表的操作"></a>2.2.2 表的操作</h3><ol>
<li>创建表 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):002:0&gt; create <span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;info&#x27;</span></span><br></pre></td></tr></table></figure></li>
<li>插入数据到表 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):003:0&gt; put <span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;1001&#x27;</span>,<span class="string">&#x27;info:sex&#x27;</span>,<span class="string">&#x27;male&#x27;</span></span><br><span class="line">hbase(main):004:0&gt; put <span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;1001&#x27;</span>,<span class="string">&#x27;info:age&#x27;</span>,<span class="string">&#x27;18&#x27;</span></span><br><span class="line">hbase(main):005:0&gt; put <span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;1002&#x27;</span>,<span class="string">&#x27;info:name&#x27;</span>,<span class="string">&#x27;Janna&#x27;</span></span><br><span class="line">hbase(main):006:0&gt; put <span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;1002&#x27;</span>,<span class="string">&#x27;info:sex&#x27;</span>,<span class="string">&#x27;female&#x27;</span></span><br><span class="line">hbase(main):007:0&gt; put <span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;1002&#x27;</span>,<span class="string">&#x27;info:age&#x27;</span>,<span class="string">&#x27;20&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>扫描查看表数据 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):008:0&gt; scan <span class="string">&#x27;student&#x27;</span></span><br><span class="line">hbase(main):009:0&gt; scan <span class="string">&#x27;student&#x27;</span>,&#123;STARTROW =&gt; <span class="string">&#x27;1001&#x27;</span>, STOPROW  =&gt; <span class="string">&#x27;1001&#x27;</span>&#125;</span><br><span class="line">hbase(main):010:0&gt; scan <span class="string">&#x27;student&#x27;</span>,&#123;STARTROW =&gt; <span class="string">&#x27;1001&#x27;</span>&#125;</span><br></pre></td></tr></table></figure></li>
<li>查看表结构 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):011:0&gt; describe <span class="string">&#x27;student&#x27;</span></span><br></pre></td></tr></table></figure></li>
<li>更新指定字段的数据 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):012:0&gt; put <span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;1001&#x27;</span>,<span class="string">&#x27;info:name&#x27;</span>,<span class="string">&#x27;Nick&#x27;</span></span><br><span class="line">hbase(main):013:0&gt; put <span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;1001&#x27;</span>,<span class="string">&#x27;info:age&#x27;</span>,<span class="string">&#x27;100&#x27;</span></span><br></pre></td></tr></table></figure></li>
<li>查看“指定行”或“指定列族:列”的数据 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):014:0&gt; get <span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;1001&#x27;</span></span><br><span class="line">hbase(main):015:0&gt; get <span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;1001&#x27;</span>,<span class="string">&#x27;info:name&#x27;</span></span><br></pre></td></tr></table></figure></li>
<li>统计表数据行数 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):021:0&gt; count <span class="string">&#x27;student&#x27;</span></span><br></pre></td></tr></table></figure></li>
<li>删除数据<ul>
<li>删除某rowkey的全部数据：  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):016:0&gt; deleteall <span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;1001&#x27;</span></span><br></pre></td></tr></table></figure></li>
<li>删除某rowkey的某一列数据：  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):017:0&gt; delete <span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;1002&#x27;</span>,<span class="string">&#x27;info:sex&#x27;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>清空表数据 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):018:0&gt; truncate <span class="string">&#x27;student&#x27;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>提示：清空表的操作顺序为先disable，然后再truncate。</p>
</blockquote>
</li>
<li>删除表<ul>
<li>首先需要先让该表为disable状态：  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):019:0&gt; <span class="built_in">disable</span> <span class="string">&#x27;student&#x27;</span></span><br></pre></td></tr></table></figure></li>
<li>然后才能drop这个表：  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):020:0&gt; drop <span class="string">&#x27;student&#x27;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>提示：如果直接drop表，会报错：ERROR: Table student is enabled. Disable it first.</p>
</blockquote>
</li>
</ul>
</li>
<li>变更表信息<ul>
<li>将info列族中的数据存放3个版本：  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):022:0&gt; alter <span class="string">&#x27;student&#x27;</span>,&#123;NAME=&gt;<span class="string">&#x27;info&#x27;</span>,VERSIONS=&gt;3&#125;</span><br><span class="line">hbase(main):022:0&gt; get <span class="string">&#x27;student&#x27;</span>,<span class="string">&#x27;1001&#x27;</span>,&#123;COLUMN=&gt;<span class="string">&#x27;info:name&#x27;</span>,VERSIONS=&gt;3&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h1 id="第3章-HBase-API"><a href="#第3章-HBase-API" class="headerlink" title="第3章 HBase API"></a>第3章 HBase API</h1><h2 id="3-1-DDL"><a href="#3-1-DDL" class="headerlink" title="3.1 DDL"></a>3.1 DDL</h2><h3 id="3-1-1-创建命名空间"><a href="#3-1-1-创建命名空间" class="headerlink" title="3.1.1 创建命名空间"></a>3.1.1 创建命名空间</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">create_namespace</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Configuration configuration = HBaseConfiguration.create();</span><br><span class="line">    configuration.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;hadoop001,hadoop002,hadoop003,hadoop004,hadoop005&quot;</span>);</span><br><span class="line">    <span class="keyword">try</span> (</span><br><span class="line">            Connection connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">            Admin admin = connection.getAdmin();</span><br><span class="line"></span><br><span class="line">    ) &#123;</span><br><span class="line">        <span class="keyword">final</span> String namespace = <span class="string">&quot;api_test&quot;</span>;</span><br><span class="line">        NamespaceDescriptor.Builder builder = NamespaceDescriptor.create(namespace);</span><br><span class="line">        admin.createNamespace(builder.build());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-1-2-查看命名空间"><a href="#3-1-2-查看命名空间" class="headerlink" title="3.1.2 查看命名空间"></a>3.1.2 查看命名空间</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">list_namespace</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Configuration configuration = HBaseConfiguration.create();</span><br><span class="line">    configuration.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;hadoop001,hadoop002,hadoop003,hadoop004,hadoop005&quot;</span>);</span><br><span class="line">    <span class="keyword">try</span> (</span><br><span class="line">            Connection connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">            Admin admin = connection.getAdmin();</span><br><span class="line"></span><br><span class="line">    ) &#123;</span><br><span class="line">        NamespaceDescriptor[] namespaceDescriptors = admin.listNamespaceDescriptors();</span><br><span class="line">        <span class="keyword">for</span> (NamespaceDescriptor namespaceDescriptor : namespaceDescriptors) &#123;</span><br><span class="line">            System.out.println(namespaceDescriptor.getName());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-1-3-删除命名空间"><a href="#3-1-3-删除命名空间" class="headerlink" title="3.1.3 删除命名空间"></a>3.1.3 删除命名空间</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">drop_namespace</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Configuration configuration = HBaseConfiguration.create();</span><br><span class="line">    configuration.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;hadoop001,hadoop002,hadoop003,hadoop004,hadoop005&quot;</span>);</span><br><span class="line">    <span class="keyword">try</span> (</span><br><span class="line">            Connection connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">            Admin admin = connection.getAdmin();</span><br><span class="line"></span><br><span class="line">    ) &#123;</span><br><span class="line">        admin.deleteNamespace(<span class="string">&quot;api_test&quot;</span>);</span><br><span class="line">        NamespaceDescriptor[] namespaceDescriptors = admin.listNamespaceDescriptors();</span><br><span class="line">        <span class="keyword">for</span> (NamespaceDescriptor namespaceDescriptor : namespaceDescriptors) &#123;</span><br><span class="line">            System.out.println(namespaceDescriptor);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<h3 id="3-1-4-判断表是否存在"><a href="#3-1-4-判断表是否存在" class="headerlink" title="3.1.4 判断表是否存在"></a>3.1.4 判断表是否存在</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">tableExists</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Configuration configuration = HBaseConfiguration.create();</span><br><span class="line">    configuration.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;hadoop001,hadoop002,hadoop003,hadoop004,hadoop005&quot;</span>);</span><br><span class="line">    <span class="keyword">try</span> (</span><br><span class="line">            Connection connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">            Admin admin = connection.getAdmin();</span><br><span class="line"></span><br><span class="line">    ) &#123;</span><br><span class="line">        TableName tableName = TableName.valueOf(<span class="string">&quot;api_test_table&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">boolean</span> b = admin.tableExists(tableName);</span><br><span class="line">        System.out.println(b);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-1-5-创建表"><a href="#3-1-5-创建表" class="headerlink" title="3.1.5 创建表"></a>3.1.5 创建表</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">create_table</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Configuration configuration = HBaseConfiguration.create();</span><br><span class="line">    configuration.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;hadoop001,hadoop002,hadoop003,hadoop004,hadoop005&quot;</span>);</span><br><span class="line">    <span class="keyword">try</span> (</span><br><span class="line">            Connection connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">            Admin admin = connection.getAdmin();</span><br><span class="line"></span><br><span class="line">    ) &#123;</span><br><span class="line">        TableName tableName = TableName.valueOf(<span class="string">&quot;api_test_table&quot;</span>);</span><br><span class="line">        TableDescriptorBuilder tableDescriptorBuilder = TableDescriptorBuilder.newBuilder(tableName);</span><br><span class="line">        ColumnFamilyDescriptorBuilder columnFamilyDescriptorBuilder = ColumnFamilyDescriptorBuilder.newBuilder(<span class="string">&quot;info&quot;</span>.getBytes(StandardCharsets.UTF_8));</span><br><span class="line">        columnFamilyDescriptorBuilder.setMaxVersions(<span class="number">3</span>);</span><br><span class="line">        tableDescriptorBuilder.setColumnFamily(columnFamilyDescriptorBuilder.build());</span><br><span class="line"></span><br><span class="line">        admin.createTable(tableDescriptorBuilder.build());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-1-6-删除表"><a href="#3-1-6-删除表" class="headerlink" title="3.1.6 删除表"></a>3.1.6 删除表</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">drop_table</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Configuration configuration = HBaseConfiguration.create();</span><br><span class="line">    configuration.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;hadoop001,hadoop002,hadoop003,hadoop004,hadoop005&quot;</span>);</span><br><span class="line">    <span class="keyword">try</span> (</span><br><span class="line">            Connection connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">            Admin admin = connection.getAdmin();</span><br><span class="line"></span><br><span class="line">    ) &#123;</span><br><span class="line">        TableName tableName = TableName.valueOf(<span class="string">&quot;api_test_table&quot;</span>);</span><br><span class="line">        admin.disableTable(tableName);</span><br><span class="line">        admin.deleteTable(tableName);</span><br><span class="line">        TableName[] tableNames = admin.listTableNames();</span><br><span class="line">        <span class="keyword">for</span> (TableName tableName1 : tableNames) &#123;</span><br><span class="line">            System.out.println(tableName1);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-1-7-修改表"><a href="#3-1-7-修改表" class="headerlink" title="3.1.7 修改表"></a>3.1.7 修改表</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">alter_table</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Configuration configuration = HBaseConfiguration.create();</span><br><span class="line">    configuration.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;hadoop001,hadoop002,hadoop003,hadoop004,hadoop005&quot;</span>);</span><br><span class="line">    <span class="keyword">try</span> (</span><br><span class="line">            Connection connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">            Admin admin = connection.getAdmin();</span><br><span class="line"></span><br><span class="line">    ) &#123;</span><br><span class="line">        TableName tableName = TableName.valueOf(<span class="string">&quot;api_test_table&quot;</span>);</span><br><span class="line"></span><br><span class="line">        ColumnFamilyDescriptorBuilder columnFamilyDescriptorBuilder</span><br><span class="line">                = ColumnFamilyDescriptorBuilder.newBuilder(<span class="string">&quot;job&quot;</span>.getBytes(StandardCharsets.UTF_8));</span><br><span class="line">        columnFamilyDescriptorBuilder.setMaxVersions(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        admin.addColumnFamily(tableName, columnFamilyDescriptorBuilder.build());</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        ColumnFamilyDescriptorBuilder infoFamilyDescriptorBuilder</span><br><span class="line">                = ColumnFamilyDescriptorBuilder.newBuilder(<span class="string">&quot;info&quot;</span>.getBytes(StandardCharsets.UTF_8));</span><br><span class="line">        infoFamilyDescriptorBuilder.setMaxVersions(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">        admin.modifyColumnFamily(tableName, infoFamilyDescriptorBuilder.build());</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="3-1-8-查看表"><a href="#3-1-8-查看表" class="headerlink" title="3.1.8 查看表"></a>3.1.8 查看表</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">list_table</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Configuration configuration = HBaseConfiguration.create();</span><br><span class="line">    configuration.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;hadoop001,hadoop002,hadoop003,hadoop004,hadoop005&quot;</span>);</span><br><span class="line">    <span class="keyword">try</span> (</span><br><span class="line">            Connection connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">            Admin admin = connection.getAdmin();</span><br><span class="line"></span><br><span class="line">    ) &#123;</span><br><span class="line">        TableName[] tableNames = admin.listTableNames();</span><br><span class="line">        <span class="keyword">for</span> (TableName tableName : tableNames) &#123;</span><br><span class="line">            System.out.println(tableName);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="3-2-DML"><a href="#3-2-DML" class="headerlink" title="3.2 DML"></a>3.2 DML</h2><h3 id="3-2-1-插入数据"><a href="#3-2-1-插入数据" class="headerlink" title="3.2.1 插入数据"></a>3.2.1 插入数据</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Configuration configuration = HBaseConfiguration.create();</span><br><span class="line">    configuration.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;hadoop001,hadoop002,hadoop003,hadoop004,hadoop005&quot;</span>);</span><br><span class="line">    TableName tableName = TableName.valueOf(<span class="string">&quot;api_test_table&quot;</span>);</span><br><span class="line">    <span class="keyword">try</span> (</span><br><span class="line">            Connection connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">            Table table = connection.getTable(tableName);</span><br><span class="line">    ) &#123;</span><br><span class="line">        <span class="keyword">final</span> Put put_1001 = <span class="keyword">new</span> Put(<span class="string">&quot;1001&quot;</span>.getBytes(StandardCharsets.UTF_8));</span><br><span class="line">        put_1001.addColumn(<span class="string">&quot;info&quot;</span>.getBytes(StandardCharsets.UTF_8),</span><br><span class="line">                <span class="string">&quot;name&quot;</span>.getBytes(StandardCharsets.UTF_8),</span><br><span class="line">                <span class="string">&quot;张三&quot;</span>.getBytes(StandardCharsets.UTF_8));</span><br><span class="line">        table.put(put_1001);</span><br><span class="line"></span><br><span class="line">        put_1001.addColumn(<span class="string">&quot;info&quot;</span>.getBytes(StandardCharsets.UTF_8),</span><br><span class="line">                <span class="string">&quot;age&quot;</span>.getBytes(StandardCharsets.UTF_8),</span><br><span class="line">                <span class="string">&quot;18&quot;</span>.getBytes(StandardCharsets.UTF_8));</span><br><span class="line">        table.put(put_1001);</span><br><span class="line"></span><br><span class="line">        put_1001.addColumn(<span class="string">&quot;info&quot;</span>.getBytes(StandardCharsets.UTF_8),</span><br><span class="line">                <span class="string">&quot;gender&quot;</span>.getBytes(StandardCharsets.UTF_8),</span><br><span class="line">                <span class="string">&quot;male&quot;</span>.getBytes(StandardCharsets.UTF_8));</span><br><span class="line">        table.put(put_1001);</span><br><span class="line">        </span><br><span class="line">        put_1001.addColumn(<span class="string">&quot;info&quot;</span>.getBytes(StandardCharsets.UTF_8),</span><br><span class="line">                <span class="string">&quot;telephone&quot;</span>.getBytes(StandardCharsets.UTF_8),</span><br><span class="line">                <span class="string">&quot;18889898899&quot;</span>.getBytes(StandardCharsets.UTF_8));</span><br><span class="line"></span><br><span class="line">        table.put(put_1001);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-2-2-查询单条数据"><a href="#3-2-2-查询单条数据" class="headerlink" title="3.2.2 查询单条数据"></a>3.2.2 查询单条数据</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">get</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Configuration configuration = HBaseConfiguration.create();</span><br><span class="line">    configuration.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;hadoop001,hadoop002,hadoop003,hadoop004,hadoop005&quot;</span>);</span><br><span class="line">    TableName tableName = TableName.valueOf(<span class="string">&quot;api_test_table&quot;</span>);</span><br><span class="line">    <span class="keyword">try</span> (</span><br><span class="line">            Connection connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">            Table table = connection.getTable(tableName);</span><br><span class="line">    ) &#123;</span><br><span class="line">        <span class="keyword">final</span> Get get = <span class="keyword">new</span> Get(<span class="string">&quot;1001&quot;</span>.getBytes(StandardCharsets.UTF_8));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> Result result = table.get(get);</span><br><span class="line">        <span class="keyword">final</span> Cell[] cells = result.rawCells();</span><br><span class="line">        <span class="keyword">for</span> (Cell cell : cells) &#123;</span><br><span class="line">            printCell(cell);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">printCell</span><span class="params">(Cell cell)</span> </span>&#123;</span><br><span class="line">    String row = <span class="keyword">new</span> String(CellUtil.cloneRow(cell), StandardCharsets.UTF_8);</span><br><span class="line">    String family = <span class="keyword">new</span> String(CellUtil.cloneFamily(cell), StandardCharsets.UTF_8);</span><br><span class="line">    String qualifier = <span class="keyword">new</span> String(CellUtil.cloneQualifier(cell), StandardCharsets.UTF_8);</span><br><span class="line">    String value = <span class="keyword">new</span> String(CellUtil.cloneValue(cell), StandardCharsets.UTF_8);</span><br><span class="line"></span><br><span class="line">    System.out.println(</span><br><span class="line">            <span class="string">&quot;row:&quot;</span> + row + <span class="string">&quot; &quot;</span> +</span><br><span class="line">                    <span class="string">&quot;family:&quot;</span> + family + <span class="string">&quot; &quot;</span> +</span><br><span class="line">                    <span class="string">&quot;qualifier:&quot;</span> + qualifier + <span class="string">&quot; &quot;</span> +</span><br><span class="line">                    <span class="string">&quot;value:&quot;</span> + value + <span class="string">&quot; &quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-2-3-范围查询"><a href="#3-2-3-范围查询" class="headerlink" title="3.2.3 范围查询"></a>3.2.3 范围查询</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">scan</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Configuration configuration = HBaseConfiguration.create();</span><br><span class="line">    configuration.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;hadoop001,hadoop002,hadoop003,hadoop004,hadoop005&quot;</span>);</span><br><span class="line">    TableName tableName = TableName.valueOf(<span class="string">&quot;api_test_table&quot;</span>);</span><br><span class="line">    <span class="keyword">try</span> (</span><br><span class="line">            Connection connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">            Table table = connection.getTable(tableName);</span><br><span class="line">    ) &#123;</span><br><span class="line">        <span class="keyword">final</span> Scan scan = <span class="keyword">new</span> Scan();</span><br><span class="line">        scan.withStartRow(<span class="string">&quot;1001&quot;</span>.getBytes(StandardCharsets.UTF_8));</span><br><span class="line">        scan.withStopRow(<span class="string">&quot;1005&quot;</span>.getBytes(StandardCharsets.UTF_8));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> ResultScanner scanner = table.getScanner(scan);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (Result result : scanner) &#123;</span><br><span class="line">            <span class="keyword">final</span> Cell[] cells = result.rawCells();</span><br><span class="line">            <span class="keyword">for</span> (Cell cell : cells) &#123;</span><br><span class="line">                printCell(cell);</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-2-4-追加数据"><a href="#3-2-4-追加数据" class="headerlink" title="3.2.4 追加数据"></a>3.2.4 追加数据</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">append</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Configuration configuration = HBaseConfiguration.create();</span><br><span class="line">    configuration.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;hadoop001,hadoop002,hadoop003,hadoop004,hadoop005&quot;</span>);</span><br><span class="line">    TableName tableName = TableName.valueOf(<span class="string">&quot;api_test_table&quot;</span>);</span><br><span class="line">    <span class="keyword">try</span> (</span><br><span class="line">            Connection connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">            Table table = connection.getTable(tableName);</span><br><span class="line">    ) &#123;</span><br><span class="line">        <span class="keyword">final</span> Append append = <span class="keyword">new</span> Append(<span class="string">&quot;1001&quot;</span>.getBytes(StandardCharsets.UTF_8));</span><br><span class="line">        append.addColumn(<span class="string">&quot;info&quot;</span>.getBytes(StandardCharsets.UTF_8),</span><br><span class="line">                <span class="string">&quot;salary&quot;</span>.getBytes(StandardCharsets.UTF_8),</span><br><span class="line">                <span class="string">&quot;400000&quot;</span>.getBytes(StandardCharsets.UTF_8));</span><br><span class="line">        table.append(append);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-2-5-删除数据"><a href="#3-2-5-删除数据" class="headerlink" title="3.2.5 删除数据"></a>3.2.5 删除数据</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">delete</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Configuration configuration = HBaseConfiguration.create();</span><br><span class="line">    configuration.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;hadoop001,hadoop002,hadoop003,hadoop004,hadoop005&quot;</span>);</span><br><span class="line">    TableName tableName = TableName.valueOf(<span class="string">&quot;api_test_table&quot;</span>);</span><br><span class="line">    <span class="keyword">try</span> (</span><br><span class="line">            Connection connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">            Table table = connection.getTable(tableName);</span><br><span class="line">    ) &#123;</span><br><span class="line">        <span class="keyword">final</span> Delete delete = <span class="keyword">new</span> Delete(<span class="string">&quot;1001&quot;</span>.getBytes(StandardCharsets.UTF_8));</span><br><span class="line">        delete.addColumn(<span class="string">&quot;info&quot;</span>.getBytes(StandardCharsets.UTF_8),</span><br><span class="line">                <span class="string">&quot;name&quot;</span>.getBytes(StandardCharsets.UTF_8)</span><br><span class="line">        );</span><br><span class="line">        table.delete(delete);</span><br><span class="line">        get();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-2-6-清空数据"><a href="#3-2-6-清空数据" class="headerlink" title="3.2.6 清空数据"></a>3.2.6 清空数据</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">truncate</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Configuration configuration = HBaseConfiguration.create();</span><br><span class="line">    configuration.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="string">&quot;hadoop001,hadoop002,hadoop003,hadoop004,hadoop005&quot;</span>);</span><br><span class="line">    TableName tableName = TableName.valueOf(<span class="string">&quot;api_test_table&quot;</span>);</span><br><span class="line">    <span class="keyword">try</span> (</span><br><span class="line">            Connection connection = ConnectionFactory.createConnection(configuration);</span><br><span class="line">            <span class="keyword">final</span> Admin admin = connection.getAdmin()</span><br><span class="line">    ) &#123;</span><br><span class="line">        admin.disableTable(tableName);</span><br><span class="line">        admin.truncateTable(tableName, <span class="keyword">false</span>);</span><br><span class="line">        scan();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="第4章-HBase进阶"><a href="#第4章-HBase进阶" class="headerlink" title="第4章 HBase进阶"></a>第4章 HBase进阶</h1><h2 id="4-1-架构原理"><a href="#4-1-架构原理" class="headerlink" title="4.1 架构原理"></a>4.1 架构原理</h2><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16360144290588.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<h3 id="4-1-1-Client"><a href="#4-1-1-Client" class="headerlink" title="4.1.1 Client"></a>4.1.1 Client</h3><ol>
<li>HBase META表：记录了用户所有表拆分出来的的 Region 映射信息，META可以有多个 Regoin</li>
<li>Client 访问用户数据前需要首先访问 ZooKeeper，找到META表所在RegionServer，最后才能找到用户数据的位置去访问，中间需要多次网络操作，不过 client 端会做 cache 缓存。</li>
</ol>
<h3 id="4-1-2-ZooKeeper"><a href="#4-1-2-ZooKeeper" class="headerlink" title="4.1.2 ZooKeeper"></a>4.1.2 ZooKeeper</h3><ol>
<li>ZooKeeper 为 HBase 提供 Failover 机制，选举 Master，避免单点 Master 单点故障问题</li>
<li>存储所有 Region 的寻址入口：<del>-ROOT-表在哪台服务器上</del> META表的位置信息(zookeeper路径：<code>/hbase/meta-region-server</code>)</li>
<li>实时监控 RegionServer 的状态，将 RegionServer 的上线和下线信息实时通知给 Master</li>
</ol>
<h3 id="4-1-3-Meta表结构"><a href="#4-1-3-Meta表结构" class="headerlink" title="4.1.3 Meta表结构"></a>4.1.3 Meta表结构</h3><ol>
<li>hbase:metab: 表存放着整个集群的所有Region信息，客户端数据的读写需要定位到具体需要操作的Region，说白了就是一张字典表。meta表只会有一个Region，这是为了确保meta表多次操作的原子性。</li>
<li>Meta表结构与内容 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):002:0&gt; scan <span class="string">&#x27;hbase:meta&#x27;</span></span><br><span class="line">ROW                                                                                         COLUMN+CELL</span><br><span class="line"> api_test_table                                                                             column=table:state, timestamp=1635927178467, value=\x08\x00</span><br><span class="line"> api_test_table,,1635927178047.d0d5f57b5659e0911c7aabbaa3a1bc04.                            column=info:regioninfo, timestamp=1635927185877, value=&#123;ENCODED =&gt; d0d5f57b5659e0911c7aabbaa3a1bc04, NAME =&gt; <span class="string">&#x27;api_test_table,,1635927178047.d0d5f57b5659e0911c7aabbaa3a1bc04.&#x27;</span>, STARTKEY =&gt; <span class="string">&#x27;&#x27;</span>, ENDKEY =&gt; <span class="string">&#x27;&#x27;</span>&#125;</span><br><span class="line"> api_test_table,,1635927178047.d0d5f57b5659e0911c7aabbaa3a1bc04.                            column=info:seqnumDuringOpen, timestamp=1635927185877, value=\x00\x00\x00\x00\x00\x00\x00\x05</span><br><span class="line"> api_test_table,,1635927178047.d0d5f57b5659e0911c7aabbaa3a1bc04.                            column=info:server, timestamp=1635927185877, value=hadoop001:16020</span><br><span class="line"> api_test_table,,1635927178047.d0d5f57b5659e0911c7aabbaa3a1bc04.                            column=info:serverstartcode, timestamp=1635927185877, value=1635912473426</span><br><span class="line"> api_test_table,,1635927178047.d0d5f57b5659e0911c7aabbaa3a1bc04.                            column=info:sn, timestamp=1635927185668, value=hadoop001,16020,1635912473426</span><br><span class="line"> api_test_table,,1635927178047.d0d5f57b5659e0911c7aabbaa3a1bc04.                            column=info:state, timestamp=1635927185877, value=OPEN</span><br><span class="line"> hbase:namespace                                                                            column=table:state, timestamp=1635908733224, value=\x08\x00</span><br><span class="line"> hbase:namespace,,1635908732447.5584783366fc148c901aaffe044a32ec.                           column=info:regioninfo, timestamp=1635922081791, value=&#123;ENCODED =&gt; 5584783366fc148c901aaffe044a32ec, NAME =&gt; <span class="string">&#x27;hbase:namespace,,1635908732447.5584783366fc148c901aaffe044a32ec.&#x27;</span>, STARTKEY =&gt; <span class="string">&#x27;&#x27;</span>, ENDKEY =&gt; <span class="string">&#x27;&#x27;</span>&#125;</span><br><span class="line"> hbase:namespace,,1635908732447.5584783366fc148c901aaffe044a32ec.                           column=info:seqnumDuringOpen, timestamp=1635922081791, value=\x00\x00\x00\x00\x00\x00\x00\x15</span><br><span class="line"> hbase:namespace,,1635908732447.5584783366fc148c901aaffe044a32ec.                           column=info:server, timestamp=1635922081791, value=hadoop004:16020</span><br><span class="line"> hbase:namespace,,1635908732447.5584783366fc148c901aaffe044a32ec.                           column=info:serverstartcode, timestamp=1635922081791, value=1635912472425</span><br><span class="line"> hbase:namespace,,1635908732447.5584783366fc148c901aaffe044a32ec.                           column=info:sn, timestamp=1635922081349, value=hadoop004,16020,1635912472425</span><br><span class="line"> hbase:namespace,,1635908732447.5584783366fc148c901aaffe044a32ec.                           column=info:state, timestamp=1635922081791, value=OPEN</span><br><span class="line"> student                                                                                    column=table:state, timestamp=1635910393993, value=\x08\x00</span><br><span class="line"> student,,1635910393240.55ab1df9560f226f1e7b4bc063e429ac.                                   column=info:regioninfo, timestamp=1635912481491, value=&#123;ENCODED =&gt; 55ab1df9560f226f1e7b4bc063e429ac, NAME =&gt; <span class="string">&#x27;student,,1635910393240.55ab1df9560f226f1e7b4bc063e429ac.&#x27;</span>, STARTKEY =&gt; <span class="string">&#x27;&#x27;</span>, ENDKEY =&gt; <span class="string">&#x27;&#x27;</span>&#125;</span><br><span class="line"> student,,1635910393240.55ab1df9560f226f1e7b4bc063e429ac.                                   column=info:seqnumDuringOpen, timestamp=1635912481491, value=\x00\x00\x00\x00\x00\x00\x00\x0F</span><br><span class="line"> student,,1635910393240.55ab1df9560f226f1e7b4bc063e429ac.                                   column=info:server, timestamp=1635912481491, value=hadoop003:16020</span><br><span class="line"> student,,1635910393240.55ab1df9560f226f1e7b4bc063e429ac.                                   column=info:serverstartcode, timestamp=1635912481491, value=1635912471638</span><br><span class="line"> student,,1635910393240.55ab1df9560f226f1e7b4bc063e429ac.                                   column=info:sn, timestamp=1635912480984, value=hadoop003,16020,1635912471638</span><br><span class="line"> student,,1635910393240.55ab1df9560f226f1e7b4bc063e429ac.                                   column=info:state, timestamp=1635912481491, value=OPEN</span><br><span class="line">6 row(s)</span><br><span class="line">Took 0.0450 seconds</span><br></pre></td></tr></table></figure></li>
<li>Meta表组成说明<ol>
<li>Rowkey组成: meta表中的一个Rowkey就代表了一个region。<ul>
<li>格式： <code>[table],[region start key],[region id]</code><ul>
<li>region id 由该 region 生成的时间戳（精确到毫秒）与 region encoded 组成</li>
<li>region encoded 由 region 所在的 表名, StartKey, 时间戳这三者的MD5值产生， HBase 在 HDFS 上存储 region 的路径就是 region encoded。</li>
</ul>
</li>
<li>[region start key]为空的，说明这是该table的第一个region。若对应region中startkey和endkey都为空的话，表明这个table只有一个region</li>
<li>示例<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Rowkey: student,,1635910393240.55ab1df9560f226f1e7b4bc063e429ac.</span><br><span class="line">table: student</span><br><span class="line">region start key: 空</span><br><span class="line">region id timestamp: 1635910393240</span><br><span class="line">region id encoded: 55ab1df9560f226f1e7b4bc063e429ac</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>Column组成<table>
<thead>
<tr>
<th>列名</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>info:state</td>
<td>Region状态</td>
</tr>
<tr>
<td>info:sn</td>
<td>Region Server Node，由server和serverstartcode 组成</td>
</tr>
<tr>
<td>info:serverstartcode</td>
<td>Region Server启动Code，实质上就是Region Server启动的时间戳</td>
</tr>
<tr>
<td>info:server</td>
<td>Region Server 地址和端口</td>
</tr>
<tr>
<td>info:seqnumDuringOpen</td>
<td>表示Region在线时长的一个二进制串</td>
</tr>
<tr>
<td>info:regioninfo</td>
<td>Region 的详细信息，和 .regioninfo 内容相同</td>
</tr>
</tbody></table>
</li>
<li>info:regioninfo 是重要信息<ul>
<li>ENCODED：基于${表名},${起始键},${region时间戳}生成的32位md5字符串，region数据存储在hdfs上时使用的唯一编号，可以从meta表中根据该值定位到hdfs中的具体路径。 rowkey中最后的${encode编码}就是 ENCODED 的值，其是rowkey组成的一部分。</li>
<li>NAME：与 ROWKEY 值相同</li>
<li>STARTKEY：该 region 的起始键</li>
<li>ENDKEY：该 region 的结束键</li>
</ul>
</li>
</ol>
</li>
</ol>
<h3 id="4-1-4-Master"><a href="#4-1-4-Master" class="headerlink" title="4.1.4 Master"></a>4.1.4 Master</h3><ol>
<li>为 RegionServer 分配 Region</li>
<li>负责 RegionServer 的负载均衡</li>
<li>发现失效的 RegionServer 并重新分配其上的 Region</li>
<li>HDFS 上的垃圾文件（HBase）回收</li>
<li>处理 Schema 更新请求（表的创建，删除，修改，列簇的增加等等）</li>
</ol>
<h3 id="4-1-5-RegionServer"><a href="#4-1-5-RegionServer" class="headerlink" title="4.1.5 RegionServer"></a>4.1.5 RegionServer</h3><ol>
<li>RegionServer 维护 Master 分配给它的 Region，处理对这些 Region 的 IO 请求</li>
<li>RegionServer 负责 Split 在运行过程中变得过大的 Region，负责 Compact 操作</li>
</ol>
<ul>
<li>可以看到，client 访问 HBase 上数据的过程并不需要 master 参与（寻址访问 zookeeper 和 RegioneServer，数据读写访问 RegioneServer），Master 仅仅维护者 Table 和 Region 的元数据信息，负载很低。</li>
<li>META 存的是所有的 Region 的位置信息，那么 RegioneServer 当中 Region 在进行分裂之后 的新产生的 Region，是由 Master 来决定发到哪个 RegioneServer，这就意味着，只有 Master 知道 new Region 的位置信息，所以，由 Master 来管理META表当中的数据的 CRUD</li>
</ul>
<ol start="5">
<li>所以结合以上两点表明，在没有 Region 分裂的情况，Master 宕机一段时间是可以忍受的。</li>
</ol>
<h3 id="4-1-6-HRegion"><a href="#4-1-6-HRegion" class="headerlink" title="4.1.6 HRegion"></a>4.1.6 HRegion</h3><ol>
<li>table在行的方向上分隔为多个Region。Region是HBase中分布式存储和负载均衡的最小单元，即不同的region可以分别在不同的Region Server上，但同一个Region是不会拆分到多个server上。</li>
<li>Region按大小分裂（split），每个表一般是只有一个region。随着数据不断插入表，region不断增大，当region的某个列族达到一个阈值时就会分裂两个新的region。</li>
<li>每个region由以下信息标识：&lt; 表名,startRowkey,创建时间&gt;</li>
<li>由元数据表META记录该region的endRowkey</li>
</ol>
<h3 id="4-1-7-Store"><a href="#4-1-7-Store" class="headerlink" title="4.1.7 Store"></a>4.1.7 Store</h3><ol>
<li>每一个region由一个或多个store组成，至少是一个store，hbase会把一起访问的数据放在一个store里面，即为每个 ColumnFamily建一个store，如果有几个ColumnFamily，也就有几个Store。</li>
<li>一个Store由一个memStore和0或者 多个StoreFile组成。</li>
<li>HBase以store的大小来判断是否需要切分region</li>
</ol>
<h3 id="4-1-8-MemStore"><a href="#4-1-8-MemStore" class="headerlink" title="4.1.8 MemStore"></a>4.1.8 MemStore</h3><ol>
<li>写缓存，由于HFile中的数据要求是有序的，所以数据是先存储在MemStore中，排好序后，等到达刷写时机才会刷写到HFile，每次刷写都会形成一个新的HFile。</li>
<li>memStore 是放在内存里的。保存修改的数据即keyValues。当memStore的大小达到一个阀值（默认128MB）时，memStore会被flush到文 件，即生成一个快照。目前hbase 会有一个线程来负责memStore的flush操作。</li>
<li>进入MemStore的数据对rowkey进行字典序排序</li>
</ol>
<h3 id="4-1-9-StoreFile"><a href="#4-1-9-StoreFile" class="headerlink" title="4.1.9 StoreFile"></a>4.1.9 StoreFile</h3><ol>
<li>保存实际数据的物理文件，StoreFile以HFile的形式存储在HDFS上。每个Store会有一个或多个StoreFile（HFile），数据在每个StoreFile中都是有序的。</li>
<li>memStore内存中的数据写到文件后就是StoreFile，StoreFile底层是以HFile的格式保存。当storefile文件的数量增长到一定阈值后，系统会进行合并（minor、major compaction），在合并过程中会进行版本合并和删除工作（majar），形成更大的storefile。</li>
</ol>
<h3 id="4-1-10-HFile"><a href="#4-1-10-HFile" class="headerlink" title="4.1.10 HFile"></a>4.1.10 HFile</h3><ol>
<li>HBase中KeyValue数据的存储格式，HFile是Hadoop的 二进制格式文件，实际上StoreFile就是对Hfile做了轻量级包装，即StoreFile底层就是HFile。</li>
</ol>
<h3 id="4-1-11-HLog"><a href="#4-1-11-HLog" class="headerlink" title="4.1.11 HLog"></a>4.1.11 HLog</h3><ol>
<li>HLog(WAL log)：WAL意为write ahead log，用来做灾难恢复使用，HLog记录数据的所有变更，一旦region server 宕机，就可以从log中进行恢复。</li>
<li>由于数据要经MemStore排序后才能刷写到HFile，但把数据保存在内存中会有很高的概率导致数据丢失，为了解决这个问题，数据会先写在一个叫做Write-Ahead logfile的文件中，然后再写入MemStore中。所以在系统出现故障的时候，数据可以通过这个日志文件重建。</li>
<li>HLog文件就是一个普通的Hadoop Sequence File， Sequence File的value是key时HLogKey对象，其中记录了写入数据的归属信息，除了table和region名字外，还同时包括sequence number和timestamp，timestamp是写入时间，sequence number的起始值为0，或者是最近一次存入文件系统中的sequence number。 Sequence File的value是HBase的KeyValue对象，即对应HFile中的KeyValue。</li>
</ol>
<h2 id="4-2-写流程"><a href="#4-2-写流程" class="headerlink" title="4.2 写流程"></a>4.2 写流程</h2><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16360175069448.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ol>
<li>Client先访问zookeeper，获取hbase:meta表位于哪个Region Server。</li>
<li>访问对应的Region Server，获取hbase:meta表，根据读请求的namespace:table/rowkey，查询出目标数据位于哪个Region Server中的哪个Region中。并将该table的region信息以及meta表的位置信息缓存在客户端的meta cache，方便下次访问。</li>
<li>与目标Region Server进行通讯；</li>
<li>将数据顺序写入（追加）到WAL；</li>
<li>将数据写入对应的MemStore，数据会在MemStore进行排序（rowKey 字典序）；</li>
<li>向客户端发送ack；</li>
<li>等达到MemStore的刷写时机后，将数据刷写到HFile。</li>
</ol>
<h2 id="4-3-MemStore-Flush"><a href="#4-3-MemStore-Flush" class="headerlink" title="4.3 MemStore Flush"></a>4.3 MemStore Flush</h2><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16360739438242.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"><br>MemStore刷写时机：</p>
<ul>
<li><p>MemStore 级别限制：</p>
<ul>
<li><code>hbase.hregion.memstore.flush.size</code></li>
<li>默认值：128M</li>
<li>当某个memstore的大小达到128M(默认情况下)时，<font color ='red' >其所在region的所有memstore都会刷写</font>，这个时候是不阻塞写操作的</li>
</ul>
</li>
<li><p>Region 级别限制：</p>
<ul>
<li><code>hbase.hregion.memstore.flush.size</code> * <code>hbase.hregion.memstore.block.multiplier</code> <ul>
<li>默认值: 128M * 4 = 512M</li>
<li>当一个Region的MemStore总量达到512M（默认情况下）时，会阻塞这个region的写操作，并强制刷写到HFile。触发这个刷新只会发生在MemStore即将写满128M时put了一个巨大的记录的情况，这时会阻塞写操作，强制刷写成功才能继续写入</li>
</ul>
</li>
</ul>
</li>
<li><p>RegionServer 级别限制：</p>
<ul>
<li><p><code>java_heapsize</code> * <code>hbase.regionserver.global.memstore.size</code> </p>
<ul>
<li>默认值：java_heapsize * 0.4</li>
<li>当RegionServer上所有的MemStore占用到达heap的40%时，强制阻塞所有的写操作，将所有的MemStore刷写到HFile</li>
</ul>
</li>
<li><p><code>java_heapsize</code> * <code>hbase.regionserver.global.memstore.size</code> * <code>hbase.regionserver.global.memstore.size.upper.limit</code></p>
<ul>
<li>默认值：java_heapsize * 0.4 * 0.95</li>
<li>当region server中memstore的总大小达到上述内存限制时，region server会把它的所有region按照其所有memstore的大小顺序（由大到小）依次进行刷写。直到region server中所有memstore的总大小减小到<code>hbase.regionserver.global.memstore.size.lower.limit</code>以下。</li>
</ul>
</li>
<li><p><code>hbase.regionserver.optionalcacheflushinterval</code></p>
<ul>
<li>默认值：3600000，1小时</li>
<li>到达自动刷写的时间，也会触发memstore flush。</li>
</ul>
</li>
<li><p><code>hbase.regionserver.max.logs</code></p>
<ul>
<li>默认值：32</li>
<li>当WAL文件的数量超过32，region会按照时间顺序依次进行刷写，直到WAL文件数量减小到hbase.regionserver.max.log以下（该属性名已经废弃，现无需手动设置，最大值为32）。</li>
</ul>
</li>
</ul>
</li>
<li><p>手动执行:</p>
<ul>
<li>可以通过 shell 命令 flush ‘tableName’ 或者 flush ‘regionName’ 分别对一个表或者一个 Region 进行 flush。 </li>
</ul>
</li>
</ul>
<h2 id="4-4-读流程"><a href="#4-4-读流程" class="headerlink" title="4.4 读流程"></a>4.4 读流程</h2><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16360830898136.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<h3 id="4-4-1-读流程"><a href="#4-4-1-读流程" class="headerlink" title="4.4.1 读流程"></a>4.4.1 读流程</h3><ol>
<li>Client先访问zookeeper，获取hbase:meta表位于哪个Region Server。</li>
<li>访问对应的Region Server，获取hbase:meta表，根据读请求的namespace:table/rowkey，查询出目标数据位于哪个Region Server中的哪个Region中。并将该table的region信息以及meta表的位置信息缓存在客户端的meta cache，方便下次访问。</li>
<li>与目标Region Server进行通讯；</li>
<li>分别在Block Cache（读缓存），MemStore和Store File（HFile）中查询目标数据，并将查到的所有数据进行合并。此处所有数据是指同一条数据的不同版本（time stamp）或者不同的类型（Put/Delete）。<ul>
<li>如果在 Memstore 中找不到，则在 Storefile 中扫描 为了能快速的判断要查询的数据在不在这个 StoreFile 中，应用了 BloomFilter</li>
<li>BloomFilter，布隆过滤器：迅速判断一个元素是不是在一个庞大的集合内，但是他有一个 弱点：它有一定的误判率</li>
<li>误判率：原本不存在与该集合的元素，布隆过滤器有可能会判断说它存在，但是，如果布隆过滤器，判断说某一个元素不存在该集合，那么该元素就一定不在该集合内）</li>
</ul>
</li>
<li>将从文件中查询到的数据块（Block，HFile数据存储单元，默认大小为64KB）缓存到Block Cache。</li>
<li>将合并后的最终结果返回给客户端。</li>
</ol>
<h3 id="4-4-1-Block-Cache读缓存"><a href="#4-4-1-Block-Cache读缓存" class="headerlink" title="4.4.1 Block Cache读缓存"></a>4.4.1 Block Cache读缓存</h3><ol>
<li>读缓存：RegionServer级别，占堆内存的40%(默认)</li>
<li>当写操作导致缓存数据过期时，RegionServer会将过期的块释放  </li>
<li>如果没有命中BlockCache，会去memstore和所有的storefile里面查找数据</li>
</ol>
<h3 id="4-4-1-1-LruBlockCache"><a href="#4-4-1-1-LruBlockCache" class="headerlink" title="4.4.1.1 LruBlockCache"></a>4.4.1.1 LruBlockCache</h3><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16360911357506.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ul>
<li><p>LruBlockCache内部较为简单，主要就是一个map，如上图所示，由hfilename+offset来唯一标识一个block；</p>
</li>
<li><p>LruBlockCache所能够使用的内存为堆的一定比例，通过hfile.block.cache.size设置，默认是0.4；</p>
</li>
<li><p>maxSize = heapSize * hfile.block.cache.size，以下参数都根据maxSize计算；<br><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16360926195851.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ul>
<li>acceptSize<ul>
<li>使用量达到一定比例时会触发驱逐，该阈值通过hbase.lru.blockcache.acceptable.factor设置，默认是0.99；</li>
</ul>
</li>
<li>minSize<ul>
<li>驱逐后最少剩余比例，该阈值通过hbase.lru.blockcache.min.factor设置，默认是0.95；</li>
</ul>
</li>
<li>hardLimit<ul>
<li>使用量达到一定比例时则拒绝写入，该阈值通过hbase.lru.blockcache.hard.capacity.limit.factor设置，默认是1.2，这意味允许一定的超出；</li>
</ul>
</li>
</ul>
</li>
<li><p>关于驱逐：</p>
<ol>
<li>block分为3种类型，由BlockPriority字段区分，取值为single、mutli、inMem，空间分配默认为0.25：0.5：0.25；</li>
<li>系统表以及其它指定了InMem的表所含block会标记为inMem，其它block初次存入时标记为single，再次访问时会修改为multi；</li>
<li>存放时只要还有空间即可放入，空间分配比例只是在驱逐发生时进行计算使用；</li>
<li>驱逐时，会用minSize乘以各类型的比例，得到各类型最少要保留的minSize；</li>
<li>根据目前的算法，驱逐后的size，应该是略大于minSize的一个值，伪代码如下； <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">expectFreeSize = usedSize - minSize;//预期释放总大小</span><br><span class="line">freedSize = 0;//当前已释放总大小</span><br><span class="line">n=3;//类型数量</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">type</span> <span class="keyword">in</span> (<span class="string">&#x27;single&#x27;</span>,<span class="string">&#x27;multi&#x27;</span>,<span class="string">&#x27;inMem&#x27;</span>):</span><br><span class="line">    overFlow = type.usedSize - type.minSize</span><br><span class="line">    toBeFree = min(overFlow,(expectFreeSize - freedSize)/n)</span><br><span class="line">    free(toBeFree)</span><br><span class="line">    freedSize += toBeFree</span><br><span class="line">    n--;</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ul>
<h3 id="4-4-1-2-CombinedBlockCache-LruBlockCache-BucketCache"><a href="#4-4-1-2-CombinedBlockCache-LruBlockCache-BucketCache" class="headerlink" title="4.4.1.2 CombinedBlockCache = LruBlockCache + BucketCache"></a>4.4.1.2 CombinedBlockCache = LruBlockCache + BucketCache</h3><ol>
<li>BucketCache<ol>
<li>LruBlockCache的优点是实现简单，缺点是block的存入和释放伴随着内存的申请和释放，会带来内存碎片和gc过多的问题；</li>
<li>BucketCache采用了类似池的思路，预先申请内存并划分为一个个的bucket，这些bucket会一直存在并重复使用；</li>
</ol>
</li>
</ol>
<p>总体的读写流程如下图所示：<br><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16360926651279.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"><br>Block缓存写入流程：</p>
<ol>
<li>将block写入RAMCache，然后系统会根据blockkey进行hash，根据hash结果将block分配到一组blockingQueue中；</li>
<li>HBase会同时启动多个WriteThead，分别关联一个blockingQueue，并发的执行异步写入；</li>
<li>每个WriteThead读取到block数据后，调用bucketAllocator为这些block分配内存空间；</li>
<li>BucketAllocator会选择与block大小对应的bucket进行存放，并且返回对应的物理地址偏移量offset；</li>
<li>WriteThead将block以及分配好的物理地址偏移量传给IOEngine模块，执行具体的内存写入操作；</li>
<li>写入成功后，将类似这样的映射关系写入BackingMap中，方便后续查找时根据blockkey可以直接定位；</li>
</ol>
<p>Block缓存读取流程：</p>
<ol>
<li>首先从RAMCache中查找，对于还没有来得及写入到bucket的缓存block，一定存储在RAMCache中；</li>
<li>如果在RAMCache中没有找到，再在BackingMap中根据blockKey找到对应entry；</li>
<li>根据entry中的offset可以直接从内存中查找对应的block数据；</li>
</ol>
<p>其中最核心的组件是BucketAllocator和IoEngine，前者负责block的逻辑地址分配，后者负责block的实际物理存放，内部结构如下：<br><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16361213582414.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ol>
<li>hbase中blocksize是可以灵活设置的，bucketCache预设了一组支持的大小，从4K~512k不等；</li>
<li>一个Bucket只能存放一种size的block，一种size对应一个BucketSizeInfo进行管理；</li>
<li>初始化时，每种size先分配1个bucket，剩余的都分配给最大的那个size，如黑色箭头所示；</li>
<li>分配过程中当前size如果空间不够，会挪用其它size的空闲bucket，如棕色箭头所示，这意味着有可能某个Bucket一开始存放了32k的block</li>
<li>释放后空闲，被挪用后变成存放64k的block；</li>
<li>ioEngine有多种实现，可支持onheap、offheap、disk等；</li>
</ol>
<p>关于驱逐：</p>
<ol>
<li>2种情况下会触发<ol>
<li>1是已使用超过95%（acceptableFactor），</li>
<li>2是某个size的block分配不了(总量虽然没达到阈值，但不存在完全空闲的bucket供挪用)；</li>
<li>驱逐后的最少剩余比例为85%（minFactor），遍历各个bucketSizeInfo，把超过85%的部分加起来，再乘以一个系数0.1（extraFreeFactor），就是要释放的大小；</li>
<li>具体计算方法复用了LruBlockCache的代码，也是按照single、multi、inMem及其比例进行计算和释放；</li>
<li>实际清理动作是修改一些状态数据，比如Bucket对象的freeList、freeCount，以及backMapping的键值对等，并不需要对底层的byteBuffer做什么操作；</li>
<li>对于refCount大于0的block，会先将其markedForEvict置为true，待各个使用方读取完成后调用returnBlock进行释放；</li>
</ol>
</li>
</ol>
<h2 id="4-5-StoreFile-Compaction"><a href="#4-5-StoreFile-Compaction" class="headerlink" title="4.5 StoreFile Compaction"></a>4.5 StoreFile Compaction</h2><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16360927692130.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ul>
<li>由于memstore每次刷写都会生成一个新的HFile，且同一个字段的不同版本（timestamp）和不同类型（Put/Delete）有可能会分布在不同的HFile中，因此查询时需要遍历所有的HFile。为了减少HFile的个数，以及清理掉过期和删除的数据，会进行StoreFile Compaction。</li>
<li>Compaction分为两种，分别是Minor Compaction和Major Compaction。<ul>
<li>Minor Compaction会将临近的若干个较小的HFile合并成一个较大的HFile，但不会清理过期和删除的数据；不会对cell合并；性能要求低</li>
<li>Major Compaction会将一个Store下的所有的HFile合并成一个大HFile，并且会清理掉过期和删除的数据，对所有cell进行排序，性能要求高</li>
</ul>
</li>
<li>触发时机：<ul>
<li>Minor Compaction自动执行，超过3个以上的storeFile，根据ExploringCompactionPolicy算法判断触发</li>
<li>Major Compaction：默认七天一次，推荐手动执行</li>
</ul>
</li>
</ul>
<h2 id="4-6-Region-Split"><a href="#4-6-Region-Split" class="headerlink" title="4.6 Region Split"></a>4.6 Region Split</h2><ul>
<li>默认情况下，每个Table起初只有一个Region，随着数据的不断写入，Region会自动进行拆分。刚拆分时，两个子Region都位于当前的Region Server，但处于负载均衡的考虑，HMaster有可能会将某个Region转移给其他的Region Server。</li>
<li>Region Split时机：<ol>
<li>当1个region中的某个Store下所有StoreFile的总大小超过<code>hbase.hregion.max.filesize（默认值：10G）</code>，该Region就会进行拆分（0.94版本之前）。</li>
<li>当1个region中的某个Store下所有StoreFile的总大小超过<code>Min(R^3 * 2 * &quot;hbase.hregion.memstore.flush.size&quot;,hbase.hregion.max.filesize&quot;)</code>，该Region就会进行拆分，其中R为当前Region Server中属于该Table的Region个数（0.94版本之后）。快速分裂：使表能尽快分布到所有Region</li>
<li>Hbase 2.0引入了新的split策略：如果当前RegionServer上改表只有一个Region，按照<code>2 * hbase.hregion.memstore.flush.size 默认128M</code>分裂，否则按照<code>hbase.hregion.max.filesize 默认值10G</code>分裂。防止Region过多，导致小文件过多</li>
</ol>
</li>
<li>Region Split过程<br>  在子region文件夹下生成两个子文件夹daughterA、daughterB，并在两个文件夹内生成reference文件，分别指向父region中对应的文件随着Compaction的进行，RefenceFile会逐渐被删除，此时父Region数据没用了， 会被删除，Split结束<h2 id="4-7-Region-Merge"><a href="#4-7-Region-Merge" class="headerlink" title="4.7 Region Merge"></a>4.7 Region Merge</h2>如果Region数量过多，可以手动合并Region</li>
</ul>
<h1 id="第5章-HBase优化"><a href="#第5章-HBase优化" class="headerlink" title="第5章 HBase优化"></a>第5章 HBase优化</h1><h2 id="5-1-预分区"><a href="#5-1-预分区" class="headerlink" title="5.1 预分区"></a>5.1 预分区</h2><p>每一个region维护着StartRow与EndRow，如果加入的数据符合某个Region维护的RowKey范围，则该数据交给这个Region维护。那么依照这个原则，我们可以将数据所要投放的分区提前大致的规划好，以提高HBase性能。</p>
<ol>
<li>手动设定预分区 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase&gt; create <span class="string">&#x27;staff1&#x27;</span>,<span class="string">&#x27;info&#x27;</span>,<span class="string">&#x27;partition1&#x27;</span>,SPLITS =&gt; [<span class="string">&#x27;1000&#x27;</span>,<span class="string">&#x27;2000&#x27;</span>,<span class="string">&#x27;3000&#x27;</span>,<span class="string">&#x27;4000&#x27;</span>]</span><br></pre></td></tr></table></figure></li>
<li>生成16进制序列预分区 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase&gt; create <span class="string">&#x27;staff2&#x27;</span>,<span class="string">&#x27;info&#x27;</span>,<span class="string">&#x27;partition2&#x27;</span>,&#123;NUMREGIONS =&gt; 15, SPLITALGO =&gt; <span class="string">&#x27;HexStringSplit&#x27;</span>&#125;</span><br></pre></td></tr></table></figure></li>
<li>按照文件中设置的规则预分区<ul>
<li>创建splits.txt文件内容如下：  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">aaaa</span><br><span class="line">bbbb</span><br><span class="line">cccc</span><br><span class="line">dddd</span><br></pre></td></tr></table></figure></li>
<li>然后执行：  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="string">&#x27;staff3&#x27;</span>,<span class="string">&#x27;partition3&#x27;</span>,SPLITS_FILE <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;/home/atguigu/hbase/splits.txt&#x27;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>使用JavaAPI创建预分区 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//自定义算法，产生一系列hash散列值存储在二维数组中</span></span><br><span class="line"><span class="keyword">byte</span>[][] splitKeys = 某个散列值函数</span><br><span class="line"><span class="comment">//创建HbaseAdmin实例</span></span><br><span class="line">HBaseAdmin hAdmin = <span class="keyword">new</span> HBaseAdmin(HbaseConfiguration.create());</span><br><span class="line"><span class="comment">//创建HTableDescriptor实例</span></span><br><span class="line">HTableDescriptor tableDesc = <span class="keyword">new</span> HTableDescriptor(tableName);</span><br><span class="line"><span class="comment">//通过HTableDescriptor实例和散列值二维数组创建带有预分区的Hbase表</span></span><br><span class="line">hAdmin.createTable(tableDesc, splitKeys);</span><br></pre></td></tr></table></figure>
<h2 id="5-2-RowKey设计"><a href="#5-2-RowKey设计" class="headerlink" title="5.2 RowKey设计"></a>5.2 RowKey设计</h2>一条数据的唯一标识就是RowKey，那么这条数据存储于哪个分区，取决于RowKey处于哪个一个预分区的区间内，设计RowKey的主要目的 ，就是让数据均匀的分布于所有的region中，在一定程度上防止数据倾斜。接下来我们就谈一谈RowKey常用的设计方案。</li>
<li>生成随机数、hash、散列值, 比如： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">原本rowKey为1001的，SHA1后变成：dd01903921ea24941c26a48f2cec24e0bb0e8cc7</span><br><span class="line">原本rowKey为3001的，SHA1后变成：49042c54de64a1e9bf0b33e00245660ef92dc7bd</span><br><span class="line">原本rowKey为5001的，SHA1后变成：7b61dec07e02c188790670af43e717f0f46e8913</span><br></pre></td></tr></table></figure>
<ul>
<li>在做此操作之前，一般我们会选择从数据集中抽取样本，来决定什么样的rowKey来Hash后作为每个分区的临界值。</li>
</ul>
</li>
<li>字符串反转 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">20170524000001转成10000042507102</span><br><span class="line">20170524000002转成20000042507102</span><br></pre></td></tr></table></figure>
 这样也可以在一定程度上散列逐步put进来的数据。</li>
<li>字符串拼接 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">20170524000001_a12e</span><br><span class="line">20170524000001_93i7</span><br></pre></td></tr></table></figure>
<h2 id="5-3-内存优化"><a href="#5-3-内存优化" class="headerlink" title="5.3 内存优化"></a>5.3 内存优化</h2>HBase操作过程中需要大量的内存开销，毕竟Table是可以缓存在内存中的，一般会分配整个可用内存的70%给HBase的Java堆。但是不建议分配非常大的堆内存，因为GC过程持续太久会导致RegionServer处于长期不可用状态，一般16~48G内存就可以了，如果因为框架占用内存过高导致系统内存不足，框架一样会被系统服务拖死。</li>
</ol>
<h2 id="5-4-基础优化"><a href="#5-4-基础优化" class="headerlink" title="5.4 基础优化"></a>5.4 基础优化</h2><ol>
<li>允许在HDFS的文件中追加内容<ul>
<li>hdfs-site.xml、hbase-site.xml</li>
<li>属性：dfs.support.append</li>
<li>解释：开启HDFS追加同步，可以优秀的配合HBase的数据同步和持久化。默认值为true。</li>
</ul>
</li>
<li>优化DataNode允许的最大文件打开数<ul>
<li>hdfs-site.xml</li>
<li>属性：dfs.datanode.max.transfer.threads</li>
<li>解释：HBase一般都会同一时间操作大量的文件，根据集群的数量和规模以及数据动作，设置为4096或者更高。默认值：4096</li>
</ul>
</li>
<li>优化延迟高的数据操作的等待时间<ul>
<li>hdfs-site.xml</li>
<li>属性：dfs.image.transfer.timeout</li>
<li>解释：如果对于某一次数据操作来讲，延迟非常高，socket需要等待更长的时间，建议把该值设置为更大的值（默认60000毫秒），以确保socket不会被timeout掉。</li>
</ul>
</li>
<li>优化数据的写入效率<ul>
<li>mapred-site.xml</li>
<li>属性：<ul>
<li>mapreduce.map.output.compress</li>
<li>mapreduce.map.output.compress.codec</li>
</ul>
</li>
<li>解释：开启这两个数据可以大大提高文件的写入效率，减少写入时间。第一个属性值修改为true，第二个属性值修改为：org.apache.hadoop.io.compress.GzipCodec或者其他压缩方式。</li>
</ul>
</li>
<li>设置RPC监听数量<ul>
<li>hbase-site.xml</li>
<li>属性：Hbase.regionserver.handler.count</li>
<li>解释：默认值为30，用于指定RPC监听的数量，可以根据客户端的请求数进行调整，读写请求较多时，增加此值。</li>
</ul>
</li>
<li>优化HStore文件大小<ul>
<li>hbase-site.xml</li>
<li>属性：hbase.hregion.max.filesize</li>
<li>解释：默认值10737418240（10GB），如果需要运行HBase的MR任务，可以减小此值，因为一个region对应一个map任务，如果单个region过大，会导致map任务执行时间过长。该值的意思就是，如果HFile的大小达到这个数值，则这个region会被切分为两个Hfile。</li>
</ul>
</li>
<li>优化HBase客户端缓存<ul>
<li>hbase-site.xml</li>
<li>属性：hbase.client.write.buffer</li>
<li>解释：用于指定Hbase客户端缓存，增大该值可以减少RPC调用次数，但是会消耗更多内存，反之则反之。一般我们需要设定一定的缓存大小，以达到减少RPC次数的目的。</li>
</ul>
</li>
<li>指定scan.next扫描HBase所获取的行数<ul>
<li>hbase-site.xml</li>
<li>属性：hbase.client.scanner.caching</li>
<li>解释：用于指定scan.next方法获取的默认行数，值越大，消耗内存越大。</li>
</ul>
</li>
<li>flush、compact、split机制<br> 当MemStore达到阈值，将Memstore中的数据Flush进Storefile；compact机制则是把flush出来的小文件合并成大的Storefile文件。split则是当Region达到阈值，会把过大的Region一分为二。<ul>
<li>属性：<ul>
<li>hbase.hregion.memstore.flush.size：134217728<ul>
<li>128M就是Memstore的默认阈值</li>
<li>这个参数的作用是当单个HRegion内所有的Memstore大小总和超过指定值时，flush该HRegion的所有memstore。RegionServer的flush是通过将请求添加一个队列，模拟生产消费模型来异步处理的。那这里就有一个问题，当队列来不及消费，产生大量积压请求时，可能会导致内存陡增，最坏的情况是触发OOM。</li>
</ul>
</li>
<li>hbase.regionserver.global.memstore.upperLimit：0.8</li>
<li>hbase.regionserver.global.memstore.lowerLimit：0.6<ul>
<li>当MemStore使用内存总量达到hbase.regionserver.global.memstore.upperLimit指定值时，将会有多个MemStores flush到文件中，MemStore flush 顺序是按照大小降序执行的，直到刷新到MemStore使用内存略小于lowerLimit</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h1 id="第6章-整合Phoenix"><a href="#第6章-整合Phoenix" class="headerlink" title="第6章 整合Phoenix"></a>第6章 整合Phoenix</h1><h2 id="6-1-Phoenix简介"><a href="#6-1-Phoenix简介" class="headerlink" title="6.1 Phoenix简介"></a>6.1 Phoenix简介</h2><h3 id="6-1-1-Phoenix定义"><a href="#6-1-1-Phoenix定义" class="headerlink" title="6.1.1 Phoenix定义"></a>6.1.1 Phoenix定义</h3><p>Phoenix是HBase的开源SQL皮肤。可以使用标准JDBC API代替HBase客户端API来创建表，插入数据和查询HBase数据。</p>
<h3 id="6-1-2-Phoenix特点"><a href="#6-1-2-Phoenix特点" class="headerlink" title="6.1.2 Phoenix特点"></a>6.1.2 Phoenix特点</h3><ol>
<li>容易集成：如Spark，Hive，Pig，Flume和Map Reduce；</li>
<li>操作简单：DML命令以及通过DDL命令创建和操作表和版本化增量更改；</li>
<li>支持HBase二级索引创建。</li>
</ol>
<h3 id="6-1-3-Phoenix架构"><a href="#6-1-3-Phoenix架构" class="headerlink" title="6.1.3 Phoenix架构"></a>6.1.3 Phoenix架构</h3><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16361629213598.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<h2 id="6-2-Phoenix快速入门"><a href="#6-2-Phoenix快速入门" class="headerlink" title="6.2 Phoenix快速入门"></a>6.2 Phoenix快速入门</h2><h3 id="6-2-1-安装"><a href="#6-2-1-安装" class="headerlink" title="6.2.1 安装"></a>6.2.1 安装</h3><ol>
<li>官网地址:<a target="_blank" rel="noopener" href="http://phoenix.apache.org/">http://phoenix.apache.org/</a></li>
<li>Phoenix部署<ol>
<li>上传并解压tar包 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 module]$ tar -zxvf apache-phoenix-5.0.0-HBase-2.0-bin.tar.gz -C /opt/module/</span><br><span class="line">[atguigu@hadoop001 module]$ mv apache-phoenix-5.0.0-HBase-2.0-bin phoenix-5.0.0</span><br></pre></td></tr></table></figure></li>
<li>复制server包并拷贝到各个节点的hbase/lib <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 phoenix-5.0.0]$ cp /opt/module/phoenix-5.0.0/phoenix-5.0.0-HBase-2.0-server.jar /opt/module/hbase-2.0.5/lib/</span><br><span class="line">[atguigu@hadoop001 phoenix-5.0.0]$ xsync /opt/module/hbase-2.0.5/lib/phoenix-5.0.0-HBase-2.0-server.jar</span><br></pre></td></tr></table></figure></li>
<li>配置环境变量 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#phoenix</span></span><br><span class="line"><span class="built_in">export</span> PHOENIX_HOME=/opt/module/phoenix-5.0.0</span><br><span class="line"><span class="built_in">export</span> PHOENIX_CLASSPATH=<span class="variable">$PHOENIX_HOME</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$PHOENIX_HOME</span>/bin</span><br></pre></td></tr></table></figure></li>
<li>连接Phoenix <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 software]$ sqlline.py hadoop001,hadoop002,hadoop003,hadoop004,hadoop005:2181</span><br><span class="line">Setting property: [incremental, <span class="literal">false</span>]</span><br><span class="line">Setting property: [isolation, TRANSACTION_READ_COMMITTED]</span><br><span class="line">issuing: !connect jdbc:phoenix:hadoop001,hadoop002,hadoop003,hadoop004,hadoop005:2181 none none org.apache.phoenix.jdbc.PhoenixDriver</span><br><span class="line">Connecting to jdbc:phoenix:hadoop001,hadoop002,hadoop003,hadoop004,hadoop005:2181</span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/opt/module/phoenix-5.0.0/phoenix-5.0.0-HBase-2.0-client.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:/opt/module/ha-hadoop-3.1.3/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html<span class="comment">#multiple_bindings for an explanation.</span></span><br><span class="line">21/11/06 10:06:53 WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes <span class="built_in">where</span> applicable</span><br><span class="line">Connected to: Phoenix (version 5.0)</span><br><span class="line">Driver: PhoenixEmbeddedDriver (version 5.0)</span><br><span class="line">Autocommit status: <span class="literal">true</span></span><br><span class="line">Transaction isolation: TRANSACTION_READ_COMMITTED</span><br><span class="line">Building list of tables and columns <span class="keyword">for</span> tab-completion (<span class="built_in">set</span> fastconnect to <span class="literal">true</span> to skip)...</span><br><span class="line">133/133 (100%) Done</span><br><span class="line">Done</span><br><span class="line">sqlline version 1.2.0</span><br><span class="line">0: jdbc:phoenix:hadoop001,hadoop002,hadoop003&gt;</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h3 id="6-2-2-Phoenix-Shell操作"><a href="#6-2-2-Phoenix-Shell操作" class="headerlink" title="6.2.2 Phoenix Shell操作"></a>6.2.2 Phoenix Shell操作</h3><ol>
<li>表的操作<ul>
<li>显示所有表  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:phoenix:hadoop001,hadoop002,hadoop003<span class="operator">&gt;</span> <span class="operator">!</span><span class="keyword">table</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+--------------+-------------+---------------+----------+------------+----------------------------+-----------------+--------------+-----------------+---------------+</span></span><br><span class="line"><span class="operator">|</span> TABLE_CAT  <span class="operator">|</span> TABLE_SCHEM  <span class="operator">|</span> TABLE_NAME  <span class="operator">|</span>  TABLE_TYPE   <span class="operator">|</span> REMARKS  <span class="operator">|</span> TYPE_NAME  <span class="operator">|</span> SELF_REFERENCING_COL_NAME  <span class="operator">|</span> REF_GENERATION  <span class="operator">|</span> INDEX_STATE  <span class="operator">|</span> IMMUTABLE_ROWS  <span class="operator">|</span> SALT_BUCKETS  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+--------------+-------------+---------------+----------+------------+----------------------------+-----------------+--------------+-----------------+---------------+</span></span><br><span class="line"><span class="operator">|</span>            <span class="operator">|</span> <span class="keyword">SYSTEM</span>       <span class="operator">|</span> CATALOG     <span class="operator">|</span> <span class="keyword">SYSTEM</span> <span class="keyword">TABLE</span>  <span class="operator">|</span>          <span class="operator">|</span>            <span class="operator">|</span>                            <span class="operator">|</span>                 <span class="operator">|</span>              <span class="operator">|</span> <span class="literal">false</span>           <span class="operator">|</span> <span class="keyword">null</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>            <span class="operator">|</span> <span class="keyword">SYSTEM</span>       <span class="operator">|</span> <span class="keyword">FUNCTION</span>    <span class="operator">|</span> <span class="keyword">SYSTEM</span> <span class="keyword">TABLE</span>  <span class="operator">|</span>          <span class="operator">|</span>            <span class="operator">|</span>                            <span class="operator">|</span>                 <span class="operator">|</span>              <span class="operator">|</span> <span class="literal">false</span>           <span class="operator">|</span> <span class="keyword">null</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>            <span class="operator">|</span> <span class="keyword">SYSTEM</span>       <span class="operator">|</span> LOG         <span class="operator">|</span> <span class="keyword">SYSTEM</span> <span class="keyword">TABLE</span>  <span class="operator">|</span>          <span class="operator">|</span>            <span class="operator">|</span>                            <span class="operator">|</span>                 <span class="operator">|</span>              <span class="operator">|</span> <span class="literal">true</span>            <span class="operator">|</span> <span class="number">32</span>            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>            <span class="operator">|</span> <span class="keyword">SYSTEM</span>       <span class="operator">|</span> SEQUENCE    <span class="operator">|</span> <span class="keyword">SYSTEM</span> <span class="keyword">TABLE</span>  <span class="operator">|</span>          <span class="operator">|</span>            <span class="operator">|</span>                            <span class="operator">|</span>                 <span class="operator">|</span>              <span class="operator">|</span> <span class="literal">false</span>           <span class="operator">|</span> <span class="keyword">null</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>            <span class="operator">|</span> <span class="keyword">SYSTEM</span>       <span class="operator">|</span> STATS       <span class="operator">|</span> <span class="keyword">SYSTEM</span> <span class="keyword">TABLE</span>  <span class="operator">|</span>          <span class="operator">|</span>            <span class="operator">|</span>                            <span class="operator">|</span>                 <span class="operator">|</span>              <span class="operator">|</span> <span class="literal">false</span>           <span class="operator">|</span> <span class="keyword">null</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+--------------+-------------+---------------+----------+------------+----------------------------+-----------------+--------------+-----------------+---------------+</span></span><br><span class="line"><span class="number">0</span>: jdbc:phoenix:hadoop001,hadoop002,hadoop003<span class="operator">&gt;</span> <span class="operator">!</span>tables</span><br><span class="line"><span class="operator">+</span><span class="comment">------------+--------------+-------------+---------------+----------+------------+----------------------------+-----------------+--------------+-----------------+---------------+</span></span><br><span class="line"><span class="operator">|</span> TABLE_CAT  <span class="operator">|</span> TABLE_SCHEM  <span class="operator">|</span> TABLE_NAME  <span class="operator">|</span>  TABLE_TYPE   <span class="operator">|</span> REMARKS  <span class="operator">|</span> TYPE_NAME  <span class="operator">|</span> SELF_REFERENCING_COL_NAME  <span class="operator">|</span> REF_GENERATION  <span class="operator">|</span> INDEX_STATE  <span class="operator">|</span> IMMUTABLE_ROWS  <span class="operator">|</span> SALT_BUCKETS  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+--------------+-------------+---------------+----------+------------+----------------------------+-----------------+--------------+-----------------+---------------+</span></span><br><span class="line"><span class="operator">|</span>            <span class="operator">|</span> <span class="keyword">SYSTEM</span>       <span class="operator">|</span> CATALOG     <span class="operator">|</span> <span class="keyword">SYSTEM</span> <span class="keyword">TABLE</span>  <span class="operator">|</span>          <span class="operator">|</span>            <span class="operator">|</span>                            <span class="operator">|</span>                 <span class="operator">|</span>              <span class="operator">|</span> <span class="literal">false</span>           <span class="operator">|</span> <span class="keyword">null</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>            <span class="operator">|</span> <span class="keyword">SYSTEM</span>       <span class="operator">|</span> <span class="keyword">FUNCTION</span>    <span class="operator">|</span> <span class="keyword">SYSTEM</span> <span class="keyword">TABLE</span>  <span class="operator">|</span>          <span class="operator">|</span>            <span class="operator">|</span>                            <span class="operator">|</span>                 <span class="operator">|</span>              <span class="operator">|</span> <span class="literal">false</span>           <span class="operator">|</span> <span class="keyword">null</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>            <span class="operator">|</span> <span class="keyword">SYSTEM</span>       <span class="operator">|</span> LOG         <span class="operator">|</span> <span class="keyword">SYSTEM</span> <span class="keyword">TABLE</span>  <span class="operator">|</span>          <span class="operator">|</span>            <span class="operator">|</span>                            <span class="operator">|</span>                 <span class="operator">|</span>              <span class="operator">|</span> <span class="literal">true</span>            <span class="operator">|</span> <span class="number">32</span>            <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>            <span class="operator">|</span> <span class="keyword">SYSTEM</span>       <span class="operator">|</span> SEQUENCE    <span class="operator">|</span> <span class="keyword">SYSTEM</span> <span class="keyword">TABLE</span>  <span class="operator">|</span>          <span class="operator">|</span>            <span class="operator">|</span>                            <span class="operator">|</span>                 <span class="operator">|</span>              <span class="operator">|</span> <span class="literal">false</span>           <span class="operator">|</span> <span class="keyword">null</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span>            <span class="operator">|</span> <span class="keyword">SYSTEM</span>       <span class="operator">|</span> STATS       <span class="operator">|</span> <span class="keyword">SYSTEM</span> <span class="keyword">TABLE</span>  <span class="operator">|</span>          <span class="operator">|</span>            <span class="operator">|</span>                            <span class="operator">|</span>                 <span class="operator">|</span>              <span class="operator">|</span> <span class="literal">false</span>           <span class="operator">|</span> <span class="keyword">null</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------+--------------+-------------+---------------+----------+------------+----------------------------+-----------------+--------------+-----------------+---------------+</span></span><br><span class="line"><span class="number">0</span>: jdbc:phoenix:hadoop001,hadoop002,hadoop003<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>创建表  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 直接指定单个列作为RowKey</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> STUDENT (</span><br><span class="line">    id <span class="type">VARCHAR</span> <span class="keyword">primary</span> key,</span><br><span class="line">    name <span class="type">VARCHAR</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- 指定多个列的联合作为RowKey</span></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> IF <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> US_POPULATION (</span><br><span class="line">    State <span class="type">CHAR</span>(<span class="number">2</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    City <span class="type">VARCHAR</span> <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">    Population <span class="type">BIGINT</span></span><br><span class="line"><span class="keyword">CONSTRAINT</span> my_pk <span class="keyword">PRIMARY</span> KEY (state, city));</span><br></pre></td></tr></table></figure>
<blockquote>
<p>在phoenix中，表名等会自动转换为大写，若要小写，使用双引号如”us_population”。</p>
</blockquote>
</li>
<li>插入数据</li>
<li>查询记录  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student;</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> student <span class="keyword">where</span> id<span class="operator">=</span><span class="string">&#x27;1001&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li>删除记录  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> student <span class="keyword">where</span> id<span class="operator">=</span><span class="string">&#x27;1001&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li>删除表  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> student;</span><br></pre></td></tr></table></figure></li>
<li>退出命令行  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">!</span>quit</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>表的映射<br> 默认情况下，直接在HBase中创建的表，通过Phoenix是查看不到的。如果要在Phoenix中操作直接在HBase中创建的表，则需要在Phoenix中进行表的映射。映射方式有两种：视图映射和表映射。<ul>
<li>视图映射<ol>
<li>Phoenix创建的视图是只读的，所以只能用来做查询，无法通过视图对源数据进行修改等操作</li>
<li>HBase创建表 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):<span class="number">031</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">create</span> <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;info1&#x27;</span>,<span class="string">&#x27;info2&#x27;</span></span><br><span class="line">Created <span class="keyword">table</span> test</span><br><span class="line">Took <span class="number">0.7934</span> seconds</span><br><span class="line"><span class="operator">=</span><span class="operator">&gt;</span> Hbase::<span class="keyword">Table</span> <span class="operator">-</span> test</span><br><span class="line">hbase(main):<span class="number">032</span>:<span class="number">0</span><span class="operator">&gt;</span> put <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;10001&#x27;</span>,<span class="string">&#x27;info1:name&#x27;</span>,<span class="string">&#x27;zhangsan&#x27;</span></span><br><span class="line">Took <span class="number">0.0326</span> seconds</span><br><span class="line">hbase(main):<span class="number">033</span>:<span class="number">0</span><span class="operator">&gt;</span> put <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;10002&#x27;</span>,<span class="string">&#x27;info1:name&#x27;</span>,<span class="string">&#x27;zhangsan&#x27;</span></span><br><span class="line">Took <span class="number">0.0040</span> seconds</span><br><span class="line">hbase(main):<span class="number">034</span>:<span class="number">0</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>Phoenix创建视图，查询 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:phoenix:thin:url<span class="operator">=</span>http:<span class="operator">/</span><span class="operator">/</span>localhost:<span class="number">876</span><span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">view</span> &quot;test&quot;(id <span class="type">varchar</span> <span class="keyword">primary</span> key,&quot;info1&quot;.&quot;name&quot; <span class="type">varchar</span>, &quot;info2&quot;.&quot;address&quot; <span class="type">varchar</span>);</span><br><span class="line"><span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">5.836</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:phoenix:thin:url<span class="operator">=</span>http:<span class="operator">/</span><span class="operator">/</span>localhost:<span class="number">876</span><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> &quot;test&quot;;</span><br><span class="line"><span class="operator">+</span><span class="comment">--------+-----------+----------+</span></span><br><span class="line"><span class="operator">|</span>   ID   <span class="operator">|</span>   name    <span class="operator">|</span> address  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------+-----------+----------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">10001</span>  <span class="operator">|</span> zhangsan  <span class="operator">|</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="number">10002</span>  <span class="operator">|</span> zhangsan  <span class="operator">|</span>          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">--------+-----------+----------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> selected (<span class="number">0.044</span> seconds)</span><br></pre></td></tr></table></figure></li>
<li>删除视图<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:phoenix:thin:url<span class="operator">=</span>http:<span class="operator">/</span><span class="operator">/</span>localhost:<span class="number">876</span><span class="operator">&gt;</span> <span class="keyword">drop</span> <span class="keyword">view</span> &quot;test&quot;;</span><br><span class="line"> <span class="keyword">No</span> <span class="keyword">rows</span> affected (<span class="number">0.015</span> seconds)</span><br><span class="line"> <span class="number">0</span>: jdbc:phoenix:thin:url<span class="operator">=</span>http:<span class="operator">/</span><span class="operator">/</span>localhost:<span class="number">876</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li>表映射<ol>
<li>HBase中不存在表时，可以直接使用create table指令创建需要的表,系统将会自动在Phoenix和HBase中创建person_infomation的表，并会根据指令内的参数对表结构进行初始化。</li>
<li>当HBase中已经存在表时，可以以类似创建视图的方式创建关联表，只需要将create view改为create table即可。<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:phoenix:hadoop101,hadoop102,hadoop103<span class="operator">&gt;</span> <span class="keyword">create</span> <span class="keyword">table</span> &quot;test&quot;(id <span class="type">varchar</span> <span class="keyword">primary</span> key,&quot;info1&quot;.&quot;name&quot; <span class="type">varchar</span>, &quot;info2&quot;.&quot;address&quot; <span class="type">varchar</span>) column_encoded_bytes<span class="operator">=</span><span class="number">0</span>;</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ul>
</li>
</ol>
<h3 id="6-2-3-Phoenix-JDBC操作"><a href="#6-2-3-Phoenix-JDBC操作" class="headerlink" title="6.2.3 Phoenix JDBC操作"></a>6.2.3 Phoenix JDBC操作</h3><ol>
<li>创建项目并导入依赖 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.phoenix/phoenix-queryserver-client --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.phoenix<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>phoenix-queryserver-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.0.0-HBase-2.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>编写代码 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PhoenixJDBC</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> String connectionUrl = ThinClientUtil.getConnectionUrl(<span class="string">&quot;hadoop001&quot;</span>, <span class="number">8765</span>);</span><br><span class="line">        System.out.println(connectionUrl);</span><br><span class="line">        <span class="keyword">try</span> (</span><br><span class="line"></span><br><span class="line">                <span class="keyword">final</span> Connection connection = DriverManager.getConnection(connectionUrl);</span><br><span class="line">                <span class="keyword">final</span> PreparedStatement preparedStatement = connection.prepareStatement(<span class="string">&quot;select * from student&quot;</span>);</span><br><span class="line"></span><br><span class="line">        )&#123;</span><br><span class="line">            <span class="keyword">final</span> ResultSet resultSet = preparedStatement.executeQuery();</span><br><span class="line">            <span class="keyword">while</span> (resultSet.next()) &#123;</span><br><span class="line">                <span class="keyword">final</span> String id = resultSet.getString(<span class="number">1</span>);</span><br><span class="line">                <span class="keyword">final</span> String name = resultSet.getString(<span class="number">2</span>);</span><br><span class="line">                System.out.println(<span class="string">&quot;id: &quot;</span> + id + <span class="string">&quot;,&quot;</span> + <span class="string">&quot;name: &quot;</span> + name);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="6-3-Phoenix二级索引"><a href="#6-3-Phoenix二级索引" class="headerlink" title="6.3 Phoenix二级索引"></a>6.3 Phoenix二级索引</h2><p>已经有索引的情况下，</p>
<h3 id="6-3-1-HBase协处理器（扩展）"><a href="#6-3-1-HBase协处理器（扩展）" class="headerlink" title="6.3.1 HBase协处理器（扩展）"></a>6.3.1 HBase协处理器（扩展）</h3><ol>
<li>案例需求<br> 编写协处理器，实现在往A表插入数据的同时让HBase自身（协处理器）向B表中插入一条数据。</li>
<li>实现步骤<ol>
<li>创建一个maven项目，并引入以下依赖。 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">&lt;</span>dependencies<span class="operator">&gt;</span></span><br><span class="line">    <span class="operator">&lt;</span>dependency<span class="operator">&gt;</span></span><br><span class="line">        <span class="operator">&lt;</span>groupId<span class="operator">&gt;</span>org.apache.hbase<span class="operator">&lt;</span><span class="operator">/</span>groupId<span class="operator">&gt;</span></span><br><span class="line">        <span class="operator">&lt;</span>artifactId<span class="operator">&gt;</span>hbase<span class="operator">-</span>client<span class="operator">&lt;</span><span class="operator">/</span>artifactId<span class="operator">&gt;</span></span><br><span class="line">        <span class="operator">&lt;</span>version<span class="operator">&gt;</span><span class="number">2.2</span><span class="number">.4</span><span class="operator">&lt;</span><span class="operator">/</span>version<span class="operator">&gt;</span></span><br><span class="line">    <span class="operator">&lt;</span><span class="operator">/</span>dependency<span class="operator">&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="operator">&lt;</span>dependency<span class="operator">&gt;</span></span><br><span class="line">        <span class="operator">&lt;</span>groupId<span class="operator">&gt;</span>org.apache.hbase<span class="operator">&lt;</span><span class="operator">/</span>groupId<span class="operator">&gt;</span></span><br><span class="line">        <span class="operator">&lt;</span>artifactId<span class="operator">&gt;</span>hbase<span class="operator">-</span>server<span class="operator">&lt;</span><span class="operator">/</span>artifactId<span class="operator">&gt;</span></span><br><span class="line">        <span class="operator">&lt;</span>version<span class="operator">&gt;</span><span class="number">2.2</span><span class="number">.4</span><span class="operator">&lt;</span><span class="operator">/</span>version<span class="operator">&gt;</span></span><br><span class="line">    <span class="operator">&lt;</span><span class="operator">/</span>dependency<span class="operator">&gt;</span></span><br><span class="line"><span class="operator">&lt;</span><span class="operator">/</span>dependencies<span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>定义FruitTableCoprocessor类并继承BaseRegionObserver类 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FruitTableCoprocessor</span> <span class="keyword">extends</span> <span class="title">BaseRegionObserver</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">postPut</span><span class="params">(ObserverContext&lt;RegionCoprocessorEnvironment&gt; e, Put put, WALEdit edit, Durability durability)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取连接</span></span><br><span class="line">        Connection connection = ConnectionFactory.createConnection(HBaseConfiguration.create());</span><br><span class="line"></span><br><span class="line">        <span class="comment">//获取表对象</span></span><br><span class="line">        Table table = connection.getTable(TableName.valueOf(<span class="string">&quot;fruit&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">//插入数据</span></span><br><span class="line">        table.put(put);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//关闭资源</span></span><br><span class="line">        table.close();</span><br><span class="line">        connection.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h3 id="6-3-2-二级索引配置文件"><a href="#6-3-2-二级索引配置文件" class="headerlink" title="6.3.2 二级索引配置文件"></a>6.3.2 二级索引配置文件</h3><ul>
<li>添加如下配置到HBase的HRegionserver节点的hbase-site.xml  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- phoenix regionserver 配置参数--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.regionserver.wal.codec<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hbase.regionserver.wal.IndexedWALEditCodec<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.region.server.rpc.scheduler.factory.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hbase.ipc.PhoenixRpcSchedulerFactory<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Factory to create the Phoenix RPC Scheduler that uses separate queues for index and metadata updates<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rpc.controllerfactory.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hbase.ipc.controller.ServerRpcControllerFactory<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Factory to create the Phoenix RPC Scheduler that uses separate queues for index and metadata updates<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="6-3-3-全局二级索引"><a href="#6-3-3-全局二级索引" class="headerlink" title="6.3.3 全局二级索引"></a>6.3.3 全局二级索引</h3><ul>
<li><p>Global Index是默认的索引格式，创建全局索引时，会在HBase中建立一张新表。也就是说索引数据和数据表是存放在不同的表中的，因此<font color ='red' >全局索引适用于多读少写的业务场景</font>。</p>
</li>
<li><p>写数据的时候会消耗大量开销，因为索引表也要更新，而索引表是分布在不同的数据节点上的，跨节点的数据传输带来了较大的性能消耗。</p>
</li>
<li><p>在读数据的时候Phoenix会选择索引表来降低查询消耗的时间。</p>
</li>
<li><p>创建单个字段的全局索引</p>
  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> INDEX my_index <span class="keyword">ON</span> my_table (my_col);</span><br></pre></td></tr></table></figure>
<p>  <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16361817666391.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"><br>  <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16361818090972.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<blockquote>
<p><font color ='red' >如果想查询的字段不是索引字段的话索引表不会被使用，也就是说不会带来查询速度的提升。</font></p>
</blockquote>
<ol>
<li>联合索引 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:phoenix:thin:url<span class="operator">=</span>http:<span class="operator">/</span><span class="operator">/</span>localhost:<span class="number">876</span><span class="operator">&gt;</span> <span class="keyword">create</span> index IDX_STU_NAME_AGE_IN <span class="keyword">on</span> STUDENT(name) INCLUDE(age);</span><br><span class="line"><span class="number">6</span> <span class="keyword">rows</span> affected (<span class="number">5.78</span> seconds)</span><br></pre></td></tr></table></figure></li>
<li>INCLOUD <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:phoenix:thin:url<span class="operator">=</span>http:<span class="operator">/</span><span class="operator">/</span>localhost:<span class="number">876</span><span class="operator">&gt;</span> <span class="keyword">create</span> index IDX_STU_NAME_AGE_IN <span class="keyword">on</span> STUDENT(name) INCLUDE(age);</span><br><span class="line"><span class="number">6</span> <span class="keyword">rows</span> affected (<span class="number">5.78</span> seconds)</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ul>
<h3 id="6-3-4-本地二级索引"><a href="#6-3-4-本地二级索引" class="headerlink" title="6.3.4 本地二级索引"></a>6.3.4 本地二级索引</h3><p>Local Index适用于写操作频繁的场景。<br>索引数据和数据表的数据是存放在同一张表中（且是同一个Region），避免了在写操作的时候往不同服务器的索引表中写索引带来的额外开销。查询的字段不是索引字段索引表也会被使用，这会带来查询速度的提升。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">LOCAL</span> INDEX my_index <span class="keyword">ON</span> my_table (my_column);</span><br></pre></td></tr></table></figure>
<p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16361840708409.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<h1 id="第7章-与Hive的集成"><a href="#第7章-与Hive的集成" class="headerlink" title="第7章 与Hive的集成"></a>第7章 与Hive的集成</h1><h2 id="7-1-HBase与Hive的对比"><a href="#7-1-HBase与Hive的对比" class="headerlink" title="7.1 HBase与Hive的对比"></a>7.1 HBase与Hive的对比</h2><ol>
<li>Hive<ul>
<li>数仓工具<br>  Hive的本质其实就相当于将HDFS中已经存储的文件在Mysql中做了一个双射关系，以方便使用HQL去管理查询。</li>
<li>用于数据分析、清洗<br>  Hive适用于离线的数据分析和清洗，延迟较高。</li>
<li>基于HDFS、MapReduce<br>  Hive存储的数据依旧在DataNode上，编写的HQL语句终将是转换为MapReduce代码执行。</li>
</ul>
</li>
<li>HBase<ol>
<li>数据库<br> 是一种面向列族存储的非关系型数据库。</li>
<li>用于存储结构化和非结构化的数据<br> 适用于单表非关系型数据的存储，不适合做关联查询，类似JOIN等操作。</li>
<li>基于HDFS<br> 数据持久化存储的体现形式是HFile，存放于DataNode中，被ResionServer以region的形式进行管理。</li>
<li>延迟较低，接入在线业务使用<br> 面对大量的企业数据，HBase可以直线单表大量数据的存储，同时提供了高效的数据访问速度。</li>
</ol>
</li>
</ol>
<h2 id="7-2-HBase与Hive集成使用"><a href="#7-2-HBase与Hive集成使用" class="headerlink" title="7.2 HBase与Hive集成使用"></a>7.2 HBase与Hive集成使用</h2><ol>
<li><p>HBase没有计算分析能力，用Hive辅助分析</p>
</li>
<li><p>HBase扮演HDFS的角色，提供数据存储<br>在hive-site.xml中修改zookeeper的属性，如下：</p>
 <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102,hadoop103,hadoop104<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.zookeeper.client.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>建立Hive表，关联HBase表，插入数据到Hive表的同时能够影响HBase表。</p>
<ol>
<li>在Hive中创建表同时关联HBase <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> hive_hbase_emp_table(</span><br><span class="line">    empno    <span class="type">int</span>,</span><br><span class="line">    ename    string,</span><br><span class="line">    job      string,</span><br><span class="line">    mgr      <span class="type">int</span>,</span><br><span class="line">    hiredate string,</span><br><span class="line">    sal      <span class="keyword">double</span>,</span><br><span class="line">    comm     <span class="keyword">double</span>,</span><br><span class="line">    deptno   <span class="type">int</span></span><br><span class="line">)</span><br><span class="line">STORED <span class="keyword">BY</span> <span class="string">&#x27;org.apache.hadoop.hive.hbase.HBaseStorageHandler&#x27;</span></span><br><span class="line"><span class="keyword">WITH</span> SERDEPROPERTIES (&quot;hbase.columns.mapping&quot; <span class="operator">=</span> &quot;:key,info:ename,info:job,info:mgr,info:hiredate,info:sal,info:comm,info:deptno&quot;)</span><br><span class="line">TBLPROPERTIES (&quot;hbase.table.name&quot; <span class="operator">=</span> &quot;hbase_emp_table&quot;);</span><br></pre></td></tr></table></figure>
<blockquote>
<p>提示：完成之后，可以分别进入Hive和HBase查看，都生成了对应的表</p>
</blockquote>
</li>
<li>在Hive中导入数据到hive_hbase_emp_table <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> hive_hbase_emp_table</span><br><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> emp <span class="keyword">where</span> sal<span class="operator">&gt;</span><span class="number">3000</span>;</span><br></pre></td></tr></table></figure></li>
<li>查看Hive以及关联的HBase表中是否已经成功的同步插入了数据<ul>
<li>Hive：  <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> hive_hbase_emp_table;</span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------------------+-----------------------------+---------------------------+---------------------------+--------------------------------+---------------------------+----------------------------+------------------------------+</span></span><br><span class="line"><span class="operator">|</span> hive_hbase_emp_table.empno  <span class="operator">|</span> hive_hbase_emp_table.ename  <span class="operator">|</span> hive_hbase_emp_table.job  <span class="operator">|</span> hive_hbase_emp_table.mgr  <span class="operator">|</span> hive_hbase_emp_table.hiredate  <span class="operator">|</span> hive_hbase_emp_table.sal  <span class="operator">|</span> hive_hbase_emp_table.comm  <span class="operator">|</span> hive_hbase_emp_table.deptno  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------------------+-----------------------------+---------------------------+---------------------------+--------------------------------+---------------------------+----------------------------+------------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">7839</span>                        <span class="operator">|</span> KING                        <span class="operator">|</span> PRESIDENT                 <span class="operator">|</span> <span class="keyword">NULL</span>                      <span class="operator">|</span> <span class="number">1981</span><span class="number">-11</span><span class="number">-17</span>                     <span class="operator">|</span> <span class="number">5000.0</span>                    <span class="operator">|</span> <span class="keyword">NULL</span>                       <span class="operator">|</span> <span class="number">10</span>                           <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">-----------------------------+-----------------------------+---------------------------+---------------------------+--------------------------------+---------------------------+----------------------------+------------------------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> selected (<span class="number">0.237</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
<li>HBase：  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):010:0&gt; scan <span class="string">&#x27;hbase_emp_table&#x27;</span></span><br><span class="line">ROW                                           COLUMN+CELL</span><br><span class="line"> 7839                                         column=info:deptno, timestamp=1636185055717, value=10</span><br><span class="line"> 7839                                         column=info:ename, timestamp=1636185055717, value=KING</span><br><span class="line"> 7839                                         column=info:hiredate, timestamp=1636185055717, value=1981-11-17</span><br><span class="line"> 7839                                         column=info:job, timestamp=1636185055717, value=PRESIDENT</span><br><span class="line"> 7839                                         column=info:sal, timestamp=1636185055717, value=5000.0</span><br><span class="line">1 row(s)</span><br><span class="line">Took 0.0418 seconds</span><br><span class="line">hbase(main):011:0&gt;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>在HBase中已经存储了某一张表hbase_emp_table，然后在Hive中创建一个外部表来关联HBase中的hbase_emp_table这张表，使之可以借助Hive来分析HBase这张表中的数据。<ol>
<li>在Hive中创建外部表 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">EXTERNAL</span> <span class="keyword">TABLE</span> relevance_hbase_emp (</span><br><span class="line">    empno    <span class="type">int</span>,</span><br><span class="line">    ename    string,</span><br><span class="line">    job      string,</span><br><span class="line">    mgr      <span class="type">int</span>,</span><br><span class="line">    hiredate string,</span><br><span class="line">    sal      <span class="keyword">double</span>,</span><br><span class="line">    comm     <span class="keyword">double</span>,</span><br><span class="line">    deptno   <span class="type">int</span></span><br><span class="line">)</span><br><span class="line">STORED <span class="keyword">BY</span> <span class="string">&#x27;org.apache.hadoop.hive.hbase.HBaseStorageHandler&#x27;</span></span><br><span class="line"><span class="keyword">WITH</span> SERDEPROPERTIES (&quot;hbase.columns.mapping&quot; <span class="operator">=</span> &quot;:key,info:ename,info:job,info:mgr,info:hiredate,info:sal,info:comm,info:deptno&quot;)</span><br><span class="line">TBLPROPERTIES (&quot;hbase.table.name&quot; <span class="operator">=</span> &quot;hbase_emp_table&quot;);</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>关联后就可以使用Hive函数进行一些分析操作了 <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span> <span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> relevance_hbase_emp;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------+----------------------------+--------------------------+--------------------------+-------------------------------+--------------------------+---------------------------+-----------------------------+</span></span><br><span class="line"><span class="operator">|</span> relevance_hbase_emp.empno  <span class="operator">|</span> relevance_hbase_emp.ename  <span class="operator">|</span> relevance_hbase_emp.job  <span class="operator">|</span> relevance_hbase_emp.mgr  <span class="operator">|</span> relevance_hbase_emp.hiredate  <span class="operator">|</span> relevance_hbase_emp.sal  <span class="operator">|</span> relevance_hbase_emp.comm  <span class="operator">|</span> relevance_hbase_emp.deptno  <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------+----------------------------+--------------------------+--------------------------+-------------------------------+--------------------------+---------------------------+-----------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="number">7839</span>                       <span class="operator">|</span> KING                       <span class="operator">|</span> PRESIDENT                <span class="operator">|</span> <span class="keyword">NULL</span>                     <span class="operator">|</span> <span class="number">1981</span><span class="number">-11</span><span class="number">-17</span>                    <span class="operator">|</span> <span class="number">5000.0</span>                   <span class="operator">|</span> <span class="keyword">NULL</span>                      <span class="operator">|</span> <span class="number">10</span>                          <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------+----------------------------+--------------------------+--------------------------+-------------------------------+--------------------------+---------------------------+-----------------------------+</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span> selected (<span class="number">0.248</span> seconds)</span><br><span class="line"><span class="number">0</span>: jdbc:hive2:<span class="operator">/</span><span class="operator">/</span>hadoop001:<span class="number">10000</span><span class="operator">&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
</li>
</ol>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/HBase/" rel="tag">HBase</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Phoenix/" rel="tag">Phoenix</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" rel="tag">数据库</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-Flume"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/11/07/Flume/"
    >Flume</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/11/07/Flume/" class="article-date">
  <time datetime="2021-11-07T00:08:28.000Z" itemprop="datePublished">2021-11-07</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/">数据采集</a>
  </div>
   
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="Flume"><a href="#Flume" class="headerlink" title="Flume"></a>Flume</h1><h1 id="一、Flume-概述"><a href="#一、Flume-概述" class="headerlink" title="一、Flume 概述"></a>一、Flume 概述</h1><h2 id="1-1-Flume-定义"><a href="#1-1-Flume-定义" class="headerlink" title="1.1 Flume 定义"></a>1.1 Flume 定义</h2><ul>
<li>Flume 是 Cloudera 提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传<br>输的系统。Flume 基于流式架构，灵活简单。<br>  <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16357485584074.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
</ul>
<h2 id="1-2-Flume-基础架构"><a href="#1-2-Flume-基础架构" class="headerlink" title="1.2 Flume 基础架构"></a>1.2 Flume 基础架构</h2><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16357485788013.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<h3 id="1-2-1-Agent"><a href="#1-2-1-Agent" class="headerlink" title="1.2.1 Agent"></a>1.2.1 Agent</h3><ul>
<li>Agent 是一个 JVM 进程，它以事件的形式将数据从源头送至目的。</li>
<li>Agent 主要有 3 个部分组成，Source、Channel、Sink。<h3 id="1-2-2-Source"><a href="#1-2-2-Source" class="headerlink" title="1.2.2 Source"></a>1.2.2 Source</h3></li>
<li>Source 是负责接收数据到 Flume Agent 的组件。Source 组件可以处理各种类型、各种格式的日志数据，包括 avro、thrift、exec、jms、spooling directory、netcat、taildir、sequence generator、syslog、http、legacy。<h3 id="1-2-3-Sink"><a href="#1-2-3-Sink" class="headerlink" title="1.2.3 Sink"></a>1.2.3 Sink</h3></li>
<li>Sink 不断地轮询 Channel 中的事件且批量地移除它们，并将这些事件批量写入到存储<br>或索引系统、或者被发送到另一个 Flume Agent。</li>
<li>Sink 组件目的地包括 hdfs、logger、avro、thrift、ipc、file、HBase、solr、自定义。<h3 id="1-2-4-Channel"><a href="#1-2-4-Channel" class="headerlink" title="1.2.4 Channel"></a>1.2.4 Channel</h3></li>
<li>Channel 是位于 Source 和 Sink 之间的缓冲区。因此，Channel 允许 Source 和 Sink 运作在不同的速率上。Channel 是线程安全的，可以同时处理几个 Source 的写入操作和几个</li>
<li>Sink 的读取操作。<ul>
<li>Flume 自带两种 Channel：Memory Channel 和 File Channel。<ul>
<li>Memory Channel 是内存中的队列。Memory Channel 在不需要关心数据丢失的情景下适用。如果需要关心数据丢失，那么 Memory Channel 就不应该使用，因为程序死亡、机器宕机或者重启都会导致数据丢失。</li>
<li>File Channel 将所有事件写到磁盘。因此在程序关闭或机器宕机的情况下不会丢失数据。<h3 id="1-2-5-Event"><a href="#1-2-5-Event" class="headerlink" title="1.2.5 Event"></a>1.2.5 Event</h3></li>
</ul>
</li>
</ul>
</li>
<li>传输单元，Flume 数据传输的基本单元，以 Event 的形式将数据从源头送至目的地。Event 由 Header 和 Body 两部分组成，Header 用来存放该 event 的一些属性，为 K-V 结构，</li>
<li>Body 用来存放该条数据，形式为字节数组。<br><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16357486063296.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
</ul>
<h1 id="二、Flume入门"><a href="#二、Flume入门" class="headerlink" title="二、Flume入门"></a>二、Flume入门</h1><h2 id="2-1-Flume安装部署"><a href="#2-1-Flume安装部署" class="headerlink" title="2.1 Flume安装部署"></a>2.1 Flume安装部署</h2><h3 id="2-1-1-安装地址"><a href="#2-1-1-安装地址" class="headerlink" title="2.1.1 安装地址"></a>2.1.1 安装地址</h3><ol>
<li>Flume官网地址：<a target="_blank" rel="noopener" href="http://flume.apache.org/">http://flume.apache.org/</a></li>
<li>文档查看地址：<a target="_blank" rel="noopener" href="http://flume.apache.org/FlumeUserGuide.html">http://flume.apache.org/FlumeUserGuide.html</a></li>
<li>下载地址：<a target="_blank" rel="noopener" href="http://archive.apache.org/dist/flume/">http://archive.apache.org/dist/flume/</a><h3 id="2-1-2-安装部署"><a href="#2-1-2-安装部署" class="headerlink" title="2.1.2 安装部署"></a>2.1.2 安装部署</h3></li>
<li>将apache-flume-1.9.0-bin.tar.gz上传到linux的/opt/software目录下</li>
<li>解压apache-flume-1.9.0-bin.tar.gz到/opt/module/目录下 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 software]$ tar -zxf /opt/software/apache-flume-1.9.0-bin.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure></li>
<li>修改apache-flume-1.9.0-bin的名称为flume <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 module]$ mv /opt/module/apache-flume-1.9.0-bin /opt/module/flume</span><br></pre></td></tr></table></figure></li>
<li>将lib文件夹下的guava-11.0.2.jar删除以兼容Hadoop 3.1.3 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 lib]$  rm /opt/module/flume/lib/guava-11.0.2.jar</span><br></pre></td></tr></table></figure></li>
<li>环境变量 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#FLUME_HOME</span></span><br><span class="line"><span class="built_in">export</span> FLUME_HOME=/opt/module/flume-1.9.0</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$FLUME_HOME</span>/bin</span><br></pre></td></tr></table></figure>
<h3 id="2-1-3-连接HDFS集群"><a href="#2-1-3-连接HDFS集群" class="headerlink" title="2.1.3 连接HDFS集群"></a>2.1.3 连接HDFS集群</h3></li>
<li>使用场景：应用服务器部署FLume Agent采集应用运行日志，上送到Flume Server，由FlumeServer存储到HDFS集群<br> <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16359837253952.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>配置步骤<ol>
<li>复制Hadoop集群的hdfs-site.xml、core-site.xml两个配置到$FLUME_HOME/conf目录 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp <span class="variable">$HADOOP_HOME</span>/etc/hadoop/core-site.xml atguigu@datax:/opt/module/flume-1.9.0/conf</span><br><span class="line"></span><br><span class="line">scp <span class="variable">$HADOOP_HOME</span>/etc/hadoop/hdfs-site.xml atguigu@datax:/opt/module/flume-1.9.0/conf</span><br></pre></td></tr></table></figure></li>
<li>复制hadoop-common-3.1.3.jar到$FLUME_HOME/lib目录 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp <span class="variable">$HADOOP_HOME</span>/share/hadoop/common/hadoop-common-3.1.3.jar atguigu@datax:/opt/module/flume-1.9.0/lib</span><br></pre></td></tr></table></figure></li>
<li>复制Hadoop common依赖包到$FLUME_HOME/lib目录 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp <span class="variable">$HADOOP_HOME</span>/share/hadoop/common/lib/*.jar atguigu@datax:/opt/module/flume-1.9.0/lib</span><br></pre></td></tr></table></figure></li>
<li>复制<code>$HADOOP_HOME/share/hadoop/hdfs/*.jar</code>到$FLUME_HOME/lib目录 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp <span class="variable">$HADOOP_HOME</span>/share/hadoop/hdfs/*.jar atguigu@datax:/opt/module/flume-1.9.0/lib</span><br></pre></td></tr></table></figure></li>
<li>准备配置 a1.conf <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Name the components on this agent</span></span><br><span class="line"><span class="comment"># a1:表示agent的名称</span></span><br><span class="line"><span class="comment"># r1:表示a1的Source的名称</span></span><br><span class="line"><span class="attr">a1.sources</span> = r1</span><br><span class="line"><span class="comment"># k1:表示a1的Sink的名称</span></span><br><span class="line"><span class="attr">a1.sinks</span> = k1</span><br><span class="line"><span class="comment"># c1:表示a1的Channel的名称</span></span><br><span class="line"><span class="attr">a1.channels</span> = c1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe/configure the source</span></span><br><span class="line"><span class="comment"># 表示a1的输入源类型为netcat端口类型</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = netcat</span><br><span class="line"><span class="comment"># 表示a1的监听的主机</span></span><br><span class="line"><span class="attr">a1.sources.r1.bind</span> = <span class="number">0.0</span>.<span class="number">0.0</span></span><br><span class="line"><span class="comment"># 表示a1的监听的端口号</span></span><br><span class="line"><span class="attr">a1.sources.r1.port</span> = <span class="number">44444</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe the sink</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = hdfs</span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.path</span> = hdfs://mycluster/flume/%Y%m%d/%H</span><br><span class="line"><span class="comment">#上传文件的前缀</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.filePrefix</span> = logs-</span><br><span class="line"><span class="comment">#是否按照时间滚动文件夹</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.round</span> = <span class="literal">true</span></span><br><span class="line"><span class="comment">#多少时间单位创建一个新的文件夹</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.roundValue</span> = <span class="number">1</span></span><br><span class="line"><span class="comment">#重新定义时间单位</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.roundUnit</span> = hour</span><br><span class="line"><span class="comment">#是否使用本地时间戳</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.useLocalTimeStamp</span> = <span class="literal">true</span></span><br><span class="line"><span class="comment">#积攒多少个Event才flush到HDFS一次</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.batchSize</span> = <span class="number">100</span></span><br><span class="line"><span class="comment">#设置文件类型，可支持压缩</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.fileType</span> = DataStream</span><br><span class="line"><span class="comment">#多久生成一个新的文件</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollInterval</span> = <span class="number">60</span></span><br><span class="line"><span class="comment">#设置每个文件的滚动大小</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollSize</span> = <span class="number">134217700</span></span><br><span class="line"><span class="comment">#文件的滚动与Event数量无关</span></span><br><span class="line"><span class="attr">a1.sinks.k1.hdfs.rollCount</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Use a channel which buffers events in memory</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="number">1000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Bind the source and sink to the channel</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = c1</span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = c1</span><br></pre></td></tr></table></figure></li>
<li>启动Flume <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flume-ng agent -c <span class="variable">$FLUME_HOME</span>/conf -f <span class="variable">$FLUME_HOME</span>/conf/<span class="built_in">jobs</span>/a1.conf -n a1 -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure></li>
<li>打开nc测试，检查HDFS文件</li>
</ol>
</li>
<li>异常记录<ol>
<li><code>java.lang.NoClassDefFoundError</code>类型的异常为缺少jar包导致<ul>
<li>解决方案：复制hadoop-common-3.1.3.jar到$FLUME_HOME/lib目录</li>
</ul>
</li>
<li><code>java.lang.NoSuchMethodError</code>类型异常为jar包冲突导致<ul>
<li>解决方案：相同jar包保留一个版本，具体保留那个需要测试是否存在兼容性问题，优先保留Flume原生依赖jar</li>
</ul>
</li>
<li><code>No FileSystem for scheme &quot;hdfs&quot;</code>异常 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">2021-11-04 10:32:45,923 (SinkRunner-PollingRunner-DefaultSinkProcessor) [WARN - org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:454)] HDFS IO error</span><br><span class="line">org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme &quot;hdfs&quot;</span><br><span class="line">	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3281)</span><br><span class="line">	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3301)</span><br><span class="line">	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:124)</span><br><span class="line">	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3352)</span><br><span class="line">	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3320)</span><br><span class="line">	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:479)</span><br><span class="line">	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:361)</span><br><span class="line">	at org.apache.flume.sink.hdfs.BucketWriter$1.call(BucketWriter.java:255)</span><br><span class="line">	at org.apache.flume.sink.hdfs.BucketWriter$1.call(BucketWriter.java:247)</span><br><span class="line">	at org.apache.flume.sink.hdfs.BucketWriter$8$1.run(BucketWriter.java:727)</span><br><span class="line">	at org.apache.flume.auth.SimpleAuthenticator.execute(SimpleAuthenticator.java:50)</span><br><span class="line">	at org.apache.flume.sink.hdfs.BucketWriter$8.call(BucketWriter.java:724)</span><br><span class="line">	at java.util.concurrent.FutureTask.run(FutureTask.java:266)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:748)</span><br></pre></td></tr></table></figure>
<ul>
<li>解决方案：复制<code>$HADOOP_HOME/share/hadoop/hdfs/*.jar</code>到$FLUME_HOME/lib目录  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp <span class="variable">$HADOOP_HOME</span>/share/hadoop/hdfs/*.jar atguigu@datax:/opt/module/flume-1.9.0/lib</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><code>java.net.UnknownHostException: mycluster</code> 找不到mycluster<ul>
<li>解决方案：复制Hadoop集群的hdfs-site.xml、core-site.xml两个配置到$FLUME_HOME/conf目录  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 ha-hadoop-3.1.3]$ scp <span class="variable">$HADOOP_HOME</span>/etc/hadoop/core-site.xml atguigu@datax:/opt/module/flume-1.9.0/conf</span><br><span class="line"></span><br><span class="line">[atguigu@hadoop001 ha-hadoop-3.1.3]$ scp <span class="variable">$HADOOP_HOME</span>/etc/hadoop/hdfs-site.xml atguigu@datax:/opt/module/flume-1.9.0/conf</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><code>org.apache.hadoop.security.AccessControlException: Permission denied:</code> HDFS 权限不足，换用户 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chown -R atguigu:atguigu flume-1.9.0/</span><br><span class="line">use atguigu</span><br></pre></td></tr></table></figure>
<h2 id="2-2-Flume入门案例"><a href="#2-2-Flume入门案例" class="headerlink" title="2.2 Flume入门案例"></a>2.2 Flume入门案例</h2><h3 id="2-2-1-监控端口数据官方案例"><a href="#2-2-1-监控端口数据官方案例" class="headerlink" title="2.2.1 监控端口数据官方案例"></a>2.2.1 监控端口数据官方案例</h3></li>
</ol>
</li>
<li>案例需求：<ul>
<li>使用Flume监听一个端口，收集该端口数据，并打印到控制台。 </li>
</ul>
</li>
<li>需求分析：<br> <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16357500185897.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>实现步骤：<ol>
<li>安装netcat工具 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 module]$ sudo yum -y install nc</span><br></pre></td></tr></table></figure>
<ul>
<li>测试  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开启端口</span></span><br><span class="line">[atguigu@hadoop001 ~]$ nc -l localhost 6666</span><br><span class="line">asdf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试连通</span></span><br><span class="line">[atguigu@hadoop001 ~]$ nc localhost 6666</span><br><span class="line">asdf</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>判断44444端口是否被占用 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 flume-telnet]$ sudo netstat -nlp | grep 44444</span><br></pre></td></tr></table></figure></li>
<li>在flume目录下创建job文件夹并进入job文件夹。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 flume]$ mkdir job</span><br><span class="line">[atguigu@hadoop102 flume]$ <span class="built_in">cd</span> job/</span><br></pre></td></tr></table></figure></li>
<li>在job文件夹下创建Flume Agent配置文件flume-netcat-logger.conf。添加内容如下： <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Name the components on this agent</span></span><br><span class="line"><span class="comment"># a1:表示agent的名称</span></span><br><span class="line"><span class="comment"># r1:表示a1的Source的名称</span></span><br><span class="line"><span class="attr">a1.sources</span> = r1</span><br><span class="line"><span class="comment"># k1:表示a1的Sink的名称</span></span><br><span class="line"><span class="attr">a1.sinks</span> = k1</span><br><span class="line"><span class="comment"># c1:表示a1的Channel的名称</span></span><br><span class="line"><span class="attr">a1.channels</span> = c1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe/configure the source</span></span><br><span class="line"><span class="comment"># 表示a1的输入源类型为netcat端口类型</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = netcat</span><br><span class="line"><span class="comment"># 表示a1的监听的主机</span></span><br><span class="line"><span class="attr">a1.sources.r1.bind</span> = localhost</span><br><span class="line"><span class="comment"># 表示a1的监听的端口号</span></span><br><span class="line"><span class="attr">a1.sources.r1.port</span> = <span class="number">44444</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe the sink</span></span><br><span class="line"><span class="comment"># 表示a1的输出目的地是控制台logger类型</span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = logger</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use a channel which buffers events in memory</span></span><br><span class="line"><span class="comment"># 表示a1的channel类型是memory内存型</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = memory</span><br><span class="line"><span class="comment"># 表示a1的channel总容量1000个event</span></span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="number">1000</span></span><br><span class="line"><span class="comment"># 表示a1的channel传输时收集到了100条event以后再去提交事务</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Bind the source and sink to the channel</span></span><br><span class="line"><span class="comment"># 表示将r1和c1连接起来</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = c1</span><br><span class="line"><span class="comment"># 表示将k1和c1连接起来</span></span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = c1</span><br></pre></td></tr></table></figure></li>
<li>先开启flume监听端口<ul>
<li>第一种写法：  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 flume]$ bin/flume-ng agent --conf conf/ --name a1 --conf-file job/flume-netcat-logger.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure></li>
<li>第二种写法：  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop102 flume]$ bin/flume-ng agent -c conf/ -n a1 -f job/flume-netcat-logger.conf -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>
<ul>
<li>参数说明：<ul>
<li>–conf/-c：表示配置文件存储在conf/目录</li>
<li>–name/-n：表示给agent起名为a1</li>
<li>–conf-file/-f：flume本次启动读取的配置文件是在job文件夹下的flume-telnet.conf文件。</li>
<li>-Dflume.root.logger=INFO,console ：-D表示flume运行时动态修改flume.root.logger参数属性值，并将控制台日志打印级别设置为INFO级别。日志级别包括:log、info、warn、error。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
</li>
</ol>
<pre><code>7. 使用netcat工具向本机的44444端口发送内容
    <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 ~]$ nc localhost 44444</span><br><span class="line">hello</span><br><span class="line">OK</span><br><span class="line">atguigu</span><br><span class="line">OK</span><br><span class="line">123</span><br><span class="line">OK</span><br></pre></td></tr></table></figure>
8. 在Flume监听页面观察接收数据情况
    <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2021-11-01 16:15:15,418 INFO  [lifecycleSupervisor-1-1] source.NetcatSource (NetcatSource.java:start(166)) - Created serverSocket:sun.nio.ch.ServerSocketChannelImpl[/127.0.0.1:44444]</span><br><span class="line">2021-11-01 16:15:47,687 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] sink.LoggerSink (LoggerSink.java:process(95)) - Event: &#123; headers:&#123;&#125; body: 68 65 6C 6C 6F                                  hello &#125;</span><br><span class="line">2021-11-01 16:15:51,920 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] sink.LoggerSink (LoggerSink.java:process(95)) - Event: &#123; headers:&#123;&#125; body: 61 74 67 75 69 67 75                            atguigu &#125;</span><br><span class="line">2021-11-01 16:15:53,944 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] sink.LoggerSink (LoggerSink.java:process(95)) - Event: &#123; headers:&#123;&#125; body: 31 32 33                                        123 &#125;</span><br></pre></td></tr></table></figure>
</code></pre>
<h3 id="2-2-2-实时监控单个追加文件"><a href="#2-2-2-实时监控单个追加文件" class="headerlink" title="2.2.2 实时监控单个追加文件"></a>2.2.2 实时监控单个追加文件</h3><ol>
<li>案例需求：实时监控Hive日志，并上传到HDFS中</li>
<li>需求分析：<br> <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16357546764719.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>实现步骤：<ol>
<li>Flume要想将数据输出到HDFS，依赖Hadoop相关jar包。确认Hadoop和Java环境变量配置正确 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#JAVA_HOME</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_212</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br><span class="line"></span><br><span class="line"><span class="comment">#HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/opt/module/ha-hadoop-3.1.3</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/sbin</span><br></pre></td></tr></table></figure></li>
<li>创建flume-file-hdfs.conf文件<ul>
<li>注：要想读取Linux系统中的文件，就得按照Linux命令的规则执行命令。由于Hive日志在Linux系统中所以读取文件的类型选择：exec即execute执行的意思。表示执行Linux命令来读取文件。  <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Name the components on this agent</span></span><br><span class="line"><span class="attr">a2.sources</span> = r2</span><br><span class="line"><span class="attr">a2.sinks</span> = k2</span><br><span class="line"><span class="attr">a2.channels</span> = c2</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe/configure the source</span></span><br><span class="line"><span class="attr">a2.sources.r2.type</span> = exec</span><br><span class="line"><span class="attr">a2.sources.r2.command</span> = tail -f /opt/module/hive/logs/hive.log</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe the sink</span></span><br><span class="line"><span class="attr">a2.sinks.k2.type</span> = hdfs</span><br><span class="line"><span class="attr">a2.sinks.k2.hdfs.path</span> = hdfs://hadoop001:<span class="number">8020</span>/flume/%Y%m%d/%H</span><br><span class="line"><span class="comment">#上传文件的前缀</span></span><br><span class="line"><span class="attr">a2.sinks.k2.hdfs.filePrefix</span> = logs-</span><br><span class="line"><span class="comment">#是否按照时间滚动文件夹</span></span><br><span class="line"><span class="attr">a2.sinks.k2.hdfs.round</span> = <span class="literal">true</span></span><br><span class="line"><span class="comment">#多少时间单位创建一个新的文件夹</span></span><br><span class="line"><span class="attr">a2.sinks.k2.hdfs.roundValue</span> = <span class="number">1</span></span><br><span class="line"><span class="comment">#重新定义时间单位</span></span><br><span class="line"><span class="attr">a2.sinks.k2.hdfs.roundUnit</span> = hour</span><br><span class="line"><span class="comment">#是否使用本地时间戳</span></span><br><span class="line"><span class="attr">a2.sinks.k2.hdfs.useLocalTimeStamp</span> = <span class="literal">true</span></span><br><span class="line"><span class="comment">#积攒多少个Event才flush到HDFS一次</span></span><br><span class="line"><span class="attr">a2.sinks.k2.hdfs.batchSize</span> = <span class="number">100</span></span><br><span class="line"><span class="comment">#设置文件类型，可支持压缩</span></span><br><span class="line"><span class="attr">a2.sinks.k2.hdfs.fileType</span> = DataStream</span><br><span class="line"><span class="comment">#多久生成一个新的文件</span></span><br><span class="line"><span class="attr">a2.sinks.k2.hdfs.rollInterval</span> = <span class="number">60</span></span><br><span class="line"><span class="comment">#设置每个文件的滚动大小</span></span><br><span class="line"><span class="attr">a2.sinks.k2.hdfs.rollSize</span> = <span class="number">134217700</span></span><br><span class="line"><span class="comment">#文件的滚动与Event数量无关</span></span><br><span class="line"><span class="attr">a2.sinks.k2.hdfs.rollCount</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Use a channel which buffers events in memory</span></span><br><span class="line"><span class="attr">a2.channels.c2.type</span> = memory</span><br><span class="line"><span class="attr">a2.channels.c2.capacity</span> = <span class="number">1000</span></span><br><span class="line"><span class="attr">a2.channels.c2.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Bind the source and sink to the channel</span></span><br><span class="line"><span class="attr">a2.sources.r2.channels</span> = c2</span><br><span class="line"><span class="attr">a2.sinks.k2.channel</span> = c2</span><br></pre></td></tr></table></figure></li>
<li>注意: 对于所有与时间相关的转义序列，Event Header中必须存在以 “timestamp”的key（除非hdfs.useLocalTimeStamp设置为true，此方法会使用TimestampInterceptor自动添加timestamp）。a3.sinks.k3.hdfs.useLocalTimeStamp = true</li>
</ul>
</li>
<li>运行Flume <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flume-ng agent --conf conf/ --name a2 --conf-file flume-file-hdfs.conf</span><br></pre></td></tr></table></figure></li>
<li>在HDFS上查看文件。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 job]$ hadoop fs -ls /flume/20211101/16</span><br><span class="line">Found 2 items</span><br><span class="line">-rw-r--r--   3 atguigu supergroup      79991 2021-11-01 16:48 /flume/20211101/16/logs-.1635756437252</span><br><span class="line">-rw-r--r--   3 atguigu supergroup       5037 2021-11-01 16:49 /flume/20211101/16/logs-.1635756498528</span><br><span class="line">[atguigu@hadoop001 job]$</span><br></pre></td></tr></table></figure>
<h3 id="2-2-3-实时监控目录下多个新文件"><a href="#2-2-3-实时监控目录下多个新文件" class="headerlink" title="2.2.3 实时监控目录下多个新文件"></a>2.2.3 实时监控目录下多个新文件</h3>1）案例需求：使用Flume监听整个目录的文件，并上传至HDFS<br>2）需求分析：</li>
</ol>
</li>
</ol>
<h3 id="2-2-4-实时监控目录下的多个追加文件"><a href="#2-2-4-实时监控目录下的多个追加文件" class="headerlink" title="2.2.4 实时监控目录下的多个追加文件"></a>2.2.4 实时监控目录下的多个追加文件</h3><ul>
<li>Exec source适用于监控一个实时追加的文件，不能实现断点续传；</li>
<li>Spooldir Source适合用于同步新文件，但不适合对实时追加日志的文件进行监听并同步；</li>
<li>Taildir Source适合用于监听多个实时追加的文件，并且能够实现断点续传。</li>
</ul>
<ol>
<li>案例需求:使用Flume监听整个目录的实时追加文件，并上传至HDFS</li>
<li>需求分析:<br> <img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16357594199633.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></li>
<li>实现步骤：<ol>
<li>创建配置文件flume-taildir-hdfs.conf, 添加如下内容 <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">a3.sources</span> = r3</span><br><span class="line"><span class="attr">a3.sinks</span> = k3</span><br><span class="line"><span class="attr">a3.channels</span> = c3</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe/configure the source</span></span><br><span class="line"><span class="attr">a3.sources.r3.type</span> = TAILDIR</span><br><span class="line"><span class="attr">a3.sources.r3.positionFile</span> = /opt/module/flume/tail_dir.json</span><br><span class="line"><span class="attr">a3.sources.r3.filegroups</span> = f1 f2</span><br><span class="line"><span class="attr">a3.sources.r3.filegroups.f1</span> = /opt/module/flume/files/.*file.*</span><br><span class="line"><span class="attr">a3.sources.r3.filegroups.f2</span> = /opt/module/flume/files2/.*log.*</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe the sink</span></span><br><span class="line"><span class="attr">a3.sinks.k3.type</span> = hdfs</span><br><span class="line"><span class="attr">a3.sinks.k3.hdfs.path</span> = hdfs://hadoop001:<span class="number">8020</span>/flume/TAILDIR/%Y%m%d/%H</span><br><span class="line"><span class="comment">#上传文件的前缀</span></span><br><span class="line"><span class="attr">a3.sinks.k3.hdfs.filePrefix</span> = upload-</span><br><span class="line"><span class="comment">#是否按照时间滚动文件夹</span></span><br><span class="line"><span class="attr">a3.sinks.k3.hdfs.round</span> = <span class="literal">true</span></span><br><span class="line"><span class="comment">#多少时间单位创建一个新的文件夹</span></span><br><span class="line"><span class="attr">a3.sinks.k3.hdfs.roundValue</span> = <span class="number">1</span></span><br><span class="line"><span class="comment">#重新定义时间单位</span></span><br><span class="line"><span class="attr">a3.sinks.k3.hdfs.roundUnit</span> = hour</span><br><span class="line"><span class="comment">#是否使用本地时间戳</span></span><br><span class="line"><span class="attr">a3.sinks.k3.hdfs.useLocalTimeStamp</span> = <span class="literal">true</span></span><br><span class="line"><span class="comment">#积攒多少个Event才flush到HDFS一次</span></span><br><span class="line"><span class="attr">a3.sinks.k3.hdfs.batchSize</span> = <span class="number">100</span></span><br><span class="line"><span class="comment">#设置文件类型，可支持压缩</span></span><br><span class="line"><span class="attr">a3.sinks.k3.hdfs.fileType</span> = DataStream</span><br><span class="line"><span class="comment">#多久生成一个新的文件</span></span><br><span class="line"><span class="attr">a3.sinks.k3.hdfs.rollInterval</span> = <span class="number">60</span></span><br><span class="line"><span class="comment">#设置每个文件的滚动大小大概是128M</span></span><br><span class="line"><span class="attr">a3.sinks.k3.hdfs.rollSize</span> = <span class="number">134217700</span></span><br><span class="line"><span class="comment">#文件的滚动与Event数量无关</span></span><br><span class="line"><span class="attr">a3.sinks.k3.hdfs.rollCount</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Use a channel which buffers events in memory</span></span><br><span class="line"><span class="attr">a3.channels.c3.type</span> = memory</span><br><span class="line"><span class="attr">a3.channels.c3.capacity</span> = <span class="number">1000</span></span><br><span class="line"><span class="attr">a3.channels.c3.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Bind the source and sink to the channel</span></span><br><span class="line"><span class="attr">a3.sources.r3.channels</span> = c3</span><br><span class="line"><span class="attr">a3.sinks.k3.channel</span> = c3</span><br></pre></td></tr></table></figure></li>
<li>运行Flume, 监控文件夹 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">flume-ng agent --conf conf/ --name a3 --conf-file job/flume-taildir-hdfs.conf</span><br></pre></td></tr></table></figure></li>
<li>查看HDFS上的数据 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 logs]$ hadoop fs -ls /flume/TAILDIR/20211101/18</span><br><span class="line">Found 1 items</span><br><span class="line">-rw-r--r--   3 atguigu supergroup   77439185 2021-11-01 18:05 /flume/TAILDIR/20211101/18/upload-.1635761078949</span><br><span class="line">[atguigu@hadoop001 logs]$</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li>Taildir说明：<ul>
<li>Taildir Source维护了一个json格式的position File，其会定期的往position File中更新每个文件读取到的最新的位置，因此能够实现断点续传。Position File的格式如下：  <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">&quot;inode&quot;</span>:<span class="number">2496272</span>,<span class="attr">&quot;pos&quot;</span>:<span class="number">12</span>,<span class="attr">&quot;file&quot;</span>:<span class="string">&quot;/opt/module/flume/files/file1.txt&quot;</span>&#125;</span><br><span class="line">&#123;<span class="attr">&quot;inode&quot;</span>:<span class="number">2496275</span>,<span class="attr">&quot;pos&quot;</span>:<span class="number">12</span>,<span class="attr">&quot;file&quot;</span>:<span class="string">&quot;/opt/module/flume/files/file2.txt&quot;</span>&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>注：Linux中储存文件元数据的区域就叫做inode，每个inode都有一个号码，操作系统用inode号码来识别不同的文件，Unix/Linux系统内部不使用文件名，而使用inode号码来识别文件。</li>
</ul>
</li>
</ol>
<h1 id="三、Flume进阶"><a href="#三、Flume进阶" class="headerlink" title="三、Flume进阶"></a>三、Flume进阶</h1><h2 id="3-1-Flume事务"><a href="#3-1-Flume事务" class="headerlink" title="3.1 Flume事务"></a>3.1 Flume事务</h2><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16358198414212.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ol>
<li>Put事务流程<ul>
<li>doPut:将批数据先写入临时缓冲区putList</li>
<li>doCommit:检查channel内存队列是否足够合并。</li>
<li>doRollback:channel内存队列空间不足，回滚数据</li>
</ul>
</li>
<li>Take事务<ul>
<li>doTake:将数据取到临时缓冲区takeList，并将数据发送到HDFS</li>
<li>doCommit:如果数据全部发送成功，则清除临时缓冲区takeList</li>
<li>doRollback:数据发送过程中如果出现异常，rollback将临时缓冲区takeList中的数据归还给channel内存队列。</li>
</ul>
</li>
</ol>
<h2 id="3-2-Flume-Agent内部原理"><a href="#3-2-Flume-Agent内部原理" class="headerlink" title="3.2 Flume Agent内部原理"></a>3.2 Flume Agent内部原理</h2><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16358207311935.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ol>
<li>ChannelSelector<ul>
<li>ChannelSelector的作用就是选出Event将要被发往哪个Channel。其共有两种类型，分别是Replicating（复制）和Multiplexing（多路复用）。</li>
<li>ReplicatingSelector会将同一个Event发往所有的Channel，Multiplexing会根据相应的原则，将不同的Event发往不同的Channel。</li>
</ul>
</li>
<li>SinkProcessor<ul>
<li>SinkProcessor共有三种类型，分别是DefaultSinkProcessor、LoadBalancingSinkProcessor和FailoverSinkProcessor</li>
<li>DefaultSinkProcessor对应的是单个的Sink，LoadBalancingSinkProcessor和FailoverSinkProcessor对应的是Sink Group，LoadBalancingSinkProcessor可以实现负载均衡的功能，FailoverSinkProcessor可以错误恢复的功能。</li>
</ul>
</li>
</ol>
<h2 id="3-3-Flume拓扑结构"><a href="#3-3-Flume拓扑结构" class="headerlink" title="3.3 Flume拓扑结构"></a>3.3 Flume拓扑结构</h2><h3 id="3-3-1-简单串联"><a href="#3-3-1-简单串联" class="headerlink" title="3.3.1 简单串联"></a>3.3.1 简单串联</h3><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16359417802480.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"><br>这种模式是将多个flume顺序连接起来了，从最初的source开始到最终sink传送的目的存储系统。此模式不建议桥接过多的flume数量， flume数量过多不仅会影响传输速率，而且一旦传输过程中某个节点flume宕机，会影响整个传输系统。</p>
<h3 id="3-3-2-复制和多路复用"><a href="#3-3-2-复制和多路复用" class="headerlink" title="3.3.2 复制和多路复用"></a>3.3.2 复制和多路复用</h3><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16359418050492.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"><br>Flume支持将事件流向一个或者多个目的地。这种模式可以将相同数据复制到多个channel中，或者将不同数据分发到不同的channel中，sink可以选择传送到不同的目的地。</p>
<h3 id="3-3-3-负载均衡和故障转移"><a href="#3-3-3-负载均衡和故障转移" class="headerlink" title="3.3.3 负载均衡和故障转移"></a>3.3.3 负载均衡和故障转移</h3><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16359418259918.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"><br>Flume支持使用将多个sink逻辑上分到一个sink组，sink组配合不同的SinkProcessor可以实现负载均衡和错误恢复的功能。</p>
<h3 id="3-3-4-聚合"><a href="#3-3-4-聚合" class="headerlink" title="3.3.4 聚合"></a>3.3.4 聚合</h3><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16359418605656.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"><br>这种模式是我们最常见的，也非常实用，日常web应用通常分布在上百个服务器，大者甚至上千个、上万个服务器。产生的日志，处理起来也非常麻烦。用flume的这种组合方式能很好的解决这一问题，每台服务器部署一个flume采集日志，传送到一个集中收集日志的flume，再由此flume上传到hdfs、hive、hbase等，进行日志分析。</p>
<h2 id="3-4-Flume企业开发案例"><a href="#3-4-Flume企业开发案例" class="headerlink" title="3.4 Flume企业开发案例"></a>3.4 Flume企业开发案例</h2><h3 id="3-4-1-复制案例"><a href="#3-4-1-复制案例" class="headerlink" title="3.4.1 复制案例"></a>3.4.1 复制案例</h3><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16359420042208.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<ul>
<li>需求描述：<ul>
<li>使用Flume1监控文件变动，Flume1将变动内容传递给Flume2，</li>
<li>Flume2负责存储到HDFS。同时Flume1将变动内容传递给Flume3，</li>
<li>Flume3负责输出到控制台</li>
</ul>
</li>
<li>功能实现<ol>
<li>创建Flume1 的核心配置文件 a1.conf（<font color ='red' >channel selector指定replicating</font>） 具体配置信息如下： <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Named(agent,source,channel,sink)</span></span><br><span class="line"><span class="attr">a1.sources</span> = r1</span><br><span class="line"><span class="attr">a1.channels</span> = c1 c2</span><br><span class="line"><span class="attr">a1.sinks</span> = k1 k2</span><br><span class="line"><span class="comment">#Source</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = TAILDIR</span><br><span class="line"><span class="attr">a1.sources.r1.filegroups</span> = f1 f2</span><br><span class="line"><span class="attr">a1.sources.r1.filegroups.f1</span> = /opt/module/flume-<span class="number">1.9</span>.<span class="number">0</span>/jobs/taildir/.*file.*</span><br><span class="line"><span class="attr">a1.sources.r1.filegroups.f2</span> = /opt/module/flume-<span class="number">1.9</span>.<span class="number">0</span>/jobs/taildir/.*log.*</span><br><span class="line"><span class="attr">a1.sources.r1.positionFile</span> = /opt/module/flume-<span class="number">1.9</span>.<span class="number">0</span>/jobs/taildir/position/position.json</span><br><span class="line"></span><br><span class="line"><span class="comment">#channel selector</span></span><br><span class="line"><span class="attr">a1.sources.r1.selector.type</span> = replicating</span><br><span class="line"></span><br><span class="line"><span class="comment">#Channel</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="number">10000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.channels.c2.type</span> = memory</span><br><span class="line"><span class="attr">a1.channels.c2.capacity</span> = <span class="number">10000</span></span><br><span class="line"><span class="attr">a1.channels.c2.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"><span class="comment">#Sink </span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = avro</span><br><span class="line"><span class="attr">a1.sinks.k1.hostname</span> = localhost</span><br><span class="line"><span class="attr">a1.sinks.k1.port</span> = <span class="number">7777</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k2.type</span> = avro</span><br><span class="line"><span class="attr">a1.sinks.k2.hostname</span> = localhost</span><br><span class="line"><span class="attr">a1.sinks.k2.port</span> = <span class="number">8888</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Bind</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = c1 c2</span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = c1</span><br><span class="line"><span class="attr">a1.sinks.k2.channel</span> = c2</span><br></pre></td></tr></table></figure></li>
<li>创建Flume2 的核心配置文件 a2.conf 具体配置信息如下： <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Named(agent,source,channel,sink)</span></span><br><span class="line"><span class="attr">a2.sources</span> = r1</span><br><span class="line"><span class="attr">a2.channels</span> = c1 </span><br><span class="line"><span class="attr">a2.sinks</span> = k1 </span><br><span class="line"></span><br><span class="line"><span class="comment">#Source</span></span><br><span class="line"><span class="attr">a2.sources.r1.type</span> = avro</span><br><span class="line"><span class="attr">a2.sources.r1.bind</span> = localhost</span><br><span class="line"><span class="attr">a2.sources.r1.port</span> = <span class="number">7777</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Channel</span></span><br><span class="line"><span class="attr">a2.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a2.channels.c1.capacity</span> = <span class="number">10000</span></span><br><span class="line"><span class="attr">a2.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Sink </span></span><br><span class="line"><span class="attr">a2.sinks.k1.type</span> = hdfs</span><br><span class="line"><span class="attr">a2.sinks.k1.hdfs.path</span> = hdfs://mycluster/flume/%Y%m%d/%H</span><br><span class="line"><span class="comment">#上传文件的前缀</span></span><br><span class="line"><span class="attr">a2.sinks.k1.hdfs.filePrefix</span> = logs-</span><br><span class="line"><span class="comment">#是否按照时间滚动文件夹</span></span><br><span class="line"><span class="attr">a2.sinks.k1.hdfs.round</span> = <span class="literal">true</span></span><br><span class="line"><span class="comment">#多少时间单位创建一个新的文件夹</span></span><br><span class="line"><span class="attr">a2.sinks.k1.hdfs.roundValue</span> = <span class="number">1</span></span><br><span class="line"><span class="comment">#重新定义时间单位</span></span><br><span class="line"><span class="attr">a2.sinks.k1.hdfs.roundUnit</span> = hour</span><br><span class="line"><span class="comment">#是否使用本地时间戳</span></span><br><span class="line"><span class="attr">a2.sinks.k1.hdfs.useLocalTimeStamp</span> = <span class="literal">true</span></span><br><span class="line"><span class="comment">#积攒多少个Event才flush到HDFS一次</span></span><br><span class="line"><span class="attr">a2.sinks.k1.hdfs.batchSize</span> = <span class="number">100</span></span><br><span class="line"><span class="comment">#设置文件类型，可支持压缩</span></span><br><span class="line"><span class="attr">a2.sinks.k1.hdfs.fileType</span> = DataStream</span><br><span class="line"><span class="comment">#多久生成一个新的文件</span></span><br><span class="line"><span class="attr">a2.sinks.k1.hdfs.rollInterval</span> = <span class="number">60</span></span><br><span class="line"><span class="comment">#设置每个文件的滚动大小</span></span><br><span class="line"><span class="attr">a2.sinks.k1.hdfs.rollSize</span> = <span class="number">134217700</span></span><br><span class="line"><span class="comment">#文件的滚动与Event数量无关</span></span><br><span class="line"><span class="attr">a2.sinks.k1.hdfs.rollCount</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Bind</span></span><br><span class="line"><span class="attr">a2.sources.r1.channels</span> = c1 </span><br><span class="line"><span class="attr">a2.sinks.k1.channel</span> = c1</span><br></pre></td></tr></table></figure></li>
<li>创建Flume3 的核心配置文件 a3.conf 具体配置信息如下： <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Named(agent,source,channel,sink)</span></span><br><span class="line"><span class="attr">a3.sources</span> = r1</span><br><span class="line"><span class="attr">a3.channels</span> = c1 </span><br><span class="line"><span class="attr">a3.sinks</span> = k1 </span><br><span class="line"></span><br><span class="line"><span class="comment">#Source</span></span><br><span class="line"><span class="attr">a3.sources.r1.type</span> = avro</span><br><span class="line"><span class="attr">a3.sources.r1.bind</span> = localhost</span><br><span class="line"><span class="attr">a3.sources.r1.port</span> = <span class="number">8888</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Channel</span></span><br><span class="line"><span class="attr">a3.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a3.channels.c1.capacity</span> = <span class="number">10000</span></span><br><span class="line"><span class="attr">a3.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Sink </span></span><br><span class="line"><span class="attr">a3.sinks.k1.type</span> = logger</span><br><span class="line"></span><br><span class="line"><span class="comment">#Bind</span></span><br><span class="line"><span class="attr">a3.sources.r1.channels</span> = c1 </span><br><span class="line"><span class="attr">a3.sinks.k1.channel</span> = c1</span><br></pre></td></tr></table></figure></li>
<li>分别启动 Flume2和Flume3 然后在启动Flume1 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动Flume2</span></span><br><span class="line">flume-ng agent -c <span class="variable">$FLUME_HOME</span>/conf -f <span class="variable">$FLUME_HOME</span>/<span class="built_in">jobs</span>/replicating/a2.conf -n a2 -Dflume.root.logger=INFO,console</span><br><span class="line"><span class="comment"># 启动Flume3</span></span><br><span class="line">flume-ng agent -c <span class="variable">$FLUME_HOME</span>/conf -f <span class="variable">$FLUME_HOME</span>/<span class="built_in">jobs</span>/replicating/a3.conf -n a3 -Dflume.root.logger=INFO,console</span><br><span class="line"><span class="comment"># 启动Flume1</span></span><br><span class="line">flume-ng agent -c <span class="variable">$FLUME_HOME</span>/conf -f <span class="variable">$FLUME_HOME</span>/<span class="built_in">jobs</span>/replicating/a1.conf -n a1 -Dflume.root.logger=INFO,console </span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li>测试效果：往待监控的文件中追加内容，观察hdfs和控制台的变化！ <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#flume1日志</span></span><br><span class="line">2021-11-03 21:05:48,539 (PollableSourceRunner-TaildirSource-r1) [INFO - org.apache.flume.source.taildir.TaildirSource.closeTailFiles(TaildirSource.java:307)] Closed file: /opt/module/flume-1.9.0/<span class="built_in">jobs</span>/taildir/replicating.log, inode: 104723556, pos: 43</span><br><span class="line"></span><br><span class="line"><span class="comment">#flume2日志</span></span><br><span class="line">2021-11-03 21:11:56,526 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.HDFSDataStream.configure(HDFSDataStream.java:57)] Serializer = TEXT, UseRawLocalFileSystem = <span class="literal">false</span></span><br><span class="line">2021-11-03 21:11:56,538 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:246)] Creating hdfs://mycluster/flume/20211103/21/logs-.1635945116527.tmp</span><br><span class="line"></span><br><span class="line"><span class="comment">#flume3日志</span></span><br><span class="line">2021-11-03 21:12:10,471 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 32 30 32 31 E5 B9 B4 20 31 31 E6 9C 88 20 30 33 2021... 11... 03 &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="3-4-2-负载均衡案例"><a href="#3-4-2-负载均衡案例" class="headerlink" title="3.4.2 负载均衡案例"></a>3.4.2 负载均衡案例</h3><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/02qi-ye-an-lifu-zai-jun-hengan-li-shi-li-tu.png?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10" alt="02_企业案例-负载均衡-案例实例图"></li>
</ol>
</li>
<li>需求描述：<ul>
<li>使用Flume1监控端口数据，将监控的数据按照指定规则（轮训、随机） </li>
<li>传递给Flume2和Flume3,最后Flume2和Flume3将数据打印到控制台</li>
</ul>
</li>
<li>功能实现：<ol>
<li>创建Flume1 的核心配置文件 a1.conf（<font color ='red' >processor.type = load_balance processorprocessor.selector = round_robin</font>） 具体配置信息如下： <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Named(agent,source,channel,sink)</span></span><br><span class="line"><span class="attr">a1.sources</span> = r1</span><br><span class="line"><span class="attr">a1.channels</span> = c1</span><br><span class="line"><span class="attr">a1.sinks</span> = k1 k2</span><br><span class="line"></span><br><span class="line"><span class="comment">#Source</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = netcat</span><br><span class="line"><span class="attr">a1.sources.r1.bind</span> = localhost</span><br><span class="line"><span class="attr">a1.sources.r1.port</span> = <span class="number">6666</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Channel</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="number">10000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Sink </span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = avro</span><br><span class="line"><span class="attr">a1.sinks.k1.hostname</span> = localhost</span><br><span class="line"><span class="attr">a1.sinks.k1.port</span> = <span class="number">7777</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k2.type</span> = avro</span><br><span class="line"><span class="attr">a1.sinks.k2.hostname</span> = localhost</span><br><span class="line"><span class="attr">a1.sinks.k2.port</span> = <span class="number">8888</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Sink Processor</span></span><br><span class="line"><span class="attr">a1.sinkgroups</span> = g1</span><br><span class="line"><span class="attr">a1.sinkgroups.g1.sinks</span> = k1 k2</span><br><span class="line"><span class="attr">a1.sinkgroups.g1.processor.type</span> = load_balance</span><br><span class="line"><span class="attr">a1.sinkgroups.g1.processor.selector</span> = round_robin</span><br><span class="line"></span><br><span class="line"><span class="comment">#Bind</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = c1</span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = c1</span><br><span class="line"><span class="attr">a1.sinks.k2.channel</span> = c1</span><br></pre></td></tr></table></figure></li>
<li>创建Flume2 的核心配置文件 a2.conf 具体配置信息如下： <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Named(agent,source,channel,sink)</span></span><br><span class="line"><span class="attr">a2.sources</span> = r1</span><br><span class="line"><span class="attr">a2.channels</span> = c1 </span><br><span class="line"><span class="attr">a2.sinks</span> = k1 </span><br><span class="line"></span><br><span class="line"><span class="comment">#Source</span></span><br><span class="line"><span class="attr">a2.sources.r1.type</span> = avro</span><br><span class="line"><span class="attr">a2.sources.r1.bind</span> = localhost</span><br><span class="line"><span class="attr">a2.sources.r1.port</span> = <span class="number">7777</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Channel</span></span><br><span class="line"><span class="attr">a2.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a2.channels.c1.capacity</span> = <span class="number">10000</span></span><br><span class="line"><span class="attr">a2.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Sink </span></span><br><span class="line"><span class="attr">a2.sinks.k1.type</span> = logger</span><br><span class="line"></span><br><span class="line"><span class="comment">#Bind</span></span><br><span class="line"><span class="attr">a2.sources.r1.channels</span> = c1 </span><br><span class="line"><span class="attr">a2.sinks.k1.channel</span> = c1</span><br></pre></td></tr></table></figure></li>
<li>创建Flume3 的核心配置文件 a3.conf 具体配置信息如下： <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Named(agent,source,channel,sink)</span></span><br><span class="line"><span class="attr">a3.sources</span> = r1</span><br><span class="line"><span class="attr">a3.channels</span> = c1 </span><br><span class="line"><span class="attr">a3.sinks</span> = k1 </span><br><span class="line"></span><br><span class="line"><span class="comment">#Source</span></span><br><span class="line"><span class="attr">a3.sources.r1.type</span> = avro</span><br><span class="line"><span class="attr">a3.sources.r1.bind</span> = localhost</span><br><span class="line"><span class="attr">a3.sources.r1.port</span> = <span class="number">8888</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Channel</span></span><br><span class="line"><span class="attr">a3.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a3.channels.c1.capacity</span> = <span class="number">10000</span></span><br><span class="line"><span class="attr">a3.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Sink </span></span><br><span class="line"><span class="attr">a3.sinks.k1.type</span> = logger</span><br><span class="line"></span><br><span class="line"><span class="comment">#Bind</span></span><br><span class="line"><span class="attr">a3.sources.r1.channels</span> = c1 </span><br><span class="line"><span class="attr">a3.sinks.k1.channel</span> = c1</span><br></pre></td></tr></table></figure></li>
<li>分别启动 Flume2和Flume3 然后在启动Flume1 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动Flume2</span></span><br><span class="line">flume-ng agent -c <span class="variable">$FLUME_HOME</span>/conf -f <span class="variable">$FLUME_HOME</span>/<span class="built_in">jobs</span>/loadbalnace/a2.conf -n a2 -Dflume.root.logger=INFO,console</span><br><span class="line"><span class="comment"># 启动Flume3</span></span><br><span class="line">flume-ng agent -c <span class="variable">$FLUME_HOME</span>/conf -f <span class="variable">$FLUME_HOME</span>/<span class="built_in">jobs</span>/loadbalnace/a3.conf -n a3 -Dflume.root.logger=INFO,console</span><br><span class="line"><span class="comment"># 启动Flume1</span></span><br><span class="line">flume-ng agent -c <span class="variable">$FLUME_HOME</span>/conf -f <span class="variable">$FLUME_HOME</span>/<span class="built_in">jobs</span>/loadbalnace/a1.conf -n a1 -Dflume.root.logger=INFO,console </span><br></pre></td></tr></table></figure></li>
<li>测试效果：启动nc客户端 发消息，Flume1负责监听nc发来消息，然后以负载均衡的方式发送给Flume2和Flume3 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#发送TCP消息到flume1</span></span><br><span class="line">[atguigu@hadoop001 loadbalnace]$ nc localhost 6666</span><br><span class="line">a</span><br><span class="line">OK</span><br><span class="line">b</span><br><span class="line">OK</span><br><span class="line">c</span><br><span class="line">OK</span><br><span class="line">d</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line"><span class="comment"># flume2日志    </span></span><br><span class="line">2021-11-03 21:23:39,584 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 61                                              a &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># flume3日志    </span></span><br><span class="line">2021-11-03 21:23:42,237 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 62                                              b &#125;</span><br><span class="line">2021-11-03 21:23:42,237 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 63                                              c &#125;</span><br><span class="line">2021-11-03 21:23:42,237 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 64                                              d &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ul>
<h3 id="3-4-3-故障转移案例"><a href="#3-4-3-故障转移案例" class="headerlink" title="3.4.3 故障转移案例"></a>3.4.3 故障转移案例</h3><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/03qi-ye-an-ligu-zhang-zhuan-yian-li-shi-li-tu.png?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10" alt="03企业案例-故障转移-案例实例图"></p>
<ul>
<li><p>需求描述：</p>
<ul>
<li>使用Flume1监控端口数据，将监控到的数据按照故障转移的方式</li>
<li>传递给Flume2或者Flume3, Flume2或者Flume3将数据打印控制台</li>
</ul>
</li>
<li><p>功能实现：</p>
<ol>
<li>创建Flume1 的核心配置文件 a1.conf 具体配置信息如下：  <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Named(agent,source,channel,sink)</span></span><br><span class="line"><span class="attr">a1.sources</span> = r1</span><br><span class="line"><span class="attr">a1.channels</span> = c1</span><br><span class="line"><span class="attr">a1.sinks</span> = k1 k2 </span><br><span class="line"><span class="comment">#Source</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = netcat</span><br><span class="line"><span class="attr">a1.sources.r1.bind</span> = localhost</span><br><span class="line"><span class="attr">a1.sources.r1.port</span> = <span class="number">6666</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Channel</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="number">10000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Sink </span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = avro</span><br><span class="line"><span class="attr">a1.sinks.k1.hostname</span> = localhost</span><br><span class="line"><span class="attr">a1.sinks.k1.port</span> = <span class="number">7777</span></span><br><span class="line"></span><br><span class="line"><span class="attr">a1.sinks.k2.type</span> = avro</span><br><span class="line"><span class="attr">a1.sinks.k2.hostname</span> = localhost</span><br><span class="line"><span class="attr">a1.sinks.k2.port</span> = <span class="number">8888</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Sink Processor</span></span><br><span class="line"><span class="attr">a1.sinkgroups</span> = g1</span><br><span class="line"><span class="attr">a1.sinkgroups.g1.sinks</span> = k1 k2</span><br><span class="line"><span class="attr">a1.sinkgroups.g1.processor.type</span> = failover</span><br><span class="line"><span class="attr">a1.sinkgroups.g1.processor.priority.k1</span> = <span class="number">5</span></span><br><span class="line"><span class="attr">a1.sinkgroups.g1.processor.priority.k2</span> = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Bind</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = c1</span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = c1</span><br><span class="line"><span class="attr">a1.sinks.k2.channel</span> = c1   </span><br></pre></td></tr></table></figure></li>
<li>创建Flume2 的核心配置文件 a2.conf 具体配置信息如下： <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Named(agent,source,channel,sink)</span></span><br><span class="line"><span class="attr">a2.sources</span> = r1</span><br><span class="line"><span class="attr">a2.channels</span> = c1 </span><br><span class="line"><span class="attr">a2.sinks</span> = k1 </span><br><span class="line"></span><br><span class="line"><span class="comment">#Source</span></span><br><span class="line"><span class="attr">a2.sources.r1.type</span> = avro</span><br><span class="line"><span class="attr">a2.sources.r1.bind</span> = localhost</span><br><span class="line"><span class="attr">a2.sources.r1.port</span> = <span class="number">7777</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Channel</span></span><br><span class="line"><span class="attr">a2.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a2.channels.c1.capacity</span> = <span class="number">10000</span></span><br><span class="line"><span class="attr">a2.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Sink </span></span><br><span class="line"><span class="attr">a2.sinks.k1.type</span> = logger</span><br><span class="line"></span><br><span class="line"><span class="comment">#Bind</span></span><br><span class="line"><span class="attr">a2.sources.r1.channels</span> = c1 </span><br><span class="line"><span class="attr">a2.sinks.k1.channel</span> = c1</span><br></pre></td></tr></table></figure></li>
<li>创建Flume3 的核心配置文件 a3.conf 具体配置信息如下： <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Named(agent,source,channel,sink)</span></span><br><span class="line"><span class="attr">a3.sources</span> = r1</span><br><span class="line"><span class="attr">a3.channels</span> = c1 </span><br><span class="line"><span class="attr">a3.sinks</span> = k1 </span><br><span class="line"><span class="comment">#Source</span></span><br><span class="line"><span class="attr">a3.sources.r1.type</span> = avro</span><br><span class="line"><span class="attr">a3.sources.r1.bind</span> = localhost</span><br><span class="line"><span class="attr">a3.sources.r1.port</span> = <span class="number">8888</span></span><br><span class="line"><span class="comment">#Channel</span></span><br><span class="line"><span class="attr">a3.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a3.channels.c1.capacity</span> = <span class="number">10000</span></span><br><span class="line"><span class="attr">a3.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"><span class="comment">#Sink </span></span><br><span class="line"><span class="attr">a3.sinks.k1.type</span> = logger</span><br><span class="line"><span class="comment">#Bind</span></span><br><span class="line"><span class="attr">a3.sources.r1.channels</span> = c1 </span><br><span class="line"><span class="attr">a3.sinks.k1.channel</span> = c1</span><br></pre></td></tr></table></figure></li>
<li>分别启动 Flume2和Flume3 然后在启动Flume1 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动Flume2</span></span><br><span class="line">flume-ng agent -c <span class="variable">$FLUME_HOME</span>/conf -f <span class="variable">$FLUME_HOME</span>/<span class="built_in">jobs</span>/failover/a2.conf -n a2 -Dflume.root.logger=INFO,console</span><br><span class="line"><span class="comment"># 启动Flume3</span></span><br><span class="line">flume-ng agent -c <span class="variable">$FLUME_HOME</span>/conf -f <span class="variable">$FLUME_HOME</span>/<span class="built_in">jobs</span>/failover/a3.conf -n a3 -Dflume.root.logger=INFO,console</span><br><span class="line"><span class="comment"># 启动Flume1</span></span><br><span class="line">flume-ng agent -c <span class="variable">$FLUME_HOME</span>/conf -f <span class="variable">$FLUME_HOME</span>/<span class="built_in">jobs</span>/failover/a1.conf -n a1 -Dflume.root.logger=INFO,console </span><br></pre></td></tr></table></figure></li>
<li>启动nc客户端，发送消息，Flume1或者Flume2监听到消息打印到控制台，然后在模拟退出一台Flume 再发消息，查看结果。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 failover]$ nc localhost 6666</span><br><span class="line">a</span><br><span class="line">OK</span><br><span class="line">b</span><br><span class="line">OK</span><br><span class="line">c</span><br><span class="line">OK</span><br><span class="line">d</span><br><span class="line">OK</span><br><span class="line"><span class="comment"># 查看flume2收到消息</span></span><br><span class="line"><span class="comment"># 停掉flume2继续发送消息</span></span><br><span class="line">1</span><br><span class="line">OK</span><br><span class="line">2</span><br><span class="line">OK</span><br><span class="line">3</span><br><span class="line">OK</span><br><span class="line">4</span><br><span class="line">OK</span><br><span class="line"><span class="comment"># 查看flume3收到消息，故障转移完成</span></span><br><span class="line"><span class="comment"># 重新启动flume2继续发送消息</span></span><br><span class="line">q</span><br><span class="line">OK</span><br><span class="line">w</span><br><span class="line">OK</span><br><span class="line">e</span><br><span class="line">OK</span><br><span class="line">r</span><br><span class="line">OK</span><br><span class="line"><span class="comment"># 查看flume2收到消息</span></span><br></pre></td></tr></table></figure></li>
<li>注意事项：模拟a3 故障后，a1会将数据发送给a2,但是如果把a3重新启动后，不会在第一时间将a3作为Active的sink,而是<br>遵循一个默认的规避原则，从2秒开始，a3故障一次重新启动后就对其规避使用累加上一次的两倍时间，默认30秒是上限。</li>
</ol>
</li>
</ul>
<h3 id="3-4-4-聚合案例"><a href="#3-4-4-聚合案例" class="headerlink" title="3.4.4 聚合案例"></a>3.4.4 聚合案例</h3><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/04qi-ye-an-liju-hean-li-shi-li-tu.png?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10" alt="04_企业案例-聚合-案例实例图"></p>
<ul>
<li>需求描述：<ul>
<li>使用Flume1（hadoop102）监听端口数据，Flume2（hadoop103）监控追加文件的数据，</li>
<li>然后Flume1和Flume2将结果传递给Flume3,最后由Flume3将结果打印到控制台</li>
</ul>
</li>
<li>实现功能：<ol>
<li>准备工作<ul>
<li>将Flume软件发送给hadoop002和hadoop003</li>
<li>同步环境变量</li>
</ul>
</li>
<li>在hadoop102创建Flume1 的核心配置文件 a1.conf 具体配置信息如下（监控端口数据） <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Named(agent,source,channel,sink)</span></span><br><span class="line"><span class="attr">a1.sources</span> = r1</span><br><span class="line"><span class="attr">a1.channels</span> = c1</span><br><span class="line"><span class="attr">a1.sinks</span> = k1</span><br><span class="line"></span><br><span class="line"><span class="comment">#Source</span></span><br><span class="line"><span class="attr">a1.sources.r1.type</span> = netcat</span><br><span class="line"><span class="attr">a1.sources.r1.bind</span> = localhost</span><br><span class="line"><span class="attr">a1.sources.r1.port</span> = <span class="number">6666</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Channel</span></span><br><span class="line"><span class="attr">a1.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a1.channels.c1.capacity</span> = <span class="number">10000</span></span><br><span class="line"><span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Sink </span></span><br><span class="line"><span class="attr">a1.sinks.k1.type</span> = avro</span><br><span class="line"><span class="attr">a1.sinks.k1.hostname</span> = hadoop003</span><br><span class="line"><span class="attr">a1.sinks.k1.port</span> = <span class="number">8888</span></span><br><span class="line"><span class="comment">#Bind</span></span><br><span class="line"><span class="attr">a1.sources.r1.channels</span> = c1</span><br><span class="line"><span class="attr">a1.sinks.k1.channel</span> = c1</span><br></pre></td></tr></table></figure></li>
<li>在hadoop103创建Flume2 的核心配置文件 a2.conf 具体配置信息如下（监控文件追加的数据）  <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Named(agent,source,channel,sink)</span></span><br><span class="line"><span class="attr">a2.sources</span> = r1</span><br><span class="line"><span class="attr">a2.channels</span> = c1</span><br><span class="line"><span class="attr">a2.sinks</span> = k1</span><br><span class="line"></span><br><span class="line"><span class="comment">#Source</span></span><br><span class="line"><span class="attr">a2.sources.r1.type</span> = TAILDIR</span><br><span class="line"><span class="attr">a2.sources.r1.filegroups</span> = f1 f2</span><br><span class="line"><span class="attr">a2.sources.r1.filegroups.f1</span> = /opt/module/flume-<span class="number">1.9</span>.<span class="number">0</span>/jobs/taildir/.*file.*</span><br><span class="line"><span class="attr">a2.sources.r1.filegroups.f2</span> = /opt/module/flume-<span class="number">1.9</span>.<span class="number">0</span>/jobs/taildir/.*log.*</span><br><span class="line"><span class="attr">a2.sources.r1.positionFile</span> = /opt/module/flume-<span class="number">1.9</span>.<span class="number">0</span>/jobs/taildir/position/position.json</span><br><span class="line"></span><br><span class="line"><span class="comment">#Channel</span></span><br><span class="line"><span class="attr">a2.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a2.channels.c1.capacity</span> = <span class="number">10000</span></span><br><span class="line"><span class="attr">a2.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Sink </span></span><br><span class="line"><span class="attr">a2.sinks.k1.type</span> = avro</span><br><span class="line"><span class="attr">a2.sinks.k1.hostname</span> = hadoop003</span><br><span class="line"><span class="attr">a2.sinks.k1.port</span> = <span class="number">8888</span></span><br><span class="line"><span class="comment">#Bind</span></span><br><span class="line"><span class="attr">a2.sources.r1.channels</span> = c1</span><br><span class="line"><span class="attr">a2.sinks.k1.channel</span> = c1</span><br></pre></td></tr></table></figure></li>
<li>在hadoop104创建Flume3 的核心配置文件 a2.conf 具体配置信息如下(监控 Flume1和Flume2发送的数据) <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Named(agent,source,channel,sink)</span></span><br><span class="line"><span class="attr">a3.sources</span> = r1</span><br><span class="line"><span class="attr">a3.channels</span> = c1</span><br><span class="line"><span class="attr">a3.sinks</span> = k1</span><br><span class="line"></span><br><span class="line"><span class="comment">#Source</span></span><br><span class="line"><span class="attr">a3.sources.r1.type</span> = avro</span><br><span class="line"><span class="attr">a3.sources.r1.bind</span> = <span class="number">0.0</span>.<span class="number">0.0</span></span><br><span class="line"><span class="attr">a3.sources.r1.port</span> = <span class="number">8888</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Channel</span></span><br><span class="line"><span class="attr">a3.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a3.channels.c1.capacity</span> = <span class="number">10000</span></span><br><span class="line"><span class="attr">a3.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Sink </span></span><br><span class="line"><span class="attr">a3.sinks.k1.type</span> = logger</span><br><span class="line"><span class="comment">#Bind</span></span><br><span class="line"><span class="attr">a3.sources.r1.channels</span> = c1</span><br><span class="line"><span class="attr">a3.sinks.k1.channel</span> = c1</span><br></pre></td></tr></table></figure></li>
<li>分别启动 Flume3 然后再启动Flume1和Flume2 <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动Flume3（hadoop104）</span></span><br><span class="line">flume-ng agent -c $FLUME_HOME/conf -f $FLUME_HOME/jobs/aggre/a3.conf -n a3 <span class="attr">-Dflume.root.logger</span>=INFO,console</span><br><span class="line"><span class="comment"># 启动Flume2（hadoop103）</span></span><br><span class="line">flume-ng agent -c $FLUME_HOME/conf -f $FLUME_HOME/jobs/aggre/a2.conf -n a2 <span class="attr">-Dflume.root.logger</span>=INFO,console</span><br><span class="line"><span class="comment"># 启动Flume1 (hadoop102)</span></span><br><span class="line">flume-ng agent -c $FLUME_HOME/conf -f $FLUME_HOME/jobs/aggre/a1.conf -n a1 <span class="attr">-Dflume.root.logger</span>=INFO,console </span><br></pre></td></tr></table></figure></li>
<li>启动nc客户端，发送消息到Flume1，在Flume2监听监听的文件追加内容，查看flume3结果。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 发送数据到Flume1</span></span><br><span class="line">[atguigu@hadoop002 ~]$ nc hadoop001 6666</span><br><span class="line">1</span><br><span class="line">OK</span><br><span class="line">2</span><br><span class="line">OK</span><br><span class="line">3</span><br><span class="line">OK</span><br><span class="line">4</span><br><span class="line">OK</span><br><span class="line"><span class="comment"># 追加内容到Flume2监控的文件       </span></span><br><span class="line">[atguigu@hadoop002 ~]$ <span class="built_in">echo</span> `date`</span><br><span class="line">2021年 11月 03日 星期三 22:00:52 CST</span><br><span class="line">[atguigu@hadoop002 ~]$ <span class="built_in">echo</span> `date` &gt;&gt; /opt/module/flume-1.9.0/<span class="built_in">jobs</span>/taildir/aggre.log</span><br><span class="line">[atguigu@hadoop002 ~]$ <span class="built_in">echo</span> `date` &gt;&gt; /opt/module/flume-1.9.0/<span class="built_in">jobs</span>/taildir/aggre.log</span><br><span class="line">[atguigu@hadoop002 ~]$ <span class="built_in">echo</span> `date` &gt;&gt; /opt/module/flume-1.9.0/<span class="built_in">jobs</span>/taildir/aggre.log</span><br><span class="line"></span><br><span class="line"><span class="comment">#Flume3日志</span></span><br><span class="line">2021-11-03 22:00:23,272 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 31                                              1 &#125;</span><br><span class="line">2021-11-03 22:00:23,272 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 32                                              2 &#125;</span><br><span class="line">2021-11-03 22:00:23,272 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 33                                              3 &#125;</span><br><span class="line">2021-11-03 22:00:23,272 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 34                                              4 &#125;</span><br><span class="line">2021-11-03 22:01:33,278 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 32 30 32 31 E5 B9 B4 20 31 31 E6 9C 88 20 30 33 2021... 11... 03 &#125;</span><br><span class="line">2021-11-03 22:01:37,280 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 32 30 32 31 E5 B9 B4 20 31 31 E6 9C 88 20 30 33 2021... 11... 03 &#125;</span><br><span class="line">2021-11-03 22:01:37,280 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;&#125; body: 32 30 32 31 E5 B9 B4 20 31 31 E6 9C 88 20 30 33 2021... 11... 03 &#125;</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ul>
<h3 id="3-4-4-多路-拦截器-案例"><a href="#3-4-4-多路-拦截器-案例" class="headerlink" title="3.4.4 多路+拦截器 案例"></a>3.4.4 多路+拦截器 案例</h3><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16359488070644.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"> </p>
<ul>
<li>需求描述：<ul>
<li>使用Flume1监控端口数据 </li>
<li>添加拦截器功能 对数据进行分类拦截，然后通过多路组件将不同规则的数据分别放入不同的channel中 </li>
<li>每一个channel对应一个 avro sink  </li>
<li>flume2 flume3 flume4 分别根据规则接受来自不同 avro sink 的数据，最后打印控制台</li>
</ul>
</li>
<li>完成功能：<ol>
<li>a1.conf (Flume1) <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">    <span class="comment">#Named(agent,source,channel,sink)</span></span><br><span class="line">    <span class="attr">a1.sources</span> = r1</span><br><span class="line">    <span class="attr">a1.channels</span> = c1 c2 c3 </span><br><span class="line">    <span class="attr">a1.sinks</span> = k1 k2 k3</span><br><span class="line">    <span class="comment">#Source</span></span><br><span class="line">    <span class="attr">a1.sources.r1.type</span> = netcat</span><br><span class="line">    <span class="attr">a1.sources.r1.bind</span> = <span class="number">0.0</span>.<span class="number">0.0</span></span><br><span class="line">    <span class="attr">a1.sources.r1.port</span> = <span class="number">6666</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#channel selector</span></span><br><span class="line">    <span class="attr">a1.sources.r1.selector.type</span> = multiplexing</span><br><span class="line">    <span class="attr">a1.sources.r1.selector.header</span> = title</span><br><span class="line">    <span class="attr">a1.sources.r1.selector.mapping.at</span> = c1</span><br><span class="line">    <span class="attr">a1.sources.r1.selector.mapping.sg</span> = c2</span><br><span class="line">    <span class="attr">a1.sources.r1.selector.mapping.ot</span> = c3</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#interceptor</span></span><br><span class="line">    <span class="attr">a1.sources.r1.interceptors</span> = i1</span><br><span class="line">    <span class="attr">a1.sources.r1.interceptors.i1.type</span> = com.atguigu.flume.interecptor.MyInterceptor<span class="variable">$MyBuilder</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#Channel</span></span><br><span class="line">    <span class="attr">a1.channels.c1.type</span> = memory</span><br><span class="line">    <span class="attr">a1.channels.c1.capacity</span> = <span class="number">10000</span></span><br><span class="line">    <span class="attr">a1.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line">    </span><br><span class="line">    <span class="attr">a1.channels.c2.type</span> = memory</span><br><span class="line">    <span class="attr">a1.channels.c2.capacity</span> = <span class="number">10000</span></span><br><span class="line">    <span class="attr">a1.channels.c2.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line">    </span><br><span class="line">    <span class="attr">a1.channels.c3.type</span> = memory</span><br><span class="line">    <span class="attr">a1.channels.c3.capacity</span> = <span class="number">10000</span></span><br><span class="line">    <span class="attr">a1.channels.c3.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#Sink </span></span><br><span class="line">    <span class="attr">a1.sinks.k1.type</span> = avro</span><br><span class="line">    <span class="attr">a1.sinks.k1.hostname</span> = <span class="number">0.0</span>.<span class="number">0.0</span></span><br><span class="line">    <span class="attr">a1.sinks.k1.port</span> = <span class="number">7777</span></span><br><span class="line">    </span><br><span class="line">    <span class="attr">a1.sinks.k2.type</span> = avro</span><br><span class="line">    <span class="attr">a1.sinks.k2.hostname</span> = <span class="number">0.0</span>.<span class="number">0.0</span></span><br><span class="line">    <span class="attr">a1.sinks.k2.port</span> = <span class="number">8888</span></span><br><span class="line">    </span><br><span class="line">    <span class="attr">a1.sinks.k3.type</span> = avro</span><br><span class="line">    <span class="attr">a1.sinks.k3.hostname</span> = <span class="number">0.0</span>.<span class="number">0.0</span></span><br><span class="line">    <span class="attr">a1.sinks.k3.port</span> = <span class="number">9999</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#Bind</span></span><br><span class="line">    <span class="attr">a1.sources.r1.channels</span> = c1 c2 c3 </span><br><span class="line">    <span class="attr">a1.sinks.k1.channel</span> = c1</span><br><span class="line">    <span class="attr">a1.sinks.k2.channel</span> = c2</span><br><span class="line">    <span class="attr">a1.sinks.k3.channel</span> = c3</span><br><span class="line">    ```   </span><br><span class="line">1. a2.conf (Flume2)</span><br><span class="line">    ```ini</span><br><span class="line">    <span class="comment">#Named(agent,source,channel,sink)</span></span><br><span class="line">    <span class="attr">a2.sources</span> = r1</span><br><span class="line">    <span class="attr">a2.channels</span> = c1 </span><br><span class="line">    <span class="attr">a2.sinks</span> = k1 </span><br><span class="line">    </span><br><span class="line">    <span class="comment">#Source</span></span><br><span class="line">    <span class="attr">a2.sources.r1.type</span> = avro</span><br><span class="line">    <span class="attr">a2.sources.r1.bind</span> = <span class="number">0.0</span>.<span class="number">0.0</span></span><br><span class="line">    <span class="attr">a2.sources.r1.port</span> = <span class="number">7777</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#Channel</span></span><br><span class="line">    <span class="attr">a2.channels.c1.type</span> = memory</span><br><span class="line">    <span class="attr">a2.channels.c1.capacity</span> = <span class="number">10000</span></span><br><span class="line">    <span class="attr">a2.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#Sink </span></span><br><span class="line">    <span class="attr">a2.sinks.k1.type</span> = logger</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#Bind</span></span><br><span class="line">    <span class="attr">a2.sources.r1.channels</span> = c1 </span><br><span class="line">    <span class="attr">a2.sinks.k1.channel</span> = c1</span><br></pre></td></tr></table></figure></li>
<li>a3.conf (Flume3) <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Named(agent,source,channel,sink)</span></span><br><span class="line"><span class="attr">a3.sources</span> = r1</span><br><span class="line"><span class="attr">a3.channels</span> = c1 </span><br><span class="line"><span class="attr">a3.sinks</span> = k1 </span><br><span class="line"></span><br><span class="line"><span class="comment">#Source</span></span><br><span class="line"><span class="attr">a3.sources.r1.type</span> = avro</span><br><span class="line"><span class="attr">a3.sources.r1.bind</span> = <span class="number">0.0</span>.<span class="number">0.0</span></span><br><span class="line"><span class="attr">a3.sources.r1.port</span> = <span class="number">8888</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Channel</span></span><br><span class="line"><span class="attr">a3.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a3.channels.c1.capacity</span> = <span class="number">10000</span></span><br><span class="line"><span class="attr">a3.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Sink </span></span><br><span class="line"><span class="attr">a3.sinks.k1.type</span> = logger</span><br><span class="line"></span><br><span class="line"><span class="comment">#Bind</span></span><br><span class="line"><span class="attr">a3.sources.r1.channels</span> = c1 </span><br><span class="line"><span class="attr">a3.sinks.k1.channel</span> = c1</span><br></pre></td></tr></table></figure></li>
<li>a4.conf  (Flume4) <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Named(agent,source,channel,sink)</span></span><br><span class="line"><span class="attr">a4.sources</span> = r1</span><br><span class="line"><span class="attr">a4.channels</span> = c1 </span><br><span class="line"><span class="attr">a4.sinks</span> = k1 </span><br><span class="line"></span><br><span class="line"><span class="comment">#Source</span></span><br><span class="line"><span class="attr">a4.sources.r1.type</span> = avro</span><br><span class="line"><span class="attr">a4.sources.r1.bind</span> = <span class="number">0.0</span>.<span class="number">0.0</span></span><br><span class="line"><span class="attr">a4.sources.r1.port</span> = <span class="number">9999</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Channel</span></span><br><span class="line"><span class="attr">a4.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">a4.channels.c1.capacity</span> = <span class="number">10000</span></span><br><span class="line"><span class="attr">a4.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Sink </span></span><br><span class="line"><span class="attr">a4.sinks.k1.type</span> = logger</span><br><span class="line"></span><br><span class="line"><span class="comment">#Bind</span></span><br><span class="line"><span class="attr">a4.sources.r1.channels</span> = c1 </span><br><span class="line"><span class="attr">a4.sinks.k1.channel</span> = c1</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ul>
<ol start="5">
<li>测试：<ol>
<li>将自定义拦截器打包上传至Linux 中 <ul>
<li>注意：修改Flume1的 a1.conf 文件中的  <figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">a1.sources.r1.interceptors.i1.type</span> = com.atguigu.flume.interceptor.DataTypeInterceptor<span class="variable">$MyBuilder</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>执行以下运行命令<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">flume-ng agent -c <span class="variable">$FLUME_HOME</span>/conf -f <span class="variable">$FLUME_HOME</span>/<span class="built_in">jobs</span>/multiplexing/a1.conf -n a1 -Dflume.root.logger=INFO,console</span><br><span class="line"></span><br><span class="line">flume-ng agent -c <span class="variable">$FLUME_HOME</span>/conf -f <span class="variable">$FLUME_HOME</span>/<span class="built_in">jobs</span>/multiplexing/a2.conf -n a2 -Dflume.root.logger=INFO,console</span><br><span class="line"></span><br><span class="line">flume-ng agent -c <span class="variable">$FLUME_HOME</span>/conf -f <span class="variable">$FLUME_HOME</span>/<span class="built_in">jobs</span>/multiplexing/a3.conf -n a3 -Dflume.root.logger=INFO,console</span><br><span class="line"></span><br><span class="line">flume-ng agent -c <span class="variable">$FLUME_HOME</span>/conf -f <span class="variable">$FLUME_HOME</span>/<span class="built_in">jobs</span>/multiplexing/a4.conf -n a4 -Dflume.root.logger=INFO,console</span><br><span class="line"> </span><br></pre></td></tr></table></figure></li>
<li>nc模拟发送消息<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[atguigu@hadoop001 ~]$ nc hadoop001 6666</span><br><span class="line"><span class="comment"># 发送atguiguaaa路由到flueme2</span></span><br><span class="line">atguiguaaa</span><br><span class="line">OK</span><br><span class="line"><span class="comment"># 发送shangguiguasdf路由到flueme3</span></span><br><span class="line">shangguiguasdf</span><br><span class="line">OK</span><br><span class="line"><span class="comment"># 发送asdasdf路由到flueme4</span></span><br><span class="line">asdasdf</span><br><span class="line">OK</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li>自定义拦截器 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyInterceptor</span> <span class="keyword">implements</span> <span class="title">Interceptor</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 初始方法</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initialize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 拦截器的核心逻辑方法</span></span><br><span class="line"><span class="comment">     * 需求：</span></span><br><span class="line"><span class="comment">     *    区别采集数据的内容，包含 atguigu 或者 包含 sangguigu 再或者包含 其他</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> event</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Event <span class="title">intercept</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 获取event中的header</span></span><br><span class="line">        Map&lt;String, String&gt; headers = event.getHeaders();</span><br><span class="line">        <span class="comment">// 获取event 中 body</span></span><br><span class="line">        <span class="keyword">byte</span>[] body = event.getBody();</span><br><span class="line">        String data = <span class="keyword">new</span> String(body);</span><br><span class="line">        <span class="keyword">if</span>(data.contains(<span class="string">&quot;atguigu&quot;</span>))&#123;</span><br><span class="line">            headers.put(<span class="string">&quot;title&quot;</span>,<span class="string">&quot;at&quot;</span>);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(data.contains(<span class="string">&quot;shangguigu&quot;</span>))&#123;</span><br><span class="line">            headers.put(<span class="string">&quot;title&quot;</span>,<span class="string">&quot;sg&quot;</span>);</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            headers.put(<span class="string">&quot;title&quot;</span>,<span class="string">&quot;ot&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> event;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 拦截器的核心逻辑方法，当来的多个event会循环调用 上面的 intercept</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> list</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Event&gt; <span class="title">intercept</span><span class="params">(List&lt;Event&gt; list)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (Event event : list) &#123;</span><br><span class="line">            intercept(event);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> list;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 收尾工作</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 声明一个内部类</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyBuilder</span> <span class="keyword">implements</span> <span class="title">Builder</span></span>&#123;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 实例化当前拦截器对象</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Interceptor <span class="title">build</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> MyInterceptor();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 读取flume的配置信息</span></span><br><span class="line"><span class="comment">         * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Context context)</span> </span>&#123;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="第4章-企业真实面试题"><a href="#第4章-企业真实面试题" class="headerlink" title="第4章 企业真实面试题"></a>第4章 企业真实面试题</h1><h2 id="4-1-你是如何实现Flume数据传输的监控的"><a href="#4-1-你是如何实现Flume数据传输的监控的" class="headerlink" title="4.1 你是如何实现Flume数据传输的监控的"></a>4.1 你是如何实现Flume数据传输的监控的</h2><ul>
<li>第三方框架Prometheus+Grafana 或者Ganglia<h2 id="4-2-Flume的Source，Sink，Channel的作用？你们Source是什么类型？"><a href="#4-2-Flume的Source，Sink，Channel的作用？你们Source是什么类型？" class="headerlink" title="4.2 Flume的Source，Sink，Channel的作用？你们Source是什么类型？"></a>4.2 Flume的Source，Sink，Channel的作用？你们Source是什么类型？</h2></li>
<li>作用<ol>
<li>Source组件是专门用来收集数据的，可以处理各种类型、各种格式的日志数据，包括avro、thrift、exec、jms、spooling directory、netcat、sequence generator、syslog、http、legacy</li>
<li>Channel组件对采集到的数据进行缓存，可以存放在Memory或File中。</li>
<li>Sink组件是用于把数据发送到目的地的组件，目的地包括Hdfs、Logger、avro、thrift、ipc、file、Hbase、solr、自定义。</li>
</ol>
</li>
<li>采用的Source类型为：<ul>
<li>监控后台日志：exec</li>
<li>监控后台产生日志的端口：netcat</li>
</ul>
</li>
</ul>
<h2 id="4-3-Flume的Channel-Selectors"><a href="#4-3-Flume的Channel-Selectors" class="headerlink" title="4.3 Flume的Channel Selectors"></a>4.3 Flume的Channel Selectors</h2><p><img src="https://anzhen-tech-imges.oss-cn-beijing.aliyuncs.com/2021/11/07/16360037790920.jpg?x-oss-process=image/auto-orient,1/quality,q_90/watermark,text_YW56aGVuLnRlY2g,size_40,x_10,y_10"></p>
<h2 id="4-4-Flume参数调优"><a href="#4-4-Flume参数调优" class="headerlink" title="4.4 Flume参数调优"></a>4.4 Flume参数调优</h2><ol>
<li>Source<ul>
<li>增加Source个数（使用Tair Dir Source时可增加FileGroups个数）可以增大Source的读取数据的能力。例如：当某一个目录产生的文件过多时需要将这个文件目录拆分成多个文件目录，同时配置好多个Source 以保证Source有足够的能力获取到新产生的数据。</li>
<li>batchSize参数决定Source一次批量运输到Channel的event条数，适当调大这个参数可以提高Source搬运Event到Channel时的性能。</li>
</ul>
</li>
<li>Channel <ul>
<li>type：选择memory时Channel的性能最好，但是如果Flume进程意外挂掉可能会丢失数据。type选择file时Channel的容错性更好，但是性能上会比memory channel差。使用file Channel时dataDirs配置多个不同盘下的目录可以提高性能。</li>
<li>Capacity：参数决定Channel可容纳最大的event条数。transactionCapacity 参数决定每次Source往channel里面写的最大event条数和每次Sink从channel里面读的最大event条数。transactionCapacity需要大于Source和Sink的batchSize参数。</li>
</ul>
</li>
<li>Sink <ul>
<li>增加Sink的个数可以增加Sink消费event的能力。Sink也不是越多越好够用就行，过多的Sink会占用系统资源，造成系统资源不必要的浪费。</li>
<li>batchSize参数决定Sink一次批量从Channel读取的event条数，适当调大这个参数可以提高Sink从Channel搬出event的性能。</li>
</ul>
</li>
</ol>
<h2 id="4-5-Flume的事务机制"><a href="#4-5-Flume的事务机制" class="headerlink" title="4.5 Flume的事务机制"></a>4.5 Flume的事务机制</h2><p>Flume的事务机制（类似数据库的事务机制）：Flume使用两个独立的事务分别负责从Soucrce到Channel，以及从Channel到Sink的事件传递。比如spooling directory source 为文件的每一行创建一个事件，一旦事务中所有的事件全部传递到Channel且提交成功，那么Soucrce就将该文件标记为完成。同理，事务以类似的方式处理从Channel到Sink的传递过程，如果因为某种原因使得事件无法记录，那么事务将会回滚。且所有的事件都会保持到Channel中，等待重新传递。</p>
<h2 id="4-6-Flume采集数据会丢失吗"><a href="#4-6-Flume采集数据会丢失吗" class="headerlink" title="4.6 Flume采集数据会丢失吗?"></a>4.6 Flume采集数据会丢失吗?</h2><p>根据Flume的架构原理，Flume是不可能丢失数据的，其内部有完善的事务机制，Source到Channel是事务性的，Channel到Sink是事务性的，因此这两个环节不会出现数据的丢失，唯一可能丢失数据的情况是Channel采用memoryChannel，agent宕机导致数据丢失，或者Channel存储数据已满，导致Source不再写入，未写入的数据丢失。<br>Flume不会丢失数据，但是有可能造成数据的重复，例如数据已经成功由Sink发出，但是没有接收到响应，Sink会再次发送数据，此时可能会导致数据的重复。次发送数据，此时可能会导致数据的重复。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Flume/" rel="tag">Flume</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/" rel="tag">数据采集</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-hello-world"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2021/11/06/hello-world/"
    >Hello World</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2021/11/06/hello-world/" class="article-date">
  <time datetime="2021-11-06T10:56:35.808Z" itemprop="datePublished">2021-11-06</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-about-me"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2019/11/07/about-me/"
    >about_me</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2019/11/07/about-me/" class="article-date">
  <time datetime="2019-11-07T03:06:44.000Z" itemprop="datePublished">2019-11-07</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>Hello world</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
    </footer>
  </div>

    
 
    
</article>

    
  </article>
  

  
  <nav class="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/2/">上一页</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span>
  </nav>
  
</section>
</div>

      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2019-2021
        <i class="ri-heart-fill heart_icon"></i> Anzhen
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>访问人数:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>浏览次数:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src=''></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="anzhen.tech"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/HDFS">HDFS</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Yarn">Yarn</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/MR">MR</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Hive">Hive</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86">数据采集</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/HBase">HBase</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Kafka">Kafka</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Spark">Spark</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Flink">Flink</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/MySQL">MySQL</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/Java">Java</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/interview">面试宝典</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/2019/11/07/about-me">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="搜索">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.png">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.png">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->
 <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
  var ayerConfig = {
    mathjax: true,
  };
</script>

<!-- Katex -->

<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    <div id="music">
    
    
    
    <iframe frameborder="no" border="1" marginwidth="0" marginheight="0" width="200" height="52"
        src="//music.163.com/outchain/player?type=2&id=318916815&auto=1&height=32"></iframe>
</div>

<style>
    #music {
        position: fixed;
        right: 15px;
        bottom: 0;
        z-index: 998;
    }
</style>
    
    

  </div>
</body>

</html>